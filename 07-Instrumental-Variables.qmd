# Instrumental Variables Regression {#ivr}

The current version of this chapter is basically completly taken from the free online book: [www.econometrics-with-r.org](www.econometrics-with-r.org) [@Hanck_et_al_2019]

\bigskip

Regression models may suffer from problems like omitted variables, measurement errors and simultaneous causality. If so, the error term $\eps_i$ is correlated with the regressor, $X_{ik}$ say, and the corresponding coefficient  of interest, $\beta_k$, is estimated \textbf{inconsistently}. If one is lucky, one can add, for instance, the omitted variables to the regression to mitigate the risk of biased estimations (\say{omitted variables bias}).  However, if omitted variables cannot be measured or are not available for other reasons, multiple regression cannot solve the problem. The same issue arises if there is \say{simultaneous causality}.  When causality runs from $X$ to $Y$ \emph{and vice versa} (e.g. if $Y=\text{Demanded quantity of a good}$ and $X=\text{Price of this good}$), there will be an estimation bias that cannot be corrected for by multiple regression.

A general technique for obtaining a consistent estimator of the coefficient of interest is instrumental variables (IV) regression. In this chapter we focus on the IV regression tool called *two-stage least squares* (TSLS). The first sections briefly recap the general mechanics and assumptions of IV regression and show how to perform TSLS estimation using \textsf{R}. Next, IV regression is used for estimating the elasticity of the demand for cigarettes --- a classical example where multiple regression fails to do the job because of simultaneous causality. 


## The IV Estimator with a Single Regressor and a Single Instrument {#TIVEWASRAASI}

Consider the simple regression model 
\begin{align}
  Y_i = \beta_1 + \beta_2 X_i + \eps_i \ \ , \ \ i=1,\dots,n, \label{eq:srm12}
\end{align}
where the error term $\eps_i$ is correlated with the regressor $X_i$ ($X$ is the called \say{\textit{endogenous}}). In this case Assumption 2 is violated, that is, strict exogeneity and orthogonality between $X_i$ and $\eps_i$ do not hold. Therefore, OLS estimation (also maximum likelihood and methods of moments estimation) is inconsistent for the true $\beta_2$. In the most simple case, IV regression uses a single instrumental variable $Z_i$ to obtain a consistent estimator for $\beta_2$.


\paragraph*{Conditions for valid instruments:} $Z_i$ must satisfy two conditions to be a valid instrument:
\begin{enumerate}
\item \textbf{Instrument relevance condition:}\\
$X_i$ and its instrument $Z_i$ \emph{must be} correlated: $\rho_{Z,X} \neq 0$.
\item \textbf{Instrument exogeneity condition:}\\
$E(\eps_i|Z_i)=0$. As a consequence: The instrument $Z_i$ \emph{must not be} correlated with the error term $\eps_i$: $\rho_{Z,\eps} = 0$.
\end{enumerate}

### The Two-Stage Least Squares Estimator 

As can be guessed from its name, TSLS proceeds in two stages. In the first stage, the variation in the endogenous regressor $X_i$ is decomposed into a \say{problem-free} component that is explained by the (exogenous) instrument $Z_i$ and a problematic component that is correlated with the error $\eps_i$. The second stage uses the problem-free component of the variation in $X_i$ to estimate $\beta_2$.

The first stage regression model is 
$$
X_i = \pi_0 + \pi_1 Z_i + \nu_i,
$$ 
where $\pi_0 + \pi_1 Z_i$ is the component of $X_i$ that is explained by $Z_i$ while $\nu_i$ is the component (an error term) that cannot be explained by $Z_i$ and exhibits correlation with $\eps_i$. 

Using the OLS estimates $\widehat{\pi}_0$ and $\widehat{\pi}_1$ we obtain predicted values $\widehat{X}_i=\hat\pi_0+\hat\pi_1 Z_i,\ i=1,\dots,n$. If $Z_i$ is a valid instrument, the $\widehat{X}_i$ are problem-free in the sense that $\widehat{X}_i$ is \textbf{exogenous} in a regression of $Y_i$ on $\widehat{X}_i$ which is done in the second stage regression. The second stage produces $\widehat{\beta}_1^{TSLS}$ and $\widehat{\beta}_2^{TSLS}$, the TSLS estimates of $\beta_1$ and $\beta_2$.

For the case of a single instrument one can show that the TSLS estimator of $\beta_2$ is
\begin{align}
\widehat{\beta}_2^{TSLS} = \frac{s_{ZY}}{s_{ZX}} = \frac{\frac{1}{n-1}\sum_{i=1}^n(Y_i - \overline{Y})(Z_i - \overline{Z})}{\frac{1}{n-1}\sum_{i=1}^n(X_i - \overline{X})(Z_i - \overline{Z})}, \label{eq:simpletsls}
\end{align}
which is nothing but the ratio of the sample covariance between $Z_i$ and $Y_i$ to the sample covariance between $Z_i$ and $X_i$.

The estimator in \eqref{eq:simpletsls} is a consistent estimator for $\beta_2$ in \eqref{eq:srm12} under the assumption that $Z_i$ is a valid instrument. The CLT implies that the distribution of $\widehat{\beta}_2^{TSLS}$ can be approximated by a normal distribution if the sample size $n$ is large. This allows us to use $t$-statistics, $F$-statistics, confidence intervals, etc. 


### Application: Demand For Cigarettes (1/2)

The relation between the demand for and the price of commodities is a simple yet widespread problem in economics. Health economics is concerned with the study of how health-affecting behavior of individuals is influenced by the health-care system and regulation policy. Probably the most prominent example in public policy debates is smoking as it is related to many illnesses and negative externalities.

It is plausible that cigarette consumption can be reduced by taxing cigarettes more heavily. The question is by *how much* taxes must be increased to reach a certain reduction in cigarette consumption. Economists use elasticities to answer this kind of question. Since the price elasticity for the demand of cigarettes is unknown, it must be estimated. A simple OLS regression of log quantity on log price cannot be used to estimate the effect of interest since there is simultaneous causality between demand and supply. Instead, IV regression can be used.

We use the data set `CigarettesSW` which comes with the package `AER`. It is a panel data set that contains observations on cigarette consumption and several economic indicators for all 48 continental federal states of the U.S. from 1985 to 1995.  In the following, however, we consider data for the cross section of states in 1995 only -- that is, we transform the panel data to a cross-sectional data set. We start by loading the package, attaching the data set. An overview about summary statistics for each of the variables is returned by `summary(CigarettesSW)`.  Use `?CigarettesSW` for a detailed description of the variables.

```{r, warning=FALSE, message=FALSE, eval=FALSE, purl=FALSE}
# load the data set and get an overview
library("AER")
data("CigarettesSW")
summary(CigarettesSW)
```

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=FALSE, purl=TRUE}
# load the data set and get an overview
library("AER")
data("CigarettesSW")
summary(CigarettesSW)
```


We are interested in estimating $\beta_2$ in 
\begin{align}
  \log(Q_i^{cigarettes}) = \beta_1 + \beta_2 \log(P_i^{cigarettes}) + \eps_i, \label{eq:cigstsls}
\end{align}
where $Q_i^{cigarettes}$ is the number of cigarette packs per capita sold and $P_i^{cigarettes}$ is the after-tax average real price per pack of cigarettes in state $i=1,\dots,n=48$. 

The instrumental variable we are going to use for instrumenting the endogenous regressor $\log(P_i^{cigarettes})$ is $SalesTax$, the portion of taxes on cigarettes arising from the general sales tax. $SalesTax$ is measured in dollars per pack. The idea is that:
\begin{enumerate}
\item $SalesTax$ is a relevant instrument as it is included in the after-tax average price per pack. 
\item Also, it is plausible that $SalesTax$ is exogenous since the sales tax does not influence quantity sold directly but indirectly through the price.
\end{enumerate}

In the following, we perform some transformations in order to obtain deflated cross section data for the year 1995. We also compute the sample correlation between the sales tax and price per pack. The sample correlation is a consistent estimator of the population correlation. The estimate of approximately $0.614$ indicates that $SalesTax$ and $P_i^{cigarettes}$ exhibit positive correlation which meets our expectations: higher sales taxes lead to higher prices. However, a correlation analysis like this is not sufficient for checking whether the instrument is relevant.  We will later come back to the issue of checking whether an instrument is relevant and exogenous; see Chapter \@ref(civ). 
```{r}
# compute real per capita prices
CigarettesSW$rprice <- with(CigarettesSW, price / cpi)

#  compute the sales tax
CigarettesSW$salestax <- with(CigarettesSW, (taxs - tax) / cpi)

# check the correlation between sales tax and price
cor(CigarettesSW$salestax, CigarettesSW$price)

# generate a subset for the year 1995
c1995 <- subset(CigarettesSW, year == "1995")
```

The first stage regression is 
$$
\log(P_i^{cigarettes}) = \pi_0 + \pi_1 SalesTax_i + \nu_i.
$$ 
We estimate this model in \textsf{R} using `lm()`. In the second stage we run a regression of $\log(Q_i^{cigarettes})$ on $\widehat{\log(P_i^{cigarettes})}$ to obtain $\widehat{\beta}_1^{TSLS}$ and $\widehat{\beta}_2^{TSLS}$.

```{r}
# perform the first stage regression
cig_s1 <- lm(log(rprice) ~ salestax, data = c1995)

coeftest(cig_s1, vcov = vcovHC, type = "HC1")
```

The first stage regression is 
$$
\widehat{\log(P_i^{cigarettes})} = \underset{(0.03)}{4.62} + \underset{(0.005)}{0.031}\; SalesTax_i
$$ 
which predicts the relation between sales tax price per cigarettes to be positive. How much of the observed variation in $\log(P^{cigarettes})$ is explained by the instrument $SalesTax$? This can be answered by looking at the regression's $R^2$ which states that about $47\%$ of the variation in after tax prices is explained by the variation of the sales tax across states.

```{r}
# inspect the R^2 of the first stage regression
summary(cig_s1)$r.squared
```

We next store $\widehat{\log(P_i^{cigarettes})}$, the fitted values obtained by the first stage regression `cig_s1`, in the variable `lcigp_pred`.

```{r}
# store the predicted values
lcigp_pred <- cig_s1$fitted.values
```

Next, we run the second stage regression which gives us the TSLS estimates we seek.

```{r}
# run the stage 2 regression
cig_s2 <- lm(log(c1995$packs) ~ lcigp_pred)
coeftest(cig_s2, vcov = vcovHC, type = "HC1")
```

Thus estimating the model \eqref{eq:cigstsls} using TSLS yields 
\begin{align}
  \widehat{\log(Q_i^{cigarettes})} = \underset{(1.60)}{9.72} - \underset{(0.33)}{1.08} \widehat{\log(P_i^{cigarettes})}, \label{eq:ecigstsls}
\end{align}

The function `ivreg()` from the package `AER` carries out TSLS procedure automatically. It is used similarly as `lm()`. Instruments can be added to the usual specification of the regression formula using a vertical bar separating the model equation from the instruments. Thus, for the regression at hand the correct formula is `log(packs) ~ log(rprice) | salestax`.

```{r}
# perform TSLS using 'ivreg()'
cig_ivreg <- ivreg(log(packs) ~ log(rprice) | salestax, 
                   data = c1995)

coeftest(cig_ivreg, vcov = vcovHC, type = "HC1")
```

We find that the coefficient estimates coincide for both approaches.


\paragraph*{Two Notes on the Computation of TSLS Standard Errors:}
\begin{enumerate}
\item We have demonstrated that running the individual regressions for each stage of TSLS using `lm()` leads to the same coefficient estimates as when using `ivreg()`. However, the standard errors reported for the second-stage regression, e.g., by `coeftest()` or `summary()`, are \textbf{invalid}: neither adjusts for using predictions from the first-stage regression as regressors in the second-stage regression. Fortunately, `ivreg()` performs the necessary adjustment automatically. This is another advantage over manual step-by-step estimation which we have done above for demonstrating the mechanics of the procedure.
\item Just like in multiple regression it is important to compute heteroskedasticity-robust standard errors as we have done above using `vcovHC()`.
\end{enumerate}

The TSLS estimate for $\beta_2$ in \eqref{eq:ecigstsls} suggests that an increase in cigarette prices by one percent reduces cigarette consumption by roughly $1.08$ percentage points, which is fairly elastic. However, we should keep in mind that this estimate might not be trustworthy even though we used IV estimation: there still might be a bias due to \textbf{omitted variables}. Thus a multiple IV regression approach is needed to reduce the risk of omitted variable biases.


## The General IV Regression Model {#TGIVRM}

The simple IV regression model is easily extended to a multiple regression model which we refer to as the general IV regression model. In this model we distinguish between four types of variables: the dependent variable, included exogenous variables, included endogenous variables and instrumental variables:
\begin{align}
  Y_i = \beta_1 + \beta_2 X_{2i} + \dots + \beta_K X_{Ki} + \beta_{K+1} W_{1i} + \dots + \beta_{K+r} W_{ri} + \eps_i, \label{eq:givmodel}
\end{align}
with $i=1,\dots,n$ is the general instrumental variables regression model where
\begin{itemize}
\item $Y_i$ is the dependent variable
\item $\beta_1,\dots,\beta_{K+r}$ are $K+r$ unknown regression coefficients
\item $X_{2i},\dots,X_{Ki}$ are $K-1$ endogenous regressors 
\item $W_{1i},\dots,W_{ri}$ are $r$ exogenous regressors which are uncorrelated with $\eps_i$
\item $\eps_i$ is the error term
\item $Z_{1i},\dots,Z_{mi}$ are $m$ instrumental variables
\end{itemize}
\vspace{0.5cm}

The coefficients are \textbf{overidentified} if $m>(K-1)$. If $m<(K-1)$, the coefficients are \textbf{underidentified} and when $m=(K-1)$ they are \textbf{exactly identified}. For estimation of the IV regression model we require exact identification or overidentification.


Estimating regression models with TSLS using multiple instruments by means of `ivreg()` is straightforward. There are, however, some subtleties in correctly specifying the regression formula. Assume that you want to estimate the model 
$$
Y_i = \beta_1 + \beta_2 X_{2i} + \beta_3 X_{3i} + \beta_4 W_{1i} + \eps_i
$$ 
where $X_{2i}$ and $X_{3i}$ are endogenous regressors that shall be instrumented by $Z_{1i}$, $Z_{2i}$ and $Z_{3i}$, and where $W_{1i}$ is an exogenous regressor. Say the corresponding data is available in a `data.frame` with column names `y`, `x2`, `x3`, `w1`, `z1`, `z2` and `z3`. It might be tempting to specify the argument `formula` in your call of `ivreg()` as `y ~ x2 + x3 + w1 | z1 + z2 + z3` which is, however, \textbf{wrong}. As explained in the documentation of `ivreg()` (see `?ivreg`), it is necessary to list *all* exogenous variables as instruments too, that is joining them by `+`'s on the right of the vertical bar: `y ~ x2 + x3 + w1 | w1 + z1 + z2 + z3`, where `w1` is "instrumenting itself". 


Similarly to the simple IV regression model, the general IV model \eqref{eq:givmodel} can be estimated using the two-stage least squares estimator:

\begin{itemize}
\item \textbf{First-stage regression(s):}\\
Run an OLS regression for each of the endogenous variables ($X_{2i},\dots,X_{Ki}$) on all instrumental variables ($Z_{1i},\dots,Z_{mi}$), all exogenous variables ($W_{1i},\dots,W_{ri}$) \textbf{and an intercept}. Compute the fitted values ($\widehat{X}_{2i},\dots,\widehat{X}_{Ki}$).
\item \textbf{Second-stage regression:}\\
Regress the dependent variable on the predicted values of all endogenous regressors, all exogenous variables and an intercept using OLS. This gives $\widehat{\beta}_{1}^{TSLS},\dots,\widehat{\beta}_{K+r}^{TSLS}$, the TSLS estimates of the model coefficients.
\end{itemize}

In the general IV regression model, the instrument relevance and instrument exogeneity assumptions are equivalent to the case of the simple regression model with a single endogenous regressor and only one instrument. That is, for $Z_{1i},\dots,Z_{mi}$ to be a set of valid instruments, the following two conditions must be fulfilled:
\begin{enumerate}
\item \textbf{Instrument Relevance}\\
If there are $K-1$ endogenous variables, $r$ exogenous variables and $m\geq K-1$ instruments and the $\widehat{X}_{2i}^*,\dots,\widehat{X}_{Ki}^*$ are the predicted values from the $K-1$ population first stage regressions, it must hold that $$(\widehat{X}_{2i}^*,\dots,\widehat{X}_{Ki}^*, W_{1i}, \dots, W_{ri},1)$$ are not perfectly multicollinear, where \say{$1$} denotes the constant regressor (intercept) which equals $1$ for all observations.\\
\textit{Explanations}:  Let's say there is only one endogenous regressor $X_i$. If all the instruments $Z_{1i},\dots,Z_{mi}$ are irrelevant, all the $\widehat{X}^*_i$ are just the mean of $X$ such that there is perfect multicollinearity with the constant intercept $1$.\\
\item \textbf{Instrument Exogeneity}\\
$E(\eps_i|Z_{1i},\dots,Z_{im})=0$. Consequently, all $m$ instruments must be uncorrelated with the error term, 
$$
\rho_{Z_{1},\eps} = 0,\dots,\rho_{Z_{m},\eps} = 0.
$$
\end{enumerate}

One can show that if the IV regression assumptions hold, the TSLS estimator in \eqref{eq:givmodel} is consistent and normally distributed when the sample size $n$ is large. That is, if we have valid instruments, we obtain valid statistical inference using $t$-tests, $F$-tests and confidence intervals for the model coefficients.


### Application: Demand for Cigarettes (2/2)

The estimated elasticity of the demand for cigarettes in \eqref{eq:srm12} is $1.08$. Although \eqref{eq:srm12} was estimated using IV regression it is plausible that this IV estimate is biased. The TSLS estimator is inconsistent for the true $\beta_2$ if the instrument (here: the real sales tax per pack) is invalid, i.e., if the instrument correlates with the error term. This is likely to be the case here since there are economic factors, like state income, which impact the demand for cigarettes and correlate with the sales tax. States with high personal income tend to generate tax revenues by income taxes and less by sales taxes. Consequently, state income should be included in the regression model.
\begin{align}
  \log(Q_i^{cigarettes}) = \beta_1 + \beta_2 \log(P_i^{cigarettes}) + \beta_3 \log(income_i) + \eps_i \label{eq:mcigstsls1}
\end{align}

Before estimating \eqref{eq:mcigstsls1} using `ivreg()` we define $income$ as real per capita income `rincome` and append it to the data set `CigarettesSW`.

```{r}
# add real income to the dataset (cpi: consumer price index)
CigarettesSW$rincome <- with(CigarettesSW, 
                             income / population / cpi)

c1995 <- subset(CigarettesSW, year == "1995")
```

```{r}
# estimate the model
cig_ivreg2 <- ivreg(log(packs) ~ log(rprice) + 
                                 log(rincome) | log(rincome) + 
                    salestax, data = c1995)

coeftest(cig_ivreg2, vcov = vcovHC, type = "HC1")
```

We obtain
\begin{align}
  \widehat{\log(Q_i^{cigarettes})} = \underset{(1.26)}{9.42} - \underset{(0.37)}{1.14} \log(P_i^{cigarettes}) + \underset{(0.31)}{0.21} \log(income_i). \label{eq:emcigstsls2}
\end{align}

In the following we add the cigarette-specific taxes ($cigtax_i$) as a further instrumental variable and estimate again using TSLS.

```{r}
# add cigtax to the data set
CigarettesSW$cigtax <- with(CigarettesSW, tax/cpi)

c1995 <- subset(CigarettesSW, year == "1995")
```

```{r}
# estimate the model
cig_ivreg3 <- ivreg(log(packs) ~ log(rprice) + log(rincome) | 
                    log(rincome) + salestax + cigtax, 
                    data = c1995)

coeftest(cig_ivreg3, vcov = vcovHC, type = "HC1")
```

Using the two instruments $salestax_i$ and $cigtax_i$ we have $m=2$ for one endogenous regressor -- so the coefficient on the endogenous regressor $\log(P_i^{cigarettes})$ is *overidentified*. The TSLS estimate of \eqref{eq:mcigstsls1} is

\begin{align}
\widehat{\log(Q_i^{cigarettes})} = \underset{(0.96)}{9.89} - \underset{(0.25)}{1.28} \log(P_i^{cigarettes}) + \underset{(0.25)}{0.28} \log(income_i). \label{eq:emcigstsls3}
\end{align}

Should we trust the estimates presented in \eqref{eq:emcigstsls2} or rather rely on \eqref{eq:emcigstsls3}? The estimates obtained using both instruments are more precise since in \eqref{eq:emcigstsls3} all standard errors reported are smaller than in \eqref{eq:emcigstsls2}. In fact, the standard error for the estimate of the demand elasticity is only two thirds of the standard error when the sales tax is the only instrument used. This is due to more information being used in estimation \eqref{eq:emcigstsls3}. *If* the instruments are valid, \eqref{eq:emcigstsls3} can be considered more reliable. 

However, without insights regarding the validity of the instruments it is not sensible to make such a statement. This stresses why checking instrument validity is essential. Chapter \@ref(civ) briefly discusses guidelines in checking instrument validity and presents approaches that allow to test for instrument relevance and exogeneity under certain conditions. These are then used in an application to the demand for cigarettes in Chapter \@ref(attdfc).

## Checking Instrument Validity {#civ}

### Instrument Relevance

Instruments that explain little variation in the endogenous regressor $X_i$ are called *weak instruments*. Weak instruments provide little information about the variation in $X_i$ that is exploited by IV regression to estimate the effect of interest: the estimate of the coefficient on the endogenous regressor is estimated inaccurately. Moreover, weak instruments cause the distribution of the estimator to deviate considerably from a normal distribution even in large samples such that the usual methods for obtaining inference about the true coefficient on $X_i$ may produce wrong results. 

\paragraph*{A Rule of Thumb for Checking for Weak Instruments:} Consider the case of a single endogenous regressor $X_i$ and $m$ instruments $Z_{1i},\dots,Z_{mi}$. If the coefficients on all instruments in the population first-stage regression of a TSLS estimation are zero, the instruments do not explain any of the variation in the $X_i$ which clearly violates assumption that instruments must be relevant. Although the latter case is unlikely to be encountered in practice, we should ask ourselves to what extent the assumption of instrument relevance should be fulfilled. While this is hard to answer for general IV regression, in the case of a \textit{single} endogenous regressor $X_i$ one may use \textbf{the following rule of thumb}: Compute the $F$-statistic which corresponds to the hypothesis that the coefficients on $Z_{1i},\dots,Z_{mi}$ are all zero in the first-stage regression. If the $F$-statistic is less than $10$, the instruments are \say{weak} such that the TSLS estimate of the coefficient on $X_i$ is probably biased and no valid statistical inference about its true value can be made. 

This rule of thumb is easily implemented in \textsf{R}. Run the first-stage regression using `lm()` and subsequently compute the heteroskedasticity-robust $F$-statistic by means of `linearHypothesis()`. This is part of the application to the demand for cigarettes discussed in Chapter \@ref(attdfc).


#### If Instruments are Weak {-}

There are two ways to proceed if instruments are weak:

1. Discard the weak instruments and/or find stronger instruments. While the former is only an option if the unknown coefficients remain identified when the weak instruments are discarded, the latter can be very difficult and even may require a redesign of the whole study.

2. Stick with the weak instruments but use methods that improve upon TSLS in this scenario, for example limited information maximum likelihood estimation. (Out of the scope of this course.)

3. Use tests that allow for inferences robust to weak instruments: \textbf{Anderson-Rubin test} 

<!-- \citep{AR1949} -->


### Instrument Validity 

If there is correlation between an instrument and the error term, IV regression is not consistent. The overidentifying restrictions test (also called the $J$-test) is an approach to test the hypothesis that \textbf{additional} instruments are exogenous. For the $J$-test to be applicable there need to be more instruments than endogenous regressors. 

<!-- or \say{Overidentifying Restrictions Test} -->

\paragraph*{The $J$-Statistic (or Sargan-Hansen test)}
Take $\hat{\eps}_i^{TSLS},\ i = 1,\dots,n$, the residuals of the TSLS estimation of the general IV regression model \eqref{eq:givmodel}. Run the OLS regression
\begin{align}
\hat{\eps}_i^{TSLS} =& \delta_0 + \delta_1 Z_{1i} + \dots + \delta_m Z_{mi} + \delta_{m+1} W_{1i} + \dots + \delta_{m+r} W_{ri} + e_i \label{eq:jstatreg}
\end{align}
and test the joint hypothesis 
$$
H_0: \delta_1 = \dots \delta_{m} = 0
$$ 
which states that all instruments are exogenous. This can be done using the corresponding $F$-statistic by computing 
$$
J = m  F.
$$ 
This test is the overidentifying restrictions test and the statistic is called the $J$-statistic with 
$$
J \overset{H_0}{\to}_d \chi^2_{m-(K-1)}\quad\text{as}\quad n\to\infty
$$ 
under the \textbf{assumption of homoskedasticity}. The degrees of freedom $m-(K-1)$ state the degree of overidentification since this is the number of instruments $m$ minus the number of endogenous regressors $K-1$.


It is important to note that the $J$-statistic is only $\chi^2_{m-(K-1)}$ distributed when the error term $\eps_i$ in the regression \@ref(eq:jstatreg) is homoskedastic. A discussion of the heteroskedasticity-robust $J$-statistic is beyond the scope of this chapter. The application in the next section shows how to apply the $J$-test using `linearHypothesis()`.

## Application to the Demand for Cigarettes {#attdfc}

Are the general sales tax and the cigarette-specific tax valid instruments? If not, TSLS is not helpful to estimate the demand elasticity for cigarettes discussed in Chapter \@ref(TGIVRM). As discussed in Chapter \@ref(TIVEWASRAASI), both variables are likely to be relevant but whether they are exogenous is a different question.

One can argue that cigarette-specific taxes could be endogenous because there might be state specific historical factors like economic importance of the tobacco farming and cigarette production industry that lobby for low cigarette specific taxes. Since it is plausible that tobacco growing states have higher rates of smoking than others, this would lead to endogeneity of cigarette specific taxes. If we had data on the size on the tobacco and cigarette industry, we could solve this potential issue by including the information in the regression. Unfortunately, this is not the case.

However, since the role of the tobacco and cigarette industry is a factor that can be assumed to differ across states but not over time we may exploit the panel structure of `CigarettesSW`. Alternatively, a (non-panel) regression using data on *changes*  between two time periods eliminates such state specific and time invariant effects. Next, we consider such changes in variables between 1985 and 1995. That is, we are interested in estimating the *long-run elasticity* of the demand for cigarettes.

The model to be estimated by TSLS using the general sales tax and the cigarette-specific sales tax as instruments hence is
\begin{align}
\begin{split}
  \log(Q_{i,1995}^{cigarettes}) - \log(Q_{i,1985}^{cigarettes}) =
  & \, \beta_1 + \beta_2 \left[\log(P_{i,1995}^{cigarettes}) - \log(P_{i,1985}^{cigarettes}) \right] \\ 
  &+ \beta_3 \left[\log(income_{i,1995}) - \log(income_{i,1985})\right] + \eps_i. \end{split}(\#eq:diffivreg)
\end{align}

We first create differences from 1985 to 1995 for the dependent variable, the regressors and both instruments. 

```{r}
# subset data for year 1985
c1985 <- subset(CigarettesSW, year == "1985")

# define differences in variables
packsdiff <- log(c1995$packs) - log(c1985$packs)

pricediff <- log(c1995$price/c1995$cpi) - log(c1985$price/c1985$cpi)

incomediff <- log(c1995$income/c1995$population/c1995$cpi) -
log(c1985$income/c1985$population/c1985$cpi)

salestaxdiff <- (c1995$taxs - c1995$tax)/c1995$cpi - (c1985$taxs - c1985$tax)/c1985$cpi

cigtaxdiff <- c1995$tax/c1995$cpi - c1985$tax/c1985$cpi
```

We now perform three different IV estimations of \@ref(eq:diffivreg) using `ivreg()`:

1. TSLS using only the difference in the sales taxes between 1985 and 1995 as the instrument.

2. TSLS using only the difference in the cigarette-specific sales taxes 1985 and 1995 as the instrument.  

3. TSLS using both the difference in the sales taxes 1985 and 1995 and the difference in the cigarette-specific sales taxes 1985 and 1995 as instruments.

```{r}
# estimate the three models
cig_ivreg_diff1 <- ivreg(packsdiff ~ pricediff + 
                           incomediff | incomediff + 
                         salestaxdiff)

cig_ivreg_diff2 <- ivreg(packsdiff ~ pricediff + 
                           incomediff | incomediff + 
                         cigtaxdiff)

cig_ivreg_diff3 <- ivreg(packsdiff ~ pricediff + 
                           incomediff | incomediff + 
                         salestaxdiff + cigtaxdiff)
```

As usual we use `coeftest()` in conjunction with `vcovHC()` to obtain robust coefficient summaries for all models.

```{r}
# robust coefficient summary for 1.
coeftest(cig_ivreg_diff1, vcov = vcovHC, type = "HC1")

# robust coefficient summary for 2.
coeftest(cig_ivreg_diff2, vcov = vcovHC, type = "HC1")

# robust coefficient summary for 3.
coeftest(cig_ivreg_diff3, vcov = vcovHC, type = "HC1")
```

We proceed by generating a tabulated summary of the estimation results using `stargazer()`.

```{r, eval = FALSE, echo=TRUE}
library(stargazer)
# gather robust standard errors in a list
rob_se <- list(sqrt(diag(vcovHC(cig_ivreg_diff1, type = "HC1"))),
               sqrt(diag(vcovHC(cig_ivreg_diff2, type = "HC1"))),
               sqrt(diag(vcovHC(cig_ivreg_diff3, type = "HC1"))))

# generate table
stargazer(cig_ivreg_diff1, cig_ivreg_diff2, cig_ivreg_diff3,
  header = FALSE, 
  type = "latex",
  omit.table.layout = "n",
  digits = 3, 
  column.labels = c("IV: salestax", "IV: cigtax", 
                    "IVs: salestax, cigtax"),
  dep.var.labels.include = FALSE,
  dep.var.caption = 
"Dependent Variable: 1985-1995 Difference in Log per Pack Price",
  se = rob_se)
```

<!--html_preserve-->

<!-- ```{r, message=F, warning=F, results='asis', echo=F, purl=F, eval=my_output == "html"} -->
<!-- # gather robust standard errors in a list -->
<!-- rob_se <- list(sqrt(diag(vcovHC(cig_ivreg_diff1, type = "HC1"))), -->
<!--                sqrt(diag(vcovHC(cig_ivreg_diff2, type = "HC1"))), -->
<!--                sqrt(diag(vcovHC(cig_ivreg_diff3, type = "HC1")))) -->

<!-- stargazer(cig_ivreg_diff1, cig_ivreg_diff2,cig_ivreg_diff3, -->
<!--   header = FALSE,  -->
<!--   type = "html", -->
<!--   digits = 3,  -->
<!--   column.labels = c("IV: salestax", "IV: cigtax", "IVs: salestax, cigtax"), -->
<!--   dep.var.labels.include = FALSE, -->
<!--   dep.var.caption = "Dependent variable: 1985-1995 difference in log per pack price", -->
<!--   se = rob_se) -->

<!-- stargazer_html_title("TSLS Estimates of the Long-Term Elasticity of the Demand for Cigarettes using Panel Data", "tslseotlteotdfcupd") -->
<!-- ``` -->

<!--/html_preserve-->

```{r, message=F, warning=F, results='asis', eval=TRUE, echo=FALSE, purl=FALSE}
suppressMessages(library(stargazer))

# gather robust standard errors in a list
rob_se <- list(sqrt(diag(vcovHC(cig_ivreg_diff1, type = "HC1"))),
               sqrt(diag(vcovHC(cig_ivreg_diff2, type = "HC1"))),
               sqrt(diag(vcovHC(cig_ivreg_diff3, type = "HC1"))))

stargazer(cig_ivreg_diff1, cig_ivreg_diff2,cig_ivreg_diff3,
  title = "\\label{tab:tslseotlteotdfcupd} TSLS Estimates of the Long-Term Elasticity of the Demand for Cigarettes using Panel Data",
  header = FALSE, 
  digits = 3,
  type = "latex",
  no.space = T,
  column.sep.width = "0pt",
  omit.table.layout = "n",
  column.labels = c("IV: salestax", "IV: cigtax", "IVs: salestax, cigtax"),
  dep.var.labels.include = FALSE,
  dep.var.caption = "Dep. variable: 1985-95 diff in log price/pack",
  se = rob_se)
```

Table \@ref(tab:tslseotlteotdfcupd) reports negative estimates of the coefficient on `pricediff` that are quite different in magnitude. Which one should we trust? This hinges on the validity of the instruments used. To assess this we compute $F$-statistics for the first-stage regressions of all three models to check instrument relevance. 

```{r}
# first-stage regressions
mod_relevance1 <- lm(pricediff ~ salestaxdiff + incomediff)
mod_relevance2 <- lm(pricediff ~ cigtaxdiff   + incomediff)
mod_relevance3 <- lm(pricediff ~ incomediff   + salestaxdiff + 
                                                cigtaxdiff)
```

```{r}
# check instrument relevance for model (1)
linearHypothesis(mod_relevance1, 
                 "salestaxdiff = 0", 
                 vcov = vcovHC, type = "HC1")
```

```{r}
# check instrument relevance for model (2)
linearHypothesis(mod_relevance2, 
                 "cigtaxdiff = 0", 
                 vcov = vcovHC, type = "HC1")
```

```{r}
# check instrument relevance for model (3)
linearHypothesis(mod_relevance3, 
                 c("salestaxdiff = 0", "cigtaxdiff = 0"), 
                 vcov = vcovHC, type = "HC1")
```

All $F$-statistics are larger than $10$; so, the rule of thumb for detecting weak instruments would suggest that the instruments are not weak.

Next, we also conduct the overidentifying restrictions test for model three which is the only model where the coefficient on the difference in log prices is overidentified ($m=2$, $(K-1)=1$) such that the $J$-statistic can be computed. To do this we take the residuals stored in `cig_ivreg_diff3` and regress them on both instruments and the presumably exogenous regressor `incomediff`. We again use `linearHypothesis()` to test whether the coefficients on both instruments are zero which is necessary for the exogeneity assumption to be fulfilled. Note that with `test = "Chisq"` we obtain a chi-squared distributed test statistic instead of an $F$-statistic.

```{r}
# compute the J-statistic
cig_iv_OR <- lm(residuals(cig_ivreg_diff3) ~ incomediff + 
                                 salestaxdiff + cigtaxdiff)

cig_OR_test <- linearHypothesis(cig_iv_OR, 
                               c("salestaxdiff = 0", 
                                 "cigtaxdiff = 0"), 
                               test = "Chisq")
cig_OR_test
```

**Caution**: In this case the $p$-value reported by `linearHypothesis()` is wrong because the degrees of freedom are set to $2$. This differs from the degree of overidentification ($m-(K-1)=2-(2-1)=1$) so the $J$-statistic is $\chi^2_1$ distributed instead of following a $\chi^2_2$ distribution as assumed defaultly by `linearHypothesis()`. We may compute the correct $p$-value using `pchisq()`. 

```{r}
# compute correct p-value for J-statistic
pchisq(cig_OR_test[2, 5], df = 1, lower.tail = FALSE)
```

Since this value is smaller than $0.05$ we reject the hypothesis that both instruments are exogenous at the level of $5\%$. This means one of the following: 

1. The sales tax is an invalid instrument for the per-pack price. 
2. The cigarettes-specific sales tax is an invalid instrument for the per-pack price.
3. Both instruments are invalid.

One can argue that the assumption of instrument exogeneity is more likely to hold for the general sales tax such that the IV estimate of the long-run elasticity of demand for cigarettes we consider the most trustworthy is $-0.94$, the TSLS estimate obtained using the general sales tax as the only instrument. 

The interpretation of this estimate is that over a 10-year period, an increase in the average price per package by one percent is expected to decrease consumption by about $0.94$ percentage points. This suggests that, in the long run, price increases can reduce cigarette consumption considerably.


