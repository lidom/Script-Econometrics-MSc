<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>maximumlikelihood</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="07-MaximumLikelihood_files/libs/clipboard/clipboard.min.js"></script>
<script src="07-MaximumLikelihood_files/libs/quarto-html/quarto.js"></script>
<script src="07-MaximumLikelihood_files/libs/quarto-html/popper.min.js"></script>
<script src="07-MaximumLikelihood_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="07-MaximumLikelihood_files/libs/quarto-html/anchor.min.js"></script>
<link href="07-MaximumLikelihood_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="07-MaximumLikelihood_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="07-MaximumLikelihood_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="07-MaximumLikelihood_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="07-MaximumLikelihood_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="maximum-likelihood" class="level1">
<h1>Maximum Likelihood</h1>
<section id="likelihood-principle" class="level2">
<h2 class="anchored" data-anchor-id="likelihood-principle">Likelihood Principle</h2>
<p>The basic idea behind maximum likelihood estimation is very simple: find the distribution parameters for which it is most likely that the distribution has generated the data we actually observed. We must therefore be very specific about the process that generated the data. This is a trade off – by imposing a fair amount of structure on the data, we get in return a very desirable estimator. The question always remains, however, whether we have made the right decision about the specific distribution/density function.</p>
</section>
<section id="properties-of-maximum-likelihood-estimators" class="level2">
<h2 class="anchored" data-anchor-id="properties-of-maximum-likelihood-estimators">Properties of Maximum Likelihood Estimators</h2>
Why do we like maximum likelihood as an estimation method? The answer is that: A maximum likelihood estimator <span class="math inline">\(\hat\theta\)</span> of some parameter <span class="math inline">\(\theta\in\mathbb{R}\)</span> is
<p>Thus, we have the right assumptions, maximum likelihood estimators are very appealing.</p>
<p>In the following we will consider the simple example of coin flips. Call <span class="math inline">\(\theta\)</span> the probability that we get a head <span class="math inline">\(\theta=P(\text{Coin}=\texttt{HEAD})\)</span> which implies that the probability that we get a tail is <span class="math inline">\(1-\theta=P(\text{Coin}=\texttt{TAIL})\)</span>. We don’t know the probability <span class="math inline">\(\theta\)</span> and our goal is to estimate it using an i.i.d. sample of size <span class="math inline">\(n\)</span>, i.e.&nbsp;<span class="math inline">\((X_1,\dots,X_n)\)</span> with <span class="math inline">\(X_i\overset{\text{i.i.d}}{\sim}\mathcal{B}(\theta)\)</span> for all <span class="math inline">\(i=1,\dots,n\)</span>. A given realization of this random sample is then <span class="math inline">\((x_1,\dots,x_i,\dots,x_n)\)</span> and consists of <span class="math inline">\(x_i=1\)</span> values for and <span class="math inline">\(x_j=0\)</span> for , <span class="math inline">\(i\neq j=1,\dots,n\)</span>. In total we have <span class="math inline">\(0\leq h\leq n\)</span> many heads and <span class="math inline">\(0\leq n-h\leq n\)</span> many tails.</p>
</section>
<section id="the-log-likelihood-function" class="level2">
<h2 class="anchored" data-anchor-id="the-log-likelihood-function">The (Log-)Likelihood Function</h2>
<p>How do we combine information from <span class="math inline">\(n\)</span> observations to estimate <span class="math inline">\(\theta\)</span>?</p>
<p>If we assume that all of the observations are drawn from same distribution and are independent, then joint probability of observing <span class="math inline">\(h\)</span> heads and <span class="math inline">\(n-h\)</span> tails in the <span class="math inline">\(n\)</span> coin flips that we actually observed, given <span class="math inline">\(\theta\)</span>, is: <span class="math display">\[\begin{align*}
\mathcal{L}(\theta)&amp;= \theta^h(1-\theta)^{n-h}  \\
            &amp;= \prod_{i=1}^n \theta^{x_i}(1-\theta)^{1-x_i}
\end{align*}\]</span> where <span class="math inline">\(x_i=1\)</span> for in <span class="math inline">\(i\)</span>th coin flip and <span class="math inline">\(x_i=0\)</span> for in <span class="math inline">\(i\)</span>th coin flip. The function <span class="math inline">\(\mathcal{L}\)</span> is called the .</p>
<p>In general, when the observations are identically and independently distributed (i.i.d): <span class="math display">\[\begin{equation*}
\mathcal{L}(\theta)=\prod_{i=1}^n f(x_i|\theta)
\end{equation*}\]</span> where <span class="math inline">\(f(x_i | \theta)\)</span> is the density function of the random variable <span class="math inline">\(X_i\)</span> evaluated at the realization <span class="math inline">\(X_i=x_i\)</span>; the parameter <span class="math inline">\(\theta\)</span> denotes the density function parameter(s).</p>
<p>Our goal is to choose a value for <span class="math inline">\(\theta\)</span> such that the value of the likelihood function is at a maximum, i.e.&nbsp;we choose the value of the parameter(s) that maximize the or better the likelihood of observing the data that we actually observed. That is: <span class="math display">\[\begin{equation*}
\hat\theta=\arg\max_\theta \mathcal{L}(\theta).
\end{equation*}\]</span> defines the maximum likelihood (ML) parameter estimator <span class="math inline">\(\hat\theta\)</span>.</p>
<p>Usually it’s easier to work with sums rather than products, so we can apply a monotonic transformation (taking <span class="math inline">\(\ln\)</span>) to the likelihood which yields to the : <span class="math display">\[\begin{equation*}
\ell(\theta)=\ln\mathcal{L}(\theta)=\sum_{i=1}^n \ln f(x_i|\theta).
\end{equation*}\]</span></p>
<p>In our coin flipping example: <span class="math display">\[\begin{equation*}
\ell(\theta)=\sum_{i=1}^n\left( x_i \ln(\theta) + (1-x_i)\ln(1-\theta)\right)
\end{equation*}\]</span></p>
<p>In this case, we can analytically solve for the value of <span class="math inline">\(\theta\)</span> that maximizes the log likelihood (and hence also the likelihood): <span class="math display">\[\begin{align*}
\dfrac{d \ell}{d \theta}&amp;=\sum_{i=1}^n \left(x_i\dfrac{1}{\theta} - (1-x_i)\dfrac{1}{1-\theta}\right)\\
                        &amp;=\dfrac{h}{\theta} - \dfrac{n-h}{1-\theta} \\
\end{align*}\]</span> Setting the above expression to zero and solving gives us our ML estimator (MLE): <span class="math display">\[\begin{equation*}
\hat\theta_{ML}=\dfrac{h}{n}
\end{equation*}\]</span></p>
</section>
<section id="optimization-non-analytical-solutions" class="level2">
<h2 class="anchored" data-anchor-id="optimization-non-analytical-solutions">Optimization: Non-Analytical Solutions</h2>
<p>Usually we are not so fortunate as to have a closed-form analytical solution for the MLE and must rely on the computer to find the maximizing arguments of the (log-)likelihood function. Various methods exist for finding the maximum (or minimum) of a function. (i) start at some value for parameters in the parameter space (i.e., in the space of all possible parameter-values), (ii) search across that space until values of parameters are found that yield a derivative of the log likelihood that is zero (or arbitrarily close to zero).</p>
<section id="newton-raphson-optimization" class="level3">
<h3 class="anchored" data-anchor-id="newton-raphson-optimization">Newton-Raphson Optimization</h3>
<p>One of the most-used methods for optimization is the Newton-Raphson method (or a variant of it). The Newton-Raphson method relies on Taylor-series approximations of the likelihood.</p>
<p>First-order and second-order Taylor-series approximations of a function value <span class="math inline">\(f(\theta+h)\)</span> are using the function value <span class="math inline">\(f(\theta)\)</span> and derivatives of <span class="math inline">\(f\)</span> evaluated at <span class="math inline">\(\theta\)</span>: <span class="math display">\[\begin{align*}
\text{First-order:}\quad &amp;f(\theta+h)\approx f(\theta)+f'(\theta)h \\
\text{Second-order:}\quad&amp;\phantom{f(\theta+h)}\approx f(\theta)+f'(\theta)h + (1/2) f''(\theta)h^2
\end{align*}\]</span> for small values of <span class="math inline">\(h\)</span>.</p>
<p>Suppose we want to find the value of <span class="math inline">\(\theta\)</span> that maximizes a twice-differentiable function <span class="math inline">\(f(\theta)\)</span>.</p>
<p>The Taylor-series approximation gives then <span class="math display">\[\begin{equation*}
f(\theta+h)\approx f(\theta)+f'(\theta)h + (1/2) f''(\theta)h^2
\end{equation*}\]</span> which implies <span class="math display">\[\begin{equation*}
\dfrac{\partial f(\theta+h)}{\partial h} \approx f'(\theta) + f''(\theta)h.
\end{equation*}\]</span></p>
<p>Therefore, the first-order condition for the value of <span class="math inline">\(h\)</span> that maximizes the Taylor-series expansion <span class="math inline">\(f(\theta)+f'(\theta)h + (1/2) f''(\theta)h^2\)</span> is <span class="math display">\[
0=f'(\theta)+f''(\theta)\hat h,
\]</span> giving <span class="math display">\[
\hat h = -\frac{f'(\theta)}{f''(\theta)}.
\]</span><br>
That is, in order to increase the value of <span class="math inline">\(f(\theta)\)</span> one shall substitute <span class="math inline">\(\theta\)</span> by <span class="math display">\[\begin{equation*}
\theta + \hat h = \theta- \dfrac{f'(\theta)}{f''(\theta)}
\end{equation*}\]</span></p>
<p>The Newton Raphson optimization algorithm uses this insight as following. We first must provide a starting value, <span class="math inline">\(s\)</span>, for <span class="math inline">\(\theta_0=s\)</span> and, second, decide on some (small) convergence criterion, <span class="math inline">\(t\)</span>, e.g.&nbsp;<span class="math inline">\(t=10^{-10}\)</span>, for the first derivative. Then the Newton Raphson optimization algorithm is given by: <span class="math display">\[\begin{equation*}
\begin{array}{ll}
\texttt{\textbf{let }} \theta_0=s  &amp;  \\
\texttt{\textbf{let }} i=0                &amp;  \\
\texttt{\textbf{while }}  &amp; | f'(\theta_i) | &gt;t \\
\quad\texttt{\textbf{do}}                 &amp;\left[
                                    \begin{array}{l}\texttt{\textbf{let }} i = i+1 \\
                                    \texttt{\textbf{let }} \theta_i = \theta_{i-1} - \frac{f'(\theta_{i-1})}{f''(\theta_{i-1})} \\
                                    \end{array} \right.\\
\texttt{\textbf{let }}\hat\theta=\theta_i &amp; \\
\texttt{\textbf{return }} (\hat\theta) &amp;  \\
\end{array}
\end{equation*}\]</span></p>
<p>For problems that are globally concave, the starting value <span class="math inline">\(s\)</span> doesn’t matter. For more complex problems, however, the Newton-Raphson algorithm can get stuck into a local maximum. In such cases, it is usually a good idea to try multiple starting values.</p>
<p>Let’s return to our earlier coin-flipping example, with only one head <span class="math inline">\(h=1\)</span> for a sample size of <span class="math inline">\(n=5\)</span>. We already know that <span class="math inline">\(\hat\theta_{ML}=\frac{h}{n}=\frac{1}{5}=0.2\)</span>, but let’s apply the Newton-Raphson Algorithm. Recall that <span class="math display">\[\begin{align*}
\dfrac{d \ell}{d \theta}&amp;=\dfrac{h}{\theta} - \dfrac{n-h}{1-\theta} \\
\dfrac{d^2 \ell}{d \theta^2} &amp;= -\dfrac{h}{\theta^2} - \dfrac{n-h}{(1-\theta)^2}
\end{align*}\]</span> We have <span class="math inline">\(h=1\)</span> and <span class="math inline">\(n=5\)</span>. Choosing <span class="math inline">\(t=10^{-10}\)</span> as our convergence criterion and <span class="math inline">\(\theta_0=0.4\)</span> as the starting value, allows us to run the algorithm which gives us the results shown in Table <span class="math inline">\(\ref{tab:NR}\)</span>.</p>
</section>
</section>
<section id="ols-estimation-as-ml-estimation" class="level2">
<h2 class="anchored" data-anchor-id="ols-estimation-as-ml-estimation">OLS-Estimation as ML-Estimation</h2>
<p>Now let’s return to our linear model <span class="math display">\[\begin{equation*}
Y=X\beta + \eps
\end{equation*}\]</span> To apply ML-estimation, we must make a distributional assumption about <span class="math inline">\(\eps\)</span> such as, for instance: <span class="math display">\[\begin{equation*}
\eps \sim \mathcal{N}(0, \sigma^2 I_n)
\end{equation*}\]</span> That’s Assumption 4<span class="math inline">\(^\ast\)</span> from Chapter 4; we could have chosen also another distributional assumption for <span class="math inline">\(\eps\)</span> here, but we would need to specify it correctly. That is, we are imposing here much more structure on the data than needed with the OLS estimator (in the context of large sample inference). <!-- \begin{itemize} --> <!-- \item The $\eps$'s are jointly normally distributed. --> <!-- \item The $\eps$'s are independent of one another. --> <!-- \item The $\eps$'s are identically distributed, i.e. homoskedastic. --> <!-- \end{itemize} --></p>
<p>The multivariate density for <span class="math inline">\(\eps=(\eps_1,\dots,\eps_n)'\)</span> is then <span class="math display">\[\begin{equation*}
f(\eps)=\dfrac{1}{(2\pi \sigma^2)^{n/2}} e^{-(1/2\sigma^2)(\eps'\eps)}.
\end{equation*}\]</span> Noting that <span class="math inline">\(\eps=Y-X\beta\)</span>, we get the log likelihood <span class="math display">\[\begin{align*}
\ell(\beta,\sigma^2)&amp; =-\dfrac{n}{2} \ln(2\pi) - \dfrac{n}{2}\ln(\sigma^2) - \dfrac{1}{2 \sigma^2}(Y-X\beta)'(Y-X\beta)
\end{align*}\]</span> with <span class="math inline">\(K\)</span> unknown parameters <span class="math inline">\(\beta=(\beta_1,\dots,\beta_K)'\)</span> and <span class="math inline">\(\sigma^2\)</span> (scalar).</p>
<p>Taking derivatives gives <span class="math display">\[\begin{align*}
\dfrac{\partial \ell}{\partial \beta}    &amp;= - \dfrac{1}{\sigma^2}(-X'Y + X'X\beta) \\
\dfrac{\partial \ell}{\partial \sigma^2}
%&amp;= -\dfrac{n}{2\sigma^2}+ \dfrac{1}{2\sigma^4}(Y-X\beta)'(Y-X\beta)
&amp;=-\frac{n}{2 \sigma^{2}}+\left[\frac{1}{2}(Y-X\beta)'(Y-X\beta)\right]\frac{1}{\left(\sigma^{2}\right)^{2}} \\
%&amp;=\frac{1}{2 \sigma^{2}}\left[\frac{1}{\sigma^{2}} (Y-X\beta)'(Y-X\beta)-n\right]
\end{align*}\]</span> So, we have <span class="math inline">\(K+1\)</span> equations and <span class="math inline">\(K+1\)</span> unknowns. Setting equal to zero and solving gives <span class="math display">\[\begin{align*}
\hat\beta_{ML}&amp;=(X'X)^{-1}X'Y\\
s_{ML}^2&amp;=\dfrac{1}{n}(Y-X\hat\beta_{ML})'(Y-X\hat\beta_{ML})=\dfrac{1}{n}\sum_i^n \hat\eps_i^2
\end{align*}\]</span> Thus, the MLE of the linear model, <span class="math inline">\(\hat\beta_{ML}\)</span>, is the same as the OLS estimator, <span class="math inline">\(\hat\beta\)</span>. Moreover, since the ML estimator <span class="math inline">\(\hat\beta_{ML}\)</span> is here equivalent to the OLS estimator (same formula, same mean, same variance) we can use the whole inference machinery (<span class="math inline">\(t\)</span>-test, <span class="math inline">\(F\)</span>-test, confidence intervals) from the last chapters.</p>
<p>As it is needed for the next chapter, we also give here the second derivatives of the log-likelihood function <span class="math inline">\(L\)</span> as well as the expressions of minus one times the mean of the second derivatives of the log-likelihood function <span class="math inline">\(L\)</span>: <span class="math display">\[\begin{align*}
\dfrac{\partial^2 \ell}{\partial \beta\partial \beta}&amp;= - \dfrac{1}{\sigma^2}(X'X)\\
\Rightarrow\quad (-1)\cdot E\left(\dfrac{\partial^2 \ell}{\partial \beta\partial \beta}\right)&amp;= \dfrac{1}{\sigma^2}E(X'X)\\
\end{align*}\]</span> <span class="math display">\[\begin{align*}
\dfrac{\partial^2 \ell}{\partial \sigma^2\partial \sigma^2}
&amp;=\frac{n}{2 \left(\sigma^{2}\right)^2}-\left[(Y-X\beta)'(Y-X\beta)\right]\frac{1}{\left(\sigma^{2}\right)^{3}} \\
&amp;=\frac{n}{2\sigma^{4}}-\frac{\sum_{i=1}^n\eps_i^2}{\sigma^{6}} \\
\quad\Rightarrow\quad (-1)\cdot  E\left(\dfrac{\partial^2 \ell}{\partial \sigma^2\partial \sigma^2} \right)
&amp;=-\frac{n}{2\sigma^{4}}+\frac{E\left[\sum_{i=1}^n\eps_i^2\right]}{\sigma^{6}} \\
&amp;=-\frac{n}{2\sigma^{4}}+\frac{n\sigma^2}{\sigma^{6}}
=\frac{n}{2\sigma^{4}}\\
\end{align*}\]</span> <span class="math display">\[\begin{align*}
\dfrac{\partial^2 \ell}{\partial \beta \partial \sigma^2}=\dfrac{\partial^2 L}{\partial \sigma^2 \partial \beta}&amp;= -\frac{X'(Y-X\beta)}{\sigma^4}=\frac{X'\eps}{\sigma^4}\\
\quad\Rightarrow\quad (-1)\cdot  E\left(\dfrac{\partial^2 L}{\partial \sigma^2 \partial \beta}\right)&amp;=\frac{E(X'\eps)}{\sigma^4}=\frac{E[E(X'\eps|X)]}{\sigma^4}\\
             &amp;=\frac{E[X'E(\eps|X)]}{\sigma^4}=0
\end{align*}\]</span></p>
</section>
<section id="variance-of-ml-estimators-hatbeta_ml-and-s2_ml" class="level2">
<h2 class="anchored" data-anchor-id="variance-of-ml-estimators-hatbeta_ml-and-s2_ml">Variance of ML-Estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}\)</span></h2>
<p>The variance of an MLE is given by the inverse of the Fisher information matrix. The Fisher information matrix is defined as minus one times the expected value matrix of second derivatives of the log-likelihood function. For the OLS case, the Fisher information matrix is <span class="math display">\[\begin{equation*}
\mathcal{I}\left(\begin{array}{cc}\beta \\ \sigma^2\end{array}\right)=
\left[\begin{array}{cc}
\frac{1}{\sigma^2}E(X'X) &amp; 0 \\
0 &amp; \frac{n}{2\sigma^4}
\end{array}\right]
=
\left[\begin{array}{cc}
\frac{n}{\sigma^2}\Sigma_{X'X} &amp; 0 \\
0 &amp; \ \frac{n}{2\sigma^4}
\end{array}\right],
\end{equation*}\]</span> where we used that <span class="math inline">\(E(X'X)=E(\sum_{i=1}^nX_iX_i')=nE(X_iX_i')=n\Sigma_{X'X}\)</span>. The upper left element of the Fisher information matrix is easily shown, but the derivation of the lower right element is rather tedious. So, taking the inverse of the Fisher information matrix gives the variance-covariance matrix of the estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s_{ML}^2\)</span> <span class="math display">\[\begin{equation*}
\V\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)=
\left[\begin{array}{cc}
\frac{\sigma^2}{n}\Sigma_{X'X}^{-1} &amp; 0 \\
0 &amp; \ \frac{2\sigma^4}{n}
\end{array}\right],
\end{equation*}\]</span> Given this result, it is easy to see that <span class="math inline">\(\V(\hat\beta_{ML}) \to 0\)</span> and <span class="math inline">\(\V(s_{ML}^2) \to 0\)</span> as <span class="math inline">\(n\to\infty\)</span>.</p>
</section>
<section id="consistency-of-hatbeta_ml-and-s_ml2" class="level2">
<h2 class="anchored" data-anchor-id="consistency-of-hatbeta_ml-and-s_ml2">Consistency of <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s_{ML}^2\)</span></h2>
<p>If <span class="math inline">\(E[\eps|X]=0\)</span> (strict exogeneity, follows from our Assumptions 1 and 2), then the bias of <span class="math inline">\(\hat\beta\)</span> is zero since <span class="math inline">\(E[\hat\beta_{ML}]=\beta\)</span> <span class="math display">\[\begin{align*}
E[\hat\beta_{ML}]&amp;=E[(X'X)^{-1}X'(X\beta + \eps)] \\
                 &amp;=E[E[(X'X)^{-1}X'(X\beta + \eps)|X]] \\
                 &amp;=E[E[(X'X)^{-1}X'X\beta|X]] + E[E[(X'X)^{-1}X'\eps|X]] \\
                 &amp;=E[E[\beta|X]] + E[(X'X)^{-1}X'E[\eps|X]] \\
                 &amp;=        \beta + E[(X'X)^{-1}X'E[\eps|X]] \\
                 &amp;=        \beta  \\
\Leftrightarrow E[\hat\beta_{ML}]-\beta&amp;=\operatorname{Bias}(\hat\beta_{ML})=0
\end{align*}\]</span> Of course, from this it also follows that the squared bias is equal to zero <span class="math inline">\(\text{Bias}^2(\hat\beta_{ML})=0\)</span>. This implies that the mean square error (MSE) of the ML estimator <span class="math inline">\(\hat\beta_{ML}\)</span> equals the variance of the ML estimator <span class="math inline">\(\hat\beta_{ML}\)</span>: <span class="math display">\[
\operatorname{MSE}(\hat\beta_{ML})=\underbrace{E[(\hat\beta_{ML}-\beta)^2]=\V(\hat\beta_{ML})}_{\text{MSE}(\hat\beta_{ML})=\V(\hat\beta_{ML})\text{ since }\hat\beta_{ML}\text{ is unbiased.}}\to 0\quad\text{as}\quad n\to\infty.
\]</span> Since convergence in mean square implies convergence in probability, we have established that the ML-estimator <span class="math inline">\(\hat\beta_{ML}\)</span> is a (weakly) consistent estimator of <span class="math inline">\(\beta\)</span> <span class="math display">\[
\hat\beta_{ML}\to_p \beta\quad\text{as}\quad n\to\infty.
\]</span></p>
<p>Moreover, one can also show that <span class="math inline">\(s_{ML}^2\)</span> is a biased but estimator, that is <span class="math inline">\(\operatorname{Bias}^2(s^2_{ML})\to 0\)</span> as <span class="math inline">\(n\to\infty\)</span>. Together with the result that <span class="math inline">\(\V(s^2_{ML})\to 0\)</span> as <span class="math inline">\(n\to\infty\)</span> we have that <span class="math display">\[
\operatorname{MSE}(s^2_{ML})=E[(s^2_{ML}-\sigma^2)^2]=\operatorname{Bias}^2(s^2_{ML})+\V(s^2_{ML})\to 0\quad\text{as}\quad n\to\infty.
\]</span> Again, since convergence in mean square implies convergence in probability, we have established that the ML-estimator <span class="math inline">\(s^2_{ML}\)</span> is a (weakly) consistent estimator of <span class="math inline">\(\sigma^2\)</span> <span class="math display">\[
s^2_{ML}\to_p \sigma^2\quad\text{as}\quad n\to\infty.
\]</span></p>
<p>In practice, however, one usually works with the unbiased (and consistent) alternative <span class="math inline">\(s_{UB}^2=\dfrac{1}{n-K}\sum_{i=1}^n \hat{\eps}_i^2\)</span> even though one can show that <span class="math inline">\(\operatorname{MSE}(s^2_{ML})&lt;\operatorname{MSE}(\hat\sigma^2_{UB})\)</span> for sufficiently large <span class="math inline">\(n\)</span>.</p>
</section>
<section id="asymptotic-theory-of-maximum-likelihood-estimators" class="level2">
<h2 class="anchored" data-anchor-id="asymptotic-theory-of-maximum-likelihood-estimators">Asymptotic Theory of Maximum-Likelihood Estimators</h2>
<p>So far, we only considered consistency of the ML-estimators. In the following, we consider the asymptotic distribution of ML-estimators. We only consider the simplest situation: Assume an i.i.d. sample <span class="math inline">\(X_1,\dots,X_n\)</span>, and suppose that the distribution of <span class="math inline">\(X_i\)</span> possesses a density <span class="math inline">\(f(x|\theta)\)</span>. The true parameter <span class="math inline">\(\theta\in \mathbb{R}\)</span> is unknown. (Example: density of an exponential distribution <span class="math inline">\(f(x|\theta)=\theta\exp(- \theta x)\)</span>)</p>
<p>It can generally be shown that <span class="math inline">\(\hat{\theta}_n\)</span> is a consistent estimator of <span class="math inline">\(\theta\)</span>. Derivation of the asymptotic distribution relies on a Taylor expansion (around <span class="math inline">\(\theta\)</span>) of the derivative <span class="math inline">\(\ell_n'(\cdot)\)</span> of the log-likelihood function. By the so called , we then know that for some <span class="math inline">\(\psi_n\)</span> between <span class="math inline">\(\hat{\theta}_n\)</span> and <span class="math inline">\(\theta\)</span> we have <span class="math display">\[
\ell_n'(\hat{\theta}_n)=\ell_n'(\theta)+\ell_n''(\psi_n)(\hat{\theta}_n-\theta)\quad\quad\text{(Mean Value Theorem)}
\]</span> Since <span class="math inline">\(\hat{\theta}_n\)</span> maximizes the log-Likelihood function it follows that <span class="math inline">\(\ell_n'(\hat{\theta}_n)=0\)</span>. This implies (since <span class="math inline">\(\ell_n'(\hat{\theta}_n)=\ell_n'(\theta)-\ell_n''(\psi_n)(\hat{\theta}_n-\theta)\)</span>) that <span class="math display">\[\begin{equation}
\ell_n'(\theta)=-\ell_n''(\psi_n)(\hat{\theta}_n-\theta).\label{eq:ml2}
\end{equation}\]</span> Note that necessarily <span class="math inline">\(\int_{-\infty}^{\infty} f(x|\theta)dx=1\)</span> for all possible values of the true parameter <span class="math inline">\(\theta\)</span>. Therefore, <span class="math inline">\(\int_{-\infty}^{\infty} \frac{\partial}{\partial \theta}f(x|\theta)dx=0\)</span> and <span class="math inline">\(\int_{-\infty}^{\infty} \frac{\partial^2}{\partial \theta^2}f(x|\theta)dx=0\)</span>.</p>
<p>Using this, we now show that the average <span class="math display">\[
\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i|\theta)
\]</span> is asymptotically normal. For the mean of <span class="math inline">\(\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i|\theta)\)</span> one gets: <span class="math display">\[
E\left(\frac{1}{n}\ell_n'(\theta)\right)=\frac{1}{n}E\left(\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i|\theta)\right)
=\frac{n}{n}\int_{-\infty}^{\infty} \frac{\frac{\partial}{\partial \theta}  f(x|\theta)}
{f(x|\theta)}f(x|\theta)dx=0.
\]</span> For the variance of <span class="math inline">\(\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i|\theta)\)</span> one gets: <span class="math display">\[
\V\left(\frac{1}{n}\ell_n'(\theta)\right)=\frac{n}{n^2}\V\left(\frac{\partial}{\partial \theta} \ln f(X_i|\theta)\right)
=\frac{1}{n}\underbrace{E\left(\left(\frac{\frac{\partial}{\partial \theta}  f(X_i|\theta)}
{f(X_i|\theta)}\right)^2\right)}_{=:\mathcal{J}(\theta)}=\frac{1}{n}\mathcal{J}(\theta)
\]</span> <!-- Define $\mathcal{J}(\theta):=E\left(\left(\frac{\frac{\partial}{\partial \theta}f(X_i|\theta)} --> <!-- {f(X_i|\theta)}\right)^2\right)$.  --> Moreover, the average <span class="math inline">\(\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i|\theta)\)</span> is taken over i.i.d.~random variables <span class="math inline">\(\frac{\partial}{\partial \theta} \ln f(X_i|\theta)\)</span>. So, we can apply the Lindeberg-L'evy central limit theorem from which it follows that <span class="math display">\[
\frac{\frac{1}{n}\ell_n'(\hat{\theta}_n)}{\sqrt{\frac{1}{n}\mathcal{J}(\theta)} }=\frac{\ell_n'(\hat{\theta}_n)}{\sqrt{n\mathcal{J}(\theta)} } \to_d N(0,1)
\]</span> Thus (using <span class="math inline">\(\eqref{eq:ml2}\)</span>) we also have <span class="math display">\[\begin{equation}
\frac{-\ell_n''(\psi_n)}{\sqrt{n \cdot \mathcal{J}(\theta)}}(\hat{\theta}_n-\theta) \to_d N(0,1)\label{eq:MLNorm}
\end{equation}\]</span> Further analysis requires to study the term <span class="math inline">\(\ell_n''(\psi_n)\)</span>. We begin this with studying the mean of <span class="math display">\[\begin{align*}
\frac{1}{n}\ell_n''(\theta)
&amp;=\frac{1}{n}\sum_{i=1}^n\frac{\partial^2}{\partial \theta\partial \theta}\ln f(X_i|\theta)
=\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta}\left(\frac{\partial}{\partial\theta}\ln f(X_i|\theta)\right)\\
&amp;=\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta}\left(\frac{\frac{\partial}{\partial \theta}f(X_i|\theta)}{f(X_i|\theta)}\right)\\
&amp;=\frac{1}{n}\sum_{i=1}^n
\left(
\frac{\left(\frac{\partial^2}{\partial \theta\partial \theta}f(X_i|\theta)\right) f(X_i|\theta)-\frac{\partial}{\partial\theta}f(X_i|\theta)\frac{\partial}{\partial\theta} f(X_i|\theta)}{\left(f(X_i|\theta)\right)^2}\right)
\end{align*}\]</span> Taking the mean of <span class="math inline">\(\frac{1}{n}\ell_n''(\theta)\)</span> yields: <span class="math display">\[\begin{align*}
\frac{1}{n}E(\ell_n''(\theta))
&amp;=\frac{n}{n}E\left( \frac{\frac{\partial^2}{\partial \theta^2}  f(X_i|\theta)}
{f(X_i|\theta)}-\left( \frac{\frac{\partial}{\partial \theta}  f(X_i|\theta)}
{f(X_i|\theta)}\right)^2\right)\\
&amp;=0 - E\left(\left( \frac{\frac{\partial}{\partial \theta}  f(X_i|\theta)}
{f(X_i|\theta)}\right)^2\right)=-\mathcal{J}(\theta)
\end{align*}\]</span> Taking the variance of <span class="math inline">\(\frac{1}{n}\ell_n''(\theta)\)</span> yields: <span class="math display">\[
\V\left(\frac{1}{n}\ell_n''(\theta)\right)=\frac{1}{n^2}n
\underbrace{\V\left(\frac{\partial^2}{\partial \theta \partial \theta}  \ln f(X_i|\theta)\right)}_{=\text{some fixed, deterministic number}}\to 0\quad\text{as}\quad n\to\infty
\]</span> So, <span class="math inline">\(\frac{1}{n}\ell_n''(\theta)\)</span> is an unbiased estimator for <span class="math inline">\(-\mathcal{J}(\theta)\)</span> and thus <span class="math display">\[
E\left(\left(\frac{1}{n}\ell_n''(\theta) -\left(-\mathcal{J}(\theta)\right)\right)^2\right)=\V\left(\frac{1}{n}\ell_n''(\theta)\right)\to 0\quad\text{as}\quad n\to\infty
\]</span> That is <span class="math inline">\(\frac{1}{n}\ell_n''(\theta)\)</span> is mean square consistent <span class="math display">\[
\frac{1}{n}\ell_n''(\theta)\to_{m.s.} -\mathcal{J}(\theta)\quad \hbox{as}\quad n\to\infty
\]</span> which implies that <span class="math inline">\(\frac{1}{n}\ell_n''(\theta)\)</span> is also (weakly) consistent <span class="math display">\[
\frac{1}{n}\ell_n''(\theta)\to_p -\mathcal{J}(\theta)\quad \hbox{as}\quad n\to\infty
\]</span> since mean square convergence implies convergence in probability.</p>
<p>Remember: We wanted to study <span class="math inline">\(\ell_n''(\psi_n)\)</span> in <span class="math inline">\(\eqref{eq:MLNorm}\)</span> not <span class="math inline">\(\frac{1}{n}\ell_n''(\theta)\)</span>, but we are actually close now. We know that the ML estimator <span class="math inline">\(\hat\theta_n\)</span> is (weakly) consistent, i.e., <span class="math inline">\(\hat\theta_n\to_p\theta\)</span>. From this it follows that also <span class="math inline">\(\psi_n\to_p \theta\)</span> since <span class="math inline">\(\psi_p\)</span> is a value between <span class="math inline">\(\hat\theta_n\)</span> and <span class="math inline">\(\theta\)</span> (Mean Value Theorem). Therefore, we have that also <span class="math display">\[
\frac{1}{n}\ell_n''(\psi_n)\to_p -\mathcal{J}(\theta)\quad \hbox{ as }\quad n\to\infty.
\]</span> Multiplying by <span class="math inline">\(-1/\sqrt{ \mathcal{J}(\theta)}\)</span> yields <span class="math display">\[
\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{ \mathcal{J}(\theta)}}=
n^{-1/2}\frac{-\ell_n''(\psi_n)}{\sqrt{n \cdot \mathcal{J}(\theta)}}\to_p \sqrt{ \mathcal{J}(\theta)}.
\]</span> Rewriting the quotient in <span class="math inline">\(\eqref{eq:MLNorm}\)</span> a little bit yields <span class="math display">\[
\frac{-\ell_n''(\psi_n)}{\sqrt{n \cdot \mathcal{J}(\theta)}}(\hat{\theta}_n-\theta)=
\underbrace{n^{-1/2}\frac{-\ell_n''(\psi_n)}{\sqrt{n \cdot \mathcal{J}(\theta)}}}_{\to_p \sqrt{ \mathcal{J}(\theta)}}\cdot n^{1/2}(\hat{\theta}_n-\theta).
\]</span> Thus we can conclude that (using <span class="math inline">\(\eqref{eq:MLNorm}\)</span>): <span class="math display">\[
\sqrt{ \mathcal{J}(\theta)}n^{1/2}(\hat{\theta}_n-\theta)\to_d N(0,1),
\]</span> or equivalently <span class="math display">\[(\hat{\theta}_n-\theta)\to_d N\left(0,\frac{1}{n \mathcal{J}(\theta)}\right)\]</span> with <span class="math inline">\(n \mathcal{J}(\theta)=-E(\ell_n''(\theta))=\mathcal{I}(\theta)\)</span> which is the asymptotic normality result we aimed, where <span class="math inline">\(\mathcal{I}(\theta)\)</span> is called the .</p>
<p>The above arguments can easily be generalized to multidimensional parameter vectors <span class="math inline">\(\theta\in\mathbb{R}^K\)</span>. In this case, <span class="math inline">\(\mathcal{J}(\theta)\)</span> becomes a <span class="math inline">\(K\times K\)</span> matrix, and <span class="math display">\[\hat{\theta}_n-\theta\to_dN_K\left(0,\frac{1}{n} \mathcal{J}(\theta)^{-1}\right),\]</span> where <span class="math inline">\(n\mathcal{J}(\theta)=-E(\ell_n''(\theta))=\mathcal{I}(\theta)\)</span> is called .</p>
<!-- \paragraph*{Example:} Assume an i.i.d. sample $X_1,\dots,X_n$ from an exponential distribution, i.e. the underlying density of $X_i$ is given by $f(x|\theta)=\theta\exp(-\theta x)$. We then have $\mu:=E(X_i)=\frac{1}{\theta}$ as well as $\sigma^2_X:=\textrm{var}(X_i)=\frac{1}{\theta^2}$. The -->
<!-- log-likelihood functions is given by  -->
<!-- $$l(\theta)=\sum_{i=1}^n \ln (\theta\exp(-\theta X_i)))=n \ln \theta -\sum_{i=1}^n \theta X_i$$ -->
<!-- $$\Rightarrow \quad \ell_n'(\theta)=n\frac{1}{\theta} + \sum_{i=1}^n X_i.$$ -->
<!-- As already mentioned above, the maximum-likelihood estimator of $\theta$ then is $\hat\theta_n=\frac{1}{\bar X}$. -->
<!-- Inference may then be based on likelihood-theory. We have -->
<!-- $$\mathcal{J}(\theta)=-\frac{1}{n}E(\ell''(\theta))=\frac{1}{\theta^2},$$ -->
<!-- and by the above theorem -->
<!-- $$\frac{1}{\bar X}-\theta\sim AN(0,\frac{1}{n \mathcal{J}(\theta)})\overset{a}{\sim}AN(0,\frac{\theta^2}{n}).$$ -->
<!-- This obviously coincides with the result obtained by the delta-method. -->
<!-- ## Discussion of Assumptions and Results {-} -->
<!-- \begin{itemize} -->
<!-- \item \textbf{Strict exogeneity}:  Needed to assume $\E[\eps | X]=0$ to show consistency of $\hat\beta_{ML}$.  -->
<!-- \item \textbf{Homoskedasticity and non-autocorrelation}:  We used the assumption that $\E[\eps eps']\sim(0, \sigma^2 I)$ to derive estimator of $\sigma^2$.   -->
<!-- \item \textbf{Normality}:  The normality assumption is used \textbf{only} to derive small-sample properties of the estimators. By using asymptotic arguments one can show that both $\hat\beta_{ML}$ and $s_{ML}^2$ will be distributed -->
<!-- asymptotically normally also without the normality assumption. -->
<!-- \end{itemize} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Best Linear Unbiased Estimator} -->
<!-- Given our assumptions, then by the Gauss-Markov theorem, it is possible to show that  -->
<!-- \begin{itemize}  -->
<!-- \item<1->$\hat\beta$ is the Best Linear Unbiased (BLUE) estimator of $\beta$ -->
<!-- \item<2-> The best linear unbiased estimator of any linear combination of the $\beta$'s is the same linear combination -->
<!-- of the $\hat\beta$'s. -->
<!-- \item<3-> The Best Linear Unbiased Predictor (BLUP) of $Y$ based on the vector $X_s$ is $\hat y_s=X'_s\hat\beta$ -->
<!-- \end{itemize} -->
<!-- \end{frame} -->
<!-- ## Hypothesis Testing -->
<!-- ### Testing Hypotheses about One Parameter -->
<!-- \noindent\textbf{Definition of the Score} -->
<!-- Define the \textbf{score of the log likelihood} (also known as the \textbf{gradient vector} -->
<!-- for observation $i$ -->
<!-- \begin{equation*} -->
<!-- s_i(\beta)\equiv \left(\dfrac{\partial L_i}{\partial \beta_0}(\beta), \dfrac{\partial L_i}{\partial \beta_1}(\beta), \dots, \dfrac{\partial L_i}{\partial \beta_k}(\beta)\right)' -->
<!-- \end{equation*} -->
<!-- %In the logit and probit cases, this can be shown to be -->
<!-- %\begin{equation*} -->
<!-- %s_i(\beta)\equiv\dfrac{g(x_i\beta)[y_i-G(x_i\beta)]} -->
<!-- %{G(x_i\beta)[1-G(x_i\beta)]}x_i' -->
<!-- %\end{equation*} -->
<!-- %Since $x_i$ is $1 \times (k+1)$, the score is a $(k+1) \times 1$ vector.  Recalling that in the probit %case -->
<!-- %\begin{center} -->
<!-- %$g(z)=\phi(z)$ and $G(z)=\Phi(z)$ -->
<!-- %\end{center} -->
<!-- %while with logit -->
<!-- %\begin{center} -->
<!-- %$g(z)=\exp(z)/[1+\exp(z)]^2$ and $G(z)=\exp(z)/[1+\exp(z)]$. -->
<!-- %\end{center} -->
<!-- #### Variance-Covariance Matrix {-} -->
<!-- Using the standard maximum likelihood theory it can be -->
<!-- show that the asymptotic-variance covariance matrix of the MLE $\hat\beta_{ML}$ is given by -->
<!-- \begin{equation*} -->
<!-- \text{Asy.~Var}(\hat\beta_{ML})=\left[\sum_{i=1}^N s_i(\hat\beta)s_i(\hat\beta)'\right]^{-1} -->
<!-- \end{equation*} -->
<!-- %and therefore in our case we have -->
<!-- %\begin{equation*} -->
<!-- %\text{Asy. Var-Cov}(\hat\beta)=\left[\sum_{i=1}^N\dfrac{[g(x_i\hat\beta)]^2 x_i' x_i}{G(x_i\hat\beta) -->
<!-- %[1-G(x_i\hat\beta)]}\right]^{-1} -->
<!-- %\end{equation*} -->
<!-- %with $g(\cdot)$ and $G(\cdot)$ defined as above. -->
<!-- %\vskip .1in -->
<!-- The square roots of the diagonals of this matrix will give us the -->
<!-- \textbf{standard errors} of the estimates. -->
<!-- \frametitle{Cramer-Rao Lower Bound} -->
<!-- Fisher, Cramer, and Rao showed that for any unbiased estimator $\hat\theta$, its variance-covariance -->
<!-- matrix cannot be smaller than $I^{-1}(\theta)$ where $I(\theta)$ is the \textbf{information matrix} -->
<!-- of the estimator, given by  -->
<!-- $$I(\theta) \equiv E[s(y,\theta)s(y,\theta)']$$ -->
<!-- where $s(\cdot)$ is the gradient or score.  Thus, the MLE attains the Cramer-Rao lower bound and will therefore be asymptotically efficient. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Asymptotic Distribution} -->
<!-- Now, by the usual asymptotic theory, we have -->
<!-- \begin{equation*} -->
<!-- \dfrac{\hat\beta_j - \beta_j^0}{\text{std. err.}(\hat\beta_j)}\stackrel{a}{\sim} \mathcal{N}(0,1) -->
<!-- \end{equation*} -->
<!-- where $\beta_j^0$ is the value of the parameter under the null hypothesis. -->
<!-- So, we can do our usual "$t$-tests" although because we rely on asymptotics, -->
<!-- they should probably be more properly called $z$-tests. -->
<!-- \end{frame} -->
<!-- \subsection{Testing Hypotheses about Multiple Parameters} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Testing Joint Hypotheses} -->
<!-- We may also want to test hypotheses about multiple parameters.  Here it will -->
<!-- be useful to think about the regressions implied by imposing the restrictions. -->
<!-- So, for example,  -->
<!-- \begin{equation*} -->
<!-- \begin{array}{ll} -->
<!-- H_0: & R\beta - r = 0\\ -->
<!-- H_A: & H_0 \text{ is not true} \\ -->
<!-- \end{array} -->
<!-- \end{equation*} -->
<!-- where $R$ is a $q \times (k+1)$ matrix that defines the $q$ restrictions placed on the parameters -->
<!-- under the null hypothesis and $r$ is a $q \times 1$ vector of constants. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Restricted and Unrestricted Regressions} -->
<!-- We will define the \textbf{restricted regression} as one in which we force -->
<!-- the $R\hat\beta$ to be equal to  -->
<!-- $r$ (i.e. under the null hypothesis), and the -->
<!-- \textbf{unrestricted regression} to be one in which we allow the data to tell -->
<!-- us what the values of $\beta$ should be. -->
<!-- \vskip .2in -->
<!-- Define $L_r$ as the log-likelihood corresponding to the restricted regeression -->
<!-- and $L_u$ as the log-likelihood corresponding to the unrestricted regression. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Three Asymptotically Equivalent Tests} -->
<!-- We will discuss three asymptotically equivalent tests: -->
<!-- \begin{itemize} -->
<!-- \item \textbf{Wald test}: based on the unrestricted regression -->
<!-- \item \textbf{Likelihood ratio test}: based on both the restricted and unrestrcited regressions -->
<!-- \item \textbf{Lagrange multiplier test}: based on the restricted regression. -->
<!-- \end{itemize} -->
<!-- All three tests will give us the same answer asymptotically, but will differ -->
<!-- in their values in finite samples. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Wald Test (1)} -->
<!-- From maximum likelihood theory, we know that  -->
<!-- \begin{equation*} -->
<!-- \hat\beta \adist \mathcal{N}(\beta,V) -->
<!-- \end{equation*} -->
<!-- and therefore that $R\hat\beta$ also has an asymptotically normal distribution -->
<!-- (since it is just a linear combination of asymptotically normal variables): -->
<!-- \begin{equation*} -->
<!-- (R\hat\beta - R\beta) \adist \mathcal{N}(0, RVR') -->
<!-- \end{equation*} -->
<!-- This suggests a quadratic form which we can use to test hypotheses -->
<!-- \begin{equation*} -->
<!-- W\equiv(R\hat\beta - r)'[R \hat V_u R']^{-1}(R\hat\beta - r) \adist \chi_q^2 -->
<!-- \end{equation*} -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Wald Test (2)} -->
<!-- Thus, with the \textbf{Wald test}, we need only estimate the \textit{unrestricted} regression. -->
<!-- \vskip .25in -->
<!-- It measures how far apart the estimated parameters are from the values of  -->
<!-- the parameters under the null hypothesis. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Likelihood Ratio Test} -->
<!-- More conceptually simple, perhaps, is the \textbf{Likelihood Ratio Test}. -->
<!-- \vskip .15in -->
<!-- If the null hypothesis holds, imposing restrictions on the data should lead -->
<!-- to values of $L_r$ and $L_u$ that are ``close''.  The question then, is what -->
<!-- metric to use to judget how ``close '' they are. -->
<!-- \vskip .15in -->
<!-- It can be shown that -->
<!-- \begin{equation*} -->
<!-- LR\equiv -2 [L_r - L_u] \adist \chi^2_q -->
<!-- \end{equation*} -->
<!-- Therefore the $\chi^2_q$ distribution is the proper metric for judging how close -->
<!-- the likelihoods are. -->
<!-- \vskip .15in -->
<!-- We must fit both models to calculate the differences between the restricted -->
<!-- and restricted likelihoods. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Motivation} -->
<!-- The \textbf{Lagrange Multiplier Test} (also called the \textbf{Score Test}) is based -->
<!-- on the score, or gradient, vector (as defined earlier).  The idea is to measure -->
<!-- how far away from the peak of the \textit{unrestricted} likelihood imposing the -->
<!-- restrctions forces us, which is some akin to the notion of the likelihood ratio -->
<!-- test.  -->
<!-- \vskip.15in -->
<!-- At the peak of the unrestricted log likelihood, the score would be a vector of -->
<!-- zeros.  Intuitively, then, the Lagrante Multiplier Test will measure how ``close'' -->
<!-- the score vector when we estimate the \textit{restricted} regression is to  -->
<!-- the vector of zeroes. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Derivation (1)} -->
<!-- We can think about finding the maximum of the log likelihood subject to -->
<!-- the constraints imposed by the null hypothesis.  To simplify things, suppose we have only two -->
<!-- parameters, $\beta_1$ and $\beta_2$ with $H_0: \beta_2=c$. -->
<!-- Then: -->
<!-- \begin{equation*} -->
<!-- H(\beta, \lambda)=\sum_{i=1}^N  L_i(\beta) - \lambda'(\beta_2-c) -->
<!-- \end{equation*} -->
<!-- where $\lambda$ is the Lagrange multiplier.  Then the first order conditions -->
<!-- are -->
<!-- \begin{align*} -->
<!-- \sum_{i=1}^N  \dfrac{\partial L_i (\beta)}{\partial \beta_1} \big\vert_{\tilde\beta} -->
<!-- &=\sum_{i=1}^N s_{i1}(\tilde\beta)=0\\ -->
<!-- \tilde\lambda=\sum_{i=1}^N \dfrac{\partial L_i (\beta)}{\partial \beta_1} \big\vert_{\tilde\beta} &=\sum_{i=1}^N s_{i2}(\tilde\beta)\\ -->
<!-- \end{align*} -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Derivation (2)} -->
<!-- Define $s_{i1}$ and $s_{i2}$ are the subvectors of $s_i(\beta)$ corresponding to  -->
<!-- $\beta_1$ and $\beta_2$, respectively. -->
<!-- \vskip .15in -->
<!-- So we are in some sense testing whether $\tilde\lambda$ is ``close'' to zero or -->
<!-- not, evaluated at the restricted values of the parameters. -->
<!-- \vskip .15in -->
<!-- It's possible to show, then, that -->
<!-- \begin{equation*} -->
<!-- LM\equiv  s'(\tilde\beta) \tilde V_r^{-1} s(\tilde\beta) \adist \chi^2_q -->
<!-- \end{equation*} -->
<!-- where $s(\tilde\beta)$ is the score evaluated at the \textit{restricted} estimates of -->
<!-- the parameters, and $\tilde V_r$ is the estimated variance-covariance matrix from the \textit{restricted} regression. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Relationshiop between W, LR, and LM tests} -->
<!-- \includegraphics[angle=90, scale=.60]{wald-lm-lr.ps} -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Relationship between W, LR, and LM} -->
<!-- While all three tests are asymptotically equivalent, it can be shown that in finite -->
<!-- samples -->
<!-- \begin{center} -->
<!-- $LM < LR < W$ -->
<!-- \end{center} -->
<!-- meaning that LM tests will favor not rejecting the null and W tests will favor rejecting -->
<!-- the null. -->
<!-- \end{frame} -->
<!-- \end{document} -->
<!-- \section{Goodness of Fit Measures} -->
<!-- \subsection{Goodness of Fit Measures} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Goodness of Fit in Probit and Logit} -->
<!-- As in the linear regression model, we would like to have some measure -->
<!-- of how well our model fits the data.  Unlike linear models, however, where -->
<!-- $R^2$ serves as the primary goodness-of-fit measure, there is no -->
<!-- standard metric that is used. -->
<!-- \vskip .15in -->
<!-- Now, define $L_0$ as the log likelihood of a model in which we constrain -->
<!-- all of the coefficients (except the constant) to be equal to zero. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- %------------------------------------------------- -->
<!-- %\begin{frame} -->
<!-- %\frametitle{A Note on $L_0$} -->
<!-- %Note that we do not actually need to run a  regression to estimate $L_0$. -->
<!-- %\vskip .15in -->
<!-- %With just a constant term in the model, the likelihood function is given by -->
<!-- %\begin{align*} -->
<!-- %L_0&=\sum y_i \ln(N_1/N) + \sum (1-y_i) \ln(1-N_1/N)\\ -->
<!--  %    &=N_1 \ln(N_1/N) + N_0\ln(N_0/N)\\ -->
<!-- %\end{align*} -->
<!-- %where $N_1$ indicates the number of success and $N_0$ is the number of failures. -->
<!-- %\end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Pseudo-$R^2$} -->
<!-- The first goodness-of-fit measure is meant as an analog to the $R^2$ from -->
<!-- linear regression, called the pseudo-$R^2$.  It is defined as -->
<!-- \begin{equation*} -->
<!-- \text{pseudo}-R^2=1-\dfrac{1}{1+2(L_u - L_0)/N} -->
<!-- \end{equation*} -->
<!-- Intuitively, the greater the distance between the restricted and -->
<!-- unrestricted log likelihoods, the more the model explains the variation -->
<!-- in $y$, and the greater the pseudo-$R^2$ will be. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{McFadden's $R^2$} -->
<!-- McFadden suggested an alternative goodness of fit-measures: -->
<!-- \begin{equation*} -->
<!-- \text{McFadden}-R^2= 1- L_u/L_0 -->
<!-- \end{equation*} -->
<!-- since the log likelihood is just the sum of log probabilities, it must be that -->
<!-- $L_0 < L_u < 0$. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- %\begin{frame} -->
<!-- %\frametitle{Proportion of Correct Predictions} -->
<!-- %An additional measure of the fit of the model is the number of observations for -->
<!-- %which the model correctly predicts the outcome. -->
<!-- %\end{frame} -->
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>