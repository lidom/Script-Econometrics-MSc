<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Econometrics M.Sc. - 5&nbsp; Small Sample Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./06-Asymptotics.html" rel="next">
<link href="./04-Monte-Carlo-Simulations.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Small Sample Inference</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./" class="sidebar-logo-link">
      <img src="./images/Uni_Bonn_Logo.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Econometrics M.Sc.</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Organization of the Course</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-Introduction-to-R.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-Probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-Multiple-Linear-Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-Monte-Carlo-Simulations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Monte Carlo Simulations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-Small-Sample-Inference.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Small Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-Asymptotics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Large Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-Instrumental-Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Instrumental Variables</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-testmultp" id="toc-sec-testmultp" class="nav-link active" data-scroll-target="#sec-testmultp"><span class="toc-section-number">5.1</span>  Hypothesis Tests about Multiple Parameters (F-Tests)</a>
  <ul class="collapse">
  <li><a href="#the-test-statistic-and-its-null-distribution" id="toc-the-test-statistic-and-its-null-distribution" class="nav-link" data-scroll-target="#the-test-statistic-and-its-null-distribution"><span class="toc-section-number">5.1.1</span>  The Test Statistic and its Null Distribution</a></li>
  </ul></li>
  <li><a href="#ch:testingsinglep" id="toc-ch:testingsinglep" class="nav-link" data-scroll-target="#ch\:testingsinglep"><span class="toc-section-number">5.2</span>  Tests about One Parameter (t-Tests)</a></li>
  <li><a href="#testtheory" id="toc-testtheory" class="nav-link" data-scroll-target="#testtheory"><span class="toc-section-number">5.3</span>  Testtheory</a>
  <ul class="collapse">
  <li><a href="#significance-level-alpha" id="toc-significance-level-alpha" class="nav-link" data-scroll-target="#significance-level-alpha"><span class="toc-section-number">5.3.1</span>  Significance Level <span class="math inline">\(\alpha\)</span></a></li>
  <li><a href="#critical-values" id="toc-critical-values" class="nav-link" data-scroll-target="#critical-values"><span class="toc-section-number">5.3.2</span>  Critical Values</a></li>
  <li><a href="#type-ii-error-and-power" id="toc-type-ii-error-and-power" class="nav-link" data-scroll-target="#type-ii-error-and-power"><span class="toc-section-number">5.3.3</span>  Type II Error and Power</a></li>
  <li><a href="#p-value" id="toc-p-value" class="nav-link" data-scroll-target="#p-value"><span class="toc-section-number">5.3.4</span>  <span class="math inline">\(p\)</span>-Value</a></li>
  </ul></li>
  <li><a href="#sec-CIsmallsample" id="toc-sec-CIsmallsample" class="nav-link" data-scroll-target="#sec-CIsmallsample"><span class="toc-section-number">5.4</span>  Confidence Intervals</a></li>
  <li><a href="#sec-PSSI" id="toc-sec-PSSI" class="nav-link" data-scroll-target="#sec-PSSI"><span class="toc-section-number">5.5</span>  Monte Carlo Simulations</a>
  <ul class="collapse">
  <li><a href="#check-distribution-of-hatbetax-vs-distribution-of-hatbeta" id="toc-check-distribution-of-hatbetax-vs-distribution-of-hatbeta" class="nav-link" data-scroll-target="#check-distribution-of-hatbetax-vs-distribution-of-hatbeta"><span class="toc-section-number">5.5.1</span>  Check: Distribution of <span class="math inline">\(\hat\beta|X\)</span> vs Distribution of <span class="math inline">\(\hat\beta\)</span></a></li>
  <li><a href="#check-variance-of-hatbetax-vs-variance-of-hatbeta" id="toc-check-variance-of-hatbetax-vs-variance-of-hatbeta" class="nav-link" data-scroll-target="#check-variance-of-hatbetax-vs-variance-of-hatbeta"><span class="toc-section-number">5.5.2</span>  Check: Variance of <span class="math inline">\(\hat\beta|X\)</span> vs Variance of <span class="math inline">\(\hat\beta\)</span></a></li>
  <li><a href="#check-testing-multiple-parameters" id="toc-check-testing-multiple-parameters" class="nav-link" data-scroll-target="#check-testing-multiple-parameters"><span class="toc-section-number">5.5.3</span>  Check: Testing Multiple Parameters</a></li>
  <li><a href="#dualty-of-confidence-intervals-and-hypothesis-tests" id="toc-dualty-of-confidence-intervals-and-hypothesis-tests" class="nav-link" data-scroll-target="#dualty-of-confidence-intervals-and-hypothesis-tests"><span class="toc-section-number">5.5.4</span>  Dualty of Confidence Intervals and Hypothesis Tests</a></li>
  </ul></li>
  <li><a href="#real-data-example" id="toc-real-data-example" class="nav-link" data-scroll-target="#real-data-example"><span class="toc-section-number">5.6</span>  Real Data Example</a>
  <ul class="collapse">
  <li><a href="#critical-discussion-of-the-regression-results" id="toc-critical-discussion-of-the-regression-results" class="nav-link" data-scroll-target="#critical-discussion-of-the-regression-results"><span class="toc-section-number">5.6.1</span>  Critical Discussion of the Regression Results</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="toc-section-number">5.7</span>  Exercises</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-ssinf" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Small Sample Inference</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>The content of this chapter is very much inspired by the textbook of <span class="citation" data-cites="Hayashi2000">Hayashi (<a href="#ref-Hayashi2000" role="doc-biblioref">2000</a>)</span>.</p>
<p>It’s is very hard to say when a sample size <span class="math inline">\(n\)</span> is small. Often people say something like <span class="math inline">\(n&lt;30\)</span> means small samples and <span class="math inline">\(n\geq 30\)</span> large samples, but this is, of course, only a very rough rule of thumb that may fail. The core issue with small sample sizes is that we cannot do inference using the central limit theorem. Thus we need rather strict assumptions on the distribution of the error term, in order to do <strong>exact</strong> inference in finite samples.</p>
<p><strong>Exact inference:</strong> By “exact inference” we mean correct inference for each sample size <span class="math inline">\(n\)</span>. That is, no asymptotic <span class="math inline">\((n\to\infty)\)</span> arguments will be used.</p>
<p><strong>Assumptions:</strong> Recall that we, in general, did not impose a complete distributional assumption on <span class="math inline">\(\varepsilon\)</span> in Assumption 4 (<a href="03-Multiple-Linear-Regression.html"><span>Chapter&nbsp;3</span></a>); the i.i.d. normal case in Assumption 4 was only one possible <em>option</em>. However, to do exact inference, the normality Assumption on the error terms is not a mere option, but a <em>necessity</em>. So for this chapter we assume that Assumptions 1-3 from <a href="03-Multiple-Linear-Regression.html"><span>Chapter&nbsp;3</span></a> hold and that additionally the following assumption holds:</p>
<p><strong>Assumption 4<span class="math inline">\(^\boldsymbol{\ast}\)</span>: Error distribution:</strong> For small sample cases, we assume that the error terms are <strong>i.i.d. normal</strong>, i.e., <span class="math inline">\(\varepsilon_i|X\overset{\operatorname{i.i.d.}}{\sim}\mathcal{N}(0,\sigma^2)\)</span> for all <span class="math inline">\(i=1,\dots,n\)</span> which leads to Gaussian spherical errors. That is, <span class="math display">\[
\varepsilon|X\sim\mathcal{N}\left(0,\sigma^2I_n\right),
\]</span> where <span class="math inline">\(\varepsilon=(\varepsilon_1,\dots,\varepsilon_n)'\)</span>.</p>
<div id="thm-normalbeta" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.1 (Normality of <span class="math inline">\(\hat\beta\)</span>) </strong></span>Under Assumptions 1-4<span class="math inline">\(^\ast\)</span> we have that <span id="eq-ssnorm"><span class="math display">\[
\hat\beta_n|X \sim \mathcal{N}\left(\beta,Var(\hat\beta_n|X)\right),
\tag{5.1}\]</span></span> where <span class="math inline">\(Var(\hat\beta_n|X)=\sigma^2(X'X)^{-1}\)</span>.</p>
</div>
<p>This result follows from noting that <span class="math inline">\(\hat\beta_n=(X'X)^{-1}X'Y=\beta+(X'X)^{-1}X'\varepsilon\)</span> and because <span class="math inline">\((X'X)^{-1}X'\varepsilon\)</span> is just a linear combination of the normally distributed error terms <span class="math inline">\(\varepsilon\)</span> which, therefore, is again normally distributed, conditionally on <span class="math inline">\(X\)</span>. Note that the specific normal distribution depends on the observed realization of <span class="math inline">\(X\)</span>.</p>
<p><strong>Remark:</strong> The subscript <span class="math inline">\(n\)</span> in <span class="math inline">\(\hat\beta_n\)</span> is here only to emphasize that the distribution of <span class="math inline">\(\hat\beta_n\)</span> depends on <span class="math inline">\(n\)</span>; we will, however, often simply write <span class="math inline">\(\hat\beta\)</span>.</p>
<section id="sec-testmultp" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-testmultp"><span class="header-section-number">5.1</span> Hypothesis Tests about Multiple Parameters (F-Tests)</h2>
<p>Let us consider the following system of <span class="math inline">\(q\)</span>-many null hypotheses: <span class="math display">\[\begin{align*}
H_0: \underset{(q\times K)}{R}\underset{(K\times 1)}{\beta} - \underset{(q\times 1)}{r} = \underset{(q\times 1)}{0},
\end{align*}\]</span> where the <span class="math inline">\((q \times K)\)</span> matrix <span class="math inline">\(R\)</span> and the <span class="math inline">\(q\)</span>-vector <span class="math inline">\(r=(r_{1},\dots,r_{q})'\)</span> are chosen by the statistician to specify her/his null hypothesis about the unknown true parameter vector <span class="math inline">\(\beta\)</span>. To make sure that there are no redundant equations, it is required that <span class="math inline">\(\operatorname{rank}(R)=q\)</span>.</p>
<p>We must also specify the alternative against which we are testing the null hypothesis, for instance <span class="math display">\[\begin{equation*}
H_A: R\beta -r \neq 0
\end{equation*}\]</span></p>
<p>The above multiple parameter hypotheses cover also the special case of single parameter hypothesis; for instance, by setting <span class="math inline">\(R=(0,1,0\dots,0)\)</span> and <span class="math inline">\(r=0\)</span> one get’s <span class="math display">\[\begin{equation*}
\begin{array}{ll}
H_0:  &amp; \beta_{k}=0 \\
H_A:  &amp; \beta_{k} \ne 0 \\
\end{array}
\end{equation*}\]</span></p>
<p>Under our assumptions (Assumptions 1 to 4<span class="math inline">\(^\ast\)</span>), we have that <span class="math display">\[
\begin{align*}
(R\hat\beta_n-r)|X&amp;\sim\mathcal{N}\left(R\beta -r,RVar(\hat\beta_n|X)R'\right)\\
(R\hat\beta_n-r)|X&amp;\overset{H_0}{\sim}\mathcal{N}\left(0,RVar(\hat\beta_n|X)R'\right)
\end{align*}
\]</span></p>
<p>That is,</p>
<ul>
<li>the realizations of <span class="math inline">\((R\hat\beta_n -r)|X\)</span> will scatter around the <em>unknown</em> <span class="math inline">\((R\beta -r)\)</span> in a Gaussian fashion.</li>
<li>if the null hypothesis is correct (i.e., <span class="math inline">\((R\beta-r)=0\)</span>), the realizations of <span class="math inline">\((R\hat\beta_n-r)|X\)</span> scatter around the <span class="math inline">\((q\times 1)\)</span> vector <span class="math inline">\(0\)</span>.</li>
</ul>
<p>We use a test statistic to detect a systematic location shift away from the zero vector. <!-- * if the alternative hypothesis is correct (i.e., $(R\beta-r)=a\neq 0$), there will be a systematic location-shift in $(R\hat\beta_n-r)|X$ which we try to detect using statistical hypothesis testing.  --></p>
<!-- the realizations of $R\hat\beta_n-r|X$ scatter around the $q$-vector $a\neq 0$.  So, under the alternative hypothesis,  -->
<section id="the-test-statistic-and-its-null-distribution" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="the-test-statistic-and-its-null-distribution"><span class="header-section-number">5.1.1</span> The Test Statistic and its Null Distribution</h3>
<p>The fact that <span class="math inline">\((R\hat\beta_n-r)\in\mathbb{R}^q\)</span> is a <span class="math inline">\(q\)</span>-dimensional random variable makes it a little bothersome to use as a test-statistic. Fortunately, we can turn <span class="math inline">\((R\hat\beta_n-r)\)</span> into a scalar-valued test statistic using the following quadratic form: <span class="math display">\[
W=\underbrace{(R\hat\beta_n -r)'}_{(1\times q)}\underbrace{[RVar(\hat\beta_n|X)R']^{-1}}_{(q\times q)}\underbrace{(R\hat\beta_n -r)}_{(q\times 1)}
\]</span> Note that the test statistic <span class="math inline">\(W\)</span> is simply measuring the distance (it’s a weighted L2-distance) between the <span class="math inline">\((q\times 1)\)</span> vectors <span class="math inline">\(R\hat\beta_n\)</span> and <span class="math inline">\(r\)</span>.</p>
<p>Under the null hypothesis (i.e., if <span class="math inline">\(H_0\)</span> is true), <span class="math inline">\(W|X\)</span> is a sum of <span class="math inline">\(q\)</span>-many independent squared standard normal random variables. Therefore, under the null hypothesis, <span class="math inline">\(W|X\)</span> is chi-square distributed with <span class="math inline">\(q\)</span> degrees of freedom (see <a href="02-Probability.html#sec-chisqdist"><span>Section&nbsp;2.2.10.3</span></a>), <span class="math display">\[
\begin{align*}
W|X&amp;\overset{H_0}{\sim} \chi^2_{(q)}\\
\Rightarrow \quad\quad W&amp;\overset{H_0}{\sim} \chi^2_{(q)}
\end{align*}
\]</span> Note that the distribution of <span class="math inline">\(W|X\)</span> does not depend on <span class="math inline">\(X,\)</span> (i.e.&nbsp;it’s a <span class="math inline">\(\chi^2_{(q)}\)</span>-distribution no matter the realization of <span class="math inline">\(X\)</span>) and thus our test decisions do not depend on the values of <span class="math inline">\(X.\)</span> (Good news!)</p>
<p>Usually, we do not know <span class="math inline">\(Var(\hat\beta_n|X),\)</span> and thus we need to estimate this quantity from the data. Unfortunately, in the small sample case, we can only deal with homoskedastic error terms. For truly exact finite sample inference, we need a variance estimator for which we can derive the exact small sample distribution. Therefore, we require Assumption 4<span class="math inline">\(^*\)</span> of spherical errors (i.e., <span class="math inline">\(Var(\varepsilon|X)=I_n\sigma^2\)</span>) which yields that <span class="math inline">\(Var(\hat\beta_n|X)=\sigma^2(X'X)^{-1}\)</span>, and where <span class="math inline">\(\sigma^2\)</span> can be estimated by the unbiased (<span class="math inline">\(UB\)</span>) variance estimator<br>
<span class="math display">\[
s_{UB}^2=(n-K)^{-1}\sum_{i=1}^n\hat\varepsilon_i^2.
\]</span><br>
From the normality assumption in Assumption 4<span class="math inline">\(^*\)</span>, it follows then that <span id="eq-distsquared"><span class="math display">\[
\frac{(n-K)}{\sigma^{2}}s_{UB}^2\sim\chi^2_{(n-K)}.
\tag{5.2}\]</span></span></p>
<p>The <span class="math inline">\(F\)</span> test statistic uses then <span class="math inline">\(s_{UB}^2\)</span> as an estimator of <span class="math inline">\(\sigma^2\)</span> <span class="math display">\[
F=(R\hat\beta_n -r)'[R(s_{UB}^2(X'X)^{-1})R']^{-1}(R\hat\beta_n -r)/q
\]</span> and takes into account the additional randomness (estimation errors) due to <span class="math inline">\(s_{UB}^2\)</span>, which leads to the following exact null distribution of the <span class="math inline">\(F\)</span> test <span id="eq-Ftest"><span class="math display">\[
F\overset{H_0}{\sim} F_{(q,n-K)},
\tag{5.3}\]</span></span> where <span class="math inline">\(F_{(q,n-K)}\)</span> denotes the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(q\)</span> numerator and <span class="math inline">\(n-K\)</span> denominator degrees of freedom.</p>
<p>As in the case of <span class="math inline">\(W\)</span>, the distribution of <span class="math inline">\(F\)</span> conditional on <span class="math inline">\(X\)</span> does not depend on <span class="math inline">\(X\)</span>; i.e.&nbsp;<span class="math inline">\(F|X\overset{H_0}{\sim}F_{(q,n-K)},\)</span> but <span class="math inline">\(F_{(q,n-K)}\)</span> does not depend on <span class="math inline">\(X,\)</span> thus we can write <span class="math inline">\(F\overset{H_0}{\sim}F_{(q,n-K)}.\)</span></p>
<p>The distributional statements in <a href="#eq-distsquared">Equation&nbsp;<span>5.2</span></a> and <a href="#eq-Ftest">Equation&nbsp;<span>5.3</span></a> are a little cumbersome to derive and we do not go into details here, but in case you’re interested you can find some more details, for instance, in Chapter 1 of <span class="citation" data-cites="Hayashi2000">Hayashi (<a href="#ref-Hayashi2000" role="doc-biblioref">2000</a>)</span>.</p>
<p>By contrast to <span class="math inline">\(W,\)</span> <span class="math inline">\(F\)</span> is now a practically useful test statistic, and we can use the observed value <span class="math inline">\(F_{\text{obs}}\)</span> to measure the distance of our estimate <span class="math inline">\(R\hat\beta_n\)</span> from its hypothetical value <span class="math inline">\(r.\)</span></p>
<p>Observed values, <span class="math inline">\(F_{\text{obs}}\)</span>, that are “unusually large” under the null hypothesis, lead to a rejection of the null hypothesis. The null distribution <span class="math inline">\(F_{(q,n-K)}\)</span> of <span class="math inline">\(F\)</span> is used to judge what’s “unusually large” under the null hypothesis.</p>
<p><strong>The F distribution.</strong> The F distribution is a ratio of two <span class="math inline">\(\chi^2\)</span> distributions. It has two parameters: the numerator degrees of freedom, and the denominator degrees of freedom. Each combination of the parameters yields a different F distribution. See <a href="02-Probability.html#sec-Fdist"><span>Section&nbsp;2.2.10.6</span></a> for more information on the <span class="math inline">\(F\)</span> distribution.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-1_c0e52edffc08555ebf8880c3905e5752">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="ch:testingsinglep" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="ch:testingsinglep"><span class="header-section-number">5.2</span> Tests about One Parameter (t-Tests)</h2>
<p>For testing a hypothesis about only one parameter <span class="math inline">\(\beta_k\)</span>, with <span class="math inline">\(k=1,\dots,K\)</span> <span class="math display">\[\begin{equation*}
\begin{array}{ll}
H_0: &amp; \beta_k=r\\
H_A: &amp; \beta_k\ne r\\
\end{array}
\end{equation*}\]</span> the <span class="math inline">\((q\times K)\)</span>-matrix <span class="math inline">\(R\)</span> becomes a <span class="math inline">\((1\times K)\)</span> row-vector of zeros but with a one as the <span class="math inline">\(k\)</span>th element. For instance, for testing a null hypothesis about <span class="math inline">\(\beta_k\)</span> with, e.g., <span class="math inline">\(k=2\)</span>, we have <span class="math inline">\(R=(0,1,0,\dots,0),\)</span> and thus the <span class="math inline">\(F\)</span> test statistic simplifies to <span class="math display">\[
F=\frac{\left(\hat{\beta}_k-r\right)^2}{\widehat{Var}(\hat{\beta}_k|X)}\overset{H_0}{\sim}F_{(1,n-K)},
\]</span> where <span class="math inline">\(\widehat{Var}(\hat{\beta}_k|X)=s^2_{UB}[(X'X)^{-1}]_{kk}.\)</span></p>
<p>Taking square roots yields the <span class="math inline">\(t\)</span> test statistic <span class="math display">\[
t=\frac{\hat{\beta}_k-r}{\widehat{\operatorname{SE}}(\hat{\beta}_k|X)}\overset{H_0}{\sim}t_{(n-K)},
\]</span> where <span class="math inline">\(\widehat{\operatorname{SE}}(\hat{\beta}_k|X)=s_{UB}[(X'X)^{-1/2}]_{kk},\)</span> and where <span class="math inline">\(t_{(n-K)}\)</span> denotes the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K\)</span> degrees of freedom.</p>
<p>Thus the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K\)</span> degrees of freedom is the appropriate distribution to judge whether or not an observed value <span class="math inline">\(t_{obs}\)</span> of the test statistic is “unusually large” under the null hypothesis.</p>
<p><strong>Note:</strong> All commonly used statistical software packages report <span class="math inline">\(t\)</span>-tests testing the null hypothesis <span class="math inline">\(H_0:\beta_k=0\)</span>, i.e., with <span class="math inline">\(r=0\)</span>. This means to test the null hypothesis that <span class="math inline">\(X_k\)</span> has “no (linear) effect” on <span class="math inline">\(Y\)</span>.</p>
<p><strong>The <span class="math inline">\(t\)</span> distribution.</strong> The following plot illustrates that as the degrees of freedom increase, the shape of the <span class="math inline">\(t\)</span> distribution comes closer to that of a standard normal bell curve. Already for <span class="math inline">\(25\)</span> degrees of freedom we find little difference to the standard normal density. In case of small degrees of freedom values, we find the distribution to have heavier tails than a standard normal. See <a href="02-Probability.html#sec-tdist"><span>Section&nbsp;2.2.10.4</span></a> for more information about the <span class="math inline">\(t\)</span>-distribution.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-2_8568957aa6352f1933b895f9e1ea5a71">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="testtheory" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="testtheory"><span class="header-section-number">5.3</span> Testtheory</h2>
<section id="significance-level-alpha" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="significance-level-alpha"><span class="header-section-number">5.3.1</span> Significance Level <span class="math inline">\(\alpha\)</span></h3>
<p>To actually test the null hypothesis (e.g., <span class="math inline">\(H_0\)</span>: <span class="math inline">\(R\beta-r=0\)</span> or <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_k=0\)</span>), we need to have a decision rule on when we will reject or not reject the null hypothesis. This amounts to deciding on a probability with which we are comfortable with committing a Type I error (<span class="math inline">\(\alpha\)</span>-error): rejecting the null hypothesis when it is in fact true. The probability of such a Type I error shall be bounded from above by a (small) significance level <span class="math inline">\(\alpha\)</span>, that is <span class="math display">\[
P(\text{reject } H_0| H_0\text{ is true})=P(\text{Type I Error})=\alpha
\]</span> For a given significance level (e.g., <span class="math inline">\(\alpha=0.05\)</span>) and a given alternative hypothesis, we can divide the range of all possible values of the test statistic (i.e., <span class="math inline">\(\mathbb{R}\)</span> since both <span class="math inline">\(t\in\mathbb{R}\)</span> and <span class="math inline">\(F\in\mathbb{R}\)</span>) into a <strong>rejection region</strong> and a <strong>non-rejection region</strong> by using <strong>critical values</strong> derived from the distribution of the test statistic under the null hypothesis. We can do this because the test statistics <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> have known distributions under the null hypothesis (<span class="math inline">\(t\overset{H_0}{\sim}t_{n-K}\)</span> and <span class="math inline">\(F\overset{H_0}{\sim}F_{(q,n-K)}\)</span>).</p>
<p>Indeed, under Assumption 4<span class="math inline">\(^\ast\)</span>, we know the <em>exact</em> null distributions for every sample size <span class="math inline">\(n\)</span>. Having decided on the rejection and non-rejection regions, we only need to check whether the observed (obs) sample values <span class="math inline">\(t_{obs}\)</span> or <span class="math inline">\(F_{obs}\)</span> of the test statistics <span class="math inline">\(t\)</span> or <span class="math inline">\(F\)</span> are either in the rejection or in the non-rejection region to either rejection the null hypothesis or not to rejection the null hypothesis.</p>
<p><strong>Non-conservative versus conservative tests:</strong> Since the test statistics <span class="math inline">\(F\)</span> and <span class="math inline">\(t\)</span> are continuous random variables of which we know the <em>exact</em> distributions (under Assumptions 1-4<span class="math inline">\(^\ast\)</span>), we can find critical values such that <span class="math display">\[
P(\text{Type I Error})=\alpha
\]</span> We call such tests “non-conservative” since the probability of a type I error equals the significance level <span class="math inline">\(\alpha\)</span>. Test statistics with <span class="math display">\[
P(\text{Type I Error})&lt;\alpha
\]</span> are called <em>conservative</em> test statistics; they lead to valid inferences, but will detect a correct violation of the null hypothesis less often than a non-conservative test. A test statistic with <span class="math inline">\(P(\text{Type I Error})&gt;\alpha\)</span> leads to <em>invalid</em> inferences!</p>
</section>
<section id="critical-values" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="critical-values"><span class="header-section-number">5.3.2</span> Critical Values</h3>
<section id="the-f-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-f-test">The <span class="math inline">\(F\)</span>-Test</h4>
<p>The critical value <span class="math inline">\(c_{1-\alpha}&gt;0\)</span> defines the</p>
<ul>
<li>rejection region, <span class="math inline">\(]c_{1-\alpha},\infty[\)</span>, and</li>
<li>non-rejection region, <span class="math inline">\(]0,c_{1-\alpha}]\)</span></li>
</ul>
<p>which together divide the range of test-statistic values (here <span class="math inline">\(\mathbb{R}^+\)</span> since <span class="math inline">\(F\in\mathbb{R}^+\)</span>) for a given significance level <span class="math inline">\(\alpha\in(0,1)\)</span>, such that <span class="math display">\[
P(\text{Type I Error})=P_{H_0}\Big(F\in]c_{1-\alpha},\infty[\Big)=\alpha,
\]</span> where <span class="math inline">\(c_{1-\alpha}\)</span> is here the <span class="math inline">\((1-\alpha)\)</span> quantile of the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\((q,n-K)\)</span> degrees of freedom, and where <span class="math inline">\(P_{H_0}\)</span> means that we compute the probability under the assumption that <span class="math inline">\(H_0\)</span> is true.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-3_aa0ae8567f7fc54717ecac869fbae9b5">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>The rejection region:</strong> The rejection region describes a range of values of the test statistic <span class="math inline">\(F\)</span> which we rarely see if the null hypothesis is true (only in at most <span class="math inline">\(\alpha \cdot 100\%\)</span> cases). If the observed value of the test statistic, <span class="math inline">\(F_{\text{obs}}\)</span>, falls in this region, we will reject the null hypothesis and accept Type I error rate of <span class="math inline">\(\alpha\)</span>.</p>
<p><strong>The non-rejection region:</strong> The non-rejection region describes a range of values of the test statistic <span class="math inline">\(F\)</span> which we expect to see (in <span class="math inline">\((1-\alpha) \cdot 100\%\)</span> cases) if the null hypothesis is true. If the observed value of the test statistic, <span class="math inline">\(F_{\text{obs}}\)</span> falls in this region, we will not reject the null hypothesis.</p>
<p><strong>Caution:</strong> Not rejecting the null hypothesis does not mean that we can conclude that the null hypothesis is true. We only had no sufficiently strong evidence against the null hypothesis. A violation of the null hypothesis, for instance <span class="math inline">\(R\beta -r=a\neq 0\)</span>, may simply be too small (too small <span class="math inline">\(a\)</span> value) to stand out from the estimation errors (measured by the standard error) in <span class="math inline">\(\hat\beta_k.\)</span></p>
<p>Fortunately, you do not need to read old-school distribution tables to find the critical value <span class="math inline">\(c_{1-\alpha}\)</span>, but can simply use <code>R</code></p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-4_1729164745e2beaa5cd2709144d45275">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>df1   <span class="ot">&lt;-</span> <span class="dv">9</span>    <span class="co"># numerator df</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>df2   <span class="ot">&lt;-</span> <span class="dv">120</span>  <span class="co"># denominator df</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># significance level</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Critical value:</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>crit_value <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df1 =</span> df1, <span class="at">df2 =</span> df2)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>crit_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.958763</code></pre>
</div>
</div>
<p>Changing the significance level from <span class="math inline">\(\alpha=0.05\)</span> to <span class="math inline">\(\alpha=0.01\)</span> makes the critical value <span class="math inline">\(c_{1-\alpha}\)</span> larger and, therefore, the rejection region smaller (fewer Type I errors)</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-5_31485ccc071b6fa5b7bb0fb81a287217">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.01</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Critical value:</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>crit_value <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df1 =</span> df1, <span class="at">df2 =</span> df2)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>crit_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.558574</code></pre>
</div>
</div>
</section>
<section id="the-t-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-t-test">The <span class="math inline">\(t\)</span>-Test</h4>
<p>In case of the <span class="math inline">\(t\)</span>-test, we need to differentiate between two-sided and one-sided testing.</p>
<section id="two-sided-t-test" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="two-sided-t-test">Two-Sided <span class="math inline">\(t\)</span>-Test</h5>
<p>Two-sided hypothesis: <span class="math display">\[\begin{equation*}
\begin{array}{ll}
H_0: &amp; \beta_k=r \\
H_A: &amp; \beta_k\ne r
\end{array}
\end{equation*}\]</span> In case of a two-sided <span class="math inline">\(t\)</span>-test, we reject the null hypothesis if the observed realization of the <span class="math inline">\(t\)</span>-test, <span class="math inline">\(t_{obs}\)</span>, is “far away” from zero either by being sufficiently smaller or greater than <span class="math inline">\(r\)</span>. The corresponding two-sided critical values are denoted by <span class="math inline">\(-c_{1-\alpha/2}=c_{\alpha/2}&lt;0\)</span> and <span class="math inline">\(c_{1-\alpha/2}&gt;0\)</span>, where <span class="math inline">\(c_{1-\alpha/2}&gt;0\)</span> is the <span class="math inline">\((1-\alpha/2)\)</span> quantile of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom, and where <span class="math inline">\(-c_{1-\alpha/2}=c_{\alpha/2}\)</span> due to the symmetry of the <span class="math inline">\(t\)</span>-distribution. These critical values defines the following rejection and the non-rejection regions <span class="math display">\[\begin{align*}
\text{rejection region:}&amp;\hspace{1cm}]-\infty,c_{\alpha/2}[\;\;\cup\;\;]c_{1-\alpha/2}, \infty[\\
\text{non-rejection region:}&amp;\hspace{1cm}[c_{\alpha/2},c_{1-\alpha/2}].
\end{align*}\]</span> For this rejection region it holds true that <span class="math display">\[
P(\text{Type I Error})=P_{H_0}\Big(t\in\;]-\infty,c_{\alpha/2}[\;\;\cup\;\;]c_{1-\alpha/2}, \infty[\Big)=\alpha.
\]</span></p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-6_36dfa5f6f6e892bd3763843e193e246d">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="one-sided-t-test" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="one-sided-t-test">One-Sided <span class="math inline">\(t\)</span>-Test</h5>
<p>One-sided hypothesis: <span class="math display">\[\begin{equation*}
\begin{array}{lll}
&amp;H_0: &amp; \beta_k =r\\
&amp;H_A: &amp; \beta_k &gt;r\\
(\text{or}&amp;H_A: &amp; \beta_k&lt; r)
\end{array}
\end{equation*}\]</span> In case of a one-sided <span class="math inline">\(t\)</span>-test, we will reject the null if <span class="math inline">\(t_{obs}\)</span> is sufficiently “far away” from zero in the relevant direction of <span class="math inline">\(H_A\)</span>. The corresponding critical value is either <span class="math inline">\(-c_{1-\alpha}\)</span> (<span class="math inline">\(H_A:\beta_k&lt; r\)</span>) or <span class="math inline">\(c_{1-\alpha}\)</span> (<span class="math inline">\(H_A:\beta_k&gt; r\)</span>), where <span class="math inline">\(c_{1-\alpha}\)</span> is the <span class="math inline">\((1-\alpha)\)</span> quantile of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom, and where <span class="math inline">\(-c_{1-\alpha}=c_{\alpha}\)</span> due to the symmetry of the <span class="math inline">\(t\)</span>-distribution. The critical value <span class="math inline">\(c_{1-\alpha}\)</span> defines the following rejection and the non-rejection regions:</p>
<p>For <span class="math inline">\(H_0: \beta_k=0\)</span> versus<span class="math inline">\(H_A: \beta_k &lt; 0\)</span>: <span class="math display">\[\begin{align*}
\text{rejection region:}   &amp;\hspace{2cm}]-\infty,c_{\alpha}[ \\
\text{non-rejection region:}&amp;\hspace{2cm}[c_{\alpha},\infty[
\end{align*}\]</span> such that <span class="math display">\[
P(\text{Type I Error})=P_{H_0}\Big(t\in\;]-\infty,c_{\alpha}[\Big)=\alpha.
\]</span></p>
<p>For <span class="math inline">\(H_0: \beta_k=0\)</span>versus<span class="math inline">\(H_A: \beta_k &gt; 0\)</span>: <span class="math display">\[\begin{align*}
\text{rejection region:}&amp;\hspace{1cm}]c_{1-\alpha}, \infty[\\
\text{non-rejection region:}&amp;\hspace{1cm}]-\infty,c_{1-\alpha}]
\end{align*}\]</span> such that <span class="math display">\[
P(\text{Type I Error})=P_{H_0}\Big(t\in\;]c_{1-\alpha}, \infty[\Big)=\alpha.
\]</span></p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-7_a4bc9b6f3a548d0e0f6e1a09bfaf84b1">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Fortunately, you do not need to read old-school distribution tables to find the critical values, but you can simply use <code>R</code></p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-8_25dc1e06256cd0e674778fd898684f6b">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df    <span class="ot">&lt;-</span> <span class="dv">16</span>   <span class="co"># degrees of freedom </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># significance level</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="do">## One-sided critical value (= (1-alpha) quantile):</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>c_oneSided <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df =</span> df)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>c_oneSided</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.745884</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Two-sided critical value (= (1-alpha/2) quantile):</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>c_twoSided <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>, <span class="at">df =</span> df)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="do">## lower critical value</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span>c_twoSided</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -2.119905</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="do">## upper critical value</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>c_twoSided</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.119905</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="type-ii-error-and-power" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="type-ii-error-and-power"><span class="header-section-number">5.3.3</span> Type II Error and Power</h3>
<p>A Type II error is the mistake of not rejecting the null hypothesis when in fact it should have been rejected. The probability of making a Type II error equals one minus the probability of correctly rejecting the null hypothesis (“Power”). For instance, in the case of using the <span class="math inline">\(t\)</span>-test to test the null hypothesis <span class="math inline">\(H_0: \beta_k=0\)</span> versus the one-sided alternative hypothesis <span class="math inline">\(H_A:\beta_k&gt;0\)</span>) we have that <span class="math display">\[\begin{align*}
P(\text{Type II Error})
&amp;=P_{H_A}\Big(t\;\in\;\overbrace{]-\infty,c_{1-\alpha}]}^{\text{non-rejection region}}\Big)\\
&amp;=1-\underbrace{P_{H_A}\Big(t\;\in\;\overbrace{]c_{1-\alpha},\infty[}^{\text{rejection region}}\Big)}_{\text{"Power"}},
\end{align*}\]</span> where <span class="math inline">\(P_{H_A}\)</span> means that we compute the probability under the assumption that <span class="math inline">\(H_A\)</span> is true.</p>
<p>There is a trade off between the probability of making a Type I error and the probability of making a Type II error: a lower significance level <span class="math inline">\(\alpha\)</span>, decreases <span class="math inline">\(P(\text{Type I Error})\)</span>, but necessarily increases <span class="math inline">\(P(\text{Type II Error})\)</span> and vice versa. Ideally, we would have some sense of the costs of making each of these errors, and would choose our significance level to minimize these total costs. However, the costs are often difficult to know. Moreover, the probability of making a Type II error is usually impossible to compute, since we usually do not know the true distribution of <span class="math inline">\(\hat\beta_k\)</span> under the alternative.</p>
<p>For illustration purposes, consider the case of a <span class="math inline">\(t\)</span> test for a one-sided hypothesis <span class="math display">\[\begin{equation*}
\begin{array}{ll}
H_0:  &amp; \beta_k=0 \\
H_A:  &amp; \beta_k&gt;0,
\end{array}
\end{equation*}\]</span> where the true (usually unknown) parameter value is <span class="math inline">\(\beta_k=3\)</span> and where the true (usually also unknown) standard error is <span class="math inline">\(\operatorname{SE}(\hat\beta_k|X)=\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}=1.5\)</span>. Only with the knowledge about these usually unknown quantities, we can derive the distribution of the <span class="math inline">\(t\)</span>-test statistic under the alternative hypothesis. The distribution of the <span class="math inline">\(t\)</span>-test statistic becomes here a standard normal distribution, since we assume <span class="math inline">\(\operatorname{SE}(\hat\beta_k|X)=\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}=1.5\)</span> to be a <strong>known</strong> quantity for some given sample size <span class="math inline">\(n\)</span>. (This completely unrealistic assumption is only used for illustrative purposes to explain the probability of making a Type II error and the power (i.e.&nbsp;<span class="math inline">\(1-P(\text{Type II Error})\)</span>).)</p>
<p>Under this setup, the distribution under the null hypothesis (i.e., if <span class="math inline">\(\beta_k=0\)</span> were true) is: <span class="math display">\[
t=\frac{\hat\beta_k-0}{\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}}\overset{H_0}{\sim}\mathcal{N}(0,1)
\]</span> Likewise, the distribution under the alternative hypothesis (i.e., for the actual <span class="math inline">\(\beta_k=3\)</span>) is: <span class="math display">\[\begin{align*}
t=\frac{\hat\beta_k-0}{\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}}
&amp;=\frac{\hat\beta_k+3-3-0}{\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}}\\[2ex]
&amp;=\underbrace{\frac{\hat\beta_k-3}{\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}}}_{\sim \mathcal{N}(0,1)}+\underbrace{\frac{3-0}{\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}}}_{=\Delta\text{ (mean-shift)}}\overset{H_A}{\sim}\mathcal{N}(\Delta,1)
\end{align*}\]</span></p>
<p>So, the mean-shift <span class="math inline">\(\Delta\)</span> depends on:</p>
<ul>
<li>The value of <span class="math inline">\(\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}\)</span> (here <span class="math inline">\(1.5\)</span>).<br>
</li>
<li>The difference between the actual parameter value <span class="math inline">\((\beta_k=3)\)</span> and the hypothetical parameter <span class="math inline">\((r=0)\)</span> value under the null-hypothesis.</li>
</ul>
<p>The following Graphic illustrates the probability of a type II error and the power for the case where <span class="math inline">\(\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}=1.5\)</span> such that <span class="math inline">\(\Delta=3/1.5=2\)</span>.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-9_0f939ddc00c4d0337a8692b7419e2a13">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="p-value" class="level3" data-number="5.3.4">
<h3 data-number="5.3.4" class="anchored" data-anchor-id="p-value"><span class="header-section-number">5.3.4</span> <span class="math inline">\(p\)</span>-Value</h3>
<p>The <span class="math inline">\(p\)</span>-value of a test statistic is the significance level we would obtain if we took the sample value of the observed test statistic, <span class="math inline">\(F_{\text{obs}}\)</span> or <span class="math inline">\(t_{\text{obs}},\)</span> as the border between the rejection and non-rejection regions.</p>
<ul>
<li><strong><span class="math inline">\(F\)</span>-test:</strong> <span class="math inline">\(p=P_{H_0}(F\geq F_{\text{obs}})\)</span></li>
<li><strong><span class="math inline">\(t\)</span>-test:</strong>
<ul>
<li>Two sided, i.e., <span class="math inline">\(H_0:\beta_k = r\)</span> vs.&nbsp;<span class="math inline">\(H_A:\beta_k\neq r\)</span>: <br> <span class="math inline">\(p=2\cdot\min\{P_{H_0}(t\leq t_{\text{obs}}),P_{H_0}(t\geq t_{\text{obs}})\}=P_{H_0}(|t|&gt;|t_{obs}|)\)</span> <br> The latter equality holds since the <span class="math inline">\(t\)</span> distrbution is symmetric.</li>
<li>One sided, i.e., <span class="math inline">\(H_0:\beta_k \leq r\)</span> vs.&nbsp;<span class="math inline">\(H_A:\beta_k&gt; r\)</span>: <br> <span class="math inline">\(p=P_{H_0}(t\geq t_{\text{obs}})\)</span></li>
<li>One sided, i.e., <span class="math inline">\(H_0:\beta_k \geq r\)</span> vs.&nbsp;<span class="math inline">\(H_A:\beta_k&lt; r\)</span>: <br> <span class="math inline">\(p=P_{H_0}(t\leq t_{\text{obs}})\)</span></li>
</ul></li>
</ul>
<p>Put another way, the <span class="math inline">\(p\)</span>-value is the greatest significance level for which we just fail to reject the null. Therefore, the <span class="math inline">\(p\)</span>-value is sometimes also called “marginal significance value”.</p>
<p>If the <span class="math inline">\(p\)</span>-value is strictly smaller than the chosen significance level <span class="math inline">\(\alpha\)</span>, we reject the null hypothesis.</p>
</section>
</section>
<section id="sec-CIsmallsample" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="sec-CIsmallsample"><span class="header-section-number">5.4</span> Confidence Intervals</h2>
<p>We define a two-sided <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> percent confidence interval for the <em>deterministic</em> (unknown) true <span class="math inline">\(\beta_k\)</span> as the <strong>random interval</strong> <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span> for which <span class="math display">\[
P\Big(\beta_k\in\operatorname{CI}_{k,1-\alpha}\Big)\geq 1-\alpha.
\]</span> Derivation of the random interval <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span>:</p>
<p>Observe that <span class="math display">\[
\frac{\hat\beta_k-\beta_k}{\widehat{\operatorname{SE}}(\hat\beta_k|X)}\sim t_{(n-K)}
\]</span> Therefore, <span class="math display">\[\begin{align*}
P\left(-t_{1-\alpha/2,n-K}\leq\frac{\hat\beta_k-\beta_k}{\widehat{\operatorname{SE}}(\hat\beta_k|X)}\leq t_{1-\alpha/2,n-K}\right)=1-\alpha,
\end{align*}\]</span> where <span class="math inline">\(t_{1-\alpha/2,n-K}\)</span> denotes the <span class="math inline">\((1-\alpha)\)</span> quantile of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K\)</span> degrees of freedom. Next, we can do the following equivalent transformations <span class="math display">\[\begin{align*}
P\left(-t_{1-\alpha/2,n-K}\leq\frac{\hat\beta_k-\beta_k}{\widehat{\operatorname{SE}}(\hat\beta_k|X)}\leq t_{1-\alpha/2,n-K}\right)&amp;=1-\alpha\\
\Leftrightarrow P\left(\hat\beta_k-t_{1-\alpha/2,n-K}\widehat{\operatorname{SE}}(\hat\beta_k|X)\leq \beta_k\leq\hat\beta_k +t_{1-\alpha/2,n-K}\widehat{\operatorname{SE}}(\hat\beta_k|X)\right)&amp;=1-\alpha\\
\Leftrightarrow P\left(\beta_k\in\underbrace{\left[\hat\beta_k-t_{1-\alpha/2,n-K}\widehat{\operatorname{SE}}(\hat\beta_k|X),\;\hat\beta_k +t_{1-\alpha/2,n-K}\widehat{\operatorname{SE}}(\hat\beta_k|X)\right]}_{=:\operatorname{CI}_{k,1-\alpha}}\right)&amp;=1-\alpha
\end{align*}\]</span> That is, the random interval <span class="math display">\[
\operatorname{CI}_{k,1-\alpha}=\left[\hat\beta_k-t_{1-\alpha/2,n-K}\widehat{\operatorname{SE}}(\hat\beta_k|X),\;\hat\beta_k +t_{1-\alpha/2,n-K}\widehat{\operatorname{SE}}(\hat\beta_k|X)\right]
\]</span> is our <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> percent confidence interval for <span class="math inline">\(\beta_k\)</span>.</p>
<p><strong>Interpretation:</strong> The random interval <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span> for <span class="math inline">\(\beta_k\)</span> contains the true parameter value <span class="math inline">\(\beta_k\)</span> in <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> cases of its realizations when considering infinitely many realizations. It’s best to take a look at dynamic viszualizations like this one:</p>
<center>
<a href="https://rpsychologist.com/d3/ci/">https://rpsychologist.com/d3/ci/</a>
</center>
<p>Unfortunately, this “frequentist” interpretation is not a statement about a single given <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span> realization computed for a given data set. A given, realized <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span> will either contain the true parameter <span class="math inline">\(\beta_k\)</span> or not, and usually we do not know the answer. So, confidence intervals are quite hard to interpret. However, they are very well suited as a tool to visualize estimation uncertainties in different parameter estimators, for instance, across <span class="math inline">\(\hat\beta_k\)</span>, <span class="math inline">\(k=1,\dots,K\)</span>.</p>
<center>
<img src="images/Meme_CI_2.jpg" class="img-fluid">
</center>
</section>
<section id="sec-PSSI" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="sec-PSSI"><span class="header-section-number">5.5</span> Monte Carlo Simulations</h2>
<p>Let’s check the above exact inference results using <code>R</code> and Monte Carlo simulations. First, we program a function <code>myDataGenerator()</code> which allows us to generate data from the following model, i.e., from the following fully specified data generating process: <span class="math display">\[\begin{align*}
Y_i   &amp;=\beta_1+\beta_2X_{i2}+\beta_3X_{i3}+\varepsilon_i,\qquad i=1,\dots,n\\
\beta &amp;=(\beta_1,\beta_2,\beta_3)'=(2,3,4)'\\
X_{i2}&amp;\sim U[2,10]\\
X_{i3}&amp;\sim U[12,22]\\
\varepsilon_i&amp;\sim\mathcal{N}(0,3^2),
\end{align*}\]</span> where <span class="math inline">\((Y_i,X_i)\)</span> is assumed i.i.d. across <span class="math inline">\(i=1,\dots,n\)</span>. Below, in the codes, I use <span class="math inline">\(n=10\)</span>, but, of course, other sample sizes can be considered too.</p>
<p>The below function <code>myDataGenerator()</code> allows to sample new realizations of <span class="math inline">\(Y_1,\dots,Y_n\)</span> conditionally on a given data matrix <span class="math inline">\(X\)</span>. Moreover, you can provide your own values for the sample size <span class="math inline">\(n\)</span> and for the parameter vector <span class="math inline">\(\beta=(\beta_1,\beta_2,\beta_3)'\)</span>.</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-10_db361ab6b0edc3436be701d8263f7578">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Function to generate artificial data</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="do">## If X=NULL: new X variables are generated</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="do">## If the user gives X variables, </span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="do">## the sampling of new Y variables is conditionally on </span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="do">## the given X variables.</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>myDataGenerator <span class="ot">&lt;-</span> <span class="cf">function</span>(n, beta, <span class="at">X=</span><span class="cn">NULL</span>){</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">is.null</span>(X)){</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    X   <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n), </span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">runif</span>(n, <span class="dv">2</span>, <span class="dv">10</span>), </span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">runif</span>(n,<span class="dv">12</span>, <span class="dv">22</span>))</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  eps  <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">sd=</span><span class="dv">3</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  Y    <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta <span class="sc">+</span> eps</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="st">"Y"</span><span class="ot">=</span>Y, </span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"X_1"</span><span class="ot">=</span>X[,<span class="dv">1</span>], <span class="st">"X_2"</span><span class="ot">=</span>X[,<span class="dv">2</span>], <span class="st">"X_3"</span><span class="ot">=</span>X[,<span class="dv">3</span>])</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>  <span class="do">##</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Small sample size</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>n           <span class="ot">&lt;-</span> <span class="dv">8</span>           </span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Define a true beta vector</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate Y and X data </span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>test_data     <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta=</span>beta_true)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a><span class="do">## Store the X data as 'X_cond'  </span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>X_cond        <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(test_data[,<span class="sc">-</span><span class="dv">1</span>]) <span class="co"># as matrix allows matrix multiplications</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate new Y data conditionally on X            </span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>test_data_X_cond <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n    =</span> n, </span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">beta =</span> beta_true, </span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">X    =</span> X_cond)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="do">## compare</span></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(test_data,     <span class="dv">3</span>), <span class="dv">2</span>)    <span class="co"># New Y, new X</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       Y X_1  X_2   X_3
1 103.06   1 9.77 17.79
2 110.21   1 9.09 20.98
3  91.25   1 8.79 15.05</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(test_data_X_cond, <span class="dv">3</span>), <span class="dv">2</span>) <span class="co"># New Y, old X (conditionally on X)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       Y X_1  X_2   X_3
1 105.73   1 9.77 17.79
2 118.94   1 9.09 20.98
3  88.19   1 8.79 15.05</code></pre>
</div>
</div>
<section id="check-distribution-of-hatbetax-vs-distribution-of-hatbeta" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="check-distribution-of-hatbetax-vs-distribution-of-hatbeta"><span class="header-section-number">5.5.1</span> Check: Distribution of <span class="math inline">\(\hat\beta|X\)</span> vs Distribution of <span class="math inline">\(\hat\beta\)</span></h3>
<p>The above data generating process fulfills Assumptions 1-4<span class="math inline">\(^*\)</span>. So, by theory, the estimators <span class="math inline">\(\hat\beta_k|X\)</span>, <span class="math inline">\(k=1,\dots,K=3\)</span>, should be normal distributed conditionally on <span class="math inline">\(X\)</span>, <span class="math display">\[
\hat\beta_k|X\sim\mathcal{N}(\beta_k,\sigma^2[(X'X)^{-1}]_{kk}),
\]</span> where <span class="math inline">\([(X'X)^{-1}]_{kk}\)</span> denotes the element in the <span class="math inline">\(k\)</span>th row and <span class="math inline">\(k\)</span>th column of the <span class="math inline">\(K\times K\)</span> matrix <span class="math inline">\((X'X)^{-1}\)</span>.</p>
<p>In order to check the effect of “conditioning on <span class="math inline">\(X\)</span>”, let us focus on <span class="math inline">\(\hat\beta_2\)</span> and use two different Monte Carlo simulations:</p>
<ol type="1">
<li>Generate <code>B</code><span class="math inline">\(=10000\)</span> realizations of <span class="math inline">\(\hat\beta_2\)</span> conditionally on <span class="math inline">\(X\)</span>.</li>
<li>Generate <code>B</code><span class="math inline">\(=10000\)</span> realizations of <span class="math inline">\(\hat\beta_2\)</span> <strong>un</strong>conditionally on <span class="math inline">\(X\)</span>.</li>
</ol>
<p>Then estimate the distributons from both Monte Carlo samples and compare them with the theoretical distribution <span class="math inline">\(\hat\beta_2|X\sim\mathcal{N}(\beta_k,\sigma^2[(X'X)^{-1}]_{22})\)</span>:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-11_14869255e915b0863cc841788768f798">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11100</span>) <span class="co"># seed of the random number generator</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="do">## A function to generate realizations of the estimator \hat{beta}_2</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="do">## conditionally or unconditionally on X:</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>hatbeta2_sim_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(conditional, <span class="at">X =</span> X_cond){</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(conditional <span class="sc">==</span> <span class="cn">TRUE</span>){</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>            data     <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true, <span class="at">X =</span> X)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>            lm_obj   <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> data)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>            hatbeta2 <span class="ot">&lt;-</span> <span class="fu">coef</span>(lm_obj)[<span class="dv">2</span>]</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(conditional <span class="sc">==</span> <span class="cn">FALSE</span>){</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>            data     <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>            lm_obj   <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> data)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>            hatbeta2 <span class="ot">&lt;-</span> <span class="fu">coef</span>(lm_obj)[<span class="dv">2</span>]</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(hatbeta2)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Monte Carlo replications</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Draw realizations of \hat{beta}_2</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="do">## 1. Generate \hat{beta}_2 realizations conditionally on X</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>hatbeta2_sim_cond   <span class="ot">&lt;-</span> <span class="fu">replicate</span>(B, <span class="fu">hatbeta2_sim_fun</span>(<span class="at">conditional =</span> <span class="cn">TRUE</span>,  <span class="at">X =</span> X_cond))</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="do">## 2. Generate \hat{beta}_2 realizations unconditionally on X</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>hatbeta2_sim_uncond <span class="ot">&lt;-</span> <span class="fu">replicate</span>(B, <span class="fu">hatbeta2_sim_fun</span>(<span class="at">conditional =</span> <span class="cn">FALSE</span>))</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Theoretical normal distribution of beta_hat_2 versus </span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="do">## estimated densities based on the two Monte Carlo samples</span></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"scales"</span>)</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a><span class="do">## true beta_2</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>beta_true_2     <span class="ot">&lt;-</span> beta_true[<span class="dv">2</span>] </span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="do">## true standard deviation of the error term</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>sigma           <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a><span class="do">## true variance</span></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>var_true_beta_2 <span class="ot">&lt;-</span> sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">diag</span>(<span class="fu">solve</span>(<span class="fu">t</span>(X_cond) <span class="sc">%*%</span> X_cond))[<span class="dv">2</span>]</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot</span></span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="at">expr =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> beta_true_2, <span class="at">sd=</span><span class="fu">sqrt</span>(var_true_beta_2)), </span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a><span class="at">xlab=</span><span class="st">""</span>, <span class="at">ylab=</span><span class="st">""</span>, <span class="at">col=</span><span class="fu">gray</span>(.<span class="dv">2</span>), <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">lty=</span><span class="dv">1</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">1.5</span>))</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(hatbeta2_sim_cond, <span class="at">bw =</span> <span class="fu">bw.SJ</span>(hatbeta2_sim_cond)), <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">"blue"</span>,.<span class="dv">5</span>), <span class="at">lwd=</span><span class="dv">3</span>)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(hatbeta2_sim_uncond, <span class="at">bw=</span><span class="fu">bw.SJ</span>(hatbeta2_sim_uncond)), <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">"red"</span>,.<span class="dv">5</span>), <span class="at">lwd=</span><span class="dv">3</span>)</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">lwd=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">3</span>),</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span><span class="fu">c</span>(<span class="fu">gray</span>(.<span class="dv">2</span>), <span class="fu">alpha</span>(<span class="st">"blue"</span>,.<span class="dv">45</span>), <span class="fu">alpha</span>(<span class="st">"red"</span>,.<span class="dv">5</span>)), <span class="at">bty=</span><span class="st">"n"</span>, <span class="at">legend=</span> </span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="fu">expression</span>(<span class="st">"Theoretical Gaussian Density of"</span><span class="sc">~</span><span class="fu">hat</span>(beta)[<span class="dv">2</span>]<span class="sc">~</span><span class="st">'|'</span><span class="sc">~</span>X), </span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expression</span>(<span class="st">"Empirical Density based on the 5000 MC realizations of"</span><span class="sc">~</span><span class="fu">hat</span>(beta)[<span class="dv">2</span>]<span class="sc">~</span><span class="st">'|'</span><span class="sc">~</span>X),</span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expression</span>(<span class="st">"Empirical Density based on the 5000 MC realizations of"</span><span class="sc">~</span><span class="fu">hat</span>(beta)[<span class="dv">2</span>])))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Core observations on the densities:</p>
<ul>
<li>The empirical conditional distribution of <span class="math inline">\(\hat{\beta}_2|X\)</span> matches with the theoretical conditional distribution of <span class="math inline">\(\hat{\beta}_2|X\)</span>.</li>
<li>The empirical <strong>un</strong>conditional distribution of <span class="math inline">\(\hat{\beta}_2\)</span> does not match with the theoretical conditional distribution of <span class="math inline">\(\hat{\beta}_2|X\)</span>.</li>
</ul>
</section>
<section id="check-variance-of-hatbetax-vs-variance-of-hatbeta" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="check-variance-of-hatbetax-vs-variance-of-hatbeta"><span class="header-section-number">5.5.2</span> Check: Variance of <span class="math inline">\(\hat\beta|X\)</span> vs Variance of <span class="math inline">\(\hat\beta\)</span></h3>
<p>The theoretical variance of <span class="math inline">\(\hat{\beta}_2|X\)</span> is:<br></p>
<center>
<span class="math inline">\(Var(\hat{\beta}_2|X)=\sigma^2[(X'X)^{-1}]_{22}=\)</span> <code>var_true_beta_2</code> <span class="math inline">\(=\)</span> 0.144.
</center>
<p><br></p>
<ul>
<li>The Monte Carlo approximation to the true variance of <span class="math inline">\(\hat{\beta}_2|X\)</span> is <code>var(hatbeta2_sim_cond)</code> <span class="math inline">\(=\)</span> 0.143 and thus close to the theoretical counterpart.</li>
<li>The Monte Carlo approximation to the true variance of <span class="math inline">\(\hat{\beta}_2\)</span> is <code>var(hatbeta2_sim_uncond)</code> <span class="math inline">\(=\)</span> 0.355 and thus clearly different to the theoretical counterpart.</li>
</ul>
<!-- While the unconditional distribution has a larger variance.  -->
<!-- ```{r} -->
<!-- ## True mean and variance of the true normal distribution  -->
<!-- ## of beta_hat_2|X=X_cond: -->
<!-- # true mean -->
<!-- # true variance -->
<!-- var_true_beta_2 <- sigma^2 * diag(solve(t(X_cond) %*% X_cond))[2] -->
<!-- ## Let's generate 5000 realizations from beta_hat_2  -->
<!-- ## conditionally on X=X_cond and check whether the empirical   -->
<!-- ## distribution of these 5000 realizations is close  -->
<!-- ## to the true normal distribution of beta_hat_2: -->
<!-- B          <- 5000 # MC replications -->
<!-- beta_hat_2 <- rep(NA, times=rep) -->
<!-- ## -->
<!-- for(r in 1:B){ -->
<!--     MC_data <- myDataGenerator(n    = n,  -->
<!--                                beta = beta_true,  -->
<!--                                X    = X_cond) -->
<!--     lm_obj        <- lm(Y ~ X_2 + X_3, data = MC_data) -->
<!--     beta_hat_2[r] <- coef(lm_obj)[2] -->
<!-- } -->
<!-- ## Compare -->
<!-- ## True beta_2 versus average of beta_hat_2 estimates -->
<!-- c(beta_true_2, round(mean(beta_hat_2), 4)) -->
<!-- ``` -->
<!-- The values are very close to each other, thus, on average the estimation results are basically equal to the true parameter value.  -->
<!-- ```{r} -->
<!-- ## Compare -->
<!-- ## True variance of beta_hat_2 versus  -->
<!-- ## empirical variance of beta_hat_2 estimates -->
<!-- c(round(var_true_beta_2, 4), round(var(beta_hat_2), 4)) -->
<!-- ``` -->
<!-- The values are very close to each other, thus the theoretical variance describes very well the actual variance of $\hat\beta_2|X$.  -->
<!-- ```{r, fig.align="center", echo=TRUE, fig.width = 8, fig.height = 5, out.width = "1\\textwidth"} -->
<!-- ## True normal distribution of beta_hat_2 versus  -->
<!-- ## empirical density of beta_hat_2 estimates -->
<!-- library("scales") -->
<!-- curve(expr = dnorm(x, mean = beta_true_2,  -->
<!--                    sd=sqrt(var_true_beta_2)),  -->
<!--       xlab="",ylab="", col=gray(.2), lwd=3, lty=1,  -->
<!--       xlim=range(beta_hat_2), ylim=c(0,1.1)) -->
<!-- hist(beta_hat_2, freq=FALSE, col=alpha("blue",.35), add=TRUE) -->
<!-- lines(density(beta_hat_2, bw = bw.SJ(beta_hat_2)),  -->
<!--       col=alpha("blue",.5), lwd=3) -->
<!-- legend("topleft", lty=c(1,NA,1), lwd=c(3,NA,3), pch=c(NA,15,NA), pt.cex=c(NA,2,NA), -->
<!--      col=c(gray(.2), alpha("blue",.45), alpha("blue",.5)), bty="n", legend=  -->
<!-- c(expression( -->
<!--   "Theoretical Gaussian Density of"~hat(beta)[2]~'|'~X),  -->
<!--   expression( -->
<!--   "Histogram based on the 5000 MC realizations of"~ -->
<!--   hat(beta)[2]~'|'~X),  -->
<!--   expression( -->
<!--   "Nonparametric Density Estimation based on the 5000 MC realizations of"~ -->
<!--   hat(beta)[2]~'|'~X))) -->
<!-- ``` -->
<!-- Great! The nonparametric density estimation (estimated via `density()`) and the histogram computed based on the 5000 simulated realizations of $\hat\beta_2|X$ are indicating that $\hat\beta_2|X$ is really normally distributed as described by our theoretical result in Equation @eq-ssnorm.  -->
<!-- However, what would happen if we would sample *unconditionally* on $X$? How does the distribution of $\hat\beta_2$ would then look like?  -->
<!-- ```{r} -->
<!-- set.seed(1110) -->
<!-- ## Let's generate 5000 realizations from beta_hat_2  -->
<!-- ## WITHOUT conditioning on X -->
<!-- beta_hat_2_uncond <- rep(NA, times=rep) -->
<!-- ## -->
<!-- for(r in 1:rep){ -->
<!--     MC_data <- myDataGenerator(n    = n,  -->
<!--                                beta = beta_true) -->
<!--     lm_obj               <- lm(Y ~ X_2 + X_3, data = MC_data) -->
<!--     beta_hat_2_uncond[r] <- coef(lm_obj)[2] -->
<!-- } -->
<!-- ## Compare: -->
<!-- ## True beta_2 versus average of beta_hat_2 estimates -->
<!-- c(beta_true_2, round(mean(beta_hat_2_uncond), 4)) -->
<!-- ``` -->
<!-- OK, at least on average the point point estimates are basically equal to the true parameter value.  -->
<!-- ```{r} -->
<!-- ## Compare:  -->
<!-- ## True variance of beta_hat_2 versus  -->
<!-- ## empirical variance of beta_hat_2 estimates -->
<!-- c(round(var_true_beta_2, 4), round(var(beta_hat_2_uncond), 4)) -->
<!-- ``` -->
<!-- Ouch! The theoretical variance of $\hat\beta_2|X$ is quite different from the actual variance of $\hat\beta_2$ (i.e. simulated without conditioning in $X$). That is, we cannot simply neglect that the variance of $\hat\beta_2$ depends on the observed realization of $X$ in small samples.  -->
<!-- ```{r, fig.align="center", echo=TRUE, fig.width = 8, fig.height = 5, out.width = "1\\textwidth"} -->
<!-- ## Plotting the theoretical distribution of beta_hat_2|X  -->
<!-- ## versus the simulated distribution -->
<!-- curve(expr = dnorm(x, mean = beta_true_2, sd=sqrt(var_true_beta_2)),  -->
<!--       xlab="",ylab="", col=gray(.2), lwd=3, lty=1,  -->
<!--       xlim=range(beta_hat_2_uncond), ylim=c(0,1.5)) -->
<!-- hist(beta_hat_2_uncond, freq=FALSE, col=alpha("blue",.35), add=TRUE) -->
<!-- lines(density(beta_hat_2_uncond, bw=bw.SJ(beta_hat_2_uncond)),  -->
<!--       col=alpha("blue",.5), lwd=3) -->
<!-- legend("topleft", lty=c(1,NA,1), lwd=c(3,NA,3), pch=c(NA,15,NA), pt.cex=c(NA,2,NA), -->
<!--      col=c(gray(.2), alpha("blue",.45), alpha("blue",.5)), bty="n", legend=  -->
<!-- c(expression( -->
<!--   "Theoretical Gaussian Density of"~hat(beta)[2]~'|'~X),  -->
<!-- expression( -->
<!--   "Histogram based on the 5000 MC realizations of"~ -->
<!--   hat(beta)[2]),  -->
<!-- expression("Nonparam. Density Estimation based on the 5000 MC realizations of"~ -->
<!--   hat(beta)[2]))) -->
<!-- ``` -->
<!-- Not so good. The theoretical distribution of $\hat\beta_2|X$ has much fatter tails than the simulated distribution of $\hat\beta_2$  (i.e. simulated without conditioning in $X$). That is, we cannot simply neglect that the distribution of $\hat\beta_2$ depends on the observed realization of $X$ in small samples. In large sample, however, the effect of a given realization $X$ is (fortunately) negligible, as we will see in @sec-lsinf.  -->
</section>
<section id="check-testing-multiple-parameters" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="check-testing-multiple-parameters"><span class="header-section-number">5.5.3</span> Check: Testing Multiple Parameters</h3>
<p>In the following, we do inference about multiple parameters. We test <span class="math display">\[\begin{align*}
H_0:\;&amp;\beta_2=3\quad\text{and}\quad\beta_3=4\\
\text{versus}\quad H_A:\;&amp;\beta_2\neq 3\quad\text{and/or}\quad\beta_3\neq 4.
\end{align*}\]</span> Or equivalently <span class="math display">\[\begin{align*}
H_0:\;&amp;R\beta -r = 0 \\
H_A:\;&amp;R\beta -r \neq 0,
\end{align*}\]</span> where <span class="math display">\[
R=\left(
\begin{matrix}
0&amp;1&amp;0\\
0&amp;0&amp;1\\
\end{matrix}\right)\quad\text{ and }\quad
r=\left(\begin{matrix}3\\4\\\end{matrix}\right).
\]</span> The following <code>R</code> code can be used to test this hypothesis:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-12_38ac39ca3ec03523652e0469f9429a45">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Library containing the function 'linearHyothesis()' </span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="do">## for testing multiple parameters </span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressMessages</span>(<span class="fu">library</span>(<span class="st">"car"</span>)) </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="do">## See ?linearHypothesis</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate one Monte Carlo sample (under H0)</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>data   <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimate the linear regression model parameters</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>lm_obj <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> data)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Option 1:</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>test_result <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">linearHypothesis</span>(</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">model =</span> lm_obj, </span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">hypothesis.matrix =</span> <span class="fu">c</span>(<span class="st">"X_2=3"</span>, <span class="st">"X_3=4"</span>))   </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>test_result        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear hypothesis test

Hypothesis:
X_2 = 3
X_3 = 4

Model 1: restricted model
Model 2: Y ~ X_2 + X_3

  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1      7 22.178                           
2      5 22.112  2  0.065545 0.0074 0.9926</code></pre>
</div>
</div>
<p>The <span class="math inline">\(p\)</span>-value <span class="math inline">\(p=\)</span> 0.9926 is larger than the chosen significance level <span class="math inline">\(\alpha=0.05\)</span> thus we cannot reject the null hypothesis “<span class="math inline">\(H_0:\;\beta_2=3\)</span> and <span class="math inline">\(\beta_3=4.\)</span>”</p>
<p>The following codes gives an alternative, equivalent way to compute the test result:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-13_66e3da22484f533c9cc46d6cc76c79cb">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Option 2:</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>),</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>           <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(<span class="at">model =</span> lm_obj, </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">hypothesis.matrix =</span> R, </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">rhs =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we simulated data “under the null hypothesis” and thus it is not surpising that we cannot reject the null hypothesis at a significance level of, for instance, <span class="math inline">\(\alpha=0.05\)</span>. However, in repeated samples we should nevertheless observe <span class="math inline">\(\alpha\cdot 100\%\)</span> type I errors (false rejections of <span class="math inline">\(H_0\)</span>) under the null hypothesis. Let’s check the type I error rate using the following Monte Carlo simulation:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-14_accc0d1f2cd68ff79b20080b6b61194c">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Let's generate 5000 F-test decisions and check </span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="do">## whether the empirical rate of type I errors is </span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="do">## close to the theoretical significance level. </span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>B               <span class="ot">&lt;-</span> <span class="dv">5000</span> <span class="co"># MC replications</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>F_test_pvalues  <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="at">times=</span>B)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="do">## generate new data (under H0)</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>  MC_data <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  <span class="do">## estimate </span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>  lm_obj  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> MC_data)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute test and p-value</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>  p       <span class="ot">&lt;-</span> <span class="fu">linearHypothesis</span>(lm_obj, <span class="fu">c</span>(<span class="st">"X_2=3"</span>, <span class="st">"X_3=4"</span>))<span class="sc">$</span><span class="st">`</span><span class="at">Pr(&gt;F)</span><span class="st">`</span>[<span class="dv">2</span>]</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>  <span class="do">## save the p-value</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>  F_test_pvalues[r] <span class="ot">&lt;-</span> p</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>signif_level <span class="ot">&lt;-</span>  <span class="fl">0.05</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>rejections   <span class="ot">&lt;-</span> F_test_pvalues[F_test_pvalues <span class="sc">&lt;</span> signif_level]</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">length</span>(rejections)<span class="sc">/</span>B, <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.051</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>signif_level <span class="ot">&lt;-</span>  <span class="fl">0.01</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>rejections   <span class="ot">&lt;-</span> F_test_pvalues[F_test_pvalues <span class="sc">&lt;</span> signif_level]</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">length</span>(rejections)<span class="sc">/</span>B, <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0108</code></pre>
</div>
</div>
<p>Note that this is actually a very strong result.</p>
<ul>
<li>First, we correctly control for the Type I error rate since the empirical type I error rate is not larger than the chosen significance level <span class="math inline">\(\alpha\)</span> (the nominal Type I error rate).</li>
<li>Second, the test is not conservative since the empirical type I error rate essentially matches the chosen significance level <span class="math inline">\(\alpha\)</span> (the nominal Type I error rate).
<ul>
<li>In fact, if we would increase the number of Monte Carlo repetitions, the empirical type I error rate would converge to the nominal Type I error rate <span class="math inline">\(\alpha\)</span> due to the law of large numbers.</li>
</ul></li>
<li>Last but not least: It works <strong>unconditionally</strong> on <span class="math inline">\(X\)</span> since the distribution of the <span class="math inline">\(F\)</span> statistic does not depend on <span class="math inline">\(X\)</span>. (Thus is also works conditionally on <span class="math inline">\(X\)</span> and you may check this at home.)</li>
</ul>
<p>Next, we check how well the <span class="math inline">\(F\)</span> test detects certain <strong>violations of the null hypothesis</strong>. We do this by using the same data generating process, but by testing the following incorrect (red) null hypothesis: <span class="math display">\[\begin{align*}
H_0:\;&amp;{\color{red}\beta_2=4}\quad\text{and}\quad\beta_3=4\\
H_A:\;&amp;\beta_2\neq 4\quad\text{and/or}\quad\beta_3\neq 4
\end{align*}\]</span></p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-15_972aadacf240c0c7918faa88c6167f07">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>B               <span class="ot">&lt;-</span> <span class="dv">5000</span> <span class="co"># MC replications</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>F_test_pvalues  <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="at">times=</span>B)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="do">## generate new data </span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>  MC_data <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n    =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="do">## estimate </span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  lm_obj  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> MC_data)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute test and p-value (for a false H0)</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  p       <span class="ot">&lt;-</span> <span class="fu">linearHypothesis</span>(lm_obj, <span class="fu">c</span>(<span class="st">"X_2=4"</span>, <span class="st">"X_3=4"</span>))<span class="sc">$</span><span class="st">`</span><span class="at">Pr(&gt;F)</span><span class="st">`</span>[<span class="dv">2</span>]</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="do">## save the p-value</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>  F_test_pvalues[r] <span class="ot">&lt;-</span> p</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>signif_level <span class="ot">&lt;-</span>  <span class="fl">0.05</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>rejections   <span class="ot">&lt;-</span> F_test_pvalues[F_test_pvalues <span class="sc">&lt;</span> signif_level]</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="do">## Rate of H0 rejections:</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(rejections)<span class="sc">/</span>B</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2534</code></pre>
</div>
</div>
<p>We can now correctly reject the false null hypothesis in approximately 25.34 % of all Monte Carlo replications.</p>
<p><strong>Caution:</strong> This also means that we are not able to detect the violation of the null hypothesis in 74.66 % of cases. Therefore, we can never use an insignificant test result (<span class="math inline">\(p\)</span>-value <span class="math inline">\(\geq\alpha\)</span>) as a confirmation of the null hypothesis. Obviously, there are Type II error events (false none rejections), but since we typically do not know the distribution of the test statistic under the alternative hypothesis, we cannot control this Type II error rate. We can only control the Type I error rate by using a small significance level <span class="math inline">\(\alpha\)</span>.</p>
<p>Moreover, note that the <span class="math inline">\(F\)</span> test is not informative about which part of the null hypothesis (<span class="math inline">\(\beta_2=4\)</span> and/or <span class="math inline">\(\beta_3=4\)</span>) is violated. We only get the information that at least one of the multiple parameter hypotheses is violated.</p>
</section>
<section id="dualty-of-confidence-intervals-and-hypothesis-tests" class="level3" data-number="5.5.4">
<h3 data-number="5.5.4" class="anchored" data-anchor-id="dualty-of-confidence-intervals-and-hypothesis-tests"><span class="header-section-number">5.5.4</span> Dualty of Confidence Intervals and Hypothesis Tests</h3>
<p>Confidence intervals can be computed using <code>R</code> as following:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-16_a34f2997aa14c8d8ac2bd9ad268edba7">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Significance level</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>signif_level <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Confidence level</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>conf_level   <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> signif_level</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 95% CI for beta_2</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(lm_obj, <span class="at">parm =</span> <span class="st">"X_2"</span>, <span class="at">level =</span> conf_level)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       2.5 %   97.5 %
X_2 4.328595 6.747891</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 95% CI for beta_3 </span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(lm_obj, <span class="at">parm =</span> <span class="st">"X_3"</span>, <span class="at">level =</span> conf_level)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       2.5 %   97.5 %
X_3 2.705582 4.190266</code></pre>
</div>
</div>
<p>We can use these two-sided confidence intervals to conduct hypotheses tests. This property of confidence intervals is called the <strong>duality of confidence intervals and hypothesis tests</strong>.</p>
<p>For instance, when testing the null hypothesis <span class="math display">\[\begin{align*}
H_0:&amp;\beta_3=4\\
\text{versus}\quad H_A: &amp;\beta_3\neq 4
\end{align*}\]</span> we can check whether the confidence interval <span class="math inline">\(\operatorname{CI}_{1-\alpha}\)</span> contains the hypothetical value <span class="math inline">\(4\)</span> or not.</p>
<ul>
<li>In case of <span class="math inline">\(4\in \operatorname{CI}_{1-\alpha}\)</span>, we cannot reject the null hypothesis.</li>
<li>In case of <span class="math inline">\(4\not\in \operatorname{CI}_{1-\alpha}\)</span>, we reject the null hypothesis.</li>
</ul>
<p>If the Assumption 1-4<span class="math inline">\(^\ast\)</span> hold true, then <span class="math inline">\(\operatorname{CI}_{1-\alpha}\)</span> is an exact confidence interval. That is, under the null hypothesis, it falsely rejects the null hypothesis in only <span class="math inline">\(\alpha\cdot 100\%\)</span> of resamplings. Let’s check this in the following Monte Carlo simulation:</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-17_08f7eeb3875f63bcde4dbc7bfc810bfd">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>signif_level <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>confint_m    <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow=</span><span class="dv">2</span>, <span class="at">ncol=</span>B)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>  <span class="do">## generate new data </span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>  MC_data <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>  <span class="do">## estimate</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  lm_obj  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> MC_data)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute confidence interval </span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>  CI <span class="ot">&lt;-</span> <span class="fu">confint</span>(lm_obj, <span class="at">parm=</span><span class="st">"X_2"</span>, <span class="at">level=</span><span class="dv">1</span><span class="sc">-</span>signif_level)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  <span class="do">## save confidence interval</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>  confint_m[,r] <span class="ot">&lt;-</span> CI</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="do">## check whether true parameter is inside the CI</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>inside_CI  <span class="ot">&lt;-</span> confint_m[<span class="dv">1</span>,] <span class="sc">&lt;=</span> beta_true_2 <span class="sc">&amp;</span> </span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>                beta_true_2 <span class="sc">&lt;=</span> confint_m[<span class="dv">2</span>,]</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="do">## CI-lower, CI-upper, beta_true_2 inside?</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">cbind</span>(<span class="fu">t</span>(confint_m), inside_CI))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                       inside_CI
[1,] 2.112011 4.324384         1
[2,] 1.799873 3.583575         1
[3,] 1.079170 3.578387         1
[4,] 1.060780 3.772007         1
[5,] 1.855253 4.479890         1
[6,] 1.205334 4.216992         1</code></pre>
</div>
</div>
<p>The following code computes the relative frequency of confidence intervals <strong>not containing</strong> the true parameter value <span class="math inline">\((\beta_2=3)\)</span>:</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-18_adc729f88faee41af26d6c4eb45b018a">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">length</span>(inside_CI[inside_CI <span class="sc">==</span> <span class="cn">FALSE</span>])<span class="sc">/</span>B, <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.048</code></pre>
</div>
</div>
<p>That’s good! The relative frequency is basically equal to the chosen <span class="math inline">\(\alpha=0.05\)</span> value.</p>
<p>Next, we visualize a sample of <code>nCIs &lt;- 100</code> realizations of the random confidence interval:</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-19_33856b068073bc6e40feb305133cc536">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>nCIs <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="dv">0</span>,<span class="at">y=</span><span class="dv">0</span>,<span class="at">type=</span><span class="st">"n"</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,nCIs),<span class="at">ylim=</span><span class="fu">range</span>(confint_m[,<span class="dv">1</span><span class="sc">:</span>nCIs]),</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">""</span>, <span class="at">xlab=</span><span class="st">"Resamplings"</span>, <span class="at">main=</span><span class="st">"Confidence Intervals"</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nCIs){</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(inside_CI[r]<span class="sc">==</span><span class="cn">TRUE</span>){</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">lines</span>(<span class="at">x=</span><span class="fu">c</span>(r,r), <span class="at">y=</span><span class="fu">c</span>(confint_m[<span class="dv">1</span>,r], confint_m[<span class="dv">2</span>,r]), </span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="fu">gray</span>(.<span class="dv">5</span>,.<span class="dv">5</span>))</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>      <span class="fu">lines</span>(<span class="at">x=</span><span class="fu">c</span>(r,r), <span class="at">y=</span><span class="fu">c</span>(confint_m[<span class="dv">1</span>,r], confint_m[<span class="dv">2</span>,r]), </span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">"darkred"</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">4</span>, <span class="at">at=</span>beta_true_2, <span class="at">labels =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]))</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span>beta_true_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As expected, only about <span class="math inline">\(\alpha\cdot 100\%=5\%\)</span> of all confidence intervals do not contain the true parameter value <span class="math inline">\(\beta_2=3\)</span>, but about <span class="math inline">\((1-\alpha)\cdot 100\%=95\%\)</span> of all confidence intervals contain the true parameter value <span class="math inline">\(\beta_2=3\)</span>.</p>
</section>
</section>
<section id="real-data-example" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="real-data-example"><span class="header-section-number">5.6</span> Real Data Example</h2>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-20_ec303265a655b76c1792ddc1ebb406f7">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="do">## The AER package contains a lot of datasets </span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(AER))</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Attach the DoctorVisits data to make it usable</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"DoctorVisits"</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>lm_obj <span class="ot">&lt;-</span> <span class="fu">lm</span>(visits <span class="sc">~</span> gender <span class="sc">+</span> age <span class="sc">+</span> income, <span class="at">data =</span> DoctorVisits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The above <code>R</code> codes estimate the following regression model <span class="math display">\[
Y_i = \beta_1 + \beta_{gender} X_{gender,i}
              + \beta_{age} X_{age,i}
              + \beta_{income} X_{income,i} + \varepsilon_i,
\]</span> where <span class="math inline">\(i=1,\dots,n\)</span> and</p>
<ul>
<li><span class="math inline">\(X_{gender,i}=1\)</span> if the <span class="math inline">\(i\)</span>th subject is a woman and <span class="math inline">\(X_{gender,i}=0\)</span> if the <span class="math inline">\(i\)</span>th subject is a man</li>
<li><span class="math inline">\(X_{age,i}\)</span> is the age of subject <span class="math inline">\(i\)</span> measured in years divided by <span class="math inline">\(100\)</span></li>
<li><span class="math inline">\(X_{income,i}\)</span> is the annual income of subject <span class="math inline">\(i\)</span> in tens of thousands of dollars</li>
</ul>
<p>The following <code>R</code> codes produces the classic regression output table (simular tables are produced by all statistical/econometric software packages):</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-21_bb92ba764cbe646ddf4b0420d3393b94">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>lm_obj_summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(lm_obj)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>lm_obj_summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = visits ~ gender + age + income, data = DoctorVisits)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.5009 -0.3435 -0.2306 -0.1682  8.6174 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   0.15371    0.03607   4.262 2.07e-05 ***
genderfemale  0.06245    0.02345   2.662  0.00778 ** 
age           0.40235    0.05713   7.043 2.13e-12 ***
income       -0.08231    0.03167  -2.599  0.00938 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.7908 on 5186 degrees of freedom
Multiple R-squared:  0.01885,   Adjusted R-squared:  0.01829 
F-statistic: 33.22 on 3 and 5186 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The above regression output table contains the following information:</p>
<ul>
<li><p><strong>Estimate:</strong> The column “Estimate” containes the estimates <span class="math display">\[
\hat\beta_{j},\quad j\in\{1,gender, age, income\}
\]</span> You can extract them using <code>coef(lm_obj)</code>.</p></li>
<li><p><strong>Std. Error:</strong> The column “Std. Error” containes the estimates <span class="math display">\[
\widehat{\operatorname{SE}}(\hat\beta_{j}|X),\quad j\in\{1,gender, age, income\}
\]</span></p>
<ul>
<li>You can extract the total <span class="math inline">\((K\times K)=(4\times 4)\)</span> variance-covariance matrix estimate <span class="math inline">\(\widehat{Var}(\hat\beta|X)\)</span> using <code>vcov(lm_obj)</code>.</li>
<li>The diagonal <code>diag(vcov(lm_obj))</code> contains the variance estimates <span class="math inline">\(\widehat{Var}(\hat\beta_j|X)\)</span>, <span class="math inline">\(j\in\{1,gender, age, income\}\)</span>.</li>
<li>The square root of the diagonal <code>sqrt(diag(vcov(lm_obj)))</code> allows you to compute the estimated standard errors shown in the regression table.</li>
</ul></li>
<li><p><strong>t value:</strong> The column “t value” contains the observed <span class="math inline">\(t\)</span> test statistics <span class="math display">\[
t_{obs,j}=\frac{\hat\beta_{j}}{\widehat{\operatorname{SE}}(\hat\beta_{j}|X)},\quad j\in\{1,gender, age, income\}
\]</span> You can extract the values using <code>lm_obj_summary$coefficients[,3]</code>.</p></li>
<li><p><strong>Pr(&gt;|t|):</strong> The column “Pr(&gt;|t|)” contains the <span class="math inline">\(p\)</span> values <span class="math display">\[
P_{H_0}(|t|&gt;t_{obs,j}),\quad j\in\{1,gender, age, income\}
\]</span> You can extract the values using <code>lm_obj_summary$coefficients[,4]</code>.</p></li>
<li><p><strong>Residual standard error</strong> <span class="math inline">\(\sqrt{\frac{1}{n-K}\sum_{i=1}^n\hat\varepsilon^2_i}=\)</span> <code>sqrt(sum(resid(lm_obj)^2)/(n-4))</code> <span class="math inline">\(=\)</span> 0.7908</p></li>
<li><p><strong>Multiple R-squared:</strong> <span class="math inline">\(R^2=\)</span> <code>lm_obj_summary$r.squared</code> <span class="math inline">\(=\)</span> 0.01885</p></li>
<li><p><strong>Adjusted R-squared:</strong> <span class="math inline">\(\bar{R}^2=\)</span> <code>lm_obj_summary$adj.r.squared</code> <span class="math inline">\(=\)</span> 0.01829</p></li>
<li><p><strong>F-statistic:</strong> This is a standard <span class="math inline">\(F\)</span> test that tests the null hypothesis that all parameters except the intercept are zero; i.e.<br> <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_{gender}=\beta_{age}=\beta_{income}=0\)</span><br> versus<br> <span class="math inline">\(H_A\)</span>: At least one parameter is not zero.<br><br> You can replicate this test result using the following <code>R</code> code:</p></li>
</ul>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-22_0427157a7635453e30913adc56b7a914">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">model =</span> lm_obj, </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">hypothesis.matrix =</span> <span class="fu">c</span>(<span class="st">"genderfemale=0"</span>, <span class="st">"age=0"</span>, <span class="st">"income=0"</span>))  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<!-- #### Interpretation of $\hat\beta_{gender}$ {-} -->
<!-- Since $X_{gender,i}$ is a dummy variable,  -->
<section id="r-package-stargazer" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="r-package-stargazer"><code>R</code> Package Stargazer</h4>
<p>A more beautiful and “publication ready” regression output can be produced using the <code>R</code> package <code>stargazer</code> and its function <code>stargazer()</code>:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-23_845d03b820119507338a9260c8f7281a">

</div>
<center>
<div class="cell" data-ech="true" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-24_2b57864286bda5a2b91d36358011018a">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Hint: use type = "latex" to produce a latex table</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="fu">stargazer</span>(lm_obj, <span class="at">type=</span><span class="st">"html"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<table style="text-align:center">
<tbody><tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
visits
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
genderfemale
</td>
<td>
0.062<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.023)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
age
</td>
<td>
0.402<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.057)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
income
</td>
<td>
-0.082<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.032)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
0.154<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.036)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
5,190
</td>
</tr>
<tr>
<td style="text-align:left">
R<sup>2</sup>
</td>
<td>
0.019
</td>
</tr>
<tr>
<td style="text-align:left">
Adjusted R<sup>2</sup>
</td>
<td>
0.018
</td>
</tr>
<tr>
<td style="text-align:left">
Residual Std. Error
</td>
<td>
0.791 (df = 5186)
</td>
</tr>
<tr>
<td style="text-align:left">
F Statistic
</td>
<td>
33.218<sup>***</sup> (df = 3; 5186)
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
<em>Note:</em>
</td>
<td style="text-align:right">
<sup><em></em></sup><em>p&lt;0.1; <sup><strong></strong></sup><strong>p&lt;0.05; <sup></sup></strong></em>p&lt;0.01
</td>
</tr>

</tbody></table>
</div>
</center>
</section>
<section id="critical-discussion-of-the-regression-results" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="critical-discussion-of-the-regression-results"><span class="header-section-number">5.6.1</span> Critical Discussion of the Regression Results</h3>
<p>The above real data analysis does <strong>not</strong> fit into the small sample inference framework we introduced in this chapter.</p>
<ol type="1">
<li>The dependent variable <span class="math inline">\(Y_i\)</span> <code>visits</code> is a <em>categorial</em> variable taking finitely many discrete values <code>unique(DoctorVisits$visits)</code> = 1, 2, 3, 4, 8, 5, 7, 6, 9, 0. Consequently, the error term <span class="math inline">\(\varepsilon_i\)</span> <strong>cannot be normal distributed</strong>.</li>
<li>The diagnostic plot (“Residuals versus Fitted”) indicates a possible issue <strong>violation of the homoskedasticity assumption</strong>. In case of homokedastic variances, the data points <span class="math inline">\((\hat\varepsilon_i,\hat{Y}_i)\)</span>, <span class="math inline">\(i=1,\dots,n\)</span> should roughly show a homogenous scattering across the fitted values <span class="math inline">\(\hat{Y}_i=X\hat\beta\)</span>. This seems not to be the case here.</li>
</ol>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-25_c84067bad668409ebdb832a3be109dfb">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_obj, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Lukily, the data set <code>DoctorVisits</code> has a really <strong>large sample size</strong> of <span class="math inline">\(n=\)</span> 5190 and thus there is a way out of this problem: The large sample inference framework introduced in the next chapter.</p>
</section>
</section>
<section id="exercises" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="exercises"><span class="header-section-number">5.7</span> Exercises</h2>
<ul>
<li><a href="Exercises/Ch5_Exercises.pdf">Exercises for Chapter 5</a></li>
</ul>
<!-- * [Exercises of Chapter 5 with Solutions](Exercises/Ch5_Exercises_with_Solutions.pdf) -->
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Hayashi2000" class="csl-entry" role="doc-biblioentry">
Hayashi, Fumio. 2000. <em>Econometrics</em>. Princeton University Press.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./04-Monte-Carlo-Simulations.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Monte Carlo Simulations</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./06-Asymptotics.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Large Sample Inference</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>