<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8.2 Nonlinear Functions of a Single Independent Variable | Advanced Regression Analysis</title>
  <meta name="description" content="8.2 Nonlinear Functions of a Single Independent Variable | Advanced Regression Analysis" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="8.2 Nonlinear Functions of a Single Independent Variable | Advanced Regression Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/mylogo.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8.2 Nonlinear Functions of a Single Independent Variable | Advanced Regression Analysis" />
  
  
  <meta name="twitter:image" content="images/mylogo.png" />

<meta name="author" content="Dominik Liebl" />


<meta name="date" content="2020-09-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="8-1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"/>
<link rel="next" href="8-3-interactions-between-independent-variables.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><a href="http://www.dliebl.com/AdvRA/"><img src="images/mylogo.png" alt="logo" width="100%" height="100%"style="margin: 15px 0 0 0"></a></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-a-very-short-introduction-to-r-and-rstudio.html"><a href="1-a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
<li class="chapter" data-level="2" data-path="2-pt.html"><a href="2-pt.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="2.1" data-path="2-1-random-variables-and-probability-distributions.html"><a href="2-1-random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="2-1-random-variables-and-probability-distributions.html"><a href="2-1-random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="2-1-random-variables-and-probability-distributions.html"><a href="2-1-random-variables-and-probability-distributions.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="2-1-random-variables-and-probability-distributions.html"><a href="2-1-random-variables-and-probability-distributions.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
<li class="chapter" data-level="" data-path="2-1-random-variables-and-probability-distributions.html"><a href="2-1-random-variables-and-probability-distributions.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a></li>
<li class="chapter" data-level="" data-path="2-1-random-variables-and-probability-distributions.html"><a href="2-1-random-variables-and-probability-distributions.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="2-1-random-variables-and-probability-distributions.html"><a href="2-1-random-variables-and-probability-distributions.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="2-1-random-variables-and-probability-distributions.html"><a href="2-1-random-variables-and-probability-distributions.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="2-1-random-variables-and-probability-distributions.html"><a href="2-1-random-variables-and-probability-distributions.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-2-RSATDOSA.html"><a href="2-2-RSATDOSA.html"><i class="fa fa-check"></i><b>2.2</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="2-2-RSATDOSA.html"><a href="2-2-RSATDOSA.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="2-2-RSATDOSA.html"><a href="2-2-RSATDOSA.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-3-exercises-2.html"><a href="2-3-exercises-2.html"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-arosur.html"><a href="3-arosur.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="3.1" data-path="3-1-estimation-of-the-population-mean.html"><a href="3-1-estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="3-2-potsm.html"><a href="3-2-potsm.html"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="3-3-hypothesis-tests-concerning-the-population-mean.html"><a href="3-3-hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li class="chapter" data-level="" data-path="3-3-hypothesis-tests-concerning-the-population-mean.html"><a href="3-3-hypothesis-tests-concerning-the-population-mean.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="3-3-hypothesis-tests-concerning-the-population-mean.html"><a href="3-3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="3-3-hypothesis-tests-concerning-the-population-mean.html"><a href="3-3-hypothesis-tests-concerning-the-population-mean.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="3-3-hypothesis-tests-concerning-the-population-mean.html"><a href="3-3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="3-3-hypothesis-tests-concerning-the-population-mean.html"><a href="3-3-hypothesis-tests-concerning-the-population-mean.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="3-3-hypothesis-tests-concerning-the-population-mean.html"><a href="3-3-hypothesis-tests-concerning-the-population-mean.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="3-3-hypothesis-tests-concerning-the-population-mean.html"><a href="3-3-hypothesis-tests-concerning-the-population-mean.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-4-confidence-intervals-for-the-population-mean.html"><a href="3-4-confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.5" data-path="3-5-cmfdp.html"><a href="3-5-cmfdp.html"><i class="fa fa-check"></i><b>3.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.6" data-path="3-6-aattggoe.html"><a href="3-6-aattggoe.html"><i class="fa fa-check"></i><b>3.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.7" data-path="3-7-scatterplots-sample-covariance-and-sample-correlation.html"><a href="3-7-scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>3.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.8" data-path="3-8-exercises-3.html"><a href="3-8-exercises-3.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-lrwor.html"><a href="4-lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="4.1" data-path="4-1-simple-linear-regression.html"><a href="4-1-simple-linear-regression.html"><i class="fa fa-check"></i><b>4.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="4.2" data-path="4-2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="4-2-estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>4.2</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="4-2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="4-2-estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-3-measures-of-fit.html"><a href="4-3-measures-of-fit.html"><i class="fa fa-check"></i><b>4.3</b> Measures of Fit</a><ul>
<li class="chapter" data-level="" data-path="4-3-measures-of-fit.html"><a href="4-3-measures-of-fit.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="4-3-measures-of-fit.html"><a href="4-3-measures-of-fit.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="4-3-measures-of-fit.html"><a href="4-3-measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-4-tlsa.html"><a href="4-4-tlsa.html"><i class="fa fa-check"></i><b>4.4</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="4-4-tlsa.html"><a href="4-4-tlsa.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="4-4-tlsa.html"><a href="4-4-tlsa.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="4-4-tlsa.html"><a href="4-4-tlsa.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-5-tsdotoe.html"><a href="4-5-tsdotoe.html"><i class="fa fa-check"></i><b>4.5</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="4-5-tsdotoe.html"><a href="4-5-tsdotoe.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="4-5-tsdotoe.html"><a href="4-5-tsdotoe.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="4-5-tsdotoe.html"><a href="4-5-tsdotoe.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4-6-exercises-4.html"><a href="4-6-exercises-4.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-htaciitslrm.html"><a href="5-htaciitslrm.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="5.1" data-path="5-1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="5-1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="5.2" data-path="5-2-cifrc.html"><a href="5-2-cifrc.html"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="5-2-cifrc.html"><a href="5-2-cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-3-rwxiabv.html"><a href="5-3-rwxiabv.html"><i class="fa fa-check"></i><b>5.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="5-4-hah.html"><a href="5-4-hah.html"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="5-4-hah.html"><a href="5-4-hah.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="5-4-hah.html"><a href="5-4-hah.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="5-4-hah.html"><a href="5-4-hah.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="5-5-the-gauss-markov-theorem.html"><a href="5-5-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="5-5-the-gauss-markov-theorem.html"><a href="5-5-the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="5-6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="5-6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>5.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="5.7" data-path="5-7-exercises-5.html"><a href="5-7-exercises-5.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-rmwmr.html"><a href="6-rmwmr.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="6.1" data-path="6-1-omitted-variable-bias.html"><a href="6-1-omitted-variable-bias.html"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="6-2-tmrm.html"><a href="6-2-tmrm.html"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="6-3-mofimr.html"><a href="6-3-mofimr.html"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="6-4-ols-assumptions-in-multiple-regression.html"><a href="6-4-ols-assumptions-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="6-4-ols-assumptions-in-multiple-regression.html"><a href="6-4-ols-assumptions-in-multiple-regression.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="6-4-ols-assumptions-in-multiple-regression.html"><a href="6-4-ols-assumptions-in-multiple-regression.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><a href="6-5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="6.6" data-path="6-6-exercises-6.html"><a href="6-6-exercises-6.html"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-htaciimr.html"><a href="7-htaciimr.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence Intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="7-1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><a href="7-1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="7-2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="7-2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="7-2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="7-2-an-application-to-test-scores-and-the-student-teacher-ratio.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-3-joint-hypothesis-testing-using-the-f-statistic.html"><a href="7-3-joint-hypothesis-testing-using-the-f-statistic.html"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the F-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="7-4-confidence-sets-for-multiple-coefficients.html"><a href="7-4-confidence-sets-for-multiple-coefficients.html"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="7-5-model-specification-for-multiple-regression.html"><a href="7-5-model-specification-for-multiple-regression.html"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="7-5-model-specification-for-multiple-regression.html"><a href="7-5-model-specification-for-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="7-6-analysis-of-the-test-score-data-set.html"><a href="7-6-analysis-of-the-test-score-data-set.html"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="7.7" data-path="7-7-exercises-7.html"><a href="7-7-exercises-7.html"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-nrf.html"><a href="8-nrf.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="8.1" data-path="8-1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><a href="8-1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="8-2-nfoasiv.html"><a href="8-2-nfoasiv.html"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="8-2-nfoasiv.html"><a href="8-2-nfoasiv.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="8-2-nfoasiv.html"><a href="8-2-nfoasiv.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-3-interactions-between-independent-variables.html"><a href="8-3-interactions-between-independent-variables.html"><i class="fa fa-check"></i><b>8.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="8-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="8-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
<li class="chapter" data-level="8.5" data-path="8-5-exercises-8.html"><a href="8-5-exercises-8.html"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-asbomr.html"><a href="9-asbomr.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="9-1-internal-and-external-validity.html"><a href="9-1-internal-and-external-validity.html"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="9-2-ttivomra.html"><a href="9-2-ttivomra.html"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="9-3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><a href="9-3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity when the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="9-4-etsacs.html"><a href="9-4-etsacs.html"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
<li class="chapter" data-level="9.5" data-path="9-5-exercises-9.html"><a href="9-5-exercises-9.html"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-rwpd.html"><a href="10-rwpd.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="10.1" data-path="10-1-panel-data.html"><a href="10-1-panel-data.html"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="10-2-PDWTTP.html"><a href="10-2-PDWTTP.html"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="10-3-fixed-effects-regression.html"><a href="10-3-fixed-effects-regression.html"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="10-3-fixed-effects-regression.html"><a href="10-3-fixed-effects-regression.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="10-3-fixed-effects-regression.html"><a href="10-3-fixed-effects-regression.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10-4-regression-with-time-fixed-effects.html"><a href="10-4-regression-with-time-fixed-effects.html"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="10-5-tferaaseffer.html"><a href="10-5-tferaaseffer.html"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="10-6-drunk-driving-laws-and-traffic-deaths.html"><a href="10-6-drunk-driving-laws-and-traffic-deaths.html"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
<li class="chapter" data-level="10.7" data-path="10-7-exercises-10.html"><a href="10-7-exercises-10.html"><i class="fa fa-check"></i><b>10.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-rwabdv.html"><a href="11-rwabdv.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="11.1" data-path="11-1-binary-dependent-variables-and-the-linear-probability-model.html"><a href="11-1-binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="11-2-palr.html"><a href="11-2-palr.html"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="11-2-palr.html"><a href="11-2-palr.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="11-2-palr.html"><a href="11-2-palr.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-3-estimation-and-inference-in-the-logit-and-probit-models.html"><a href="11-3-estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="11-4-application-to-the-boston-hmda-data.html"><a href="11-4-application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
<li class="chapter" data-level="11.5" data-path="11-5-exercises-11.html"><a href="11-5-exercises-11.html"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-ivr.html"><a href="12-ivr.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="12-1-TIVEWASRAASI.html"><a href="12-1-TIVEWASRAASI.html"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="12-2-TGIVRM.html"><a href="12-2-TGIVRM.html"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="12-3-civ.html"><a href="12-3-civ.html"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="12-4-attdfc.html"><a href="12-4-attdfc.html"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="12-5-where-do-valid-instruments-come-from.html"><a href="12-5-where-do-valid-instruments-come-from.html"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
<li class="chapter" data-level="12.6" data-path="12-6-exercises-12.html"><a href="12-6-exercises-12.html"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-eaqe.html"><a href="13-eaqe.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="13.1" data-path="13-1-poceaie.html"><a href="13-1-poceaie.html"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="13-2-threats-to-validity-of-experiments.html"><a href="13-2-threats-to-validity-of-experiments.html"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="13-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="13-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="13-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="13-3-experimental-estimates-of-the-effect-of-class-size-reductions.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="13-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="13-3-experimental-estimates-of-the-effect-of-class-size-reductions.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="13-4-qe.html"><a href="13-4-qe.html"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="13-4-qe.html"><a href="13-4-qe.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="13-4-qe.html"><a href="13-4-qe.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="13-5-exercises-13.html"><a href="13-5-exercises-13.html"><i class="fa fa-check"></i><b>13.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-ittsraf.html"><a href="14-ittsraf.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="14.1" data-path="14-1-using-regression-models-for-forecasting.html"><a href="14-1-using-regression-models-for-forecasting.html"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="14-2-tsdasc.html"><a href="14-2-tsdasc.html"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="14-2-tsdasc.html"><a href="14-2-tsdasc.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="14-3-autoregressions.html"><a href="14-3-autoregressions.html"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a><ul>
<li><a href="14-3-autoregressions.html#autoregressive-models-of-order-p">Autoregressive Models of Order <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="14-4-cybtmpi.html"><a href="14-4-cybtmpi.html"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="14-5-apatadlm.html"><a href="14-5-apatadlm.html"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="14-5-apatadlm.html"><a href="14-5-apatadlm.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="14-6-llsuic.html"><a href="14-6-llsuic.html"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="14-7-nit.html"><a href="14-7-nit.html"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="14-8-niib.html"><a href="14-8-niib.html"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="14-9-can-you-beat-the-market-part-ii.html"><a href="14-9-can-you-beat-the-market-part-ii.html"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-eodce.html"><a href="15-eodce.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="15.1" data-path="15-1-the-orange-juice-data.html"><a href="15-1-the-orange-juice-data.html"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="15-2-dynamic-causal-effects.html"><a href="15-2-dynamic-causal-effects.html"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="15-3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><a href="15-3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="15-4-hac-standard-errors.html"><a href="15-4-hac-standard-errors.html"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="15-5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><a href="15-5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="15-6-orange-juice-prices-and-cold-weather.html"><a href="15-6-orange-juice-prices-and-cold-weather.html"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="16-atitsr.html"><a href="16-atitsr.html"><i class="fa fa-check"></i><b>16</b> Additional Topics in Time Series Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="16-1-vector-autoregressions.html"><a href="16-1-vector-autoregressions.html"><i class="fa fa-check"></i><b>16.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="16.2" data-path="16-2-ooiatdfglsurt.html"><a href="16-2-ooiatdfglsurt.html"><i class="fa fa-check"></i><b>16.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="16.3" data-path="16-3-cointegration.html"><a href="16-3-cointegration.html"><i class="fa fa-check"></i><b>16.3</b> Cointegration</a></li>
<li class="chapter" data-level="16.4" data-path="16-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><i class="fa fa-check"></i><b>16.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a><ul>
<li class="chapter" data-level="" data-path="16-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="16-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="16-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
<li class="chapter" data-level="" data-path="8-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="8-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Regression Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nfoasiv" class="section level2">
<h2><span class="header-section-number">8.2</span> Nonlinear Functions of a Single Independent Variable</h2>
<div id="polynomials" class="section level3 unnumbered">
<h3>Polynomials</h3>
<p>The approach used to obtain a quadratic model can be generalized to polynomial models of arbitrary degree <span class="math inline">\(r\)</span>,
<span class="math display">\[Y_i = \beta_0 + \beta_1 X_i + \beta_2 X_i^2 + \cdots + \beta_r X_i^r + u_i.\]</span></p>
<p>A cubic model for instance can be estimated in the same way as the quadratic model; we just have to use a polynomial of degree <span class="math inline">\(r=3\)</span> in <tt>income</tt>. This is conveniently done using the function <tt>poly()</tt>.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" data-line-number="1"><span class="co"># estimate a cubic model</span></a>
<a class="sourceLine" id="cb177-2" data-line-number="2">cubic_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(income, <span class="dt">degree =</span> <span class="dv">3</span>, <span class="dt">raw =</span> <span class="ot">TRUE</span>), <span class="dt">data =</span> CASchools)</a></code></pre></div>
<p><tt>poly()</tt> generates orthogonal polynomials which are orthogonal to the constant by default. Here, we set <tt>raw = TRUE</tt> such that raw polynomials are evaluated, see <code>?poly</code>.</p>
<p>In practice the question will arise which polynomial order should be chosen. First, similarly as for <span class="math inline">\(r=2\)</span>, we can test the null hypothesis that the true relation is linear against the alternative hypothesis that the relationship is a polynomial of degree <span class="math inline">\(r\)</span>:</p>
<p><span class="math display">\[ H_0: \beta_2=0, \ \beta_3=0,\dots,\beta_r=0 \ \ \ \text{vs.} \ \ \ H_1: \text{at least one} \ \beta_j\neq0, \ j=2,\dots,r \]</span></p>
<p>This is a joint null hypothesis with <span class="math inline">\(r-1\)</span> restrictions so it can be tested using the <span class="math inline">\(F\)</span>-test presented in Chapter <a href="7-htaciimr.html#htaciimr">7</a>. <tt>linearHypothesis()</tt> can be used to conduct such tests. For example, we may test the null of a linear model against the alternative of a polynomial of a maximal degree <span class="math inline">\(r=3\)</span> as follows.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb178-1" data-line-number="1"><span class="co"># test the hypothesis of a linear model against quadratic or polynomial</span></a>
<a class="sourceLine" id="cb178-2" data-line-number="2"><span class="co"># alternatives</span></a>
<a class="sourceLine" id="cb178-3" data-line-number="3"></a>
<a class="sourceLine" id="cb178-4" data-line-number="4"><span class="co"># set up hypothesis matrix</span></a>
<a class="sourceLine" id="cb178-5" data-line-number="5">R &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb178-6" data-line-number="6">            <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb178-7" data-line-number="7"></a>
<a class="sourceLine" id="cb178-8" data-line-number="8"><span class="co"># do the test</span></a>
<a class="sourceLine" id="cb178-9" data-line-number="9"><span class="kw">linearHypothesis</span>(cubic_model,</a>
<a class="sourceLine" id="cb178-10" data-line-number="10">                 <span class="dt">hypothesis.matrix =</span> R,</a>
<a class="sourceLine" id="cb178-11" data-line-number="11">                 <span class="dt">white.adj =</span> <span class="st">&quot;hc1&quot;</span>)</a>
<a class="sourceLine" id="cb178-12" data-line-number="12"><span class="co">#&gt; Linear hypothesis test</span></a>
<a class="sourceLine" id="cb178-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb178-14" data-line-number="14"><span class="co">#&gt; Hypothesis:</span></a>
<a class="sourceLine" id="cb178-15" data-line-number="15"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2 = 0</span></a>
<a class="sourceLine" id="cb178-16" data-line-number="16"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3 = 0</span></a>
<a class="sourceLine" id="cb178-17" data-line-number="17"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb178-18" data-line-number="18"><span class="co">#&gt; Model 1: restricted model</span></a>
<a class="sourceLine" id="cb178-19" data-line-number="19"><span class="co">#&gt; Model 2: score ~ poly(income, degree = 3, raw = TRUE)</span></a>
<a class="sourceLine" id="cb178-20" data-line-number="20"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb178-21" data-line-number="21"><span class="co">#&gt; Note: Coefficient covariance matrix supplied.</span></a>
<a class="sourceLine" id="cb178-22" data-line-number="22"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb178-23" data-line-number="23"><span class="co">#&gt;   Res.Df Df      F    Pr(&gt;F)    </span></a>
<a class="sourceLine" id="cb178-24" data-line-number="24"><span class="co">#&gt; 1    418                        </span></a>
<a class="sourceLine" id="cb178-25" data-line-number="25"><span class="co">#&gt; 2    416  2 37.691 9.043e-16 ***</span></a>
<a class="sourceLine" id="cb178-26" data-line-number="26"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb178-27" data-line-number="27"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>We provide a hypothesis matrix as the argument <tt>hypothesis.matrix</tt>. This is useful when the coefficients have long names, as is the case here due to using <tt>poly()</tt>, or when the restrictions include multiple coefficients. How the hypothesis matrix <span class="math inline">\(\mathbf{R}\)</span> is interpreted by <tt>linearHypothesis()</tt> is best seen using matrix algebra:</p>
<p>For the two linear constrains above, we have
<span class="math display">\[\begin{align*}
  \mathbf{R}\boldsymbol{\beta} =&amp; \mathbf{s} \\
  \begin{pmatrix}
    0 &amp; 0 &amp; 1 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 1
  \end{pmatrix}
  \begin{pmatrix}
    \beta_0 \\
    \beta_1 \\
    \beta_2 \\
    \beta_3 \\
  \end{pmatrix} =&amp;
  \begin{pmatrix}
   0 \\
   0
  \end{pmatrix} \\
  \begin{pmatrix}
    \beta_2 \\
    \beta_3
  \end{pmatrix}= &amp;
  \begin{pmatrix}
    0 \\
    0
  \end{pmatrix}.
\end{align*}\]</span>
<tt>linearHypothesis()</tt> uses the zero vector for <span class="math inline">\(\mathbf{s}\)</span> by default, see <code>?linearHypothesis</code>.</p>
<p>The <span class="math inline">\(p\)</span>-value for is very small so that we reject the null hypothesis. However, this does not tell us <em>which</em> <span class="math inline">\(r\)</span> to choose. In practice, one approach to determine the degree of the polynomial is to use <em>sequential testing</em>:</p>
<ol style="list-style-type: decimal">
<li>Estimate a polynomial model for some maximum value <span class="math inline">\(r\)</span>.</li>
<li>Use a <span class="math inline">\(t\)</span>-test to test <span class="math inline">\(\beta_r = 0\)</span>. <em>Rejection</em> of the null means that <span class="math inline">\(X^r\)</span> belongs in the regression equation.</li>
<li><em>Acceptance</em> of the null in step 2 means that <span class="math inline">\(X^r\)</span> can be eliminated from the model. Continue by repeating step 1 with order <span class="math inline">\(r-1\)</span> and test whether <span class="math inline">\(\beta_{r-1}=0\)</span>. If the test rejects, use a polynomial model of order <span class="math inline">\(r-1\)</span>.</li>
<li>If the tests from step 3 rejects, continue with the procedure until the coefficient on the highest power is statistically significant.</li>
</ol>
<p>There is no unambiguous guideline how to choose <span class="math inline">\(r\)</span> in step one. However, as pointed out in <span class="citation">Stock and Watson (<a href="#ref-stock2015">2015</a>)</span>, economic data is often smooth such that it is appropriate to choose small orders like <span class="math inline">\(2\)</span>, <span class="math inline">\(3\)</span>, or <span class="math inline">\(4\)</span>.</p>
<p>We will demonstrate how to apply sequential testing by the example of the cubic model.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb179-1" data-line-number="1"><span class="kw">summary</span>(cubic_model)</a>
<a class="sourceLine" id="cb179-2" data-line-number="2"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb179-3" data-line-number="3"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb179-4" data-line-number="4"><span class="co">#&gt; lm(formula = score ~ poly(income, degree = 3, raw = TRUE), data = CASchools)</span></a>
<a class="sourceLine" id="cb179-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb179-6" data-line-number="6"><span class="co">#&gt; Residuals:</span></a>
<a class="sourceLine" id="cb179-7" data-line-number="7"><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></a>
<a class="sourceLine" id="cb179-8" data-line-number="8"><span class="co">#&gt; -44.28  -9.21   0.20   8.32  31.16 </span></a>
<a class="sourceLine" id="cb179-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb179-10" data-line-number="10"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb179-11" data-line-number="11"><span class="co">#&gt;                                         Estimate Std. Error t value</span></a>
<a class="sourceLine" id="cb179-12" data-line-number="12"><span class="co">#&gt; (Intercept)                            6.001e+02  5.830e+00 102.937</span></a>
<a class="sourceLine" id="cb179-13" data-line-number="13"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)1  5.019e+00  8.595e-01   5.839</span></a>
<a class="sourceLine" id="cb179-14" data-line-number="14"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2 -9.581e-02  3.736e-02  -2.564</span></a>
<a class="sourceLine" id="cb179-15" data-line-number="15"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3  6.855e-04  4.720e-04   1.452</span></a>
<a class="sourceLine" id="cb179-16" data-line-number="16"><span class="co">#&gt;                                       Pr(&gt;|t|)    </span></a>
<a class="sourceLine" id="cb179-17" data-line-number="17"><span class="co">#&gt; (Intercept)                            &lt; 2e-16 ***</span></a>
<a class="sourceLine" id="cb179-18" data-line-number="18"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)1 1.06e-08 ***</span></a>
<a class="sourceLine" id="cb179-19" data-line-number="19"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2   0.0107 *  </span></a>
<a class="sourceLine" id="cb179-20" data-line-number="20"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3   0.1471    </span></a>
<a class="sourceLine" id="cb179-21" data-line-number="21"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb179-22" data-line-number="22"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a>
<a class="sourceLine" id="cb179-23" data-line-number="23"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb179-24" data-line-number="24"><span class="co">#&gt; Residual standard error: 12.71 on 416 degrees of freedom</span></a>
<a class="sourceLine" id="cb179-25" data-line-number="25"><span class="co">#&gt; Multiple R-squared:  0.5584,	Adjusted R-squared:  0.5552 </span></a>
<a class="sourceLine" id="cb179-26" data-line-number="26"><span class="co">#&gt; F-statistic: 175.4 on 3 and 416 DF,  p-value: &lt; 2.2e-16</span></a></code></pre></div>
<p>The estimated cubic model stored in <tt>cubic_model</tt> is</p>
<p><span class="math display">\[ \widehat{TestScore}_i = \underset{(5.83)}{600.1} + \underset{(0.86)}{5.02} \times income -\underset{(0.03)}{0.96} \times income^2 - \underset{(0.00047)}{0.00069} \times income^3. \]</span></p>
<p>The <span class="math inline">\(t\)</span>-statistic on <span class="math inline">\(income^3\)</span> is <span class="math inline">\(1.42\)</span> so the null that the relationship is quadratic cannot be rejected, even at the <span class="math inline">\(10\%\)</span> level. This is contrary to the result presented book which reports robust standard errors throughout so we will also use robust variance-covariance estimation to reproduce these results.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb180-1" data-line-number="1"><span class="co"># test the hypothesis using robust standard errors</span></a>
<a class="sourceLine" id="cb180-2" data-line-number="2"><span class="kw">coeftest</span>(cubic_model, <span class="dt">vcov. =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</a>
<a class="sourceLine" id="cb180-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb180-4" data-line-number="4"><span class="co">#&gt; t test of coefficients:</span></a>
<a class="sourceLine" id="cb180-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb180-6" data-line-number="6"><span class="co">#&gt;                                          Estimate  Std. Error  t value</span></a>
<a class="sourceLine" id="cb180-7" data-line-number="7"><span class="co">#&gt; (Intercept)                            6.0008e+02  5.1021e+00 117.6150</span></a>
<a class="sourceLine" id="cb180-8" data-line-number="8"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)1  5.0187e+00  7.0735e-01   7.0950</span></a>
<a class="sourceLine" id="cb180-9" data-line-number="9"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2 -9.5805e-02  2.8954e-02  -3.3089</span></a>
<a class="sourceLine" id="cb180-10" data-line-number="10"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3  6.8549e-04  3.4706e-04   1.9751</span></a>
<a class="sourceLine" id="cb180-11" data-line-number="11"><span class="co">#&gt;                                        Pr(&gt;|t|)    </span></a>
<a class="sourceLine" id="cb180-12" data-line-number="12"><span class="co">#&gt; (Intercept)                           &lt; 2.2e-16 ***</span></a>
<a class="sourceLine" id="cb180-13" data-line-number="13"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)1 5.606e-12 ***</span></a>
<a class="sourceLine" id="cb180-14" data-line-number="14"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2  0.001018 ** </span></a>
<a class="sourceLine" id="cb180-15" data-line-number="15"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3  0.048918 *  </span></a>
<a class="sourceLine" id="cb180-16" data-line-number="16"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb180-17" data-line-number="17"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>The reported standard errors have changed. Furthermore, the coefficient for <code>income^3</code> is now significant at the <span class="math inline">\(5\%\)</span> level. This means we reject the hypothesis that the regression function is quadratic against the alternative that it is cubic. Furthermore, we can also test if the coefficients for <tt>income^2</tt> and <tt>income^3</tt> are jointly significant using a robust version of the <span class="math inline">\(F\)</span>-test.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb181-1" data-line-number="1"><span class="co"># perform robust F-test </span></a>
<a class="sourceLine" id="cb181-2" data-line-number="2"><span class="kw">linearHypothesis</span>(cubic_model, </a>
<a class="sourceLine" id="cb181-3" data-line-number="3">                 <span class="dt">hypothesis.matrix =</span> R,</a>
<a class="sourceLine" id="cb181-4" data-line-number="4">                 <span class="dt">vcov. =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</a>
<a class="sourceLine" id="cb181-5" data-line-number="5"><span class="co">#&gt; Linear hypothesis test</span></a>
<a class="sourceLine" id="cb181-6" data-line-number="6"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb181-7" data-line-number="7"><span class="co">#&gt; Hypothesis:</span></a>
<a class="sourceLine" id="cb181-8" data-line-number="8"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)2 = 0</span></a>
<a class="sourceLine" id="cb181-9" data-line-number="9"><span class="co">#&gt; poly(income, degree = 3, raw = TRUE)3 = 0</span></a>
<a class="sourceLine" id="cb181-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb181-11" data-line-number="11"><span class="co">#&gt; Model 1: restricted model</span></a>
<a class="sourceLine" id="cb181-12" data-line-number="12"><span class="co">#&gt; Model 2: score ~ poly(income, degree = 3, raw = TRUE)</span></a>
<a class="sourceLine" id="cb181-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb181-14" data-line-number="14"><span class="co">#&gt; Note: Coefficient covariance matrix supplied.</span></a>
<a class="sourceLine" id="cb181-15" data-line-number="15"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb181-16" data-line-number="16"><span class="co">#&gt;   Res.Df Df      F    Pr(&gt;F)    </span></a>
<a class="sourceLine" id="cb181-17" data-line-number="17"><span class="co">#&gt; 1    418                        </span></a>
<a class="sourceLine" id="cb181-18" data-line-number="18"><span class="co">#&gt; 2    416  2 29.678 8.945e-13 ***</span></a>
<a class="sourceLine" id="cb181-19" data-line-number="19"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb181-20" data-line-number="20"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>With a <span class="math inline">\(p\)</span>-value of <span class="math inline">\(9.043e^{-16}\)</span>, i.e., much less than <span class="math inline">\(0.05\)</span>, the null hypothesis of linearity is rejected in favor of the alternative that the relationship is quadratic <em>or</em> cubic.</p>
<div id="interpretation-of-coefficients-in-nonlinear-regression-models" class="section level4 unnumbered">
<h4>Interpretation of Coefficients in Nonlinear Regression Models</h4>
<p>The coefficients in polynomial regression do not have a simple interpretation. Why? Think of a quadratic model: it is not helpful to think of the coefficient on <span class="math inline">\(X\)</span> as the expected change in <span class="math inline">\(Y\)</span> associated with a change in <span class="math inline">\(X\)</span> holding the other regressors constant because <span class="math inline">\(X^2\)</span> changes as <span class="math inline">\(X\)</span> varies. This is also the case for other deviations from linearity, for example in models where regressors and/or the dependent variable are log-transformed. A way to approach this is to calculate the estimated effect on <span class="math inline">\(Y\)</span> associated with a change in <span class="math inline">\(X\)</span> for one or more values of <span class="math inline">\(X\)</span>. This idea is summarized in Key Concept 8.1.</p>
<div id="KC8.1" class="keyconcept">
<h3 class="right">
Key Concept 8.1
</h3>
<h3 class="left">
The Expected Effect on <span class="math inline">\(Y\)</span> of a Change in <span class="math inline">\(X_1\)</span> in a Nonlinear Regression Model
</h3>
<p>Consider the nonlinear population regression model</p>
<p><span class="math display">\[ Y_i = f(X_{1i}, X_{2i}, \dots, X_{ki}) + u_i \ , \ i=1,\dots,n,\]</span></p>
<p>where <span class="math inline">\(f(X_{1i}, X_{2i}, \dots, X_{ki})\)</span> is the population regression function and <span class="math inline">\(u_i\)</span> is the error term.</p>
<p>Denote by <span class="math inline">\(\Delta Y\)</span> the expected change in <span class="math inline">\(Y\)</span> associated with <span class="math inline">\(\Delta X_1\)</span>, the change in <span class="math inline">\(X_1\)</span> while holding <span class="math inline">\(X_2, \cdots , X_k\)</span> constant. That is, the expected change in <span class="math inline">\(Y\)</span> is the difference</p>
<p><span class="math display">\[\Delta Y = f(X_1 + \Delta X_1, X_2, \cdots, X_k) - f(X_1, X_2, \cdots, X_k).\]</span></p>
<p>The estimator of this unknown population difference is the difference between the predicted values for these two cases. Let <span class="math inline">\(\hat{f}(X_1, X_2, \cdots, X_k)\)</span> be the predicted value of of <span class="math inline">\(Y\)</span> based on the estimator <span class="math inline">\(\hat{f}\)</span> of the population regression function. Then the predicted change in <span class="math inline">\(Y\)</span> is</p>
<span class="math display">\[\Delta \widehat{Y} = \hat{f}(X_1 + \Delta X_1, X_2, \cdots, X_k) - \hat{f}(X_1, X_2, \cdots, X_k).\]</span>
</p>
</div>
<p>For example, we may ask the following: what is the predicted change in test scores associated with a one unit change (i.e., <span class="math inline">\(\$1000\)</span>) in income, based on the estimated quadratic regression function</p>
<p><span class="math display">\[\widehat{TestScore} = 607.3 + 3.85 \times income - 0.0423 \times income^2\ ?\]</span></p>
<p>Because the regression function is quadratic, this effect depends on the <em>initial</em> district income. We therefore consider two cases:</p>
<ol style="list-style-type: decimal">
<li><p>An increase in district income form <span class="math inline">\(10\)</span> to <span class="math inline">\(11\)</span> (from <span class="math inline">\(\$10000\)</span> per capita to <span class="math inline">\(\$11000\)</span>).</p></li>
<li><p>An increase in district income from <span class="math inline">\(40\)</span> to <span class="math inline">\(41\)</span> (that is from <span class="math inline">\(\$40000\)</span> to <span class="math inline">\(\$41000\)</span>).</p></li>
</ol>
<p>In order to obtain the <span class="math inline">\(\Delta \widehat{Y}\)</span> associated with a change in income form <span class="math inline">\(10\)</span> to <span class="math inline">\(11\)</span>, we use the following formula:</p>
<p><span class="math display">\[\Delta \widehat{Y} = \left(\hat{\beta}_0 + \hat{\beta}_1 \times 11 + \hat{\beta}_2 \times 11^2\right) - \left(\hat{\beta}_0 + \hat{\beta}_1 \times 10 + \hat{\beta}_2 \times 10^2\right) \]</span>
To compute <span class="math inline">\(\widehat{Y}\)</span> using <tt>R</tt> we may use <tt>predict()</tt>.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb182-1" data-line-number="1"><span class="co"># compute and assign the quadratic model</span></a>
<a class="sourceLine" id="cb182-2" data-line-number="2">quadriatic_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(income<span class="op">^</span><span class="dv">2</span>), <span class="dt">data =</span> CASchools)</a>
<a class="sourceLine" id="cb182-3" data-line-number="3"></a>
<a class="sourceLine" id="cb182-4" data-line-number="4"><span class="co"># set up data for prediction</span></a>
<a class="sourceLine" id="cb182-5" data-line-number="5">new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">income =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">11</span>))</a>
<a class="sourceLine" id="cb182-6" data-line-number="6"></a>
<a class="sourceLine" id="cb182-7" data-line-number="7"><span class="co"># do the prediction</span></a>
<a class="sourceLine" id="cb182-8" data-line-number="8">Y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(quadriatic_model, <span class="dt">newdata =</span> new_data)</a>
<a class="sourceLine" id="cb182-9" data-line-number="9"></a>
<a class="sourceLine" id="cb182-10" data-line-number="10"><span class="co"># compute the difference</span></a>
<a class="sourceLine" id="cb182-11" data-line-number="11"><span class="kw">diff</span>(Y_hat)</a>
<a class="sourceLine" id="cb182-12" data-line-number="12"><span class="co">#&gt;        2 </span></a>
<a class="sourceLine" id="cb182-13" data-line-number="13"><span class="co">#&gt; 2.962517</span></a></code></pre></div>
<p>Analogously we can compute the effect of a change in district income from <span class="math inline">\(40\)</span> to <span class="math inline">\(41\)</span>:</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb183-1" data-line-number="1"><span class="co"># set up data for prediction</span></a>
<a class="sourceLine" id="cb183-2" data-line-number="2">new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">income =</span> <span class="kw">c</span>(<span class="dv">40</span>, <span class="dv">41</span>))</a>
<a class="sourceLine" id="cb183-3" data-line-number="3"></a>
<a class="sourceLine" id="cb183-4" data-line-number="4"><span class="co"># do the prediction</span></a>
<a class="sourceLine" id="cb183-5" data-line-number="5">Y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(quadriatic_model, <span class="dt">newdata =</span> new_data)</a>
<a class="sourceLine" id="cb183-6" data-line-number="6"></a>
<a class="sourceLine" id="cb183-7" data-line-number="7"><span class="co"># compute the difference</span></a>
<a class="sourceLine" id="cb183-8" data-line-number="8"><span class="kw">diff</span>(Y_hat)</a>
<a class="sourceLine" id="cb183-9" data-line-number="9"><span class="co">#&gt;         2 </span></a>
<a class="sourceLine" id="cb183-10" data-line-number="10"><span class="co">#&gt; 0.4240097</span></a></code></pre></div>
<p>So for the quadratic model, the expected change in <span class="math inline">\(TestScore\)</span> induced by an increase in <span class="math inline">\(income\)</span> from <span class="math inline">\(10\)</span> to <span class="math inline">\(11\)</span> is about <span class="math inline">\(2.96\)</span> points but an increase in <span class="math inline">\(income\)</span> from <span class="math inline">\(40\)</span> to <span class="math inline">\(41\)</span> increases the predicted score by only <span class="math inline">\(0.42\)</span>. Hence, the slope of the estimated quadratic regression function is <em>steeper</em> at low levels of income than at higher levels.</p>
</div>
</div>
<div id="logarithms" class="section level3 unnumbered">
<h3>Logarithms</h3>
<p>Another way to specify a nonlinear regression function is to use the natural logarithm of <span class="math inline">\(Y\)</span> and/or <span class="math inline">\(X\)</span>.
Logarithms convert changes in variables into percentage changes. This is convenient as many relationships are naturally expressed in terms of percentages.</p>
<p>There are three different cases in which logarithms might be used.</p>
<ol style="list-style-type: decimal">
<li><p>Transform <span class="math inline">\(X\)</span> with its logarithm, but not <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Analogously we could transform <span class="math inline">\(Y\)</span> to its logarithm but leave <span class="math inline">\(X\)</span> at level.</p></li>
<li><p>Both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are transformed to their logarithms.</p></li>
</ol>
<p>The interpretation of the regression coefficients is different in each case.</p>
<div id="case-i-x-is-in-logarithm-y-is-not." class="section level4 unnumbered">
<h4>Case I: <span class="math inline">\(X\)</span> is in Logarithm, <span class="math inline">\(Y\)</span> is not.</h4>
<p>The regression model then is <span class="math display">\[Y_i = \beta_0 + \beta_1 \times \ln(X_i) + u_i \text{, } i=1,...,n. \]</span> Similar as for polynomial regression we do not have to create a new variable before using <tt>lm()</tt>. We can simply adjust the
<tt>formula</tt> argument of <tt>lm()</tt> to tell <tt>R</tt> that the log-transformation of a variable should be used.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb184-1" data-line-number="1"><span class="co"># estimate a level-log model</span></a>
<a class="sourceLine" id="cb184-2" data-line-number="2">LinearLog_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(income), <span class="dt">data =</span> CASchools)</a>
<a class="sourceLine" id="cb184-3" data-line-number="3"></a>
<a class="sourceLine" id="cb184-4" data-line-number="4"><span class="co"># compute robust summary</span></a>
<a class="sourceLine" id="cb184-5" data-line-number="5"><span class="kw">coeftest</span>(LinearLog_model, </a>
<a class="sourceLine" id="cb184-6" data-line-number="6">         <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</a>
<a class="sourceLine" id="cb184-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb184-8" data-line-number="8"><span class="co">#&gt; t test of coefficients:</span></a>
<a class="sourceLine" id="cb184-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb184-10" data-line-number="10"><span class="co">#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)    </span></a>
<a class="sourceLine" id="cb184-11" data-line-number="11"><span class="co">#&gt; (Intercept) 557.8323     3.8399 145.271 &lt; 2.2e-16 ***</span></a>
<a class="sourceLine" id="cb184-12" data-line-number="12"><span class="co">#&gt; log(income)  36.4197     1.3969  26.071 &lt; 2.2e-16 ***</span></a>
<a class="sourceLine" id="cb184-13" data-line-number="13"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb184-14" data-line-number="14"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>Hence, the estimated regression function is</p>
<p><span class="math display">\[\widehat{TestScore} = 557.8 + 36.42 \times \ln(income).\]</span></p>
<p>Let us draw a plot of this function.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb185-1" data-line-number="1"><span class="co"># draw a scatterplot</span></a>
<a class="sourceLine" id="cb185-2" data-line-number="2"><span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>income, </a>
<a class="sourceLine" id="cb185-3" data-line-number="3">     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,</a>
<a class="sourceLine" id="cb185-4" data-line-number="4">     <span class="dt">pch =</span> <span class="dv">20</span>,</a>
<a class="sourceLine" id="cb185-5" data-line-number="5">     <span class="dt">data =</span> CASchools,</a>
<a class="sourceLine" id="cb185-6" data-line-number="6">     <span class="dt">main =</span> <span class="st">&quot;Linear-Log Regression Line&quot;</span>)</a>
<a class="sourceLine" id="cb185-7" data-line-number="7"></a>
<a class="sourceLine" id="cb185-8" data-line-number="8"><span class="co"># add the linear-log regression line</span></a>
<a class="sourceLine" id="cb185-9" data-line-number="9">order_id  &lt;-<span class="st"> </span><span class="kw">order</span>(CASchools<span class="op">$</span>income)</a>
<a class="sourceLine" id="cb185-10" data-line-number="10"></a>
<a class="sourceLine" id="cb185-11" data-line-number="11"><span class="kw">lines</span>(CASchools<span class="op">$</span>income[order_id],</a>
<a class="sourceLine" id="cb185-12" data-line-number="12">      <span class="kw">fitted</span>(LinearLog_model)[order_id], </a>
<a class="sourceLine" id="cb185-13" data-line-number="13">      <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, </a>
<a class="sourceLine" id="cb185-14" data-line-number="14">      <span class="dt">lwd =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="AdvRA_files/figure-html/unnamed-chunk-323-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>We can interpret <span class="math inline">\(\hat{\beta}_1\)</span> as follows: a <span class="math inline">\(1\%\)</span> increase in income is associated with an increase in test scores of <span class="math inline">\(0.01 \times 36.42 = 0.36\)</span> points. In order to get the estimated effect of a one unit change in income (that is, a change in the original units, thousands of dollars) on test scores, the method presented in Key Concept 8.1 can be used.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb186-1" data-line-number="1"><span class="co"># set up new data</span></a>
<a class="sourceLine" id="cb186-2" data-line-number="2">new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">income =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">40</span>, <span class="dv">41</span>))</a>
<a class="sourceLine" id="cb186-3" data-line-number="3"></a>
<a class="sourceLine" id="cb186-4" data-line-number="4"><span class="co"># predict the outcomes </span></a>
<a class="sourceLine" id="cb186-5" data-line-number="5">Y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(LinearLog_model, <span class="dt">newdata =</span> new_data)</a>
<a class="sourceLine" id="cb186-6" data-line-number="6"></a>
<a class="sourceLine" id="cb186-7" data-line-number="7"><span class="co"># compute the expected difference</span></a>
<a class="sourceLine" id="cb186-8" data-line-number="8">Y_hat_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(Y_hat, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb186-9" data-line-number="9">Y_hat_matrix[, <span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>Y_hat_matrix[, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb186-10" data-line-number="10"><span class="co">#&gt; [1] 3.471166 0.899297</span></a></code></pre></div>
<p>By setting <tt>nrow = 2</tt> and <tt>byrow = TRUE</tt> in <tt>matrix()</tt> we ensure that <tt>Y_hat_matrix</tt> is a <span class="math inline">\(2\times2\)</span> matrix filled row-wise with the entries of <tt>Y_hat</tt>.</p>
<p>The estimated model states that for an income increase from <span class="math inline">\(\$10000\)</span> to <span class="math inline">\(\$11000\)</span>, test scores increase by an expected amount of <span class="math inline">\(3.47\)</span> points. When income increases from <span class="math inline">\(\$40000\)</span> to <span class="math inline">\(\$41000\)</span>, the expected increase in test scores is only about <span class="math inline">\(0.90\)</span> points.</p>
</div>
<div id="case-ii-y-is-in-logarithm-x-is-not" class="section level4 unnumbered">
<h4>Case II: <span class="math inline">\(Y\)</span> is in Logarithm, <span class="math inline">\(X\)</span> is not</h4>
<p>There are cases where it is useful to regress <span class="math inline">\(\ln(Y)\)</span>.</p>
<p>The corresponding regression model then is</p>
<p><span class="math display">\[ \ln(Y_i) = \beta_0 + \beta_1 \times X_i + u_i , \ \ i=1,...,n. \]</span></p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" data-line-number="1"><span class="co"># estimate a log-linear model </span></a>
<a class="sourceLine" id="cb187-2" data-line-number="2">LogLinear_model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(score) <span class="op">~</span><span class="st"> </span>income, <span class="dt">data =</span> CASchools)</a>
<a class="sourceLine" id="cb187-3" data-line-number="3"></a>
<a class="sourceLine" id="cb187-4" data-line-number="4"><span class="co"># obtain a robust coefficient summary</span></a>
<a class="sourceLine" id="cb187-5" data-line-number="5"><span class="kw">coeftest</span>(LogLinear_model, </a>
<a class="sourceLine" id="cb187-6" data-line-number="6">         <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</a>
<a class="sourceLine" id="cb187-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb187-8" data-line-number="8"><span class="co">#&gt; t test of coefficients:</span></a>
<a class="sourceLine" id="cb187-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb187-10" data-line-number="10"><span class="co">#&gt;               Estimate Std. Error  t value  Pr(&gt;|t|)    </span></a>
<a class="sourceLine" id="cb187-11" data-line-number="11"><span class="co">#&gt; (Intercept) 6.43936234 0.00289382 2225.210 &lt; 2.2e-16 ***</span></a>
<a class="sourceLine" id="cb187-12" data-line-number="12"><span class="co">#&gt; income      0.00284407 0.00017509   16.244 &lt; 2.2e-16 ***</span></a>
<a class="sourceLine" id="cb187-13" data-line-number="13"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb187-14" data-line-number="14"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>The estimated regression function is <span class="math display">\[\widehat{\ln(TestScore)} = 6.439 + 0.00284 \times income.\]</span> An increase in district income by <span class="math inline">\(\$1000\)</span> is expected to increase test scores by <span class="math inline">\(100\times 0.00284 \% = 0.284\%\)</span>.</p>
<p>When the dependent variable in logarithm, one cannot simply use <span class="math inline">\(e^{\log(\cdot)}\)</span> to transform predictions back to the original scale, see page of the book.</p>
</div>
<div id="case-iii-x-and-y-are-in-logarithms" class="section level4 unnumbered">
<h4>Case III: <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are in Logarithms</h4>
<p>The log-log regression model is <span class="math display">\[\ln(Y_i) = \beta_0 + \beta_1 \times \ln(X_i) + u_i, \ \ i=1,...,n.\]</span></p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb188-1" data-line-number="1"><span class="co"># estimate the log-log model</span></a>
<a class="sourceLine" id="cb188-2" data-line-number="2">LogLog_model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(score) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(income), <span class="dt">data =</span> CASchools)</a>
<a class="sourceLine" id="cb188-3" data-line-number="3"></a>
<a class="sourceLine" id="cb188-4" data-line-number="4"><span class="co"># print robust coefficient summary to the console</span></a>
<a class="sourceLine" id="cb188-5" data-line-number="5"><span class="kw">coeftest</span>(LogLog_model, </a>
<a class="sourceLine" id="cb188-6" data-line-number="6">         <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</a>
<a class="sourceLine" id="cb188-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb188-8" data-line-number="8"><span class="co">#&gt; t test of coefficients:</span></a>
<a class="sourceLine" id="cb188-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb188-10" data-line-number="10"><span class="co">#&gt;              Estimate Std. Error  t value  Pr(&gt;|t|)    </span></a>
<a class="sourceLine" id="cb188-11" data-line-number="11"><span class="co">#&gt; (Intercept) 6.3363494  0.0059246 1069.501 &lt; 2.2e-16 ***</span></a>
<a class="sourceLine" id="cb188-12" data-line-number="12"><span class="co">#&gt; log(income) 0.0554190  0.0021446   25.841 &lt; 2.2e-16 ***</span></a>
<a class="sourceLine" id="cb188-13" data-line-number="13"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb188-14" data-line-number="14"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>The estimated regression function hence is <span class="math display">\[\widehat{\ln(TestScore)} = 6.336 + 0.0554 \times \ln(income).\]</span> In a log-log model, a <span class="math inline">\(1\%\)</span> change in <span class="math inline">\(X\)</span> is associated with an estimated <span class="math inline">\(\hat\beta_1 \%\)</span> change in <span class="math inline">\(Y\)</span>.</p>
<p>We now reproduce Figure 8.5 of the book.</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb189-1" data-line-number="1"><span class="co"># generate a scatterplot</span></a>
<a class="sourceLine" id="cb189-2" data-line-number="2"><span class="kw">plot</span>(<span class="kw">log</span>(score) <span class="op">~</span><span class="st"> </span>income, </a>
<a class="sourceLine" id="cb189-3" data-line-number="3">     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, </a>
<a class="sourceLine" id="cb189-4" data-line-number="4">     <span class="dt">pch =</span> <span class="dv">20</span>, </a>
<a class="sourceLine" id="cb189-5" data-line-number="5">     <span class="dt">data =</span> CASchools,</a>
<a class="sourceLine" id="cb189-6" data-line-number="6">     <span class="dt">main =</span> <span class="st">&quot;Log-Linear Regression Function&quot;</span>)</a>
<a class="sourceLine" id="cb189-7" data-line-number="7"></a>
<a class="sourceLine" id="cb189-8" data-line-number="8"><span class="co"># add the log-linear regression line</span></a>
<a class="sourceLine" id="cb189-9" data-line-number="9">order_id  &lt;-<span class="st"> </span><span class="kw">order</span>(CASchools<span class="op">$</span>income)</a>
<a class="sourceLine" id="cb189-10" data-line-number="10"></a>
<a class="sourceLine" id="cb189-11" data-line-number="11"><span class="kw">lines</span>(CASchools<span class="op">$</span>income[order_id], </a>
<a class="sourceLine" id="cb189-12" data-line-number="12">      <span class="kw">fitted</span>(LogLinear_model)[order_id], </a>
<a class="sourceLine" id="cb189-13" data-line-number="13">      <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, </a>
<a class="sourceLine" id="cb189-14" data-line-number="14">      <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb189-15" data-line-number="15"></a>
<a class="sourceLine" id="cb189-16" data-line-number="16"><span class="co"># add the log-log regression line</span></a>
<a class="sourceLine" id="cb189-17" data-line-number="17"><span class="kw">lines</span>(<span class="kw">sort</span>(CASchools<span class="op">$</span>income), </a>
<a class="sourceLine" id="cb189-18" data-line-number="18">      <span class="kw">fitted</span>(LogLog_model)[<span class="kw">order</span>(CASchools<span class="op">$</span>income)], </a>
<a class="sourceLine" id="cb189-19" data-line-number="19">      <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>, </a>
<a class="sourceLine" id="cb189-20" data-line-number="20">      <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb189-21" data-line-number="21"></a>
<a class="sourceLine" id="cb189-22" data-line-number="22"><span class="co"># add a legend</span></a>
<a class="sourceLine" id="cb189-23" data-line-number="23"><span class="kw">legend</span>(<span class="st">&quot;bottomright&quot;</span>,</a>
<a class="sourceLine" id="cb189-24" data-line-number="24">       <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;log-linear model&quot;</span>, <span class="st">&quot;log-log model&quot;</span>),</a>
<a class="sourceLine" id="cb189-25" data-line-number="25">       <span class="dt">lwd =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb189-26" data-line-number="26">       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>))</a></code></pre></div>
<p><img src="AdvRA_files/figure-html/unnamed-chunk-326-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Key Concept 8.2 summarizes the three logarithmic regression models.</p>
<div id="KC8.2" class="keyconcept">
<h3 class="right">
Key Concept 8.2
</h3>
<h3 class="left">
Logarithms in Regression: Three Cases
</h3>
<p>
Logarithms can be used to transform the dependent variable <span class="math inline">\(Y\)</span> or the independent variable <span class="math inline">\(X\)</span>, or both
(the variable being transformed must be positive). The following table summarizes these three cases and the interpretation of the regression coefficient <span class="math inline">\(\beta_1\)</span>. In each case, <span class="math inline">\(\beta_1\)</span>, can be estimated by applying OLS after taking the logarithm(s) of the dependent and/or the independent variable.
</p>
<table>
<thead>
<tr class="header">
<th align="left">
Case
</th>
<th align="left">
Model Specification
</th>
<th align="left">
Interpretation of <span class="math inline">\(\beta_1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">
<span class="math inline">\((I)\)</span>
</td>
<td align="left">
<span class="math inline">\(Y_i = \beta_0 + \beta_1 \ln(X_i) + u_i\)</span>
</td>
<td align="left">
A <span class="math inline">\(1 \%\)</span> change in <span class="math inline">\(X\)</span> is associated with a change in <span class="math inline">\(Y\)</span> of <span class="math inline">\(0.01 \times \beta_1\)</span>.
</td>
</tr>
<tr class="even">
<td align="left">
<span class="math inline">\((II)\)</span>
</td>
<td align="left">
<span class="math inline">\(\ln(Y_i) = \beta_0 + \beta_1 X_i + u_i\)</span>
</td>
<td align="left">
A change in <span class="math inline">\(X\)</span> by one unit (<span class="math inline">\(\Delta X = 1\)</span>) is associated with a <span class="math inline">\(100 \times \beta_1 \%\)</span> change in <span class="math inline">\(Y\)</span>.
</td>
</tr>
<tr class="odd">
<td align="left">
<span class="math inline">\((III)\)</span>
</td>
<td align="left">
<span class="math inline">\(\ln(Y_i) = \beta_0 + \beta_1 \ln(X_i) + u_i\)</span>
</td>
<td align="left">
A <span class="math inline">\(1\%\)</span> change in <span class="math inline">\(X\)</span> is associated with a <span class="math inline">\(\beta_1\%\)</span> change in <span class="math inline">\(Y\)</span>, so <span class="math inline">\(\beta_1\)</span> is the elasticity of <span class="math inline">\(Y\)</span> with respect to <span class="math inline">\(X\)</span>.
</td>
</tr>
</tbody>
</table>
</div>
<p>Of course we can also estimate a <em>polylog</em> model like</p>
<p><span class="math display">\[ TestScore_i = \beta_0 + \beta_1 \times \ln(income_i) + \beta_2 \times \ln(income_i)^2 + \beta_3 \times \ln(income_i)^3 + u_i \]</span></p>
<p>which models the dependent variable <span class="math inline">\(TestScore\)</span> by a third-degree polynomial of the log-transformed regressor <span class="math inline">\(income\)</span>.</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" data-line-number="1"><span class="co"># estimate the polylog model</span></a>
<a class="sourceLine" id="cb190-2" data-line-number="2">polyLog_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(income) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(<span class="kw">log</span>(income)<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(<span class="kw">log</span>(income)<span class="op">^</span><span class="dv">3</span>), </a>
<a class="sourceLine" id="cb190-3" data-line-number="3">                    <span class="dt">data =</span> CASchools)</a>
<a class="sourceLine" id="cb190-4" data-line-number="4"></a>
<a class="sourceLine" id="cb190-5" data-line-number="5"><span class="co"># print robust summary to the console</span></a>
<a class="sourceLine" id="cb190-6" data-line-number="6"><span class="kw">coeftest</span>(polyLog_model, </a>
<a class="sourceLine" id="cb190-7" data-line-number="7">         <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</a>
<a class="sourceLine" id="cb190-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb190-9" data-line-number="9"><span class="co">#&gt; t test of coefficients:</span></a>
<a class="sourceLine" id="cb190-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb190-11" data-line-number="11"><span class="co">#&gt;                  Estimate Std. Error t value  Pr(&gt;|t|)    </span></a>
<a class="sourceLine" id="cb190-12" data-line-number="12"><span class="co">#&gt; (Intercept)      486.1341    79.3825  6.1239 2.115e-09 ***</span></a>
<a class="sourceLine" id="cb190-13" data-line-number="13"><span class="co">#&gt; log(income)      113.3820    87.8837  1.2901    0.1977    </span></a>
<a class="sourceLine" id="cb190-14" data-line-number="14"><span class="co">#&gt; I(log(income)^2) -26.9111    31.7457 -0.8477    0.3971    </span></a>
<a class="sourceLine" id="cb190-15" data-line-number="15"><span class="co">#&gt; I(log(income)^3)   3.0632     3.7369  0.8197    0.4128    </span></a>
<a class="sourceLine" id="cb190-16" data-line-number="16"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb190-17" data-line-number="17"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>Comparing by <span class="math inline">\(\bar{R}^2\)</span> we find that, leaving out the log-linear model, all models have a similar adjusted fit. In the class of polynomial models, the cubic specification has the highest <span class="math inline">\(\bar{R}^2\)</span> whereas the linear-log specification is the best of the log-models.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb191-1" data-line-number="1"><span class="co"># compute the adj. R^2 for the nonlinear models</span></a>
<a class="sourceLine" id="cb191-2" data-line-number="2">adj_R2 &lt;-<span class="kw">rbind</span>(<span class="st">&quot;quadratic&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(quadratic_model)<span class="op">$</span>adj.r.squared,</a>
<a class="sourceLine" id="cb191-3" data-line-number="3">               <span class="st">&quot;cubic&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(cubic_model)<span class="op">$</span>adj.r.squared,</a>
<a class="sourceLine" id="cb191-4" data-line-number="4">               <span class="st">&quot;LinearLog&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(LinearLog_model)<span class="op">$</span>adj.r.squared,</a>
<a class="sourceLine" id="cb191-5" data-line-number="5">               <span class="st">&quot;LogLinear&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(LogLinear_model)<span class="op">$</span>adj.r.squared,</a>
<a class="sourceLine" id="cb191-6" data-line-number="6">               <span class="st">&quot;LogLog&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(LogLog_model)<span class="op">$</span>adj.r.squared,</a>
<a class="sourceLine" id="cb191-7" data-line-number="7">               <span class="st">&quot;polyLog&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(polyLog_model)<span class="op">$</span>adj.r.squared)</a>
<a class="sourceLine" id="cb191-8" data-line-number="8"></a>
<a class="sourceLine" id="cb191-9" data-line-number="9"><span class="co"># assign column names</span></a>
<a class="sourceLine" id="cb191-10" data-line-number="10"><span class="kw">colnames</span>(adj_R2) &lt;-<span class="st"> &quot;adj_R2&quot;</span></a>
<a class="sourceLine" id="cb191-11" data-line-number="11"></a>
<a class="sourceLine" id="cb191-12" data-line-number="12">adj_R2</a>
<a class="sourceLine" id="cb191-13" data-line-number="13"><span class="co">#&gt;              adj_R2</span></a>
<a class="sourceLine" id="cb191-14" data-line-number="14"><span class="co">#&gt; quadratic 0.5540444</span></a>
<a class="sourceLine" id="cb191-15" data-line-number="15"><span class="co">#&gt; cubic     0.5552279</span></a>
<a class="sourceLine" id="cb191-16" data-line-number="16"><span class="co">#&gt; LinearLog 0.5614605</span></a>
<a class="sourceLine" id="cb191-17" data-line-number="17"><span class="co">#&gt; LogLinear 0.4970106</span></a>
<a class="sourceLine" id="cb191-18" data-line-number="18"><span class="co">#&gt; LogLog    0.5567251</span></a>
<a class="sourceLine" id="cb191-19" data-line-number="19"><span class="co">#&gt; polyLog   0.5599944</span></a></code></pre></div>
<p>Let us now compare the cubic and the linear-log model by plotting the corresponding estimated regression functions.</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" data-line-number="1"><span class="co"># generate a scatterplot</span></a>
<a class="sourceLine" id="cb192-2" data-line-number="2"><span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>income, </a>
<a class="sourceLine" id="cb192-3" data-line-number="3">     <span class="dt">data =</span> CASchools,</a>
<a class="sourceLine" id="cb192-4" data-line-number="4">     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, </a>
<a class="sourceLine" id="cb192-5" data-line-number="5">     <span class="dt">pch =</span> <span class="dv">20</span>,</a>
<a class="sourceLine" id="cb192-6" data-line-number="6">     <span class="dt">main =</span> <span class="st">&quot;Linear-Log and Cubic Regression Functions&quot;</span>)</a>
<a class="sourceLine" id="cb192-7" data-line-number="7"></a>
<a class="sourceLine" id="cb192-8" data-line-number="8"><span class="co"># add the linear-log regression line</span></a>
<a class="sourceLine" id="cb192-9" data-line-number="9">order_id  &lt;-<span class="st"> </span><span class="kw">order</span>(CASchools<span class="op">$</span>income)</a>
<a class="sourceLine" id="cb192-10" data-line-number="10"></a>
<a class="sourceLine" id="cb192-11" data-line-number="11"><span class="kw">lines</span>(CASchools<span class="op">$</span>income[order_id],</a>
<a class="sourceLine" id="cb192-12" data-line-number="12">      <span class="kw">fitted</span>(LinearLog_model)[order_id], </a>
<a class="sourceLine" id="cb192-13" data-line-number="13">      <span class="dt">col =</span> <span class="st">&quot;darkgreen&quot;</span>, </a>
<a class="sourceLine" id="cb192-14" data-line-number="14">      <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb192-15" data-line-number="15"></a>
<a class="sourceLine" id="cb192-16" data-line-number="16"><span class="co"># add the cubic regression line</span></a>
<a class="sourceLine" id="cb192-17" data-line-number="17"><span class="kw">lines</span>(<span class="dt">x =</span> CASchools<span class="op">$</span>income[order_id], </a>
<a class="sourceLine" id="cb192-18" data-line-number="18">      <span class="dt">y =</span> <span class="kw">fitted</span>(cubic_model)[order_id],</a>
<a class="sourceLine" id="cb192-19" data-line-number="19">      <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>, </a>
<a class="sourceLine" id="cb192-20" data-line-number="20">      <span class="dt">lwd =</span> <span class="dv">2</span>) </a></code></pre></div>
<p><img src="AdvRA_files/figure-html/unnamed-chunk-330-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Both regression lines look nearly identical. Altogether the linear-log model may be preferable since it is more parsimonious in terms of regressors: it does not include higher-degree polynomials.</p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-stock2015">
<p>Stock, J.H., and M.W. Watson. 2015. <em>Introduction to Econometrics, Third Update, Global Edition</em>. Pearson Education Limited.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="8-1-a-general-strategy-for-modelling-nonlinear-regression-functions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="8-3-interactions-between-independent-variables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/lidom/AdvRA/edit/master/08-ch8.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
