<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Econometrics with R</title>
  <meta name="description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programing and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Econometrics with R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programing and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Econometrics with R" />
  
  <meta name="twitter:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programing and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2018-10-05">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="eaqe.html">
<link rel="next" href="eodce.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>
<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">

<!-- function to adjust height of iframes automatically depending on content loaded -->

<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>

<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/default.js"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://www.oek.wiwi.uni-due.de/en/">Chair of Econometrics at UDE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#a-very-short-introduction-to-r-and-rstudio"><i class="fa fa-check"></i><b>1.1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="2.1" data-path="pt.html"><a href="pt.html#random-variables-and-probability-distributions"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pt.html"><a href="pt.html#RSATDOSA"><i class="fa fa-check"></i><b>2.2</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pt.html"><a href="pt.html#exercises"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="arosur.html"><a href="arosur.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="3.1" data-path="arosur.html"><a href="arosur.html#estimation-of-the-population-mean"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="arosur.html"><a href="arosur.html#potsm"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="arosur.html"><a href="arosur.html#hypothesis-tests-concerning-the-population-mean"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="arosur.html"><a href="arosur.html#confidence-intervals-for-the-population-mean"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.5" data-path="arosur.html"><a href="arosur.html#cmfdp"><i class="fa fa-check"></i><b>3.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.6" data-path="arosur.html"><a href="arosur.html#aattggoe"><i class="fa fa-check"></i><b>3.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.7" data-path="arosur.html"><a href="arosur.html#scatterplots-sample-covariance-and-sample-correlation"><i class="fa fa-check"></i><b>3.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.8" data-path="arosur.html"><a href="arosur.html#exercises-1"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lrwor.html"><a href="lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="4.1" data-path="lrwor.html"><a href="lrwor.html#simple-linear-regression"><i class="fa fa-check"></i><b>4.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="4.2" data-path="lrwor.html"><a href="lrwor.html#estimating-the-coefficients-of-the-linear-regression-model"><i class="fa fa-check"></i><b>4.2</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="lrwor.html"><a href="lrwor.html#measures-of-fit"><i class="fa fa-check"></i><b>4.3</b> Measures of Fit</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="lrwor.html"><a href="lrwor.html#tlsa"><i class="fa fa-check"></i><b>4.4</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="lrwor.html"><a href="lrwor.html#tsdotoe"><i class="fa fa-check"></i><b>4.5</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="lrwor.html"><a href="lrwor.html#exercises-2"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="htaciitslrm.html"><a href="htaciitslrm.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="5.1" data-path="htaciitslrm.html"><a href="htaciitslrm.html#testing-two-sided-hypotheses-concerning-the-slope-coefficient"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="5.2" data-path="htaciitslrm.html"><a href="htaciitslrm.html#cifrc"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="htaciitslrm.html"><a href="htaciitslrm.html#rwxiabv"><i class="fa fa-check"></i><b>5.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="htaciitslrm.html"><a href="htaciitslrm.html#hah"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="htaciitslrm.html"><a href="htaciitslrm.html#the-gauss-markov-theorem"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="htaciitslrm.html"><a href="htaciitslrm.html#using-the-t-statistic-in-regression-when-the-sample-size-is-small"><i class="fa fa-check"></i><b>5.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="5.7" data-path="htaciitslrm.html"><a href="htaciitslrm.html#exercises-3"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="rmwmr.html"><a href="rmwmr.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="6.1" data-path="rmwmr.html"><a href="rmwmr.html#omitted-variable-bias"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="rmwmr.html"><a href="rmwmr.html#tmrm"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="rmwmr.html"><a href="rmwmr.html#mofimr"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="rmwmr.html"><a href="rmwmr.html#ols-assumptions-in-multiple-regression"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="rmwmr.html"><a href="rmwmr.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="rmwmr.html"><a href="rmwmr.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="rmwmr.html"><a href="rmwmr.html#the-distribution-of-the-ols-estimators-in-multiple-regression"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="6.6" data-path="rmwmr.html"><a href="rmwmr.html#exercises-4"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="htaciimr.html"><a href="htaciimr.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence Intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="htaciimr.html"><a href="htaciimr.html#hypothesis-tests-and-confidence-intervals-for-a-single-coefficient"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="htaciimr.html"><a href="htaciimr.html#an-application-to-test-scores-and-the-student-teacher-ratio"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="htaciimr.html"><a href="htaciimr.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="htaciimr.html"><a href="htaciimr.html#joint-hypothesis-testing-using-the-f-statistic"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the F-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="htaciimr.html"><a href="htaciimr.html#confidence-sets-for-multiple-coefficients"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="htaciimr.html"><a href="htaciimr.html#model-specification-for-multiple-regression"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="htaciimr.html"><a href="htaciimr.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="htaciimr.html"><a href="htaciimr.html#analysis-of-the-test-score-data-set"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="7.7" data-path="htaciimr.html"><a href="htaciimr.html#exercises-5"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nrf.html"><a href="nrf.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="8.1" data-path="nrf.html"><a href="nrf.html#a-general-strategy-for-modelling-nonlinear-regression-functions"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="nrf.html"><a href="nrf.html#nfoasiv"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="nrf.html"><a href="nrf.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="nrf.html"><a href="nrf.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="nrf.html"><a href="nrf.html#interactions-between-independent-variables"><i class="fa fa-check"></i><b>8.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="nrf.html"><a href="nrf.html#nonlinear-effects-on-test-scores-of-the-student-teacher-ratio"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
<li class="chapter" data-level="8.5" data-path="nrf.html"><a href="nrf.html#exercises-6"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="asbomr.html"><a href="asbomr.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="asbomr.html"><a href="asbomr.html#internal-and-external-validity"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="asbomr.html"><a href="asbomr.html#ttivomra"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="asbomr.html"><a href="asbomr.html#internal-and-external-validity-when-the-regression-is-used-for-forecasting"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity when the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="asbomr.html"><a href="asbomr.html#etsacs"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
<li class="chapter" data-level="9.5" data-path="asbomr.html"><a href="asbomr.html#exercises-7"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="rwpd.html"><a href="rwpd.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="10.1" data-path="rwpd.html"><a href="rwpd.html#panel-data"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="rwpd.html"><a href="rwpd.html#PDWTTP"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="rwpd.html"><a href="rwpd.html#fixed-effects-regression"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="rwpd.html"><a href="rwpd.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="rwpd.html"><a href="rwpd.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="rwpd.html"><a href="rwpd.html#regression-with-time-fixed-effects"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="rwpd.html"><a href="rwpd.html#tferaaseffer"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="rwpd.html"><a href="rwpd.html#drunk-driving-laws-and-traffic-deaths"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="rwabdv.html"><a href="rwabdv.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="11.1" data-path="rwabdv.html"><a href="rwabdv.html#binary-dependent-variables-and-the-linear-probability-model"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="rwabdv.html"><a href="rwabdv.html#palr"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="rwabdv.html"><a href="rwabdv.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="rwabdv.html"><a href="rwabdv.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="rwabdv.html"><a href="rwabdv.html#estimation-and-inference-in-the-logit-and-probit-models"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="rwabdv.html"><a href="rwabdv.html#application-to-the-boston-hmda-data"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
<li class="chapter" data-level="11.5" data-path="rwabdv.html"><a href="rwabdv.html#exercises-8"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ivr.html"><a href="ivr.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="ivr.html"><a href="ivr.html#TIVEWASRAASI"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="ivr.html"><a href="ivr.html#TGIVRM"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="ivr.html"><a href="ivr.html#civ"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="ivr.html"><a href="ivr.html#attdfc"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="ivr.html"><a href="ivr.html#where-do-valid-instruments-come-from"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
<li class="chapter" data-level="12.6" data-path="ivr.html"><a href="ivr.html#exercises-9"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="eaqe.html"><a href="eaqe.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="13.1" data-path="eaqe.html"><a href="eaqe.html#potential-outcomes-causal-effects-and-idealized-experiments"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="eaqe.html"><a href="eaqe.html#threats-to-validity-of-experiments"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="eaqe.html"><a href="eaqe.html#experimental-estimates-of-the-effect-of-class-size-reductions"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="eaqe.html"><a href="eaqe.html#quasi-experiments"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ittsraf.html"><a href="ittsraf.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="14.1" data-path="ittsraf.html"><a href="ittsraf.html#using-regression-models-for-forecasting"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="ittsraf.html"><a href="ittsraf.html#tsdasc"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="ittsraf.html"><a href="ittsraf.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="ittsraf.html"><a href="ittsraf.html#autoregressions"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a><ul>
<li><a href="ittsraf.html#autoregressive-models-of-order-p">Autoregressive Models of Order <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ittsraf.html"><a href="ittsraf.html#cybtmpi"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="ittsraf.html"><a href="ittsraf.html#apatadlm"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="ittsraf.html"><a href="ittsraf.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="ittsraf.html"><a href="ittsraf.html#llsuic"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="ittsraf.html"><a href="ittsraf.html#nit"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="ittsraf.html"><a href="ittsraf.html#niib"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="ittsraf.html"><a href="ittsraf.html#can-you-beat-the-market-part-ii"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="eodce.html"><a href="eodce.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="15.1" data-path="eodce.html"><a href="eodce.html#the-orange-juice-data"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="eodce.html"><a href="eodce.html#dynamic-causal-effects"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="eodce.html"><a href="eodce.html#dynamic-multipliers-and-cumulative-dynamic-multipliers"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="eodce.html"><a href="eodce.html#hac-standard-errors"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="eodce.html"><a href="eodce.html#estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="eodce.html"><a href="eodce.html#orange-juice-prices-and-cold-weather"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="atitsr.html"><a href="atitsr.html"><i class="fa fa-check"></i><b>16</b> Additional Topics in Time Series Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="atitsr.html"><a href="atitsr.html#vector-autoregressions"><i class="fa fa-check"></i><b>16.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="16.2" data-path="atitsr.html"><a href="atitsr.html#ooiatdfglsurt"><i class="fa fa-check"></i><b>16.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="16.3" data-path="atitsr.html"><a href="atitsr.html#cointegration"><i class="fa fa-check"></i><b>16.3</b> Cointegration</a></li>
<li class="chapter" data-level="16.4" data-path="atitsr.html"><a href="atitsr.html#volatility-clustering-and-autoregressive-conditional-heteroskedasticity"><i class="fa fa-check"></i><b>16.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a><ul>
<li class="chapter" data-level="" data-path="atitsr.html"><a href="atitsr.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="atitsr.html"><a href="atitsr.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
<li class="chapter" data-level="" data-path="atitsr.html"><a href="atitsr.html#summary-8"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Econometrics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. You can also see the annotations of others: click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="ittsraf" class="section level1">
<h1><span class="header-section-number">14</span> Introduction to Time Series Regression and Forecasting</h1>
<p>Time series data is data is collected for a single entity over time. This is fundamentally different from cross-section data which is data on multiple entities at the same point in time. Time series data allows estimation of the effect on <span class="math inline">\(Y\)</span> of a change in <span class="math inline">\(X\)</span> <em>over time</em>. This is what econometricians call a <em>dynamic causal effect</em>. Let us go back to the application to cigarette consumption of Chapter <a href="ivr.html#ivr">12</a> where we were interested in estimating the effect on cigarette demand of a price increase caused by a raise of the general sales tax. One might use time series data to assess the causal effect of a tax increase on smoking both initially and in subsequent periods.</p>
<p>Another application of time series data is forecasting. For example, weather services use time series data to predict tomorrow’s temperature by inter alia using today’s temperature and temperatures of the past. To motivate an economic example, central banks are interested in forecasting next month’s unemployment rates.</p>
<p>The remainder of Chapters in the book deals with the econometric techniques for the analysis of time series data and applications to forecasting and estimation of dynamic causal effects. This section covers the basic concepts presented in Chapter 14 of the book, explains how to visualize time series data and demonstrates how to estimate simple autoregressive models, where the regressors are past values of the dependent variable or other variables. In this context we also discuss the concept of stationarity, an important property which has far-reaching consequences.</p>
<p>Most empirical applications in this chapter are concerned with forecasting and use data on U.S. macroeconomic indicators or financial time series like Gross Domestic Product (GDP), the unemployment rate or excess stock returns.</p>
<p>The following packages and their dependencies are needed for reproduction of the code chunks presented throughout this chapter:</p>
<ul>
<li><tt>AER</tt> <span class="citation">(Christian Kleiber &amp; Zeileis, <a href="#ref-R-AER">2017</a>)</span></li>
<li><tt>dynlm</tt> <span class="citation">(Zeileis, <a href="#ref-R-dynlm">2016</a>)</span></li>
<li><tt>forecast</tt> <span class="citation">(Hyndman et al., <a href="#ref-R-forecast">2018</a>)</span></li>
<li><tt>readxl</tt> <span class="citation">(Wickham &amp; Bryan, <a href="#ref-R-readxl">2018</a>)</span></li>
<li><tt>stargazer</tt> <span class="citation">(Hlavac, <a href="#ref-R-stargazer">2018</a>)</span></li>
<li><tt>scales</tt> <span class="citation">(Wickham, <a href="#ref-R-scales">2017</a>)</span></li>
<li><tt>quantmod</tt> <span class="citation">(Ryan &amp; Ulrich, <a href="#ref-R-quantmod">2018</a>)</span></li>
<li><tt>urca</tt> <span class="citation">(Pfaff, <a href="#ref-R-urca">2016</a>)</span></li>
</ul>
<p>Please verify that the following code chunk runs on your machine without any errors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(AER)
<span class="kw">library</span>(dynlm)
<span class="kw">library</span>(forecast)
<span class="kw">library</span>(readxl)
<span class="kw">library</span>(stargazer)
<span class="kw">library</span>(scales)
<span class="kw">library</span>(quantmod)
<span class="kw">library</span>(urca)</code></pre></div>
<div id="using-regression-models-for-forecasting" class="section level2">
<h2><span class="header-section-number">14.1</span> Using Regression Models for Forecasting</h2>
<p>What is the difference between estimating models for assessment of causal effects and forecasting? Consider again the simple example of estimating the casual effect of the student-teacher ratio on test scores introduced in Chapter <a href="lrwor.html#lrwor">4</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(AER)
<span class="kw">data</span>(CASchools)   
CASchools<span class="op">$</span>STR &lt;-<span class="st"> </span>CASchools<span class="op">$</span>students<span class="op">/</span>CASchools<span class="op">$</span>teachers       
CASchools<span class="op">$</span>score &lt;-<span class="st"> </span>(CASchools<span class="op">$</span>read <span class="op">+</span><span class="st"> </span>CASchools<span class="op">$</span>math)<span class="op">/</span><span class="dv">2</span>

mod &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>STR, <span class="dt">data =</span> CASchools)
mod</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ STR, data = CASchools)
## 
## Coefficients:
## (Intercept)          STR  
##      698.93        -2.28</code></pre>
<p>As has been stressed in Chapter <a href="rmwmr.html#rmwmr">6</a>, the estimate of the coefficient on the student-teacher ratio does not have a causal interpretation due to omitted variable bias. However, in terms of deciding which school to send her child to, it might nevertheless be appealing for a parent to use <tt>mod</tt> for forecasting test scores in schooling districts where no public data about on scores are available.</p>
<p>As an example, assume that the average class in a district has <span class="math inline">\(25\)</span> students. This is not a perfect forecast but the following one-liner might be helpful for the parent to decide.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(mod, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="st">&quot;STR&quot;</span> =<span class="st"> </span><span class="dv">25</span>))</code></pre></div>
<pre><code>##        1 
## 641.9377</code></pre>
<p>In a time series context, the parent could use data on present and past years test scores to forecast next year’s test scores — a typical application for an autoregressive model.</p>
</div>
<div id="tsdasc" class="section level2">
<h2><span class="header-section-number">14.2</span> Time Series Data and Serial Correlation</h2>
<p>GDP is commonly defined as the value of goods and services produced over a given time period. The data set <tt>us_macro_quarterly.xlsx</tt> is provided by the authors and can be downloaded <a href="http://wps.pearsoned.com/wps/media/objects/11422/11696965/empirical/empex_tb/UsMacro_Quarterly.xlsx">here</a>. It provides quarterly data on U.S. real (i.e. inflation adjusted) GDP from 1947 to 2004.</p>
<p>As before, a good starting point is to plot the data. The package <tt>quantmod</tt> provides some convenient functions for plotting and computing with time series data. We also load the package <tt>readxl</tt> to read the data into <tt>R</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># attach the package &#39;quantmod&#39;</span>
<span class="kw">library</span>(quantmod)</code></pre></div>
<p>We begin by importing the data set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load US macroeconomic data</span>
USMacroSWQ &lt;-<span class="st"> </span><span class="kw">read_xlsx</span>(<span class="st">&quot;Data/us_macro_quarterly.xlsx&quot;</span>,
                         <span class="dt">sheet =</span> <span class="dv">1</span>,
                         <span class="dt">col_types =</span> <span class="kw">c</span>(<span class="st">&quot;text&quot;</span>, <span class="kw">rep</span>(<span class="st">&quot;numeric&quot;</span>, <span class="dv">9</span>)))

<span class="co"># format date column</span>
USMacroSWQ<span class="op">$</span>X__<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">as.yearqtr</span>(USMacroSWQ<span class="op">$</span>X__<span class="dv">1</span>, <span class="dt">format =</span> <span class="st">&quot;%Y:0%q&quot;</span>)

<span class="co"># adjust column names</span>
<span class="kw">colnames</span>(USMacroSWQ) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Date&quot;</span>, <span class="st">&quot;GDPC96&quot;</span>, <span class="st">&quot;JAPAN_IP&quot;</span>, <span class="st">&quot;PCECTPI&quot;</span>, 
                          <span class="st">&quot;GS10&quot;</span>, <span class="st">&quot;GS1&quot;</span>, <span class="st">&quot;TB3MS&quot;</span>, <span class="st">&quot;UNRATE&quot;</span>, <span class="st">&quot;EXUSUK&quot;</span>, <span class="st">&quot;CPIAUCSL&quot;</span>)</code></pre></div>
<p>We the first column of <tt>us_macro_quarterly.xlsx</tt> contains text and the remaining ones are numeric. Using <tt>col_types = c(“text”, rep(“numeric”, 9))</tt> we tell <tt>read_xlsx()</tt> take this into account when importing the data.</p>
<p>It is useful to work with time-series objects that keep track of the frequency of the data and are extensible. In what follows we will use objects of the class <tt>xts</tt>, see <code>?xts</code>. Since the data in <tt>USMacroSWQ</tt> are in quarterly frequency we convert the first column to <tt>yearqtr</tt> format before generating the <tt>xts</tt> object <tt>GDP</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># GDP series as xts object</span>
GDP &lt;-<span class="st"> </span><span class="kw">xts</span>(USMacroSWQ<span class="op">$</span>GDPC96, USMacroSWQ<span class="op">$</span>Date)[<span class="st">&quot;1960::2013&quot;</span>]

<span class="co"># GDP growth series as xts object</span>
GDPGrowth &lt;-<span class="st"> </span><span class="kw">xts</span>(<span class="dv">400</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(GDP<span class="op">/</span><span class="kw">lag</span>(GDP)))</code></pre></div>
<p>The following code chunks reproduce Figure 14.1 of the book.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># reproduce Figure 14.1 (a) of the book</span>
<span class="kw">plot</span>(<span class="kw">log</span>(<span class="kw">as.zoo</span>(GDP)),
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Logarithm&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;U.S. Quarterly Real GDP&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-571-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># reproduce Figure 14.1 (b) of the book</span>
<span class="kw">plot</span>(<span class="kw">as.zoo</span>(GDPGrowth),
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Logarithm&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;U.S. Real GDP Growth Rates&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-572-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="notation-lags-differences-logarithms-and-growth-rates" class="section level3 unnumbered">
<h3>Notation, Lags, Differences, Logarithms and Growth Rates</h3>
<p>For observations of a variable <span class="math inline">\(Y\)</span> recorded over time, <span class="math inline">\(Y_t\)</span> denotes the value observed at time <span class="math inline">\(t\)</span>. The period between two sequential observations <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(Y_{t-1}\)</span> is a unit of time: hours, days, weeks, months, quarters, years etc. Key Concept 14.1 introduces the essential terminology and notation for time series data we use in the subsequent sections.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.1
</h3>
<h3 class="left">
Lags, First Differences, Logarithms and Growth Rates
</h3>
<ul>
<li><p>Previous values of a time series are called <em>lags</em>. The first lag of <span class="math inline">\(Y_t\)</span> is <span class="math inline">\(Y_{t-1}\)</span>. The <span class="math inline">\(j^{th}\)</span> lag of <span class="math inline">\(Y_t\)</span> is <span class="math inline">\(Y_{t-j}\)</span>. In <tt>r ttcode(“R”)</tt>, lags of univariate or multivariate time series objects are conveniently computed by <tt>lag()</tt>, see <tt>?lag</tt>.</p></li>
<li><p>Sometimes we work with a differenced series. The first difference of a series is <span class="math inline">\(\Delta Y_{t} = Y_t - Y_{t-1}\)</span>, the difference between periods <span class="math inline">\(t\)</span> and <span class="math inline">\(t-1\)</span>. If <tt>Y</tt> is a time series, the series of first differences is computed as <tt>diff(Y)</tt>.</p></li>
<li><p>It may be convenient to work with the first difference in logarithms of a series. We denote this by <span class="math inline">\(\Delta \log(Y_t) = \log(Y_t) - \log(Y_{t-1})\)</span>. For a time series <tt>Y</tt>, this is obtained using <tt>log(Y/lag(Y))</tt>.</p></li>
<li><p><span class="math inline">\(100 \Delta \log (Y_t)\)</span> is an approximation for the percentage change between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(Y_{t-1}\)</span>.</p></li>
</ul>
</div>
<p>The definitions made in Key Concept 14.1 are useful because of two properties that are common to many economic time series:</p>
<ul>
<li><p>Exponential growth: some economic series grow approximately exponentially such that their logarithm is approximately linear.</p></li>
<li><p>The standard deviation of many economic time series is approximately proportional to their level. Therefore, the standard deviation of the logarithm of such a series is approximately constant.</p></li>
</ul>
<p>Furthermore, it is common to report growth rates in macroeconomic series which is why <span class="math inline">\(\log\)</span>-differences are often used.</p>
<p>Table 14.1 of the book presents the quarterly U.S. GDP time series, its logarithm, the annualized growth rate and the first lag of the annualized growth rate series for the period 2012:Q1 - 2013:Q1. The following simple function can be used to compute these quantities for a quarterly time series <tt>series</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute logarithms, annual growth rates and 1st lag of growth rates</span>
quants &lt;-<span class="st"> </span><span class="cf">function</span>(series) {
  s &lt;-<span class="st"> </span>series
  <span class="kw">return</span>(
    <span class="kw">data.frame</span>(<span class="st">&quot;Level&quot;</span> =<span class="st"> </span>s,
               <span class="st">&quot;Logarithm&quot;</span> =<span class="st"> </span><span class="kw">log</span>(s),
               <span class="st">&quot;AnnualGrowthRate&quot;</span> =<span class="st"> </span><span class="dv">400</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(s <span class="op">/</span><span class="st"> </span><span class="kw">lag</span>(s)),
               <span class="st">&quot;1stLagAnnualGrowthRate&quot;</span> =<span class="st"> </span><span class="kw">lag</span>(<span class="dv">400</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(s <span class="op">/</span><span class="st"> </span><span class="kw">lag</span>(s))))
    )
}</code></pre></div>
<p>The annual growth rate is computed using the approximation <span class="math display">\[Annual Growth Y_t = 400 \cdot\Delta\log(Y_t)\]</span> since <span class="math inline">\(100\cdot\Delta\log(Y_t)\)</span> is an approximation of the quarterly percentage changes, see Key Concept 14.1.</p>
<p>We call <tt>quants()</tt> on observations for the period 2011:Q3 - 2013:Q1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># obtain a data.frame with level, logarithm, annual growth rate and its 1st lag of GDP</span>
<span class="kw">quants</span>(GDP[<span class="st">&quot;2011-07::2013-01&quot;</span>])</code></pre></div>
<pre><code>##            Level Logarithm AnnualGrowthRate X1stLagAnnualGrowthRate
## 2011 Q3 15062.14  9.619940               NA                      NA
## 2011 Q4 15242.14  9.631819        4.7518062                      NA
## 2012 Q1 15381.56  9.640925        3.6422231               4.7518062
## 2012 Q2 15427.67  9.643918        1.1972004               3.6422231
## 2012 Q3 15533.99  9.650785        2.7470216               1.1972004
## 2012 Q4 15539.63  9.651149        0.1452808               2.7470216
## 2013 Q1 15583.95  9.653997        1.1392015               0.1452808</code></pre>
<div id="autocorrelation" class="section level4 unnumbered">
<h4>Autocorrelation</h4>
<p>Observations of a time series are typically correlated. This type of correlation is called <em>autocorrelation</em> or <em>serial correlation</em>. Key Concept 14.2 summarizes the concepts of population autocovariance and population autocorrelation and shows how to compute their sample equivalents.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.2
</h3>
<h3 class="left">
Autocorrelation and Autocovariance
</h3>
<p>The covariance between <span class="math inline">\(Y_t\)</span> and its <span class="math inline">\(j^{th}\)</span> lag, <span class="math inline">\(Y_{t-j}\)</span>, is called the <span class="math inline">\(j^{th}\)</span> <em>autocovariance</em> of the series <span class="math inline">\(Y_t\)</span>. The <span class="math inline">\(j^{th}\)</span> <em>autocorrelation coefficient</em>, also called the <em>serial correlation coefficient</em>, measures the correlation between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(Y_{t-j}\)</span>.</p>
We thus have
<span class="math display">\[\begin{align*}
  j^{th} \text{autocovariance} =&amp; \, Cov(Y_t,Y_{t-j}), \\
  j^{th} \text{autocorrelation} = \rho_j =&amp; \, \rho_{Y_t,Y_{t-j}} = \frac{Cov(Y_t,Y_{t-j)}}{\sqrt{Var(Y_t)Var(Y_{t-j})}}.
\end{align*}\]</span>
<p>Population autocovariance and population autocorrelation can be estimated by <span class="math inline">\(\widehat{Cov(Y_t,Y_{t-j})}\)</span>, the sample autocovariance, and <span class="math inline">\(\widehat{\rho}_j\)</span>, the sample autocorrelation:</p>
<span class="math display">\[\begin{align*}
  \widehat{Cov(Y_t,Y_{t-j})} =&amp; \, \frac{1}{T} \sum_{t=j+1}^T (Y_t - \overline{Y}_{j+1:T})(Y_{t-j} - \overline{Y}_{1:T-j}), \\
  \widehat{\rho}_j =&amp; \, \frac{\widehat{Cov(Y_t,Y_{t-j})}}{\widehat{Var(Y_t)}}
\end{align*}\]</span>
<p><span class="math inline">\(\overline{Y}_{j+1:T}\)</span> denotes the average of <span class="math inline">\(Y_{j+1}, Y{j+2}, \dots, Y_T\)</span>.</p>
<p>In <tt>R</tt> the function <tt>acf()</tt> from the package <tt>stats</tt> computes the sample autocovariance or the sample autocorrelation function.</p>
</div>
<p>Using <tt>acf()</tt> it is straightforward to compute the first four sample autocorrelations of the series <tt>GDPGrowth</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">acf</span>(<span class="kw">na.omit</span>(GDPGrowth), <span class="dt">lag.max =</span> <span class="dv">4</span>, <span class="dt">plot =</span> F)</code></pre></div>
<pre><code>## 
## Autocorrelations of series &#39;na.omit(GDPGrowth)&#39;, by lag
## 
##  0.00  0.25  0.50  0.75  1.00 
## 1.000 0.352 0.273 0.114 0.106</code></pre>
<p>This is evidence that there is mild positive autocorrelation in the growth of GDP: if GDP grows faster than average in one period, there is a tendency for it to grow faster than average in the following periods.</p>
</div>
<div id="other-examples-of-economic-time-series" class="section level4 unnumbered">
<h4>Other Examples of Economic Time Series</h4>
<p>Figure 14.2 of the book presents four plots: the U.S. unemployment rate, the U.S. Dollar / British Pound exchange rate, the logarithm of the Japanese industrial production index as well as daily changes in the Wilshire 5000 stock price index, a financial time series. The next code chunk reproduces the plots of the three macroeconomic series and adds percentage changes in the daily values of the New York Stock Exchange Composite index as a fourth one (the data set <tt>NYSESW</tt> comes with the <tt>AER</tt> package).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define series as xts objects</span>
USUnemp &lt;-<span class="st"> </span><span class="kw">xts</span>(USMacroSWQ<span class="op">$</span>UNRATE, USMacroSWQ<span class="op">$</span>Date)[<span class="st">&quot;1960::2013&quot;</span>]

DollarPoundFX &lt;-<span class="st"> </span><span class="kw">xts</span>(USMacroSWQ<span class="op">$</span>EXUSUK, USMacroSWQ<span class="op">$</span>Date)[<span class="st">&quot;1960::2013&quot;</span>]
  
JPIndProd &lt;-<span class="st"> </span><span class="kw">xts</span>(<span class="kw">log</span>(USMacroSWQ<span class="op">$</span>JAPAN_IP), USMacroSWQ<span class="op">$</span>Date)[<span class="st">&quot;1960::2013&quot;</span>]

<span class="co"># attach NYSESW data</span>
<span class="kw">data</span>(<span class="st">&quot;NYSESW&quot;</span>)  
NYSESW &lt;-<span class="st"> </span><span class="kw">xts</span>(<span class="kw">Delt</span>(NYSESW))</code></pre></div>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># divide plotting area into 2x2 matrix</span>
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))

<span class="co"># plot the series</span>
<span class="kw">plot</span>(<span class="kw">as.zoo</span>(USUnemp),
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Percent&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;US Unemployment Rate&quot;</span>,
     <span class="dt">cex.main =</span> <span class="dv">1</span>)

<span class="kw">plot</span>(<span class="kw">as.zoo</span>(DollarPoundFX),
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Dollar per pound&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;U.S. Dollar / B. Pound Exchange Rate&quot;</span>,
     <span class="dt">cex.main =</span> <span class="dv">1</span>)

<span class="kw">plot</span>(<span class="kw">as.zoo</span>(JPIndProd),
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Logarithm&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Japanese Industrial Production&quot;</span>,
     <span class="dt">cex.main =</span> <span class="dv">1</span>)

<span class="kw">plot</span>(<span class="kw">as.zoo</span>(NYSESW),
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Percent per Day&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;New York Stock Exchange Composite Index&quot;</span>,
     <span class="dt">cex.main =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-581-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>The series show quite different characteristics. The unemployment rate increases during recessions and declines during economic recoveries and growth. The Dollar/Pound exchange rates shows a deterministic pattern until the end of the Bretton Woods system. Japan’s industrial production exhibits an upward trend and decreasing growth. Daily changes in the New York Stock Exchange composite index seem to fluctuate randomly around the zero line. The sample autocorrelations support this conjecture.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute sample autocorrelation for the NYSESW series</span>
<span class="kw">acf</span>(<span class="kw">na.omit</span>(NYSESW), <span class="dt">plot =</span> F, <span class="dt">lag.max =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>## 
## Autocorrelations of series &#39;na.omit(NYSESW)&#39;, by lag
## 
##      0      1      2      3      4      5      6      7      8      9 
##  1.000  0.040 -0.016 -0.023  0.000 -0.036 -0.027 -0.059  0.013  0.017 
##     10 
##  0.004</code></pre>
<p>The first 10 sample autocorrelation coefficients are very close to zero. The default plot generated by <code>acf()</code> provides further evidence.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot sample autocorrelation for the NYSESW series</span>
<span class="kw">acf</span>(<span class="kw">na.omit</span>(NYSESW), <span class="dt">main =</span> <span class="st">&quot;Sample Autocorrelation for NYSESW Data&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-583-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The blue dashed bands represent values beyond which the autocorrelations are significantly different from zero at <span class="math inline">\(5\%\)</span> level. Even when the true autocorrelations are zero, we need to expect a few exceedences — recall the definition of a type-I-error from Key Concept 3.5. For most lags we see that the sample autocorrelation does not exceed the bands and there are only a few cases that lie marginally beyond the limits.</p>
<p>Furthermore, the <tt>NYSESW</tt> series exhibits what econometricians call <em>volatility clustering</em>: there are periods of high and periods of low variance. This is common for many financial time series.</p>
</div>
</div>
</div>
<div id="autoregressions" class="section level2">
<h2><span class="header-section-number">14.3</span> Autoregressions</h2>
<p>Autoregressive models are heavily used in economic forecasting. An autoregressive model relates a time series variable to its past values. This section discusses the basic ideas of autoregressions models, shows how they are estimated and discusses an application to forecasting GDP growth using <tt>R</tt>.</p>
<div id="the-first-order-autoregressive-model" class="section level4 unnumbered">
<h4>The First-Order Autoregressive Model</h4>
It is intuitive that the immediate past of a variable should have power to predict its near future. The simplest autoregressive model uses only the most recent outcome of the time series observed to predict future values. For a time series <span class="math inline">\(Y_t\)</span> such a model is called a first-order autoregressive model, often abbreviated AR(1), where the 1 indicates that the order of autoregression is one:
<span class="math display">\[\begin{align*}
  Y_t = \beta_0 + \beta_1 Y_{t-1} + u_t
\end{align*}\]</span>
<p>is the AR(1) population model of a time series <span class="math inline">\(Y_t\)</span>.</p>
For the GDP growth series, an autoregressive model of order one uses only the information on GDP growth observed in the last quarter to predict a future growth rate. The first-order autoregression model of GDP growth can be estimated by computing OLS estimates in the regression of <span class="math inline">\(GDPGR_t\)</span> on <span class="math inline">\(GDPGR_{t-1}\)</span>,
<span class="math display" id="eq:GDPGRAR1">\[\begin{align}
  \widehat{GDPGR}_t = \hat\beta_0 + \hat\beta_1  GDPGR_{t-1}. \tag{14.1}
\end{align}\]</span>
<p>Following the book we use data from 1962 to 2012 to estimate <a href="ittsraf.html#eq:GDPGRAR1">(14.1)</a>. This is easily done with the function <tt>ar.ols()</tt> from the package <tt>stats</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># subset data</span>
GDPGRSub &lt;-<span class="st"> </span>GDPGrowth[<span class="st">&quot;1962::2012&quot;</span>]

<span class="co"># estimate the model</span>
<span class="kw">ar.ols</span>(GDPGRSub, 
       <span class="dt">order.max =</span> <span class="dv">1</span>, 
       <span class="dt">demean =</span> F, 
       <span class="dt">intercept =</span> T)</code></pre></div>
<pre><code>## 
## Call:
## ar.ols(x = GDPGRSub, order.max = 1, demean = F, intercept = T)
## 
## Coefficients:
##      1  
## 0.3384  
## 
## Intercept: 1.995 (0.2993) 
## 
## Order selected 1  sigma^2 estimated as  9.886</code></pre>
<p>We can check that the computations done by <tt>ar.ols()</tt> are the same as done by <tt>lm()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># length of data set</span>
N &lt;-<span class="kw">length</span>(GDPGRSub)

GDPGR_level &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(GDPGRSub[<span class="op">-</span><span class="dv">1</span>])
GDPGR_lags &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(GDPGRSub[<span class="op">-</span>N])

<span class="co"># estimate the model</span>
armod &lt;-<span class="st"> </span><span class="kw">lm</span>(GDPGR_level <span class="op">~</span><span class="st"> </span>GDPGR_lags)
armod</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = GDPGR_level ~ GDPGR_lags)
## 
## Coefficients:
## (Intercept)   GDPGR_lags  
##      1.9950       0.3384</code></pre>
<p>As usual, we may use <tt>coeftest()</tt> to obtain a robust summary on the estimated regression coefficients.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># robust summary</span>
<span class="kw">coeftest</span>(armod, <span class="dt">vcov. =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 1.994986   0.351274  5.6793 4.691e-08 ***
## GDPGR_lags  0.338436   0.076188  4.4421 1.470e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
Thus the estimated model is
<span class="math display" id="eq:gdpgrar1">\[\begin{align}
  \widehat{GDPGR}_t = \underset{(0.351)}{1.995} + \underset{(0.076)}{0.338} GDPGR_{t-1} \tag{14.2}.
\end{align}\]</span>
<p>We omit the first observation for <span class="math inline">\(GDPGR_{1962 \ Q1}\)</span> from the vector of the dependent variable since <span class="math inline">\(GDPGR_{1962 \ Q1 - 1} = GDPGR_{1961 \ Q4}\)</span>, is not included in the sample. Similarly, the last observation, <span class="math inline">\(GDPGR_{2012 \ Q4}\)</span>, is excluded from the predictor vector since the data does not include <span class="math inline">\(GDPGR_{2012 \ Q4 + 1} = GDPGR_{2013 \ Q1}\)</span>. Put differently, when estimating the model, one observation is lost because of the time series structure of the data.</p>
</div>
<div id="forecasts-and-forecast-errors" class="section level4 unnumbered">
<h4>Forecasts and Forecast Errors</h4>
Suppose <span class="math inline">\(Y_t\)</span> follows an AR(1) model with an intercept and that you have an OLS estimate of the model on the basis of observations for <span class="math inline">\(T\)</span> periods. Then you may use the AR(1) model to obtain <span class="math inline">\(\widehat{Y}_{T+1\vert T}\)</span>, a forecast for <span class="math inline">\(Y_{T+1}\)</span> using data up to period <span class="math inline">\(T\)</span> where
<span class="math display">\[\begin{align*}
  \widehat{Y}_{T+1\vert T} = \hat{\beta}_0 + \hat{\beta}_1 Y_T.
\end{align*}\]</span>
The forecast error is
<span class="math display">\[\begin{align*}
  \text{Forecast error} = Y_{T+1} - \widehat{Y}_{T+1\vert T}.
\end{align*}\]</span>
</div>
<div id="forecasts-and-predicted-values" class="section level4 unnumbered">
<h4>Forecasts and Predicted Values</h4>
<p>Forecasted values of <span class="math inline">\(Y_t\)</span> are <em>not</em> what we refer to as <em>OLS predicted values</em> of <span class="math inline">\(Y_t\)</span>. Also, the forecast error is <em>not</em> an OLS residual. Forecasts and forecast errors are obtained using <em>out-of-sample</em> values while predicted values and residuals are computed for <em>in-sample</em> values that were actually observed and used in estimating the model.</p>
The root mean squared forecast error (RMSFE) measures the typical size of the forecast error and is defined as
<span class="math display">\[\begin{align*}
  RMSFE = \sqrt{E\left[\left(Y_{T+1} - \widehat{Y}_{T+1\vert T}\right)^2\right]}.
\end{align*}\]</span>
<p>The <span class="math inline">\(RMSFE\)</span> is composed of the future errors <span class="math inline">\(u_t\)</span> and the error made when estimating the coefficients. When the sample size is large, the former may be much larger than the latter so that <span class="math inline">\(RMSFE \approx \sqrt{Var()u_t}\)</span> which can be estimated by the standard error of the regression.</p>
</div>
<div id="application-to-gdp-growth" class="section level4 unnumbered">
<h4>Application to GDP Growth</h4>
<p>Using <a href="ittsraf.html#eq:gdpgrar1">(14.2)</a>, the estimated AR(1) model of GDP growth, we perform the forecast for GDP growth for 2013:Q1 (remember that the model was estimated using data for periods 1962:Q1 - 2012:Q4, so 2013:Q1 is an out-of-sample period). Plugging <span class="math inline">\(GDPGR_{2012:Q4} \approx 0.15\)</span> into <a href="ittsraf.html#eq:gdpgrar1">(14.2)</a>,</p>
<span class="math display">\[\begin{align*}
  \widehat{GDPGR}_{2013:Q1} = 1.995 + 0.348 \cdot 0.15 = 2.047.
\end{align*}\]</span>
<p>The function <tt>forecast()</tt> from the <tt>forecast</tt> package has some useful features for forecasting time series data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(forecast)

<span class="co"># assign GDP growth rate in 2012:Q4</span>
new &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;GDPGR_lags&quot;</span> =<span class="st"> </span>GDPGR_level[N<span class="op">-</span><span class="dv">1</span>])

<span class="co"># forecast GDP growth rate in 2013:Q1</span>
<span class="kw">forecast</span>(armod, <span class="dt">newdata =</span> new)</code></pre></div>
<pre><code>##   Point Forecast     Lo 80    Hi 80     Lo 95    Hi 95
## 1       2.044155 -2.036225 6.124534 -4.213414 8.301723</code></pre>
<p>Using <tt>forecast()</tt>produces the same point forecast of about 2.0, along with <span class="math inline">\(80\%\)</span> and <span class="math inline">\(95\%\)</span> forecast intervals, see section <a href="ittsraf.html#apatadlm">14.5</a>. We conclude that our AR(1) model forecasts GDP growth to be <span class="math inline">\(2\%\)</span> in 2013:Q1.</p>
<p>How accurate is this forecast? The forecast error is quite large: <span class="math inline">\(GDPGR_{2013:Q1} \approx 1.1\%\)</span> while our forecast is <span class="math inline">\(2\%\)</span>. Second, by calling <code>summary(armod)</code> shows that the model explains only little of the variation in the growth rate of GDP and the <span class="math inline">\(SER\)</span> is about <span class="math inline">\(3.16\)</span>. Leaving aside forecast uncertainty due to estimation of the model coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, the <span class="math inline">\(RMSFE\)</span> must be at least <span class="math inline">\(3.16\%\)</span>, the estimate of the standard deviation of the errors. We conclude that this forecast is pretty inaccurate.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute the forecast error</span>
<span class="kw">forecast</span>(armod, <span class="dt">newdata =</span> new)<span class="op">$</span>mean <span class="op">-</span><span class="st"> </span>GDPGrowth[<span class="st">&quot;2013&quot;</span>][<span class="dv">1</span>]</code></pre></div>
<pre><code>##                 x
## 2013 Q1 0.9049532</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># R^2</span>
<span class="kw">summary</span>(armod)<span class="op">$</span>r.squared</code></pre></div>
<pre><code>## [1] 0.1149576</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># SER</span>
<span class="kw">summary</span>(armod)<span class="op">$</span>sigma</code></pre></div>
<pre><code>## [1] 3.15979</code></pre>
</div>
<div id="autoregressive-models-of-order-p" class="section level3 unnumbered">
<h3>Autoregressive Models of Order <span class="math inline">\(p\)</span></h3>
<p>For forecasting GDP growth, the AR(<span class="math inline">\(1\)</span>) model <a href="ittsraf.html#eq:gdpgrar1">(14.2)</a> disregards any information in the past of the series that is more distant than one period. An AR(<span class="math inline">\(p\)</span>) model incorporates the information of <span class="math inline">\(p\)</span> lags of the series. The idea is explained in Key Concept 14.3.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.3
</h3>
<h3 class="left">
Autoregressions
</h3>
<p>
An AR(<span class="math inline">\(p\)</span>) model assumes that a time series <span class="math inline">\(Y_t\)</span> can be modeld by a linear function of the first <span class="math inline">\(p\)</span> of its lagged values.
<span class="math display">\[\begin{align*}
  Y_t = \beta_0 + \beta_1 Y_{t-1} + \beta_2 Y_{t-2} + \dots + \beta_p Y_{t-p} + u_t
\end{align*}\]</span>
is an autoregressive model of order <span class="math inline">\(p\)</span> where <span class="math inline">\(E(u_t\vert Y_{t-1}, Y_{t-2}, \dots,Y_{t-p})=0\)</span>.
</p>
</div>
<p>Following the book, we estimate an AR(<span class="math inline">\(2\)</span>) model of the GDP growth series from 1962:Q1 to 2012:Q4.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the AR(2) model</span>
GDPGR_AR2 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(<span class="kw">ts</span>(GDPGR_level) <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(<span class="kw">ts</span>(GDPGR_level)) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(<span class="kw">ts</span>(GDPGR_level), <span class="dv">2</span>))

<span class="kw">coeftest</span>(GDPGR_AR2, <span class="dt">vcov. =</span> sandwich)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                       Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)           1.631747   0.402023  4.0588 7.096e-05 ***
## L(ts(GDPGR_level))    0.277787   0.079250  3.5052 0.0005643 ***
## L(ts(GDPGR_level), 2) 0.179269   0.079951  2.2422 0.0260560 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
The estimation yields
<span class="math display" id="eq:GDPGRAR2">\[\begin{align}
  \widehat{GDPGR}_t = \underset{(0.40)}{1.63} + \underset{(0.08)}{0.28} GDPGR_{t-1} + \underset{(0.08)}{0.18} GDPGR_{t-1}. \tag{14.3}
\end{align}\]</span>
<p>We see that the coefficient on the second lag is significantly different from zero. The fit improves slightly: <span class="math inline">\(\bar{R}^2\)</span> grows from <span class="math inline">\(0.11\)</span> for the AR(<span class="math inline">\(1\)</span>) model to about <span class="math inline">\(0.14\)</span> and the <span class="math inline">\(SER\)</span> reduces to <span class="math inline">\(3.13\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># R^2</span>
<span class="kw">summary</span>(GDPGR_AR2)<span class="op">$</span>r.squared</code></pre></div>
<pre><code>## [1] 0.1425484</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># SER</span>
<span class="kw">summary</span>(GDPGR_AR2)<span class="op">$</span>sigma</code></pre></div>
<pre><code>## [1] 3.132122</code></pre>
<p>We may use the AR(<span class="math inline">\(2\)</span>) model to obtain a forecast for GDP growth in 2013:Q1 in the same manner as for the AR(1) model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># AR(2) forecast of GDP growth in 2013:Q1 </span>
forecast &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;2013:Q1&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(GDPGR_AR2) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, GDPGR_level[N<span class="op">-</span><span class="dv">1</span>], GDPGR_level[N<span class="op">-</span><span class="dv">2</span>]))</code></pre></div>
<p>This leads to a forecast error of roughly <span class="math inline">\(-1\%\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute AR(2) forecast error </span>
GDPGrowth[<span class="st">&quot;2013&quot;</span>][<span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>forecast</code></pre></div>
<pre><code>##                 x
## 2013 Q1 -1.025358</code></pre>
</div>
</div>
<div id="cybtmpi" class="section level2">
<h2><span class="header-section-number">14.4</span> Can You Beat the Market? (Part I)</h2>
<p>The theory of efficient capital markets states that stock prices embody all currently available information. If this hypothesis holds, it should not be possible to estimate a useful model for forecasting future stock returns using publicly available information on past returns (this is also referred to as the weak-form efficiency hypothesis): if it was possible to forecast the market, traders would be able to arbitrage, e.g., by relying on an AR(<span class="math inline">\(2\)</span>) model, they would use information that is not already priced-in which would push prices until the expected return is zero.</p>
<p>This idea is presented in the box <em>Can You Beat the Market? (Part I)</em> on p. 582 of the book. This section reproduces the estimation results.</p>
<p>We start by importing monthly data from 1931:1 to 2002:12 on excess returns of a broad-based index of stock prices, the CRSP value-weighted index. The data are provided by the authors of the book as an excel sheet which can be downloaded <a href="http://wps.aw.com/wps/media/objects/11422/11696965/data3eu/Stock_Returns_1931_2002.xlsx">here</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># read in data on stock returns</span>
SReturns &lt;-<span class="st"> </span><span class="kw">read_xlsx</span>(<span class="st">&quot;Data/Stock_Returns_1931_2002.xlsx&quot;</span>,
                      <span class="dt">sheet =</span> <span class="dv">1</span>,
                      <span class="dt">col_types =</span> <span class="st">&quot;numeric&quot;</span>)</code></pre></div>
<p>We continue by converting the data to an object of class <tt>ts</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># convert to ts object</span>
StockReturns &lt;-<span class="st"> </span><span class="kw">ts</span>(SReturns[, <span class="dv">3</span><span class="op">:</span><span class="dv">4</span>], 
                   <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1931</span>, <span class="dv">1</span>), 
                   <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">12</span>), 
                   <span class="dt">frequency =</span> <span class="dv">12</span>)</code></pre></div>
<p>Next, we estimate AR(<span class="math inline">\(1\)</span>), AR(<span class="math inline">\(2\)</span>) and AR(<span class="math inline">\(4\)</span>) models of excess returns for the time period 1960:1 to 2002:12.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate AR models:</span>

<span class="co"># AR(1)</span>
SR_AR1 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(ExReturn <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(ExReturn), 
      <span class="dt">data =</span> StockReturns, <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">12</span>))

<span class="co"># AR(2)</span>
SR_AR2 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(ExReturn <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(ExReturn) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(ExReturn, <span class="dv">2</span>), 
      <span class="dt">data =</span> StockReturns, <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">12</span>))

<span class="co"># AR(4)</span>
SR_AR4 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(ExReturn <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(ExReturn) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(ExReturn, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>), 
      <span class="dt">data =</span> StockReturns, <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">12</span>))</code></pre></div>
<p>After computing robust standard errors, we gather the results in a table generated by <tt>stargazer()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute robust standard errors</span>
rob_se &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">sandwich</span>(SR_AR1))),
               <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">sandwich</span>(SR_AR2))),
               <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">sandwich</span>(SR_AR4))))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate table using &#39;stargazer()&#39;</span>
<span class="kw">stargazer</span>(SR_AR1, SR_AR2, SR_AR4,
  <span class="dt">title =</span> <span class="st">&quot;Autoregressive Models of Monthly Excess Stock Returns&quot;</span>,
  <span class="dt">header =</span> <span class="ot">FALSE</span>, 
  <span class="dt">model.numbers =</span> F,
  <span class="dt">omit.table.layout =</span> <span class="st">&quot;n&quot;</span>,
  <span class="dt">digits =</span> <span class="dv">3</span>, 
  <span class="dt">column.labels =</span> <span class="kw">c</span>(<span class="st">&quot;AR(1)&quot;</span>, <span class="st">&quot;AR(2)&quot;</span>, <span class="st">&quot;AR(4)&quot;</span>),
  <span class="dt">dep.var.caption  =</span> <span class="st">&quot;Dependent Variable: Excess Returns on the CSRP Value-Weighted Index&quot;</span>,
  <span class="dt">dep.var.labels.include =</span> <span class="ot">FALSE</span>,
  <span class="dt">covariate.labels =</span> <span class="kw">c</span>(<span class="st">&quot;$excess return_{t-1}$&quot;</span>, <span class="st">&quot;$excess return_{t-2}$&quot;</span>, 
                       <span class="st">&quot;$excess return_{t-3}$&quot;</span>, <span class="st">&quot;$excess return_{t-4}$&quot;</span>, 
                       <span class="st">&quot;Intercept&quot;</span>),
  <span class="dt">se =</span> rob_se,
  <span class="dt">omit.stat =</span> <span class="st">&quot;rsq&quot;</span>) </code></pre></div>



<table style="text-align:center"><tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"></td><td colspan="3">Dependent Variable: Excess returns on the CSRP Value-Weighted Index</td></tr>
<tr><td></td><td colspan="3" style="border-bottom: 1px solid black"></td></tr>
<tr><td style="text-align:left"></td><td>AR(1)</td><td>AR(2)</td><td>AR(4)</td></tr>
<tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">excess return<sub>t-1</sub></td><td>0.050</td><td>0.053</td><td>0.054</td></tr>
<tr><td style="text-align:left"></td><td>(0.051)</td><td>(0.051)</td><td>(0.051)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">excess return<sub>t-2</sub></td><td></td><td>-0.053</td><td></td></tr>
<tr><td style="text-align:left"></td><td></td><td>(0.048)</td><td></td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">excess return<sub>t-3</sub></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">excess return<sub>t-4</sub></td><td></td><td></td><td>-0.054</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td>(0.048)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">Intercept</td><td></td><td></td><td>0.009</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td>(0.050)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">L(ExReturn, 1:4)4</td><td></td><td></td><td>-0.016</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td>(0.047)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">Constant</td><td>0.312</td><td>0.328<sup>*</sup></td><td>0.331</td></tr>
<tr><td style="text-align:left"></td><td>(0.197)</td><td>(0.199)</td><td>(0.202)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">Observations</td><td>516</td><td>516</td><td>516</td></tr>
<tr><td style="text-align:left">Adjusted R<sup>2</sup></td><td>0.001</td><td>0.001</td><td>-0.002</td></tr>
<tr><td style="text-align:left">Residual Std. Error</td><td>4.334 (df = 514)</td><td>4.332 (df = 513)</td><td>4.340 (df = 511)</td></tr>
<tr><td style="text-align:left">F Statistic</td><td>1.306 (df = 1; 514)</td><td>1.367 (df = 2; 513)</td><td>0.721 (df = 4; 511)</td></tr>
<tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr></table>
<caption><p style='text-align:center'><span id="tab:amomesr">Table 14.1: </span> Autoregressive Models of Monthly Excess Stock Returns</p></caption>


<p>The results are consistent with the hypothesis of efficient financial markets: there are no statistically significant coefficients in any of the estimated models and the hypotheses that all coefficients are zero cannot be rejected. <span class="math inline">\(\bar{R}^2\)</span> is almost zero in all models and even negative for the AR(<span class="math inline">\(4\)</span>) model. This suggests that none of the models are useful for forecasting stock returns.</p>
</div>
<div id="apatadlm" class="section level2">
<h2><span class="header-section-number">14.5</span> Additional Predictors and The ADL Model</h2>
<p>Instead of only using the dependent variable’s lags as predictors, an autoregressive distributed lag (ADL) model also uses lags of other variables for forecasting. The general ADL model is summarized in Key Concept 14.4:</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.4
</h3>
<h3 class="left">
The Autoregressive Distributed Lag Model
</h3>
<p>
An ADL(<span class="math inline">\(p\)</span>,<span class="math inline">\(q\)</span>) model assumes that a time series <span class="math inline">\(Y_t\)</span> can be represented by a linear function of <span class="math inline">\(p\)</span> of its lagged values and <span class="math inline">\(q\)</span> lags of another time series <span class="math inline">\(X_t\)</span>:
<span class="math display">\[\begin{align*}
  Y_t =&amp; \, \beta_0 + \beta_1 Y_{t-1} + \beta_2 Y_{t-2} + \dots + \beta_p Y_{t-p} \\ 
      &amp;+ \, \delta_1 X_{t-1} + \delta_2 X_{t-2} + \dots + \delta_q X_{t-q} X_{t-q} + u_t.
\end{align*}\]</span>
is an <em>autoregressive distributed lag model</em> with <span class="math inline">\(p\)</span> lags of <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(q\)</span> lags of <span class="math inline">\(X_t\)</span> where <span class="math display">\[E(u_t\vert Y_{t-1}, Y_{t-2}, \dots, X_{t-1}, X_{t-2}, \dots)=0.\]</span>
</p>
</div>
<div id="forecasting-gdp-growth-using-the-term-spread" class="section level4 unnumbered">
<h4>Forecasting GDP Growth Using the Term Spread</h4>
<p>Interest rates on long-term and short term treasury bonds are closely linked to macroeconomic conditions. While interest rates on both types of bonds have the same long-run tendencies, they behave quite differently in the short run. The difference in interest rates of two bonds with distinct maturity is called the <em>term spread</em>.</p>
<p>The following code chunks reproduce Figure 14.3 of the book which displays interest rates of 10-year U.S. Treasury bonds and 3-months U.S. Treasury bills from 1960 to 2012.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 3-months Treasury bills interest rate</span>
TB3MS &lt;-<span class="st"> </span><span class="kw">xts</span>(USMacroSWQ<span class="op">$</span>TB3MS, USMacroSWQ<span class="op">$</span>Date)[<span class="st">&quot;1960::2012&quot;</span>]

<span class="co"># 10-years Treasury bonds interest rate</span>
TB10YS &lt;-<span class="st"> </span><span class="kw">xts</span>(USMacroSWQ<span class="op">$</span>GS10, USMacroSWQ<span class="op">$</span>Date)[<span class="st">&quot;1960::2012&quot;</span>]

<span class="co"># term spread</span>
TSpread &lt;-<span class="st"> </span>TB10YS <span class="op">-</span><span class="st"> </span>TB3MS</code></pre></div>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># reproduce Figure 14.2 (a) of the book</span>
<span class="kw">plot</span>(<span class="kw">merge</span>(<span class="kw">as.zoo</span>(TB3MS), <span class="kw">as.zoo</span>(TB10YS)), 
     <span class="dt">plot.type =</span> <span class="st">&quot;single&quot;</span>, 
     <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;steelblue&quot;</span>),
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Percent per annum&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Interest Rates&quot;</span>)

<span class="co"># define function that transform years to class &#39;yearqtr&#39;</span>
YToYQTR &lt;-<span class="st"> </span><span class="cf">function</span>(years) {
  <span class="kw">return</span>(
      <span class="kw">sort</span>(<span class="kw">as.yearqtr</span>(<span class="kw">sapply</span>(years, paste, <span class="kw">c</span>(<span class="st">&quot;Q1&quot;</span>, <span class="st">&quot;Q2&quot;</span>, <span class="st">&quot;Q3&quot;</span>, <span class="st">&quot;Q4&quot;</span>))))
  )
}

<span class="co"># recessions</span>
recessions &lt;-<span class="st"> </span><span class="kw">YToYQTR</span>(<span class="kw">c</span>(<span class="dv">1961</span><span class="op">:</span><span class="dv">1962</span>, <span class="dv">1970</span>, <span class="dv">1974</span><span class="op">:</span><span class="dv">1975</span>, <span class="dv">1980</span><span class="op">:</span><span class="dv">1982</span>, <span class="dv">1990</span><span class="op">:</span><span class="dv">1991</span>, <span class="dv">2001</span>, <span class="dv">2007</span><span class="op">:</span><span class="dv">2008</span>))
          
<span class="co"># add color shading for recessions</span>
<span class="kw">xblocks</span>(<span class="kw">time</span>(<span class="kw">as.zoo</span>(TB3MS)), 
        <span class="kw">c</span>(<span class="kw">time</span>(TB3MS) <span class="op">%in%</span><span class="st"> </span>recessions), 
        <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.3</span>))

<span class="co"># add a legend</span>
<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, 
       <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;TB3MS&quot;</span>, <span class="st">&quot;TB10YS&quot;</span>),
       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;steelblue&quot;</span>),
       <span class="dt">lwd =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-605-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># reproduce Figure 14.2 (b) of the book</span>
<span class="kw">plot</span>(<span class="kw">as.zoo</span>(TSpread), 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Percent per annum&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Term Spread&quot;</span>)

<span class="co"># add color shading for recessions</span>
<span class="kw">xblocks</span>(<span class="kw">time</span>(<span class="kw">as.zoo</span>(TB3MS)), 
        <span class="kw">c</span>(<span class="kw">time</span>(TB3MS) <span class="op">%in%</span><span class="st"> </span>recessions), 
        <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.3</span>))</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-605-2.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>Before recessions, the gap between interest rates on long-term bonds and short term bills narrows and consequently the term spread declines drastically towards zero or even becomes negative in times of economic stress. This information might be used to improve GDP growth forecasts of future.</p>
<p>We check this by estimating an ADL(<span class="math inline">\(2\)</span>, <span class="math inline">\(1\)</span>) model and an ADL(<span class="math inline">\(2\)</span>, <span class="math inline">\(2\)</span>) model of the GDP growth rate using lags of GDP growth and lags of the term spread as regressors. We then use both models for forecasting GDP growth in 2013:Q1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># convert growth and spread series to ts objects</span>
GDPGrowth_ts &lt;-<span class="st"> </span><span class="kw">ts</span>(GDPGrowth, 
                  <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), 
                  <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2013</span>, <span class="dv">4</span>), 
                  <span class="dt">frequency =</span> <span class="dv">4</span>)

TSpread_ts &lt;-<span class="st"> </span><span class="kw">ts</span>(TSpread, 
                <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), 
                <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">4</span>), 
                <span class="dt">frequency =</span> <span class="dv">4</span>)

<span class="co"># join both ts objects</span>
ADLdata &lt;-<span class="st"> </span><span class="kw">ts.union</span>(GDPGrowth_ts, TSpread_ts)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the ADL(2,1) model of GDP growth</span>
GDPGR_ADL21 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(GDPGrowth_ts <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(GDPGrowth_ts) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(GDPGrowth_ts, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(TSpread_ts), 
      <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1962</span>, <span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">4</span>))

<span class="kw">coeftest</span>(GDPGR_ADL21, <span class="dt">vcov. =</span> sandwich)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                    Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)        0.954990   0.486976  1.9611 0.051260 . 
## L(GDPGrowth_ts)    0.267729   0.082562  3.2428 0.001387 **
## L(GDPGrowth_ts, 2) 0.192370   0.077683  2.4763 0.014104 * 
## L(TSpread_ts)      0.444047   0.182637  2.4313 0.015925 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
The estimated equation of the ADL(<span class="math inline">\(2\)</span>, <span class="math inline">\(1\)</span>) model is
<span class="math display" id="eq:gdpgradl21">\[\begin{align}
  \widehat{GDPGR}_t = \underset{(0.49)}{0.96} + \underset{(0.08)}{0.26} GDPGR_{t-1} + \underset{(0.08)}{0.19} GDPGR_{t-2} + \underset{(0.18)}{0.44} TSpread_{t-1} \tag{14.4}
\end{align}\]</span>
<p>All coefficients are significant at the level of <span class="math inline">\(5\%\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 2012:Q3 / 2012:Q4 data on GDP growth and term spread</span>
subset &lt;-<span class="st"> </span><span class="kw">window</span>(ADLdata, <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">3</span>), <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">4</span>))

<span class="co"># ADL(2,1) GDP growth forecast for 2013:Q1</span>
ADL21_forecast &lt;-<span class="st"> </span><span class="kw">coef</span>(GDPGR_ADL21) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, subset[<span class="dv">2</span>, <span class="dv">1</span>], subset[<span class="dv">1</span>, <span class="dv">1</span>], subset[<span class="dv">2</span>, <span class="dv">2</span>])
ADL21_forecast</code></pre></div>
<pre><code>##          [,1]
## [1,] 2.241689</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute the forecast error</span>
<span class="kw">window</span>(GDPGrowth_ts, <span class="kw">c</span>(<span class="dv">2013</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">2013</span>, <span class="dv">1</span>)) <span class="op">-</span><span class="st"> </span>ADL21_forecast</code></pre></div>
<pre><code>##           Qtr1
## 2013 -1.102487</code></pre>
<p>Model <a href="ittsraf.html#eq:gdpgradl21">(14.4)</a> predicts the GDP growth in 2013:Q1 to be <span class="math inline">\(2.24\%\)</span> which leads to a forecast error of <span class="math inline">\(-1.10\%\)</span>.</p>
<p>We estimate the ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) specification to see whether adding additional information on past term spread improves the forecast.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the ADL(2,2) model of GDP growth</span>
GDPGR_ADL22 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(GDPGrowth_ts <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(GDPGrowth_ts) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(GDPGrowth_ts, <span class="dv">2</span>) 
                     <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(TSpread_ts) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(TSpread_ts, <span class="dv">2</span>), 
                     <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1962</span>, <span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">4</span>))

<span class="kw">coeftest</span>(GDPGR_ADL22, <span class="dt">vcov. =</span> sandwich)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                     Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)         0.967967   0.472470  2.0487 0.041800 * 
## L(GDPGrowth_ts)     0.243175   0.077836  3.1242 0.002049 **
## L(GDPGrowth_ts, 2)  0.177070   0.077027  2.2988 0.022555 * 
## L(TSpread_ts)      -0.139554   0.422162 -0.3306 0.741317   
## L(TSpread_ts, 2)    0.656347   0.429802  1.5271 0.128326   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
We obtain
<span class="math display" id="eq:gdpgradl22">\[\begin{align}
  \begin{split}
    \widehat{GDPGR}_t =&amp; \underset{(0.47)}{0.98} + \underset{(0.08)}{0.24} GDPGR_{t-1} \\
    &amp; + \underset{(0.08)}{0.18} GDPGR_{t-2} -\underset{(0.42)}{0.14} TSpread_{t-1} + \underset{(0.43)}{0.66} TSpread_{t-2}.
  \end{split} \tag{14.5}
\end{align}\]</span>
<p>The coefficients on both lags of the term spread are not significant at the <span class="math inline">\(10\%\)</span> level.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ADL(2,2) GDP growth forecast for 2013:Q1</span>
ADL22_forecast &lt;-<span class="st"> </span><span class="kw">coef</span>(GDPGR_ADL22) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, subset[<span class="dv">2</span>, <span class="dv">1</span>], subset[<span class="dv">1</span>, <span class="dv">1</span>], subset[<span class="dv">2</span>, <span class="dv">2</span>], subset[<span class="dv">1</span>, <span class="dv">2</span>])
ADL22_forecast</code></pre></div>
<pre><code>##          [,1]
## [1,] 2.274407</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute the forecast error</span>
<span class="kw">window</span>(GDPGrowth_ts, <span class="kw">c</span>(<span class="dv">2013</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">2013</span>, <span class="dv">1</span>)) <span class="op">-</span><span class="st"> </span>ADL22_forecast</code></pre></div>
<pre><code>##           Qtr1
## 2013 -1.135206</code></pre>
<p>The ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) forecast of GDP growth in 2013:Q1 is <span class="math inline">\(2.27\%\)</span> which implies a forecast error of <span class="math inline">\(1.14\%\)</span>.</p>
<p>Do the ADL models <a href="ittsraf.html#eq:gdpgradl21">(14.4)</a> and <a href="ittsraf.html#eq:gdpgradl22">(14.5)</a> improve upon the simple AR(<span class="math inline">\(2\)</span>) model <a href="ittsraf.html#eq:GDPGRAR2">(14.3)</a>? The answer is yes: while <span class="math inline">\(SER\)</span> and <span class="math inline">\(\bar{R}^2\)</span> improve only slightly, an <span class="math inline">\(F\)</span>-test on the term spread coefficients in <a href="ittsraf.html#eq:gdpgradl22">(14.5)</a> provides evidence that the model does better in explaining GDP growth than the AR(<span class="math inline">\(2\)</span>) model as the hypothesis that both coefficients are zero cannot be rejected at the level of <span class="math inline">\(5\%\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compare adj. R2</span>
<span class="kw">c</span>(<span class="st">&quot;Adj.R2 AR(2)&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(GDPGR_AR2)<span class="op">$</span>r.squared,
  <span class="st">&quot;Adj.R2 ADL(2,1)&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(GDPGR_ADL21)<span class="op">$</span>r.squared,
  <span class="st">&quot;Adj.R2 ADL(2,2)&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(GDPGR_ADL22)<span class="op">$</span>r.squared)</code></pre></div>
<pre><code>##    Adj.R2 AR(2) Adj.R2 ADL(2,1) Adj.R2 ADL(2,2) 
##       0.1425484       0.1743996       0.1855245</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compare SER</span>
<span class="kw">c</span>(<span class="st">&quot;SER AR(2)&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(GDPGR_AR2)<span class="op">$</span>sigma,
  <span class="st">&quot;SER ADL(2,1)&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(GDPGR_ADL21)<span class="op">$</span>sigma,
  <span class="st">&quot;SER ADL(2,2)&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(GDPGR_ADL22)<span class="op">$</span>sigma)</code></pre></div>
<pre><code>##    SER AR(2) SER ADL(2,1) SER ADL(2,2) 
##     3.132122     3.070760     3.057655</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># F-test on coefficients of term spread</span>
<span class="kw">linearHypothesis</span>(GDPGR_ADL22, 
                 <span class="kw">c</span>(<span class="st">&quot;L(TSpread_ts)=0&quot;</span>, <span class="st">&quot;L(TSpread_ts, 2)=0&quot;</span>),
                 <span class="dt">vcov. =</span> sandwich)</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## L(TSpread_ts) = 0
## L(TSpread_ts, 2) = 0
## 
## Model 1: restricted model
## Model 2: GDPGrowth_ts ~ L(GDPGrowth_ts) + L(GDPGrowth_ts, 2) + L(TSpread_ts) + 
##     L(TSpread_ts, 2)
## 
## Note: Coefficient covariance matrix supplied.
## 
##   Res.Df Df      F  Pr(&gt;F)  
## 1    201                    
## 2    199  2 4.4344 0.01306 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="stationarity" class="section level4 unnumbered">
<h4>Stationarity</h4>
<p>In general, forecasts can be improved by using multiple predictors — just as in cross-sectional regression. When constructing time series models one should take into account whether the variables are <em>stationary</em> or <em>nonstationary</em>. Key Concept 14.5 explains what stationarity is.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.5
</h3>
<h3 class="left">
Stationarity
</h3>
<p>A time series <span class="math inline">\(Y_t\)</span> is stationary if its probability distribution is time independent, that is the joint distribution of <span class="math inline">\(Y_{s+1}, Y_{s+2},\dots,Y_{s+T}\)</span> does not change as <span class="math inline">\(s\)</span> is varied, regardless of <span class="math inline">\(T\)</span>.</p>
<p>Similarly, two time series <span class="math inline">\(X_t\)</span> and <span class="math inline">\(Y_t\)</span> are <em>jointly stationary</em> if the joint distribution of <span class="math inline">\((X_{s+1},Y_{s+1}, X_{s+2},Y_{s+2} \dots, X_{s+T},Y_{s+T})\)</span> does not depend on <span class="math inline">\(s\)</span>, regardless of <span class="math inline">\(T\)</span>.</p>
<p>Stationarity makes it easier to learn about the characteristics of past data.</p>
</div>
</div>
<div id="time-series-regression-with-multiple-predictors" class="section level4 unnumbered">
<h4>Time Series Regression with Multiple Predictors</h4>
<p>The concept of stationarity is a key assumption in the general time series regression model with multiple predictors. Key Concept 14.6 lays out this model and its assumptions.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.6
</h3>
<h3 class="left">
Time Series Regression with Multiple Predictors
</h3>
<p>The general time series regression model extends the ADL model such that multiple regressors and their lags are included. It uses <span class="math inline">\(p\)</span> lags of the dependent variable and <span class="math inline">\(q_l\)</span> lags of <span class="math inline">\(l\)</span> additional predictors where <span class="math inline">\(l=1,\dots,k\)</span>:</p>
<span class="math display">\[\begin{equation}
  \begin{aligned}
  Y_t =&amp;  \beta_0 + \beta_1 Y_{t-1} + \beta_2 Y_{t-2} + \dots + \beta_{p} Y_{t-p} \\
      &amp;+  \delta_{11} X_{1,t-1} + \delta_{12} X_{1,t-2} + \dots + \delta_{1q} X_{1,t-q} \\
      &amp;+  \dots \\
      &amp;+  \delta_{k1} X_{k,t-1} + \delta_{k2} X_{k,t-2} + \dots + \delta_{kq} X_{k,t-q} \\
      &amp;+  u_t 
  \end{aligned}
\end{equation}\]</span>
<p>For estimation we make the following assumptions:</p>
<ol style="list-style-type: decimal">
<li><p>The error term <span class="math inline">\(u_t\)</span> has conditional mean zero given all regressors and their lags: <span class="math display">\[E(u_t\vert Y_{t-1}, Y_{t-2}, \dots, X_{1,t-1}, X_{1,t-2} \dots, X_{k,t-1}, X_{k,t-2}, \dots)\]</span> This assumption is an extension of the conditional mean zero assumption used for AR and ADL models and guarantees that the general time series regression model stated above gives the best forecast of <span class="math inline">\(Y_t\)</span> given its lags, the additional regressors <span class="math inline">\(X_{1,t},\dots,X_{k,t}\)</span> and their lags.</p></li>
<li><p>The i.i.d. assumption for cross-sectional data is not (entirely) meaningful for time series data. We replace it by the following assumption witch consists of two parts:</p>
<ol style="list-style-type: lower-alpha">
<li><p>The <span class="math inline">\((Y_{t}, X_{1,t}, \dots, X_{k,t})\)</span> have a stationary distribution (the “identically distributed” part of the i.i.d. assumption for cross-setional data). If this does not hold, forecasts <em>may</em> be biased and inference <em>can</em> be strongly misleading.</p></li>
<li><p><span class="math inline">\((Y_{t}, X_{1,t}, \dots, X_{k,t})\)</span> and <span class="math inline">\((Y_{t-j}, X_{1,t-j}, \dots, X_{k,t-j})\)</span> become independent as <span class="math inline">\(j\)</span> gets large (the “idependently” distributed part of the i.i.d. assumption for cross-sectional data). This assumption is also called <em>weak dependence</em>. It ensures that the WLLN and the CLT hold in large samples.</p></li>
</ol></li>
<li><p>Large outliers are unlikely: <span class="math inline">\(E(X_{1,t}^4), E(X_{2,t}^4), \dots, E(X_{k,t}^4)\)</span> and <span class="math inline">\(E(Y_t^4)\)</span> have nonzero, finite fourth moments.</p></li>
<li><p>No perfect multicollinearity.</p></li>
</ol>
</div>
<p>Since many economic time series appear to be nonstationary, assumption two of Key Concept 14.6 is a crucial one in applied macroeconomics and finance which is why statistical test for stationarity or nonstationarity have been developed. Chapters <a href="ittsraf.html#llsuic">14.6</a> and <a href="ittsraf.html#nit">14.7</a> are devoted to this topic.</p>
</div>
<div id="statistical-inference-and-the-granger-causality-test" class="section level4 unnumbered">
<h4>Statistical inference and the Granger causality test</h4>
<p>If a <span class="math inline">\(X\)</span> is a useful predictor for <span class="math inline">\(Y\)</span>, in a regression of <span class="math inline">\(Y_t\)</span> on lags of its own and lags of <span class="math inline">\(X_t\)</span>, not all of the coefficients on the lags on <span class="math inline">\(X_t\)</span> are zero. This concept is called <em>Granger causality</em> and is an interesting hypothesis to test. Key Concept 14.7 summarizes the idea.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.7
</h3>
<h3 class="left">
Granger Causality Tests
</h3>
<p>The Granger causality test <span class="citation">C. Granger (<a href="#ref-granger1969">1969</a>)</span> is an <span class="math inline">\(F\)</span> test of the null hypothesis that <em>all</em> lags of a variable <span class="math inline">\(X\)</span> included in a time series regression model do not have predictive power for <span class="math inline">\(Y_t\)</span>. The Granger causality test does not test whether <span class="math inline">\(X\)</span> actually <em>causes</em> <span class="math inline">\(Y\)</span> but whether the included lags are informative in terms of predicting <span class="math inline">\(Y\)</span>.</p>
</div>
<p>We have already performed a Granger causality test on the coefficients of term spread in <a href="ittsraf.html#eq:gdpgradl22">(14.5)</a>, the ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) model of GDP growth and concluded that at least one of the first two lags of term spread has predictive power for GDP growth.</p>
</div>
<div id="forecast-uncertainty-and-forecast-intervals" class="section level3 unnumbered">
<h3>Forecast Uncertainty and Forecast Intervals</h3>
In general, it is good practice to report a measure of the uncertainty when presenting results that are affected by the latter. Uncertainty is particularly of interest when forecasting a time series. For example, consider a simple ADL<span class="math inline">\((1,1)\)</span> model
<span class="math display">\[\begin{align*}
  Y_t = \beta_0 + \beta_1 Y_{t-1} + \delta_1 X_{t-1} + u_t
\end{align*}\]</span>
where <span class="math inline">\(u_t\)</span> is a homoskedastic error term. The forecast error is
<span class="math display">\[\begin{align*}
  Y_{T+1} - \widehat{Y}_{T+1\vert T} = u_{T+1} - \left[(\widehat{\beta}_0 - \beta_0) + (\widehat{\beta}_1 - \beta_1) Y_T + (\widehat{\delta_1} - \delta_1) X_T \right].
\end{align*}\]</span>
The mean squared forecast error (MSFE) and the RMFSE are
<span class="math display">\[\begin{align*}
  MFSE =&amp; \, E\left[(Y_{T+1} - \widehat{Y}_{T+1\vert T})^2 \right] \\
       =&amp; \, \sigma_u^2 + Var\left[ (\widehat{\beta}_0 - \beta_0) + (\widehat{\beta}_1 - \beta_1) Y_T + (\widehat{\delta_1} - \delta_1) X_T \right], \\
  RMFSE =&amp; \, \sqrt{\sigma_u^2 + Var\left[ (\widehat{\beta}_0 - \beta_0) + (\widehat{\beta}_1 - \beta_1) Y_T + (\widehat{\delta_1} - \delta_1) X_T \right]}.
\end{align*}\]</span>
A <span class="math inline">\(95\%\)</span> forecast interval is an interval that covers the true value of <span class="math inline">\(Y_{T+1}\)</span> in <span class="math inline">\(95\%\)</span> of repeated applications. There is a major difference in computing a confidence interval and a forecast interval: when computing a confidence interval of a point estimate we use large sample approximations that are justified by the CLT and thus are valid for a large range of error term distributions. For computation of a forecast interval of <span class="math inline">\(Y_{T+1}\)</span>, however, we must make an additional assumption about the distribution of <span class="math inline">\(u_{T+1}\)</span>, the error term in period <span class="math inline">\(T+1\)</span>. Assuming that <span class="math inline">\(u_{T+1}\)</span> is normally distributed one can construct a <span class="math inline">\(95\%\)</span> <em>forecast interval</em> for <span class="math inline">\(Y_{T+1}\)</span> using <span class="math inline">\(SE(Y_{T+1} - \widehat{Y}_{T+1\vert T})\)</span>, an estimate of the RMSFE:
<span class="math display">\[\begin{align*}
  \widehat{Y}_{T+1\vert T} \pm 1.96 \cdot SE(Y_{T+1} - \widehat{Y}_{T+1\vert T})
\end{align*}\]</span>
<p>Of course, the computation gets more complicated when the error term is heteroskedastic or if we are interested in computing a forecast interval for <span class="math inline">\(T+s, s&gt;1\)</span>.</p>
<p>In some applications it is useful to report multiple forecast intervals for subsequent periods, see the box <em>The River of Blood</em> on p. 592 of the book. These can be visualized in a so-called fan chart. We will not replicate the fan chart presented in Figure 14.2 of book because the underlying model is by far more complex than the simple AR and ADL models treated here. Instead, in the example below we use simulated time series data and estimate an AR(<span class="math inline">\(2\)</span>) model which is then used for forecasting the subsequent <span class="math inline">\(25\)</span> future outcomes of the series.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set seed</span>
<span class="kw">set.seed</span>(<span class="dv">1234</span>)

<span class="co"># simulate the time series</span>
Y &lt;-<span class="st"> </span><span class="kw">arima.sim</span>(<span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">ar =</span> <span class="kw">c</span>(<span class="fl">0.2</span>, <span class="fl">0.2</span>)),  <span class="dt">n =</span> <span class="dv">200</span>)

<span class="co"># estimate an AR(2) model using &#39;arima()&#39;, see ?arima</span>
model &lt;-<span class="st"> </span><span class="kw">arima</span>(Y, <span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>))

<span class="co"># compute points forecasts and prediction intervals for the next 25 periods</span>
fc &lt;-<span class="st"> </span><span class="kw">forecast</span>(model, <span class="dt">h =</span> <span class="dv">25</span>, <span class="dt">level =</span> <span class="kw">seq</span>(<span class="dv">5</span>, <span class="dv">99</span>, <span class="dv">10</span>))

<span class="co"># plot a fan chart</span>
<span class="kw">plot</span>(fc, 
     <span class="dt">main =</span> <span class="st">&quot;Forecast Fan Chart for AR(2) Model of Simulated Data&quot;</span>, 
     <span class="dt">showgap =</span> F, 
     <span class="dt">fcol =</span> <span class="st">&quot;red&quot;</span>,
     <span class="dt">flty =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-618-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p><tt>arima.sim()</tt> simulates autoregressive integrated moving average (ARIMA) models. AR models belong to this class of models. We use <tt>list(order = c(2, 0, 0), ar = c(0.2, 0.2))</tt> so the DGP is <span class="math display">\[Y_t = 0.2 Y_{t-1} + 0.2 Y_{t-2} + u_t.\]</span></p>
<p>We choose <tt>level = seq(5, 99, 10)</tt> in the call of <tt>forecast()</tt> such that forecast intervals with levels <span class="math inline">\(5\%, 15\%, \dots, 95\%\)</span> are computed for each point forecast of the series.</p>
<p>The dashed red line shows point forecasts of the series for the next 25 periods based on an <span class="math inline">\(ADL(1,1)\)</span> model and the shaded areas represent the prediction intervals. The degree of shading indicates the level of the prediction interval. The darkest of the blue bands displays the <span class="math inline">\(5\%\)</span> forecast intervals and the color fades towards grey as the level of the intervals increases.</p>
</div>
</div>
<div id="llsuic" class="section level2">
<h2><span class="header-section-number">14.6</span> Lag Length Selection Using Information Criteria</h2>
<p>The selection of lag lengths in AR and ADL models can sometimes be guided by economic theory. However, there are statistical methods that are helpful to determine how many lags should be included as regressors. In general, too many lags inflate the standard errors of coefficient estimates and thus imply an increase in the forecast error while omitting lags that should be included in the model may result in an estimation bias.</p>
<p>The order of an AR model can be determined using two approaches:</p>
<ol style="list-style-type: decimal">
<li><p><strong>The F-test approach</strong></p>
<p>Estimate an AR(<span class="math inline">\(p\)</span>) model and test the significance of the largest lag(s). If the test rejects, drop the respective lag(s) from the model. This approach has the tendency to produce models where the order is too large: in a significance test we always face the risk of rejecting a true null hypothesis!</p></li>
<li><p><strong>Relying on an information criterion</strong></p>
<p>To circumvent the issue of producing too large models, one may choose the lag order that minimizes one of the following two information criteria:</p>
<ul>
<li><p>The <em>Bayes information criterion</em> (BIC):</p>
<p><span class="math display">\[BIC(p) = \log\left(\frac{SSR(p)}{T}\right) + (p + 1) \frac{\log(T)}{T}\]</span></p></li>
<li><p>The <em>Akaike information criterion</em> (AIC):</p>
<p><span class="math display">\[AIC(p) = \log\left(\frac{SSR(p)}{T}\right) + (p + 1) \frac{2}{T}\]</span></p></li>
</ul>
<p>Both criteria are estimators of the optimal lag length <span class="math inline">\(p\)</span>. The lag order <span class="math inline">\(\widehat{p}\)</span> that minimizes the respective criterion is called the <em>BIC estimate</em> or the <em>AIC estimate</em> of the optimal model order. The basic idea of both criteria is that the <span class="math inline">\(SSR\)</span> decreases as additional lags are added to the model such that the first term decreases whereas the second increases as the lag order grows. One can show that the the <span class="math inline">\(BIC\)</span> is a consistent estimator of the true lag order while the AIC is not which is due to the differing factors in the second addend. Nevertheless, both estimators are used in practice where the <span class="math inline">\(AIC\)</span> is sometimes used as an alternative when the <span class="math inline">\(BIC\)</span> yields a model with “too few” lags.</p></li>
</ol>
<p>The function <tt>dynlm()</tt> does not compute information criteria by default. We will therefore write a short function that reports the <span class="math inline">\(BIC\)</span> (along with the chosen lag order <span class="math inline">\(p\)</span> and <span class="math inline">\(R^2\)</span>) for objects of class <tt>dynlm</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute BIC for AR model objects of class &#39;dynlm&#39;</span>
BIC &lt;-<span class="st"> </span><span class="cf">function</span>(model) {
  
  ssr &lt;-<span class="st"> </span><span class="kw">sum</span>(model<span class="op">$</span>residuals<span class="op">^</span><span class="dv">2</span>)
  t &lt;-<span class="st"> </span><span class="kw">length</span>(model<span class="op">$</span>residuals)
  npar &lt;-<span class="st"> </span><span class="kw">length</span>(model<span class="op">$</span>coef)
  
  <span class="kw">return</span>(
    <span class="kw">round</span>(<span class="kw">c</span>(<span class="st">&quot;p&quot;</span> =<span class="st"> </span>npar <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,
          <span class="st">&quot;BIC&quot;</span> =<span class="st"> </span><span class="kw">log</span>(ssr<span class="op">/</span>t) <span class="op">+</span><span class="st"> </span>npar <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(t)<span class="op">/</span>t,
          <span class="st">&quot;R2&quot;</span> =<span class="st"> </span><span class="kw">summary</span>(model)<span class="op">$</span>r.squared), <span class="dv">4</span>)
  )
}</code></pre></div>
<p>Table 14.3 of the book presents a breakdown of how the <span class="math inline">\(BIC\)</span> is computed for AR(<span class="math inline">\(p\)</span>) models of GDP growth with order <span class="math inline">\(p=1,\dots,6\)</span>. The final result can easily be reproduced using <tt>sapply()</tt> and the function <tt>BIC()</tt> defined above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># apply the BIC() to an intercept-only model of GDP growth</span>
<span class="kw">BIC</span>(<span class="kw">dynlm</span>(<span class="kw">ts</span>(GDPGR_level) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>))</code></pre></div>
<pre><code>##      p    BIC     R2 
## 0.0000 2.4394 0.0000</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># loop BIC over models of different orders</span>
order &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">6</span>

BICs &lt;-<span class="st"> </span><span class="kw">sapply</span>(order, <span class="cf">function</span>(x) 
        <span class="st">&quot;AR&quot;</span> =<span class="st"> </span><span class="kw">BIC</span>(<span class="kw">dynlm</span>(<span class="kw">ts</span>(GDPGR_level) <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(<span class="kw">ts</span>(GDPGR_level), <span class="dv">1</span><span class="op">:</span>x))))

BICs</code></pre></div>
<pre><code>##       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]
## p   1.0000 2.0000 3.0000 4.0000 5.0000 6.0000
## BIC 2.3486 2.3475 2.3774 2.4034 2.4188 2.4429
## R2  0.1143 0.1425 0.1434 0.1478 0.1604 0.1591</code></pre>
<p>Note that increasing the lag order increases <span class="math inline">\(R^2\)</span> because the <span class="math inline">\(SSR\)</span> decreases as additional lags are added to the model but according to the <span class="math inline">\(BIC\)</span>, we should settle for the AR(<span class="math inline">\(2\)</span>) model instead of the AR(<span class="math inline">\(6\)</span>) model. It helps us to decide whether the decrease in <span class="math inline">\(SSR\)</span> is enough to justify adding an additional regressor.</p>
<p>If we had to compare a bigger set of models, a convenient way to select the model with the lowest <span class="math inline">\(BIC\)</span> is using the function <tt>which.min()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># select the AR model with the smallest BIC</span>
BICs[, <span class="kw">which.min</span>(BICs[<span class="dv">2</span>, ])]</code></pre></div>
<pre><code>##      p    BIC     R2 
## 2.0000 2.3475 0.1425</code></pre>
The <span class="math inline">\(BIC\)</span> may also be used to select lag lengths in time series regression models with multiple predictors. In a model with <span class="math inline">\(K\)</span> coefficients, including the intercept, we have
<span class="math display">\[\begin{align*}
    BIC(K) = \log\left(\frac{SSR(K)}{T}\right) + K \frac{\log(T)}{T}.
\end{align*}\]</span>
<p>Notice that choosing the optimal model according to the <span class="math inline">\(BIC\)</span> can be computationally demanding because there may be many different combinations of lag lengths when there are multiple predictors.</p>
<p>To give an example, we estimate ADL(<span class="math inline">\(p\)</span>,<span class="math inline">\(q\)</span>) models of GDP growth where, as above, the additional variable is the term spread between short-term and long-term bonds. We impose the restriction that <span class="math inline">\(p=q_1=\dots=q_k\)</span> so that only <span class="math inline">\(p_{max}\)</span> models (<span class="math inline">\(p=1,\dots,p_{max}\)</span>) need to be estimated. In the example below we choose <span class="math inline">\(p_{max} = 12\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># loop &#39;BIC()&#39; over multiple ADL models </span>
order &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">12</span>

BICs &lt;-<span class="st"> </span><span class="kw">sapply</span>(order, <span class="cf">function</span>(x) 
         <span class="kw">BIC</span>(<span class="kw">dynlm</span>(GDPGrowth_ts <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(GDPGrowth_ts, <span class="dv">1</span><span class="op">:</span>x) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(TSpread_ts, <span class="dv">1</span><span class="op">:</span>x), 
                   <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1962</span>, <span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">4</span>))))

BICs</code></pre></div>
<pre><code>##       [,1]   [,2]   [,3]   [,4]    [,5]    [,6]    [,7]    [,8]    [,9]
## p   2.0000 4.0000 6.0000 8.0000 10.0000 12.0000 14.0000 16.0000 18.0000
## BIC 2.3411 2.3408 2.3813 2.4181  2.4568  2.5048  2.5539  2.6029  2.6182
## R2  0.1417 0.1855 0.1950 0.2072  0.2178  0.2211  0.2234  0.2253  0.2581
##       [,10]   [,11]   [,12]
## p   20.0000 22.0000 24.0000
## BIC  2.6646  2.7205  2.7664
## R2   0.2678  0.2702  0.2803</code></pre>
<p>From the definition of <tt>BIC()</tt>, for ADL models with <span class="math inline">\(p=q\)</span> it follows that <tt>p</tt> reports the number of estimated coefficients <em>excluding</em> the intercept. Thus the lag order is obtained by dividing <tt>p</tt> by 2.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># select the ADL model with the smallest BIC</span>
BICs[, <span class="kw">which.min</span>(BICs[<span class="dv">2</span>, ])]</code></pre></div>
<pre><code>##      p    BIC     R2 
## 4.0000 2.3408 0.1855</code></pre>
<p>The <span class="math inline">\(BIC\)</span> is in favor of the ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) model <a href="ittsraf.html#eq:gdpgradl22">(14.5)</a> we have estimated before.</p>
</div>
<div id="nit" class="section level2">
<h2><span class="header-section-number">14.7</span> Nonstationarity I: Trends</h2>
<p>If a series is nonstationary, conventional hypothesis tests, confidence intervals and forecasts can be strongly misleading. The assumption of stationarity is violated if a series exhibits trends or breaks and the resulting complications in an econometric analysis depend on the specific type of the nonstationarity. This section focuses on time series that exhibit trends.</p>
<p>A series is said to exhibit a trend if it has a persistent long-term movement. One distinguishes between <em>deterministic</em> and <em>stochastic</em> trends.</p>
<ul>
<li><p>A trend is <em>deterministic</em> if it is a nonrandom function of time.</p></li>
<li><p>A trend is said to be <em>stochastic</em> if it is a random function of time.</p></li>
</ul>
<p>The figures we have produced in Chapter <a href="ittsraf.html#tsdasc">14.2</a> reveal that many economic time series show a trending behavior that is probably best modeled by stochastic trends. This is why the book focuses on the treatment of stochastic trends.</p>
<div id="the-random-walk-model-of-a-trend" class="section level4 unnumbered">
<h4>The Random Walk Model of a Trend</h4>
The simplest way to model a time series <span class="math inline">\(Y_t\)</span> that has stochastic trend is the <em>random walk</em>
<span class="math display" id="eq:randomwalk">\[\begin{align}
  Y_t = Y_{t-1} + u_t, \tag{14.6}
\end{align}\]</span>
where the <span class="math inline">\(u_t\)</span> are i.i.d. errors with <span class="math inline">\(E(u_t\vert Y_{t-1}, Y_{t-2}, \dots) = 0\)</span>. Note that
<span class="math display">\[\begin{align*}
  E(Y_t\vert Y_{t-1}, Y_{t-2}\dots) =&amp; \, E(Y_{t-1}\vert Y_{t-1}, Y_{t-2}\dots) + E(u_t\vert Y_{t-1}, Y_{t-2}\dots) \\
  =&amp; \, Y_{t-1}
\end{align*}\]</span>
<p>so the best forecast for <span class="math inline">\(Y_t\)</span> is yesterday’s observation <span class="math inline">\(Y_{t-1}\)</span>. Hence the difference between <span class="math inline">\(Y_t\)</span> and <span class="math inline">\(Y_{t-1}\)</span> is unpredictable. The path followed by <span class="math inline">\(Y_t\)</span> consists of random steps <span class="math inline">\(u_t\)</span>, hence it is called a random walk.</p>
Assume that <span class="math inline">\(Y_0\)</span>, the starting value of the random walk is <span class="math inline">\(0\)</span>. Another way to write <a href="ittsraf.html#eq:randomwalk">(14.6)</a> is
<span class="math display">\[\begin{align*}
  Y_0 =&amp; \, 0 \\
  Y_1 =&amp; \, 0 + u_1 \\
  Y_2 =&amp; \, 0 + u_1 + u_2 \\
  \vdots &amp; \, \\
  Y_t =&amp; \, \sum_{i=1}^t u_i.
\end{align*}\]</span>
Therefore we have
<span class="math display">\[\begin{align*}
  Var(Y_t) =&amp; \, Var(u_1 + u_2 + \dots + u_t) \\
           =&amp; \, t \sigma_u^2.
\end{align*}\]</span>
<p>Thus the variance of a random walk depends on <span class="math inline">\(t\)</span> which violates the assumption presented in Key Concept 14.5: a random walk is nonstationary.</p>
<p>Obviously, <a href="ittsraf.html#eq:randomwalk">(14.6)</a> is a special case of an AR(<span class="math inline">\(1\)</span>) model where <span class="math inline">\(\beta_1 = 1\)</span>. One can show that a time series that follows an AR(<span class="math inline">\(1\)</span>) model is stationary if <span class="math inline">\(\lvert\beta_1\rvert &lt; 1\)</span>. In a general AR(<span class="math inline">\(p\)</span>) model, stationarity is linked to the roots of the polynomial <span class="math display">\[1-\beta_1 z - \beta_2 z^2 - \beta_3 z^3 - \dots - \beta_p z^p.\]</span> If all roots are greater than <span class="math inline">\(1\)</span> in absolute value, the AR(<span class="math inline">\(p\)</span>) series is stationary. If at least one root equals <span class="math inline">\(1\)</span>, the AR(<span class="math inline">\(p\)</span>) is said to have a <em>unit root</em> and thus has a stochastic trend.</p>
<p>It is straightforward to simulate random walks in <tt>R</tt> using <tt>arima.sim()</tt>. The function <tt>matplot()</tt> is convenient for simple plots of the columns of a matrix.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate and plot random walks starting at 0</span>
<span class="kw">set.seed</span>(<span class="dv">1</span>)

RWs &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">replicate</span>(<span class="dt">n =</span> <span class="dv">4</span>, 
            <span class="kw">arima.sim</span>(<span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span> ,<span class="dv">0</span>)), <span class="dt">n =</span> <span class="dv">100</span>)))

<span class="kw">matplot</span>(RWs, 
        <span class="dt">type =</span><span class="st">&quot;l&quot;</span>, 
        <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;orange&quot;</span>), 
        <span class="dt">lty =</span> <span class="dv">1</span>, 
        <span class="dt">lwd =</span> <span class="dv">2</span>,
        <span class="dt">main =</span> <span class="st">&quot;Four Random Walks&quot;</span>,
        <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>,
        <span class="dt">ylab =</span> <span class="st">&quot;Value&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-624-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
Adding a constant to <a href="ittsraf.html#eq:randomwalk">(14.6)</a> yields
<span class="math display" id="eq:randomwalkdrift">\[\begin{align}
  Y_t = \beta_0 + Y_{t-1} + u_t \tag{14.7},
\end{align}\]</span>
<p>a <em>random walk model with a drift</em> which allows to model the tendency of a series to move upwards or downwards. If <span class="math inline">\(\beta_0\)</span> is positive, the series drifts upwards and it follows a downward trend if <span class="math inline">\(\beta_0\)</span> is negative.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate and plot random walks with drift</span>
<span class="kw">set.seed</span>(<span class="dv">1</span>)

RWsd &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">replicate</span>(<span class="dt">n =</span> <span class="dv">4</span>, 
           <span class="kw">arima.sim</span>(<span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)), <span class="dt">n =</span> <span class="dv">100</span>)))

<span class="kw">matplot</span>(RWsd, 
        <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, 
        <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;orange&quot;</span>), 
        <span class="dt">lty =</span> <span class="dv">1</span>, 
        <span class="dt">lwd =</span> <span class="dv">2</span>,
        <span class="dt">main =</span> <span class="st">&quot;Four Random Walks with Drift&quot;</span>,
        <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>,
        <span class="dt">ylab =</span> <span class="st">&quot;Value&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-625-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="problems-caused-by-stochastic-trends" class="section level4 unnumbered">
<h4>Problems Caused by Stochastic Trends</h4>
<p>OLS estimation of the coefficients on regressors that have a stochastic trend is problematic because the distribution of the estimator and its <span class="math inline">\(t\)</span>-statistic is non-normal, even asymptotically. This has various consequences:</p>
<ul>
<li><p><strong>Downward bias of autoregressive coefficients</strong>:</p>
<p>If <span class="math inline">\(Y_t\)</span> is a random walk, <span class="math inline">\(\beta_1\)</span> can be consistently estimated by OLS but the estimator is biased toward zero. This bias is roughly <span class="math inline">\(E(\widehat{\beta}_1) \approx 1 - 5.3/T\)</span> which is substantial for sample sizes typically encountered in macroeconomics. This estimation bias causes forecasts of <span class="math inline">\(Y_t\)</span> to perform worse than a pure random walk model.</p></li>
<li><p><strong>Non-normally distributed <span class="math inline">\(t\)</span>-statistics</strong>:</p>
<p>The nonnormal distribution of the estimated coefficient of a stochastic regressor translates to a nonnormal distribution of its <span class="math inline">\(t\)</span>-statistic so that normal critical values are invalid and therefore usual confidence intervals and hypothesis tests are invalid, too, and the true distribution of the <span class="math inline">\(t\)</span>-statistic cannot be readily determined.</p></li>
<li><p><strong>Spurious Regression</strong>:</p>
<p>When two stochastically trending time series are regressed onto each other, the estimated relationship may appear highly significant using conventional normal critical values although the series are unrelated. This is what econometricians call a <em>spurious</em> relationship.</p></li>
</ul>
<p>As an example for spurious regression, consider again the green and the red random walks that we have simulated above. We know that there is no relationship between both series: they are generated independently of each other.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot spurious relationship</span>
<span class="kw">matplot</span>(RWs[, <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)], 
        <span class="dt">lty =</span> <span class="dv">1</span>,
        <span class="dt">lwd =</span> <span class="dv">2</span>,
        <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,
        <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;darkred&quot;</span>),
        <span class="dt">xlab =</span> <span class="st">&quot;Time&quot;</span>,
        <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>,
        <span class="dt">main =</span> <span class="st">&quot;A Spurious Relationship&quot;</span>)    </code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-626-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
Imagine we did not have this information and instead conjectured that the green series is useful for predicting the red series and thus end up estimating the ADL(<span class="math inline">\(0\)</span>,<span class="math inline">\(1\)</span>) model
<span class="math display">\[\begin{align*}
  Red_t = \beta_0 + \beta_1 Green_{t-1} + u_t.
\end{align*}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate spurious AR model</span>
<span class="kw">summary</span>(<span class="kw">dynlm</span>(RWs[, <span class="dv">2</span>] <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(RWs[, <span class="dv">3</span>])))<span class="op">$</span>coefficients</code></pre></div>
<pre><code>##              Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept) -3.459488  0.3635104 -9.516889 1.354156e-15
## L(RWs[, 3])  1.047195  0.1450874  7.217687 1.135828e-10</code></pre>
<p>The result is obviously spurious: the coefficient on <span class="math inline">\(Green_{t-1}\)</span> is estimated to be about <span class="math inline">\(1\)</span> and the <span class="math inline">\(p\)</span>-value of <span class="math inline">\(1.14 \cdot 10^{-10}\)</span> of the corresponding <span class="math inline">\(t\)</span>-test indicates that the coefficient is highly significant while its true value is in fact zero.</p>
<p>As an empirical example, consider the U.S. unemployment rate and the Japanese industrial production. Both series show an upward trending behavior from the mid-1960s through the early 1980s.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot U.S. unemployment rate &amp; Japanese industrial production</span>
<span class="kw">plot</span>(<span class="kw">merge</span>(<span class="kw">as.zoo</span>(USUnemp), <span class="kw">as.zoo</span>(JPIndProd)), 
     <span class="dt">plot.type =</span> <span class="st">&quot;single&quot;</span>, 
     <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;steelblue&quot;</span>),
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Date&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Spurious Regression: Macroeconomic Time series&quot;</span>)

<span class="co"># add a legend</span>
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, 
       <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;USUnemp&quot;</span>, <span class="st">&quot;JPIndProd&quot;</span>),
       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;steelblue&quot;</span>),
       <span class="dt">lwd =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-628-1.png" width="672" /></p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate regression using data from 1962 to 1985</span>
SR_Unemp1 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(<span class="kw">ts</span>(USUnemp[<span class="st">&quot;1962::1985&quot;</span>]) <span class="op">~</span><span class="st"> </span><span class="kw">ts</span>(JPIndProd[<span class="st">&quot;1962::1985&quot;</span>]))
<span class="kw">coeftest</span>(SR_Unemp1, <span class="dt">vcov =</span> sandwich)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                 -2.37452    1.12041 -2.1193    0.0367 *  
## ts(JPIndProd[&quot;1962::1985&quot;])  2.22057    0.29233  7.5961 2.227e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
A simple regression of the U.S. unemployment rate on Japanese industrial production using data from 1962 to 1985 yields
<span class="math display" id="eq:urjpip1">\[\begin{align}
  \widehat{U.S. UR}_t = -\underset{(1.12)}{2.37} + \underset{(0.29)}{2.22} \log(JapaneseIP_t). \tag{14.8}
\end{align}\]</span>
<p>This appears to be a significant relationship: the <span class="math inline">\(t\)</span>-statistic of the coefficient on <span class="math inline">\(\log(JapaneseIP_t)\)</span> is bigger than 7.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimate regression using data from 1986 to 2012</span>
SR_Unemp2 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(<span class="kw">ts</span>(USUnemp[<span class="st">&quot;1986::2012&quot;</span>]) <span class="op">~</span><span class="st"> </span><span class="kw">ts</span>(JPIndProd[<span class="st">&quot;1986::2012&quot;</span>]))
<span class="kw">coeftest</span>(SR_Unemp2, <span class="dt">vcov =</span> sandwich)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                  41.7763     5.4066  7.7270 6.596e-12 ***
## ts(JPIndProd[&quot;1986::2012&quot;])  -7.7771     1.1714 -6.6391 1.386e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
When estimating the same model, this time with data from 1986 to 2012, we obtain
<span class="math display" id="eq:urjpip2">\[\begin{align}
  \widehat{U.S. UR}_t = \underset{(5.41)}{41.78} -\underset{(1.17)}{7.78} \log(JapaneseIP)_t \tag{14.9}
\end{align}\]</span>
<p>which surprisingly is quite different. <a href="ittsraf.html#eq:urjpip1">(14.8)</a> indicates a moderate positive relationship, in contrast to the large negative coefficient in <a href="ittsraf.html#eq:urjpip2">(14.9)</a>. This phenomenon can be attributed to stochastic trends in the series: since there is no economic reasoning that relates both trends, both regressions may be spurious.</p>
</div>
<div id="testing-for-a-unit-ar-root" class="section level4 unnumbered">
<h4>Testing for a Unit AR Root</h4>
A formal test for a stochastic trend has been proposed by <span class="citation">Dickey &amp; Fuller (<a href="#ref-dickey1979">1979</a>)</span> which thus is termed the <em>Dickey-Fuller test</em>. As discussed above, a time series that follows an AR(<span class="math inline">\(1\)</span>) model with <span class="math inline">\(\beta_1 = 1\)</span> has a stochastic trend. Thus, the testing problem is
<span class="math display">\[\begin{align*}
  H_0: \beta_1 = 1 \ \ \ \text{vs.} \ \ \ H_1: \lvert\beta_1\rvert &lt; 1.
\end{align*}\]</span>
The null hypothesis is that the AR(<span class="math inline">\(1\)</span>) model has a unit root and the alternative hypothesis is that it is stationary. One often rewrites the AR(<span class="math inline">\(1\)</span>) model by subtracting <span class="math inline">\(Y_{t-1}\)</span> on both sides:
<span class="math display">\[\begin{align*}
  Y_t = \beta_0 + \beta_1 Y_{t-1} + u_t \ \ \Leftrightarrow \ \ \Delta Y_t = \beta_0 + \delta Y_{t-1} + u_i
\end{align*}\]</span>
where <span class="math inline">\(\delta = \beta_1 - 1\)</span>. The testing problem then becomes
<span class="math display">\[\begin{align*}
  H_0: \delta = 0 \ \ \ \text{vs.} \ \ \ H_1: \delta &lt; 0
\end{align*}\]</span>
<p>which is convenient since the corresponding test statistic is reported by many relevant <tt>R</tt> functions.<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a></p>
<p>The Dickey-Fuller test can also be applied in an AR(<span class="math inline">\(p\)</span>) model. The <em>Augmented Dickey-Fuller (ADF) test</em> is summarized in Key Concept 14.8.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.8
</h3>
<h3 class="left">
The ADF Test for a Unit Root
</h3>
<p>
Consider the regression
<span class="math display" id="eq:ADFreg1">\[\begin{align}
  \Delta Y_t = \beta_0 + \delta Y_{t-1} + \gamma_1 \Delta_1 Y_{t-1} + \gamma_2 \Delta Y_{t-2} + \dots + \gamma_p \Delta Y_{t-p} + u_t. \tag{14.10}
\end{align}\]</span>
<p>The ADF test for a unit autoregressive root tests the hypothesis <span class="math inline">\(H_0: \delta = 0\)</span> (stochastic trend) against the one-sided alternative <span class="math inline">\(H_1: \delta &lt; 0\)</span> (stationarity) using the usual OLS <span class="math inline">\(t\)</span>-statistic.</p>
If it is assumed that <span class="math inline">\(Y_t\)</span> is stationary around a deterministic linear time trend, the model is augmented by the regressor <span class="math inline">\(t\)</span>:
<span class="math display" id="eq:ADFreg2">\[\begin{align}
  \Delta Y_t = \beta_0 + at + \delta Y_{t-1} + \gamma_1 \Delta_1 Y_{t-1} + \gamma_2 \Delta Y_{t-2} + \dots + \gamma_p \Delta Y_{t-p} + u_t,  \tag{14.11}
\end{align}\]</span>
<p>where again <span class="math inline">\(H_0: \delta = 0\)</span> is tested against <span class="math inline">\(H_1: \delta &lt; 0\)</span>.</p>
<p>The optimal lag length <span class="math inline">\(p\)</span> can be estimated using information criteria. In <a href="ittsraf.html#eq:ADFreg1">(14.10)</a>, <span class="math inline">\(p=0\)</span> (no lags of <span class="math inline">\(\Delta Y_t\)</span> are used as regressors) corresponds to a simple AR(<span class="math inline">\(1\)</span>).</p>
Under the null, the <span class="math inline">\(t\)</span>-statistic corresponding to <span class="math inline">\(H_0: \delta = 0\)</span> does not have a normal distribution. The critical values can only be obtained from simulation and differ for regressions <a href="ittsraf.html#eq:ADFreg1">(14.10)</a> and <a href="ittsraf.html#eq:ADFreg2">(14.11)</a> since the distribution of the ADF test statistic is sensitive to the deterministic components included in the regression.
</p>
</div>
</div>
<div id="critical-values-for-the-adf-statistic" class="section level4 unnumbered">
<h4>Critical Values for the ADF Statistic</h4>
<p>Key Concept 14.8 states that the critical values for the ADF test in the regressions <a href="ittsraf.html#eq:ADFreg1">(14.10)</a> and <a href="ittsraf.html#eq:ADFreg2">(14.11)</a> can only be determined using simulation. The idea of the simulation study is to simulate a large number of ADF test statistics and use them to estimate quantiles of their <em>asymptotic</em> distribution. This section shows how this can be done using <tt>R</tt>.</p>
<p>First, consider an AR(<span class="math inline">\(1\)</span>) model with drift. The procedure is as follows:</p>
<ul>
<li>Simulate <span class="math inline">\(N\)</span> random walks with <span class="math inline">\(n\)</span> observations using the data generating process
<span class="math display">\[\begin{align*}
  Y_t =&amp; \, \beta_0 + \beta_1 Y_{t-1} + u_t,
\end{align*}\]</span>
<p><span class="math inline">\(t=1,\dots,n\)</span> where <span class="math inline">\(N\)</span> and <span class="math inline">\(n\)</span> are large numbers.</p></li>
<li>For each random walk, estimate the regression
<span class="math display">\[\begin{align*}
  \Delta Y_t =&amp; \, \beta_0 + \beta_1 Y_{t-1} + u_t
\end{align*}\]</span>
<p>and compute ADF test statistic. Save all <span class="math inline">\(N\)</span> test statistics.</p></li>
<li><p>Estimate quantiles of the distribution of the ADF test statistic using the <span class="math inline">\(N\)</span> test statistics obtained from the simulation.</p></li>
</ul>
For the case with drift and linear time trend we replace the data generating process by
<span class="math display">\[\begin{align*}
  Y_t =&amp; \, \beta_0 + \alpha (\beta_1-1) t + \beta_1 Y_{t-1} + u_t
\end{align*}\]</span>
and estimate
<span class="math display">\[\begin{align*}
  \Delta Y_t =&amp; \, \beta_0 + \alpha t + \delta_1 Y_{t-1} + u_t.
\end{align*}\]</span>
<p>Loosely speaking, the precision of the estimated quantiles depends on two factors: <span class="math inline">\(n\)</span>, the length of the underlying series and <span class="math inline">\(N\)</span>, the number of test statistics used. Since we are interested in estimating quantiles of the <em>asymptotic</em> distribution (the Dickey-Fuller distribution) of the ADF test statistic so both using many observations and large number of simulated test statistics will increase the precision of the estimated quantiles. We choose <span class="math inline">\(n=N=1000\)</span> as the computational burden grows quickly with <span class="math inline">\(n\)</span> and <span class="math inline">\(N\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># repetitions</span>
N &lt;-<span class="st"> </span><span class="dv">1000</span>

<span class="co"># observations</span>
n &lt;-<span class="st"> </span><span class="dv">1000</span>

<span class="co"># define drift and trend </span>
drift &lt;-<span class="st"> </span><span class="fl">0.5</span>
trend &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span>n

<span class="co"># simulate N random walks with drift </span>
RWD &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">replicate</span>(<span class="dt">n =</span> N, 
            (n<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>drift <span class="op">+</span><span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)),
                                      <span class="dt">n =</span> n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)))

<span class="co"># compute ADF test statistics and store them in &#39;ADFD&#39;</span>
ADFD &lt;-<span class="st"> </span><span class="kw">numeric</span>(N)

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(RWD)) {
  ADFD[i] &lt;-<span class="st"> </span><span class="kw">summary</span>(
    <span class="kw">dynlm</span>(<span class="kw">diff</span>(RWD[, i], <span class="dv">1</span>) <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(RWD[, i], <span class="dv">1</span>)))<span class="op">$</span>coef[<span class="dv">2</span>, <span class="dv">3</span>]
}

<span class="co"># simulate N random walks with drift + trend</span>
RWDT &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">replicate</span>(<span class="dt">n =</span> N, 
                    trend <span class="op">+</span><span class="st"> </span>drift <span class="op">+</span><span class="st"> </span><span class="kw">arima.sim</span>(<span class="dt">model =</span> <span class="kw">list</span>(<span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)), 
                                              <span class="dt">n =</span> n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)))

<span class="co"># compute ADF test statistics and store them in &#39;ADFDT&#39;</span>
ADFDT &lt;-<span class="st"> </span><span class="kw">numeric</span>(N)

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(RWDT)) {
  ADFDT[i] &lt;-<span class="st"> </span><span class="kw">summary</span>(
    <span class="kw">dynlm</span>(<span class="kw">diff</span>(RWDT[, i], <span class="dv">1</span>) <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(RWDT[, i], <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">trend</span>(RWDT[, i], <span class="dt">scale =</span> F))
  )<span class="op">$</span>coef[<span class="dv">2</span>, <span class="dv">3</span>]
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate quantiles for ADF regression with a drift</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(ADFD, <span class="kw">c</span>(<span class="fl">0.1</span>, <span class="fl">0.05</span>, <span class="fl">0.01</span>)), <span class="dv">2</span>)</code></pre></div>
<pre><code>##   10%    5%    1% 
## -2.62 -2.83 -3.39</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate quantiles for ADF regression with drift and trend</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(ADFDT, <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.05</span>,<span class="fl">0.01</span>)),<span class="dv">2</span>)</code></pre></div>
<pre><code>##   10%    5%    1% 
## -3.11 -3.43 -3.97</code></pre>
<p>The estimated quantiles are close to the large-sample critical values of the ADF test statistic reported in Table 14.4 of the book.</p>
<table>
<caption><span id="tab:DFcrits">Table 14.2: </span> Large Sample Critical Values of ADF Test</caption>
<thead>
<tr class="header">
<th align="left">Deterministic Regressors</th>
<th align="left">10%</th>
<th align="left">5%</th>
<th align="left">1%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept only</td>
<td align="left">-2.57</td>
<td align="left">-2.86</td>
<td align="left">-3.43</td>
</tr>
<tr class="even">
<td align="left">Intercept and time trend</td>
<td align="left">-3.12</td>
<td align="left">-3.41</td>
<td align="left">-3.96</td>
</tr>
</tbody>
</table>
<p>The results show that using standard normal critical values is erroneous: the 5% critical value of the standard normal distribution is <span class="math inline">\(-1.64\)</span>. For the Dickey-Fuller distributions the estimated critical values are <span class="math inline">\(-2.87\)</span> (drift) and <span class="math inline">\(-3.43\)</span> (drift and linear time trend). This implies that a true null (the series has a stochastic trend) would be rejected far too often if inappropriate normal critical values were used.</p>
<p>We may use the simulated test statistics for a graphical comparison of the standard normal density and (estimates of) both Dickey-Fuller densities.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot standard normal density</span>
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x), 
      <span class="dt">from =</span> <span class="op">-</span><span class="dv">6</span>, <span class="dt">to =</span> <span class="dv">3</span>, 
      <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.6</span>), 
      <span class="dt">lty =</span> <span class="dv">2</span>,
      <span class="dt">ylab =</span> <span class="st">&quot;Density&quot;</span>,
      <span class="dt">xlab =</span> <span class="st">&quot;t-Statistic&quot;</span>,
      <span class="dt">main =</span> <span class="st">&quot;Distributions of ADF Test Statistics&quot;</span>,
      <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>, 
      <span class="dt">lwd =</span> <span class="dv">2</span>)

<span class="co"># plot density estimates of both Dickey-Fuller distributions</span>
<span class="kw">lines</span>(<span class="kw">density</span>(ADFD), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;darkgreen&quot;</span>)
<span class="kw">lines</span>(<span class="kw">density</span>(ADFDT), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)

<span class="co"># add a legend</span>
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, 
       <span class="kw">c</span>(<span class="st">&quot;N(0,1)&quot;</span>, <span class="st">&quot;Drift&quot;</span>, <span class="st">&quot;Drift+Trend&quot;</span>),
       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;darkred&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;blue&quot;</span>),
       <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>),
       <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-635-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>The deviations from the standard normal distribution are significant: both Dickey-Fuller distributions are skewed to the left and have a heavier left tail than the standard normal distribution.</p>
</div>
<div id="does-u.s.-gdp-have-a-unit-root" class="section level4 unnumbered">
<h4>Does U.S. GDP Have a Unit Root?</h4>
As an empirical example, we use the ADF test to assess whether there is a stochastic trend in U.S. GDP using the regression
<span class="math display">\[\begin{align*}
  \Delta\log(GDP_t) = \beta_0 + \alpha t + \beta_1 \log(GDP_{t-1}) + \beta_2 \Delta \log(GDP_{t-1}) + \beta_3 \Delta \log(GDP_{t-2}) + u_t.
\end{align*}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate log GDP series</span>
LogGDP &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">log</span>(GDP[<span class="st">&quot;1962::2012&quot;</span>]))

<span class="co"># estimate the model</span>
<span class="kw">coeftest</span>(
  <span class="kw">dynlm</span>(<span class="kw">diff</span>(LogGDP) <span class="op">~</span><span class="st"> </span><span class="kw">trend</span>(LogGDP, <span class="dt">scale =</span> F) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(LogGDP) 
                     <span class="op">+</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">L</span>(LogGDP)) <span class="op">+</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">L</span>(LogGDP), <span class="dv">2</span>)))</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                             Estimate  Std. Error t value Pr(&gt;|t|)   
## (Intercept)               0.27877045  0.11793233  2.3638 0.019066 * 
## trend(LogGDP, scale = F)  0.00023818  0.00011090  2.1476 0.032970 * 
## L(LogGDP)                -0.03332452  0.01441436 -2.3119 0.021822 * 
## diff(L(LogGDP))           0.08317976  0.11295542  0.7364 0.462371   
## diff(L(LogGDP), 2)        0.18763384  0.07055574  2.6594 0.008476 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
The estimation yields
<span class="math display">\[\begin{align*}
  \Delta\log(GDP_t) =&amp; \underset{(0.118)}{0.28} + \underset{(0.0001)}{0.0002} t -\underset{(0.014)}{0.033} \log(GDP_{t-1}) \\
   &amp; + \underset{(0.113)}{0.083} \Delta \log(GDP_{t-1}) + \underset{(0.071)}{0.188} \Delta \log(GDP_{t-2}) + u_t,
\end{align*}\]</span>
<p>so the ADF test statistic is <span class="math inline">\(t=-0.033/0.014 = - 2.35\)</span>. The corresponding <span class="math inline">\(5\%\)</span> critical value from Table <a href="ittsraf.html#tab:DFcrits">14.2</a> is <span class="math inline">\(-3.41\)</span> so we cannot reject the null hypothesis that <span class="math inline">\(\log(GDP)\)</span> has a stochastic trend in favor of the alternative that it is stationary around a deterministic linear time trend.</p>
<p>The ADF test can be done conveniently using <tt>ur.df()</tt> from the package <tt>urca</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># test for unit root in GDP using &#39;ur.df()&#39; from the package &#39;urca&#39;</span>
<span class="kw">summary</span>(<span class="kw">ur.df</span>(LogGDP, 
              <span class="dt">type =</span> <span class="st">&quot;trend&quot;</span>, 
              <span class="dt">lags =</span> <span class="dv">2</span>, 
              <span class="dt">selectlags =</span> <span class="st">&quot;Fixed&quot;</span>))</code></pre></div>
<pre><code>## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression trend 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.025580 -0.004109  0.000321  0.004869  0.032781 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.2790086  0.1180427   2.364 0.019076 *  
## z.lag.1     -0.0333245  0.0144144  -2.312 0.021822 *  
## tt           0.0002382  0.0001109   2.148 0.032970 *  
## z.diff.lag1  0.2708136  0.0697696   3.882 0.000142 ***
## z.diff.lag2  0.1876338  0.0705557   2.659 0.008476 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.007704 on 196 degrees of freedom
## Multiple R-squared:  0.1783, Adjusted R-squared:  0.1616 
## F-statistic: 10.63 on 4 and 196 DF,  p-value: 8.076e-08
## 
## 
## Value of test-statistic is: -2.3119 11.2558 4.267 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau3 -3.99 -3.43 -3.13
## phi2  6.22  4.75  4.07
## phi3  8.43  6.49  5.47</code></pre>
<p>The first test statistic at the bottom of the output is the one we are interested in. The number of test statistics reported depends on the test regression. For <tt>type = “trend”</tt>, the second statistics corresponds to the test that there is no unit root and no time trend while the third one corresponds to a test of the hypothesis that there is a unit root, no time trend and no drift term.</p>
</div>
</div>
<div id="niib" class="section level2">
<h2><span class="header-section-number">14.8</span> Nonstationarity II: Breaks</h2>
<p>When there are discrete (at a distinct date) or gradual (over time) changes in the population regression coefficients, the series is nonstationary. These changes are called <em>breaks</em>. There is a variety of reasons why breaks can occur in macroeconomic time series but most often they are related to changes in economic policy or major changes in the structure of the economy. See Chapter 14.7 of the book for some examples.</p>
<p>If breaks are not accounted for in the regression model, OLS estimates will reflect the average relationship. Since these estimates might be strongly misleading and result in poor forecast quality, we are interested in testing for breaks. One distinguishes between testing for a break when the date is known and testing for a break with an unknown break date.</p>
Let <span class="math inline">\(\tau\)</span> denote a known break date and let <span class="math inline">\(D_t(\tau)\)</span> be a binary variable indicating time periods before and after the break. Incorporating the break in an ADL(<span class="math inline">\(1\)</span>,<span class="math inline">\(1\)</span>) regression model yields
<span class="math display">\[\begin{align*}
  Y_t =&amp; \beta_0 + \beta_1 Y_{t-1} + \delta_1 X_{t-1} + \gamma_0 D_t(\tau) + \gamma_1\left[D_t(\tau) \cdot Y_{t-1}\right] \\ 
  &amp;+ \, \gamma_2\left[ D_t(\tau) \cdot X_{t-1} \right] + u_t,
\end{align*}\]</span>
<p>where we allow for discrete changes in <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> at the break date <span class="math inline">\(\tau\)</span>. The null hypothesis of no break, <span class="math display">\[H_0: \gamma_0=\gamma_1=\gamma_2=0,\]</span> can be tested against the alternative that at least one of the <span class="math inline">\(\gamma\)</span>’s is not zero using an <span class="math inline">\(F\)</span>-Test. This idea is called a Chow test after Gregory <span class="citation">Chow (<a href="#ref-chow1960">1960</a>)</span>.</p>
<p>When the break date is unknown the <em>Quandt likelihood ratio</em> (QLR) <em>test</em> <span class="citation">(Quandt, <a href="#ref-quandt1960">1960</a>)</span> may be used. It is a modified version of the Chow test which uses the largest of all <span class="math inline">\(F\)</span>-statistics obtained when applying the Chow test for all possible break dates in a predetermined range <span class="math inline">\(\left[\tau_0,\tau_1\right]\)</span>. The QLR test is summarized in Key Concept 14.9.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.9
</h3>
<h3 class="left">
The QLR Test for Coefficient Stability
</h3>
<p>
The QLR test can be used to test for a break in the population regression function if the date of the break is unknown. The QLR test statistic is the largest (Chow) <span class="math inline">\(F(\tau)\)</span> statistic computed over a range of eligible break dates <span class="math inline">\(\tau_0 \leq \tau \leq \tau_1\)</span>:
<span class="math display" id="eq:QLRstatistic">\[\begin{align}
  QLR = \max\left[F(\tau_0),F(\tau_0 +1),\dots,F(\tau_1)\right]. \tag{14.12}
\end{align}\]</span>
</p>
<p>The most important properties are:</p>
<ul>
<li><p>The QLR test can be applied to test whether a subset of the coefficients in the population regression function breaks but the test also rejects if there is a slow evolution of the regression function.</p></li>
<li><p>When there is a single discrete break in the population regression function that lying at a date within the range tested, the <span class="math inline">\(QLR\)</span> test statistic is <span class="math inline">\(F(\widehat{\tau})\)</span> and <span class="math inline">\(\widehat{\tau}/T\)</span> is a consistent estimator of fraction of the sample at which the break is.</p></li>
<li><p>The large-sample distribution of <span class="math inline">\(QLR\)</span> depends on <span class="math inline">\(q\)</span>, the number of restrictions being tested and both ratios of end points to the sample size, <span class="math inline">\(\tau_0/T, \tau_1/T\)</span>.</p></li>
<li><p>Similar to the ADF test, the large-sample distribution of <span class="math inline">\(QLR\)</span> is nonstandard. Critical values are presented in Table 14.5 of the book.</p></li>
</ul>
</div>
<div id="has-the-predictive-power-of-the-term-spread-been-stable" class="section level4 unnumbered">
<h4>Has the Predictive Power of the term spread been stable?</h4>
Using the QLR statistic we may test whether there is a break in the coefficients on the lags of the term spread in <a href="ittsraf.html#eq:gdpgradl22">(14.5)</a>, the ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) regression model of GDP growth. Following Key Concept 14.9 we modify the specification of <a href="ittsraf.html#eq:gdpgradl22">(14.5)</a> by adding a break dummy <span class="math inline">\(D(\tau)\)</span> and its interactions with both lags of term spread and choose the range of break points to be tested as 1970:Q1 - 2005:Q2 (these periods are the center 70% of the sample data from 1962:Q2 - 2012:Q4). Thus, the model becomes
<span class="math display">\[\begin{align*}
    GDPGR_t =&amp;\, \beta_0 + \beta_1 GDPGR_{t-1} + \beta_2 GDPGR_{t-2} \\
            &amp;+\,  \beta_3  TSpread_{t-1} + \beta_4 TSpread_{t-2} \\
            &amp;+\, \gamma_1 D(\tau) + \gamma_2 (D(\tau) \cdot TSpread_{t-1}) \\
            &amp;+\, \gamma_3 (D(\tau) \cdot TSpread_{t-2}) \\
            &amp;+\, u_t.
\end{align*}\]</span>
<p>Next, we estimate the model for each break point and compute the <span class="math inline">\(F\)</span>-statistic corresponding to the null hypothesis <span class="math inline">\(H_0: \gamma_1=\gamma_2=\gamma_3=0\)</span>. The <span class="math inline">\(QLR\)</span>-statistic is the largest of the <span class="math inline">\(F\)</span>-statistics obtained in this manner.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set up a range of possible break dates</span>
tau &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1970</span>, <span class="dv">2005</span>, <span class="fl">0.25</span>)

<span class="co"># initialize vector of F-statistics</span>
Fstats &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">length</span>(tau))

<span class="co"># estimation loop over break dates</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(tau)) {

  <span class="co"># set up dummy variable</span>
  D &lt;-<span class="st"> </span><span class="kw">time</span>(GDPGrowth_ts) <span class="op">&gt;</span><span class="st"> </span>tau[i]

  <span class="co"># estimate ADL(2,2) model with intercations</span>
  test &lt;-<span class="st"> </span><span class="kw">dynlm</span>(GDPGrowth_ts <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(GDPGrowth_ts) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(GDPGrowth_ts, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">                </span>D<span class="op">*</span><span class="kw">L</span>(TSpread_ts) <span class="op">+</span><span class="st"> </span>D<span class="op">*</span><span class="kw">L</span>(TSpread_ts, <span class="dv">2</span>),
                <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1962</span>, <span class="dv">1</span>), 
                <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">4</span>))
  
  <span class="co"># compute and save the F-statistic</span>
  Fstats[i] &lt;-<span class="st"> </span><span class="kw">linearHypothesis</span>(test, 
                                <span class="kw">c</span>(<span class="st">&quot;DTRUE=0&quot;</span>, <span class="st">&quot;DTRUE:L(TSpread_ts)&quot;</span>, 
                                  <span class="st">&quot;DTRUE:L(TSpread_ts, 2)&quot;</span>),
                                <span class="dt">vcov. =</span> sandwich)<span class="op">$</span>F[<span class="dv">2</span>]

}</code></pre></div>
<p>We determine the <span class="math inline">\(QLR\)</span> statistic using <tt>max()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># identify QLR statistic</span>
QLR &lt;-<span class="st"> </span><span class="kw">max</span>(Fstats)
QLR</code></pre></div>
<pre><code>## [1] 6.651156</code></pre>
<p>Let us check that the <span class="math inline">\(QLR\)</span>-statistic is the <span class="math inline">\(F\)</span>-statistic obtained for the regression where 1980:Q4 is chosen as the break date.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># identify the time period where the QLR-statistic is observed</span>
<span class="kw">as.yearqtr</span>(tau[<span class="kw">which.max</span>(Fstats)])</code></pre></div>
<pre><code>## [1] &quot;1980 Q4&quot;</code></pre>
<p>Since <span class="math inline">\(q=3\)</span> hypotheses are tested and the central <span class="math inline">\(70\%\)</span> of the sample are considered to contain breaks, the corresponding <span class="math inline">\(1\%\)</span> critical value of the <span class="math inline">\(QLR\)</span> test is <span class="math inline">\(6.02\)</span>. We reject the null hypothesis that all coefficients (the coefficients on both lags of term spread and the intercept) are stable since the computed <span class="math inline">\(QLR\)</span>-statistic exceeds this threshold. Thus evidence from the <span class="math inline">\(QLR\)</span> test suggests that there is a break in the ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) model of GDP growth in the early 1980s.</p>
<p>To reproduce Figure 14.5 of the book, we convert the vector of sequential break-point <span class="math inline">\(F\)</span>-statistics into a time series object and then generate a simple plot with some annotations.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># series of F-statistics</span>
Fstatsseries &lt;-<span class="st"> </span><span class="kw">ts</span>(Fstats, 
                   <span class="dt">start =</span> tau[<span class="dv">1</span>], 
                   <span class="dt">end =</span> tau[<span class="kw">length</span>(tau)], 
                   <span class="dt">frequency =</span> <span class="dv">4</span>)

<span class="co"># plot the F-statistics </span>
<span class="kw">plot</span>(Fstatsseries, 
     <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">2015</span>),
     <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">7.5</span>),
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;F-Statistic&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Break Date&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Testing for a Break in GDP ADL(2,2) Regression at Different Dates&quot;</span>)

<span class="co"># dashed horizontal lines for critical values and QLR statistic</span>
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="fl">4.71</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="fl">6.02</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">segments</span>(<span class="dv">0</span>, QLR, <span class="fl">1980.75</span>, QLR, <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>)
<span class="kw">text</span>(<span class="dv">2010</span>, <span class="fl">6.2</span>, <span class="st">&quot;1% Critical Value&quot;</span>)
<span class="kw">text</span>(<span class="dv">2010</span>, <span class="fl">4.9</span>, <span class="st">&quot;5% Critical Value&quot;</span>)
<span class="kw">text</span>(<span class="fl">1980.75</span>, QLR<span class="op">+</span><span class="fl">0.2</span>, <span class="st">&quot;QLR Statistic&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-643-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="pseudo-out-of-sample-forecasting" class="section level4 unnumbered">
<h4>Pseudo Out-of-Sample Forecasting</h4>
<p>Pseudo out-of-sample forecasts are used to simulate the out-of-sample performance (the real time forecast performance) of a time series regression model. In particular, pseudo out-of-sample forecasts allow estimation of the <span class="math inline">\(RMSFE\)</span> of the model and enable researchers to compare different model specifications with respect to their predictive power. Key Concept 14.10 summarizes this idea.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 14.10
</h3>
<h3 class="left">
Pseudo Out-of-Sample Forecasting
</h3>
<ol style="list-style-type: decimal">
<li><p>Divide the sample data into <span class="math inline">\(s=T-P\)</span> and <span class="math inline">\(P\)</span> subsequent observations. The <span class="math inline">\(P\)</span> observations are used as pseudo-out-of-sample observations.</p></li>
<li><p>Estimate the model using the first <span class="math inline">\(s\)</span> observations.</p></li>
<li><p>Compute the pseudo-forecast <span class="math inline">\(\overset{\sim}{Y}_{s+1\vert s}\)</span>.</p></li>
<li><p>Compute the pseudo-forecast-error <span class="math inline">\(\overset{\sim}{u}_{s+1} = Y_{s+1} - \overset{\sim}{Y}_{s+1\vert s}\)</span>.</p></li>
<li>Repeat steps 2 trough 4 for all remaining pseudo-out-of-sample dates.</li>
</ol>
</div>
</div>
<div id="did-the-predictive-power-of-the-term-spread-change-during-the-2000s" class="section level4 unnumbered">
<h4>Did the Predictive Power of the Term Spread Change During the 2000s?</h4>
<p>The insight gained in the previous section gives reason to presume that the pseudo-out-of-sample performance of ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) models estimated using data <em>after</em> the break in the early 1980s should not deteriorate relative to using the whole sample: provided that the coefficients of the population regression function are stable after the potential break in 1980:Q4, these models should have good predictive power. We check this by computing pseudo-out-of-sample forecasts for the period 2003:Q1 - 2012:Q4, a range covering 40 periods, where the forecast for 2003:Q1 is done using data from 1981:Q1 - 2002:Q4, the forecast for 2003:Q2 is based on data from 1981:Q1 - 2003:Q1 and so on.</p>
<p>Similarly as for the <span class="math inline">\(QLR\)</span>-test we use a <tt>for()</tt> loop for estimation of all 40 models and gather their <span class="math inline">\(SER\)</span>s and the obtained forecasts in a vector which is then used to compute pseudo-out-of-sample forecast errors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># end of sample dates</span>
EndOfSample &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">2002.75</span>, <span class="fl">2012.5</span>, <span class="fl">0.25</span>)

<span class="co"># initialize matrix forecasts</span>
forecasts &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="dv">1</span>, 
                    <span class="dt">ncol =</span> <span class="kw">length</span>(EndOfSample))

<span class="co"># initialize vector SER</span>
SER  &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">length</span>(EndOfSample))

<span class="co"># estimation loop over end of sample dates</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(EndOfSample)) {

  <span class="co"># estimate ADL(2,2) model</span>
  m &lt;-<span class="st"> </span><span class="kw">dynlm</span>(GDPGrowth_ts <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(GDPGrowth_ts) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(GDPGrowth_ts, <span class="dv">2</span>) 
                          <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(TSpread_ts) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(TSpread_ts, <span class="dv">2</span>), 
                <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1981</span>, <span class="dv">1</span>), 
                <span class="dt">end =</span> EndOfSample[i])
  
  SER[i] &lt;-<span class="st"> </span><span class="kw">summary</span>(m)<span class="op">$</span>sigma
  
  <span class="co"># sample data for one-period ahead forecast</span>
  s &lt;-<span class="st"> </span><span class="kw">window</span>(ADLdata, EndOfSample[i] <span class="op">-</span><span class="st"> </span><span class="fl">0.25</span>, EndOfSample[i])
  
  <span class="co"># compute forecast</span>
  forecasts[i] &lt;-<span class="st"> </span><span class="kw">coef</span>(m) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, s[<span class="dv">1</span>, <span class="dv">1</span>], s[<span class="dv">2</span>, <span class="dv">1</span>], s[<span class="dv">1</span>, <span class="dv">2</span>], s[<span class="dv">2</span>, <span class="dv">2</span>]) 
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute psuedo-out-of-sample forecast errors</span>
POOSFCE &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">window</span>(GDPGrowth_ts, <span class="kw">c</span>(<span class="dv">2003</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">4</span>))) <span class="op">-</span><span class="st"> </span>forecasts</code></pre></div>
<p>We next translate the pseudo-out-of-sample forecasts into an object of class <tt>ts</tt> and plot the real GDP growth rate against the forecasted series.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># series of pseudo-out-of-sample forecasts</span>
PSOSSFc &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">c</span>(forecasts), 
              <span class="dt">start =</span> <span class="dv">2003</span>, 
              <span class="dt">end =</span> <span class="fl">2012.75</span>, 
              <span class="dt">frequency =</span> <span class="dv">4</span>)

<span class="co"># plot the GDP growth time series</span>
<span class="kw">plot</span>(<span class="kw">window</span>(GDPGrowth_ts, <span class="kw">c</span>(<span class="dv">2003</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">4</span>)),
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Percent&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Pseudo-Out-Of-Sample Forecasts of GDP Growth&quot;</span>)

<span class="co"># add the series of pseudo-out-of-sample forecasts</span>
<span class="kw">lines</span>(PSOSSFc, 
      <span class="dt">lwd =</span> <span class="dv">2</span>, 
      <span class="dt">lty =</span> <span class="dv">2</span>)

<span class="co"># shade area between curves (the pseudo forecast error)</span>
<span class="kw">polygon</span>(<span class="kw">c</span>(<span class="kw">time</span>(PSOSSFc), <span class="kw">rev</span>(<span class="kw">time</span>(PSOSSFc))), 
        <span class="kw">c</span>(<span class="kw">window</span>(GDPGrowth_ts, <span class="kw">c</span>(<span class="dv">2003</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">2012</span>, <span class="dv">4</span>)), <span class="kw">rev</span>(PSOSSFc)),
        <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;blue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.3</span>),
        <span class="dt">border =</span> <span class="ot">NA</span>)

<span class="co"># add a legend</span>
<span class="kw">legend</span>(<span class="st">&quot;bottomleft&quot;</span>, 
       <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>),
       <span class="dt">lwd =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">10</span>),
       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="st">&quot;black&quot;</span>, <span class="kw">alpha</span>(<span class="st">&quot;blue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.3</span>)), 
       <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;Actual GDP growth rate&quot;</span>,
         <span class="st">&quot;Forecasted GDP growth rate&quot;</span>,
         <span class="st">&quot;Pseudo forecast Error&quot;</span>))</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-648-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>Apparently, the pseudo forecasts track the actual GDP growth rate quite well, except for the kink in 2009 which can be attributed to the recent financial crisis.</p>
<p>The <span class="math inline">\(SER\)</span> of the first model (estimated using data from 1981:Q1 to 2002:Q4) is <span class="math inline">\(2.39\)</span> so based on the in-sample fit we would expect the out of sample forecast errors to have mean zero and a root mean squared forecast error of about <span class="math inline">\(2.39\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># SER of ADL(2,2) mode using data from 1981:Q1 - 2002:Q4</span>
SER[<span class="dv">1</span>]</code></pre></div>
<pre><code>## [1] 2.389773</code></pre>
<p>The root mean squared forecast error of the pseudo-out-of-sample forecasts is somewhat larger.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute root mean squared forecast error</span>
<span class="kw">sd</span>(POOSFCE)</code></pre></div>
<pre><code>## [1] 2.667612</code></pre>
<p>An interesting hypothesis is whether the mean forecast error is zero, that is the ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) forecasts are right, on average. This hypothesis is easily tested using the function <tt>t.test()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># test if mean forecast error is zero</span>
<span class="kw">t.test</span>(POOSFCE)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  POOSFCE
## t = -1.5523, df = 39, p-value = 0.1287
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -1.5078876  0.1984001
## sample estimates:
##  mean of x 
## -0.6547438</code></pre>
<p>The hypothesis cannot be rejected at the <span class="math inline">\(10\%\)</span> significance level. Altogether the analysis suggests that the ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) model coefficients have been stable since the presumed break in the early 1980s.</p>
</div>
</div>
<div id="can-you-beat-the-market-part-ii" class="section level2">
<h2><span class="header-section-number">14.9</span> Can You Beat the Market? (Part II)</h2>
<p>The dividend yield (the ratio of current dividends to the stock price) can be considered as an indicator of future dividends: if a stock has a high current dividend yield, it can be considered undervalued and it can be presumed that the price of the stock goes up in the future, meaning that future excess returns go up.</p>
<p>This presumption can be examined using ADL models of excess returns, where lags of the logarithm of the stock’s dividend yield serve as additional regressors.</p>
<p>Unfortunately, a graphical inspection of the time series of the logarithm of the dividend yield casts doubt on the assumption that the series is stationary which, as has been discussed in Chapter <a href="ittsraf.html#nit">14.7</a>, is necessary to conduct standard inference in a regression analysis.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot logarithm of dividend yield series</span>
<span class="kw">plot</span>(StockReturns[, <span class="dv">2</span>], 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">lwd =</span> <span class="dv">2</span>, 
     <span class="dt">ylab =</span> <span class="st">&quot;Logarithm&quot;</span>, 
     <span class="dt">main =</span> <span class="st">&quot;Dividend Yield for CRSP Index&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-652-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>The Dickey-Fuller test statistic for an autoregressive unit root in an AR(<span class="math inline">\(1\)</span>) model with drift provides further evidence that the series might be nonstationary.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># test for unit root in GDP using &#39;ur.df()&#39; from the package &#39;urca&#39;</span>
<span class="kw">summary</span>(<span class="kw">ur.df</span>(<span class="kw">window</span>(StockReturns[, <span class="dv">2</span>], 
                     <span class="kw">c</span>(<span class="dv">1960</span>,<span class="dv">1</span>), 
                     <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">12</span>)), 
              <span class="dt">type =</span> <span class="st">&quot;drift&quot;</span>, 
              <span class="dt">lags =</span> <span class="dv">0</span>))</code></pre></div>
<pre><code>## 
## ############################################### 
## # Augmented Dickey-Fuller Test Unit Root Test # 
## ############################################### 
## 
## Test regression drift 
## 
## 
## Call:
## lm(formula = z.diff ~ z.lag.1 + 1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.3540  -2.9118  -0.2952   2.6374  25.5170 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -2.740964   2.080039  -1.318    0.188
## z.lag.1     -0.007652   0.005989  -1.278    0.202
## 
## Residual standard error: 4.45 on 513 degrees of freedom
## Multiple R-squared:  0.003172,   Adjusted R-squared:  0.001229 
## F-statistic: 1.633 on 1 and 513 DF,  p-value: 0.2019
## 
## 
## Value of test-statistic is: -1.2777 0.9339 
## 
## Critical values for test statistics: 
##       1pct  5pct 10pct
## tau2 -3.43 -2.86 -2.57
## phi1  6.43  4.59  3.78</code></pre>
<p>We use <tt>window()</tt> to get observations from January 1960 to December 2012 only.</p>
<p>Since the <span class="math inline">\(t\)</span>-value for the coefficient on the lagged logarithm of the dividend yield is <span class="math inline">\(-1.27\)</span>, the hypothesis that the true coefficient is zero cannot be rejected, even at the <span class="math inline">\(10\%\)</span> significance level.</p>
<p>However, it is possible to examine whether the dividend yield has predictive power for excess returns by using its differences in an ADL(<span class="math inline">\(1\)</span>,<span class="math inline">\(1\)</span>) and an ADL(<span class="math inline">\(2\)</span>,<span class="math inline">\(2\)</span>) model (remember that differencing a series with a unit root yields a stationary series), although these model specifications do not correspond to the economic reasoning mentioned above. Thus, we also estimate an ADL(<span class="math inline">\(1\)</span>,<span class="math inline">\(1\)</span>) regression using the level of the logarithm of the dividend yield.</p>
<p>That is we estimate three different specifications:</p>
<span class="math display">\[\begin{align*}
  excess \, returns_t =&amp; \, \beta_0 + \beta_1 excess \, returns_{t-1} + \beta_3 \Delta \log(dividend yield_{t-1}) + u_t \\
  \\
  excess \, returns_t =&amp; \, \beta_0 + \beta_1 excess \, returns_{t-1} + \beta_2 excess \, returns_{t-2} \\ &amp;+ \, \beta_3 \Delta \log(dividend yield_{t-1}) + \beta_4 \Delta \log(dividend yield_{t-2}) + u_t \\
  \\
  excess \, returns_t =&amp; \, \beta_0 + \beta_1 excess \, returns_{t-1} + \beta_5 \log(dividend yield_{t-1}) + u_t \\
\end{align*}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ADL(1,1) (1st difference of log dividend yield)</span>
CRSP_ADL_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">dynlm</span>(ExReturn <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(ExReturn) <span class="op">+</span><span class="st"> </span><span class="kw">d</span>(<span class="kw">L</span>(ln_DivYield)), 
                    <span class="dt">data =</span> StockReturns,
                    <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">12</span>))

<span class="co"># ADL(2,2) (1st &amp; 2nd differences of log dividend yield)</span>
CRSP_ADL_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">dynlm</span>(ExReturn <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(ExReturn) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(ExReturn, <span class="dv">2</span>) 
                    <span class="op">+</span><span class="st"> </span><span class="kw">d</span>(<span class="kw">L</span>(ln_DivYield)) <span class="op">+</span><span class="st"> </span><span class="kw">d</span>(<span class="kw">L</span>(ln_DivYield, <span class="dv">2</span>)), 
                    <span class="dt">data =</span> StockReturns,
                    <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">12</span>))

<span class="co"># ADL(1,1) (level of log dividend yield)</span>
CRSP_ADL_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">dynlm</span>(ExReturn <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(ExReturn) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(ln_DivYield),
                    <span class="dt">data =</span> StockReturns,
                    <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">1992</span>, <span class="dv">12</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># gather robust standard errors</span>
rob_se_CRSP_ADL &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">sandwich</span>(CRSP_ADL_<span class="dv">1</span>))),
                        <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">sandwich</span>(CRSP_ADL_<span class="dv">2</span>))),
                        <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">sandwich</span>(CRSP_ADL_<span class="dv">3</span>))))</code></pre></div>
<p>A tabular representation of the results can then be generated using <tt>stargazer()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">stargazer</span>(CRSP_ADL_<span class="dv">1</span>, CRSP_ADL_<span class="dv">2</span>, CRSP_ADL_<span class="dv">3</span>,
  <span class="dt">title =</span> <span class="st">&quot;ADL Models of Monthly Excess Stock Returns&quot;</span>,
  <span class="dt">header =</span> <span class="ot">FALSE</span>, 
  <span class="dt">type =</span> <span class="st">&quot;latex&quot;</span>,
  <span class="dt">column.sep.width =</span> <span class="st">&quot;-5pt&quot;</span>,
  <span class="dt">no.space =</span> T,
  <span class="dt">digits =</span> <span class="dv">3</span>, 
  <span class="dt">column.labels =</span> <span class="kw">c</span>(<span class="st">&quot;ADL(1,1)&quot;</span>, <span class="st">&quot;ADL(2,2)&quot;</span>, <span class="st">&quot;ADL(1,1)&quot;</span>),
  <span class="dt">dep.var.caption  =</span> <span class="st">&quot;Dependent Variable: Excess returns on the CSRP value-weighted index&quot;</span>,
  <span class="dt">dep.var.labels.include =</span> <span class="ot">FALSE</span>,
  <span class="dt">covariate.labels =</span> <span class="kw">c</span>(<span class="st">&quot;$excess return_{t-1}$&quot;</span>, 
                       <span class="st">&quot;$excess return_{t-2}$&quot;</span>, 
                       <span class="st">&quot;$1^{st} diff log(dividend yield_{t-1})$&quot;</span>, 
                       <span class="st">&quot;$1^{st} diff log(dividend yield_{t-2})$&quot;</span>, 
                       <span class="st">&quot;$log(dividend yield_{t-1})$&quot;</span>, 
                       <span class="st">&quot;Constant&quot;</span>),
  <span class="dt">se =</span> rob_se_CRSP_ADL) </code></pre></div>



<table style="text-align:center"><tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"></td><td colspan="3">Dependent Variable: Excess Returns on the CSRP Value-Weighted Index</td></tr>
<tr><td></td><td colspan="3" style="border-bottom: 1px solid black"></td></tr>
<tr><td style="text-align:left"></td><td>ADL(1,1)</td><td>ADL(2,2)</td><td>ADL(1,1)</td></tr>
<tr><td style="text-align:left"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>
<tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">excess return<sub>t-1</sub></td><td>0.059</td><td>0.042</td><td>0.078</td></tr>
<tr><td style="text-align:left"></td><td>(0.158)</td><td>(0.162)</td><td>(0.057)</td></tr>
<tr><td style="text-align:left">excess return<sub>t-2</sub></td><td></td><td>-0.213</td><td></td></tr>
<tr><td style="text-align:left"></td><td></td><td>(0.193)</td><td></td></tr>
<tr><td style="text-align:left">1<sup>st</sup> diff log(dividend yield<sub>t-1</sub>)</td><td>0.009</td><td>-0.012</td><td></td></tr>
<tr><td style="text-align:left"></td><td>(0.157)</td><td>(0.163)</td><td></td></tr>
<tr><td style="text-align:left">1<sup>st</sup> diff log(dividend yield<sub>t-2</sub>)</td><td></td><td>-0.161</td><td></td></tr>
<tr><td style="text-align:left"></td><td></td><td>(0.185)</td><td></td></tr>
<tr><td style="text-align:left">log(dividend yield<sub>t-1</sub>)</td><td></td><td></td><td>0.026<sup>**</sup></td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td>(0.012)</td></tr>
<tr><td style="text-align:left">Constant</td><td>0.309</td><td>0.372<sup>*</sup></td><td>8.987<sup>**</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.199)</td><td>(0.208)</td><td>(3.912)</td></tr>
<tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">Observations</td><td>516</td><td>516</td><td>396</td></tr>
<tr><td style="text-align:left">R<sup>2</sup></td><td>0.003</td><td>0.007</td><td>0.018</td></tr>
<tr><td style="text-align:left">Adjusted R<sup>2</sup></td><td>-0.001</td><td>-0.001</td><td>0.013</td></tr>
<tr><td style="text-align:left">Residual Std. Error</td><td>4.338 (df = 513)</td><td>4.337 (df = 511)</td><td>4.407 (df = 393)</td></tr>
<tr><td style="text-align:left">F Statistic</td><td>0.653 (df = 2; 513)</td><td>0.897 (df = 4; 511)</td><td>3.683<sup>**</sup> (df = 2; 393)</td></tr>
<tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"><em>Note:</em></td><td colspan="3" style="text-align:right"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>
</table>
<caption><p style='text-align:center'><span id="tab:adlmomesr">Table 14.3: </span> ADL Models of Monthly Excess Stock Returns</p></caption>


<p>For models (1) and (2) none of the individual <span class="math inline">\(t\)</span>-statistics suggest that the coefficients are different from zero. Also, we cannot reject the hypothesis that none of the lags have predictive power for excess returns at any common level of significance (an <span class="math inline">\(F\)</span>-test that the lags have predictive power does not reject for both models).</p>
<p>Things are different for model (3). The coefficient on the level of the logarithm of the dividend yield is different from zero at the <span class="math inline">\(5\%\)</span> level and the <span class="math inline">\(F\)</span>-test rejects, too. But we should be suspicious: the high degree of persistence in the dividend yield series probably renders this inference dubious because <span class="math inline">\(t\)</span>- and <span class="math inline">\(F\)</span>-statistics may follow distributions that deviate considerably from their theoretical large-sample distributions such that the usual critical values cannot be applied.</p>
<p>If model (3) were of use for predicting excess returns, pseudo-out-of-sample forecasts based on (3) should at least outperform forecasts of an intercept-only model in terms of the sample RMSFE. We can perform this type of comparison using <tt>R</tt> code in the fashion of the applications of Chapter <a href="ittsraf.html#niib">14.8</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># end of sample dates</span>
EndOfSample &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">window</span>(<span class="kw">time</span>(StockReturns), <span class="kw">c</span>(<span class="dv">1992</span>, <span class="dv">12</span>), <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">11</span>)))

<span class="co"># initialize matrix  forecasts</span>
forecasts &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="dv">2</span>, 
                    <span class="dt">ncol =</span> <span class="kw">length</span>(EndOfSample))

<span class="co"># estimation loop over end of sample dates</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(EndOfSample)) {

  <span class="co"># estimate model (3)</span>
  mod3 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(ExReturn <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(ExReturn) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(ln_DivYield), <span class="dt">data =</span> StockReturns, 
                <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), 
                <span class="dt">end =</span> EndOfSample[i])
  
  <span class="co"># estimate intercept only model</span>
  modconst &lt;-<span class="st"> </span><span class="kw">dynlm</span>(ExReturn <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> StockReturns, 
                <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1960</span>, <span class="dv">1</span>), 
                <span class="dt">end =</span> EndOfSample[i])
  
  <span class="co"># sample data for one-period ahead forecast</span>
  t &lt;-<span class="st"> </span><span class="kw">window</span>(StockReturns, EndOfSample[i], EndOfSample[i])
  
  <span class="co"># compute forecast</span>
  forecasts[, i] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">coef</span>(mod3) <span class="op">%*%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, t[<span class="dv">1</span>], t[<span class="dv">2</span>]), <span class="kw">coef</span>(modconst))
                     
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># gather data</span>
d &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="st">&quot;Excess Returns&quot;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="kw">window</span>(StockReturns[,<span class="dv">1</span>], <span class="kw">c</span>(<span class="dv">1993</span>, <span class="dv">1</span>), <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">12</span>))),
           <span class="st">&quot;Model (3)&quot;</span> =<span class="st"> </span>forecasts[<span class="dv">1</span>,], 
           <span class="st">&quot;Intercept Only&quot;</span> =<span class="st"> </span>forecasts[<span class="dv">2</span>,], 
           <span class="st">&quot;Always Zero&quot;</span> =<span class="st">  </span><span class="dv">0</span>)

<span class="co"># Compute RMSFEs</span>
<span class="kw">c</span>(<span class="st">&quot;ADL model (3)&quot;</span> =<span class="st"> </span><span class="kw">sd</span>(d[, <span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>d[, <span class="dv">2</span>]),
  <span class="st">&quot;Intercept-only model&quot;</span> =<span class="st"> </span><span class="kw">sd</span>(d[, <span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>d[, <span class="dv">3</span>]),
  <span class="st">&quot;Always zero&quot;</span> =<span class="st"> </span><span class="kw">sd</span>(d[,<span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>d[, <span class="dv">4</span>]))</code></pre></div>
<pre><code>##        ADL model (3) Intercept-only model          Always zero 
##             4.043757             4.000221             3.995428</code></pre>
<p>The comparison indicates that model (3) is not useful since it is outperformed in terms of sample RMSFE by the intercept-only model. A model forecasting excess returns always to be zero has an even lower sample RMSFE. This finding is consistent with the weak-form efficiency hypothesis which states that all publicly available information is accounted for in stock prices such that there is no way to predict future stock prices or excess returns using past observations, implying that the perceived significant relationship indicated by model (3) is wrong.</p>
<div id="summary-6" class="section level4 unnumbered">
<h4>Summary</h4>
<p>This chapter dealt with introductory topics in time series regression analysis, where variables are generally correlated from one observation to the next, a concept termed serial correlation. We presented several ways of storing and plotting time series data using <tt>R</tt> and used these for informal analysis of economic data.</p>
<p>We have introduced AR and ADL models and applied them in the context of forecasting of macroeconomic and financial time series using <tt>R</tt>. The discussion also included the topic of lag length selection. It was shown how to set up a simple function that computes the BIC for a model object supplied.</p>
<p>We have also seen how to write simple <tt>R</tt> code for performing and evaluating forecasts and demonstrated some more sophisticated approaches to conduct pseudo-out-of-sample forecasts for assessment of a model’s predictive power for unobserved future outcomes of a series, to check model stability and to compare different models.</p>
<p>Furthermore, some more technical aspects like the concept of stationarity were addressed. This included applications to testing for an autoregressive unit root with the Dickey-Fuller test and the detection of a break in the population regression function using the <span class="math inline">\(QLR\)</span> statistic. For both methods, the distribution of the relevant test statistic is non-normal, even in large samples. Concerning the Dickey-Fuller test we have used <tt>R</tt>’s random number generation facilities to produce evidence for this by means of a Monte-Carlo simulation and motivated usage of the quantiles tabulated in the book.</p>
<p>Also, empirical studies regarding the validity of the weak and the strong form efficiency hypothesis which are presented in the applications <em>Can You Beat the Market? Part I &amp; II</em> in the book have been reproduced using <tt>R</tt>.</p>
<p>In all applications of this chapter, the focus was on forecasting future outcomes rather than estimation of causal relationships between time series variables. However, the methods needed for the latter are quite similar. Chapter <a href="eodce.html#eodce">15</a> is devoted to estimation of so called <em>dynamic causal effects</em>.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-AER">
<p>Kleiber, C., &amp; Zeileis, A. (2017). AER: Applied Econometrics with R (Version 1.2-5). Retrieved from <a href="https://CRAN.R-project.org/package=AER" class="uri">https://CRAN.R-project.org/package=AER</a></p>
</div>
<div id="ref-R-dynlm">
<p>Zeileis, A. (2016). dynlm: Dynamic Linear Regression (Version 0.3-5). Retrieved from <a href="https://CRAN.R-project.org/package=dynlm" class="uri">https://CRAN.R-project.org/package=dynlm</a></p>
</div>
<div id="ref-R-forecast">
<p>Hyndman, R., Athanasopoulos, G., Bergmeir, C., Caceres, G., Chhay, L., O’Hara-Wild, M., … Yasmeen, F. (2018). forecast: Forecasting Functions for Time Series and Linear Models (Version 8.4). Retrieved from <a href="https://CRAN.R-project.org/package=forecast" class="uri">https://CRAN.R-project.org/package=forecast</a></p>
</div>
<div id="ref-R-readxl">
<p>Wickham, H., &amp; Bryan, J. (2018). readxl: Read Excel Files (Version 1.1.0). Retrieved from <a href="https://CRAN.R-project.org/package=readxl" class="uri">https://CRAN.R-project.org/package=readxl</a></p>
</div>
<div id="ref-R-stargazer">
<p>Hlavac, M. (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables (Version 5.2.2). Retrieved from <a href="https://CRAN.R-project.org/package=stargazer" class="uri">https://CRAN.R-project.org/package=stargazer</a></p>
</div>
<div id="ref-R-scales">
<p>Wickham, H. (2017). scales: Scale Functions for Visualization (Version 0.5.0). Retrieved from <a href="https://CRAN.R-project.org/package=scales" class="uri">https://CRAN.R-project.org/package=scales</a></p>
</div>
<div id="ref-R-quantmod">
<p>Ryan, J. A., &amp; Ulrich, J. M. (2018). quantmod: Quantitative Financial Modelling Framework (Version 0.4-13). Retrieved from <a href="https://CRAN.R-project.org/package=quantmod" class="uri">https://CRAN.R-project.org/package=quantmod</a></p>
</div>
<div id="ref-R-urca">
<p>Pfaff, B. (2016). urca: Unit Root and Cointegration Tests for Time Series Data (Version 1.3-0). Retrieved from <a href="https://CRAN.R-project.org/package=urca" class="uri">https://CRAN.R-project.org/package=urca</a></p>
</div>
<div id="ref-granger1969">
<p>Granger, C. (1969). Investigating Causal Relations by Econometric Models and Cross-Spectral Methods. <em>Econometrica</em>, <em>37</em>(3), 424–438.</p>
</div>
<div id="ref-dickey1979">
<p>Dickey, D. A., &amp; Fuller, W. A. (1979). Distribution of the Estimators for Autoregressive Time Series with a Unit Root. <em>Journal of the American Statistical Association</em>, <em>74</em>(366), pp. 427–431.</p>
</div>
<div id="ref-chow1960">
<p>Chow, G. C. (1960). Tests of Equality Between Sets of Coefficients in Two Linear Regressions. <em>Econometrica</em>, <em>28</em>(3), 591–605.</p>
</div>
<div id="ref-quandt1960">
<p>Quandt, R. E. (1960). Tests of the Hypothesis That a Linear Regression System Obeys Two Separate Regimes. <em>Journal of the American Statistical Association</em>, <em>55</em>(290), 324–330. doi:<a href="https://doi.org/10.1080/01621459.1960.10482067">10.1080/01621459.1960.10482067</a></p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="11">
<li id="fn11"><p>The <span class="math inline">\(t\)</span>-statistic of the Dickey-Fuller test is computed using homoskedasticity-only standard errors since under the null hypothesis, the usual <span class="math inline">\(t\)</span>-statistic is robust to conditional heteroskedasticity.<a href="ittsraf.html#fnref11">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="eaqe.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="eodce.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": true,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 1
},
"edit": null,
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
