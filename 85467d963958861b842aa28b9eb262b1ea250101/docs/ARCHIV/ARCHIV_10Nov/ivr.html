<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Econometrics with R</title>
  <meta name="description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programing and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Econometrics with R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programing and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Econometrics with R" />
  
  <meta name="twitter:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programing and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2018-10-05">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="rwabdv.html">
<link rel="next" href="eaqe.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>
<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">

<!-- function to adjust height of iframes automatically depending on content loaded -->

<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>

<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/default.js"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://www.oek.wiwi.uni-due.de/en/">Chair of Econometrics at UDE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#a-very-short-introduction-to-r-and-rstudio"><i class="fa fa-check"></i><b>1.1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="2.1" data-path="pt.html"><a href="pt.html#random-variables-and-probability-distributions"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pt.html"><a href="pt.html#RSATDOSA"><i class="fa fa-check"></i><b>2.2</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pt.html"><a href="pt.html#exercises"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="arosur.html"><a href="arosur.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="3.1" data-path="arosur.html"><a href="arosur.html#estimation-of-the-population-mean"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="arosur.html"><a href="arosur.html#potsm"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="arosur.html"><a href="arosur.html#hypothesis-tests-concerning-the-population-mean"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="arosur.html"><a href="arosur.html#confidence-intervals-for-the-population-mean"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.5" data-path="arosur.html"><a href="arosur.html#cmfdp"><i class="fa fa-check"></i><b>3.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.6" data-path="arosur.html"><a href="arosur.html#aattggoe"><i class="fa fa-check"></i><b>3.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.7" data-path="arosur.html"><a href="arosur.html#scatterplots-sample-covariance-and-sample-correlation"><i class="fa fa-check"></i><b>3.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.8" data-path="arosur.html"><a href="arosur.html#exercises-1"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lrwor.html"><a href="lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="4.1" data-path="lrwor.html"><a href="lrwor.html#simple-linear-regression"><i class="fa fa-check"></i><b>4.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="4.2" data-path="lrwor.html"><a href="lrwor.html#estimating-the-coefficients-of-the-linear-regression-model"><i class="fa fa-check"></i><b>4.2</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="lrwor.html"><a href="lrwor.html#measures-of-fit"><i class="fa fa-check"></i><b>4.3</b> Measures of Fit</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="lrwor.html"><a href="lrwor.html#tlsa"><i class="fa fa-check"></i><b>4.4</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="lrwor.html"><a href="lrwor.html#tsdotoe"><i class="fa fa-check"></i><b>4.5</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="lrwor.html"><a href="lrwor.html#exercises-2"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="htaciitslrm.html"><a href="htaciitslrm.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="5.1" data-path="htaciitslrm.html"><a href="htaciitslrm.html#testing-two-sided-hypotheses-concerning-the-slope-coefficient"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="5.2" data-path="htaciitslrm.html"><a href="htaciitslrm.html#cifrc"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="htaciitslrm.html"><a href="htaciitslrm.html#rwxiabv"><i class="fa fa-check"></i><b>5.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="htaciitslrm.html"><a href="htaciitslrm.html#hah"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="htaciitslrm.html"><a href="htaciitslrm.html#the-gauss-markov-theorem"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="htaciitslrm.html"><a href="htaciitslrm.html#using-the-t-statistic-in-regression-when-the-sample-size-is-small"><i class="fa fa-check"></i><b>5.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="5.7" data-path="htaciitslrm.html"><a href="htaciitslrm.html#exercises-3"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="rmwmr.html"><a href="rmwmr.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="6.1" data-path="rmwmr.html"><a href="rmwmr.html#omitted-variable-bias"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="rmwmr.html"><a href="rmwmr.html#tmrm"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="rmwmr.html"><a href="rmwmr.html#mofimr"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="rmwmr.html"><a href="rmwmr.html#ols-assumptions-in-multiple-regression"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="rmwmr.html"><a href="rmwmr.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="rmwmr.html"><a href="rmwmr.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="rmwmr.html"><a href="rmwmr.html#the-distribution-of-the-ols-estimators-in-multiple-regression"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="6.6" data-path="rmwmr.html"><a href="rmwmr.html#exercises-4"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="htaciimr.html"><a href="htaciimr.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence Intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="htaciimr.html"><a href="htaciimr.html#hypothesis-tests-and-confidence-intervals-for-a-single-coefficient"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="htaciimr.html"><a href="htaciimr.html#an-application-to-test-scores-and-the-student-teacher-ratio"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="htaciimr.html"><a href="htaciimr.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="htaciimr.html"><a href="htaciimr.html#joint-hypothesis-testing-using-the-f-statistic"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the F-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="htaciimr.html"><a href="htaciimr.html#confidence-sets-for-multiple-coefficients"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="htaciimr.html"><a href="htaciimr.html#model-specification-for-multiple-regression"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="htaciimr.html"><a href="htaciimr.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="htaciimr.html"><a href="htaciimr.html#analysis-of-the-test-score-data-set"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="7.7" data-path="htaciimr.html"><a href="htaciimr.html#exercises-5"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nrf.html"><a href="nrf.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="8.1" data-path="nrf.html"><a href="nrf.html#a-general-strategy-for-modelling-nonlinear-regression-functions"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="nrf.html"><a href="nrf.html#nfoasiv"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="nrf.html"><a href="nrf.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="nrf.html"><a href="nrf.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="nrf.html"><a href="nrf.html#interactions-between-independent-variables"><i class="fa fa-check"></i><b>8.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="nrf.html"><a href="nrf.html#nonlinear-effects-on-test-scores-of-the-student-teacher-ratio"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
<li class="chapter" data-level="8.5" data-path="nrf.html"><a href="nrf.html#exercises-6"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="asbomr.html"><a href="asbomr.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="asbomr.html"><a href="asbomr.html#internal-and-external-validity"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="asbomr.html"><a href="asbomr.html#ttivomra"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="asbomr.html"><a href="asbomr.html#internal-and-external-validity-when-the-regression-is-used-for-forecasting"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity when the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="asbomr.html"><a href="asbomr.html#etsacs"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
<li class="chapter" data-level="9.5" data-path="asbomr.html"><a href="asbomr.html#exercises-7"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="rwpd.html"><a href="rwpd.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="10.1" data-path="rwpd.html"><a href="rwpd.html#panel-data"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="rwpd.html"><a href="rwpd.html#PDWTTP"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="rwpd.html"><a href="rwpd.html#fixed-effects-regression"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="rwpd.html"><a href="rwpd.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="rwpd.html"><a href="rwpd.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="rwpd.html"><a href="rwpd.html#regression-with-time-fixed-effects"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="rwpd.html"><a href="rwpd.html#tferaaseffer"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="rwpd.html"><a href="rwpd.html#drunk-driving-laws-and-traffic-deaths"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="rwabdv.html"><a href="rwabdv.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="11.1" data-path="rwabdv.html"><a href="rwabdv.html#binary-dependent-variables-and-the-linear-probability-model"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="rwabdv.html"><a href="rwabdv.html#palr"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="rwabdv.html"><a href="rwabdv.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="rwabdv.html"><a href="rwabdv.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="rwabdv.html"><a href="rwabdv.html#estimation-and-inference-in-the-logit-and-probit-models"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="rwabdv.html"><a href="rwabdv.html#application-to-the-boston-hmda-data"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
<li class="chapter" data-level="11.5" data-path="rwabdv.html"><a href="rwabdv.html#exercises-8"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ivr.html"><a href="ivr.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="ivr.html"><a href="ivr.html#TIVEWASRAASI"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="ivr.html"><a href="ivr.html#TGIVRM"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="ivr.html"><a href="ivr.html#civ"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="ivr.html"><a href="ivr.html#attdfc"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="ivr.html"><a href="ivr.html#where-do-valid-instruments-come-from"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
<li class="chapter" data-level="12.6" data-path="ivr.html"><a href="ivr.html#exercises-9"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="eaqe.html"><a href="eaqe.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="13.1" data-path="eaqe.html"><a href="eaqe.html#potential-outcomes-causal-effects-and-idealized-experiments"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="eaqe.html"><a href="eaqe.html#threats-to-validity-of-experiments"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="eaqe.html"><a href="eaqe.html#experimental-estimates-of-the-effect-of-class-size-reductions"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="eaqe.html"><a href="eaqe.html#quasi-experiments"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ittsraf.html"><a href="ittsraf.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="14.1" data-path="ittsraf.html"><a href="ittsraf.html#using-regression-models-for-forecasting"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="ittsraf.html"><a href="ittsraf.html#tsdasc"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="ittsraf.html"><a href="ittsraf.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="ittsraf.html"><a href="ittsraf.html#autoregressions"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a><ul>
<li><a href="ittsraf.html#autoregressive-models-of-order-p">Autoregressive Models of Order <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ittsraf.html"><a href="ittsraf.html#cybtmpi"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="ittsraf.html"><a href="ittsraf.html#apatadlm"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="ittsraf.html"><a href="ittsraf.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="ittsraf.html"><a href="ittsraf.html#llsuic"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="ittsraf.html"><a href="ittsraf.html#nit"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="ittsraf.html"><a href="ittsraf.html#niib"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="ittsraf.html"><a href="ittsraf.html#can-you-beat-the-market-part-ii"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="eodce.html"><a href="eodce.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="15.1" data-path="eodce.html"><a href="eodce.html#the-orange-juice-data"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="eodce.html"><a href="eodce.html#dynamic-causal-effects"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="eodce.html"><a href="eodce.html#dynamic-multipliers-and-cumulative-dynamic-multipliers"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="eodce.html"><a href="eodce.html#hac-standard-errors"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="eodce.html"><a href="eodce.html#estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="eodce.html"><a href="eodce.html#orange-juice-prices-and-cold-weather"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="atitsr.html"><a href="atitsr.html"><i class="fa fa-check"></i><b>16</b> Additional Topics in Time Series Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="atitsr.html"><a href="atitsr.html#vector-autoregressions"><i class="fa fa-check"></i><b>16.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="16.2" data-path="atitsr.html"><a href="atitsr.html#ooiatdfglsurt"><i class="fa fa-check"></i><b>16.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="16.3" data-path="atitsr.html"><a href="atitsr.html#cointegration"><i class="fa fa-check"></i><b>16.3</b> Cointegration</a></li>
<li class="chapter" data-level="16.4" data-path="atitsr.html"><a href="atitsr.html#volatility-clustering-and-autoregressive-conditional-heteroskedasticity"><i class="fa fa-check"></i><b>16.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a><ul>
<li class="chapter" data-level="" data-path="atitsr.html"><a href="atitsr.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="atitsr.html"><a href="atitsr.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
<li class="chapter" data-level="" data-path="atitsr.html"><a href="atitsr.html#summary-8"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Econometrics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. You can also see the annotations of others: click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="ivr" class="section level1">
<h1><span class="header-section-number">12</span> Instrumental Variables Regression</h1>
<p>As discussed in Chapter <a href="asbomr.html#asbomr">9</a>, regression models may suffer from problems like omitted variables, measurement errors and simultaneous causality. If so, the error term is correlated with the regressor of interest and so that the corresponding coefficient is estimated inconsistently. So far we have assumed that we can add the omitted variables to the regression to mitigate the risk of biased estimation of the causal effect of interest. However, if omitted factors cannot be measured or are not available for other reasons, multiple regression cannot solve the problem. The same issue arises if there is simultaneous causality. When causality runs from <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span> and vice versa, there will be an estimation bias that cannot be corrected for by multiple regression.</p>
<p>A general technique for obtaining a consistent estimator of the coefficient of interest is instrumental variables (IV) regression. In this chapter we focus on the IV regression tool called <em>two-stage least squares</em> (TSLS). The first sections briefly recap the general mechanics and assumptions of IV regression and show how to perform TSLS estimation using <tt>R</tt>. Next, IV regression is used for estimating the elasticity of the demand for cigarettes — a classical example where multiple regression fails to do the job because of simultaneous causality.</p>
<p>Just like for the previous chapter, the packages <tt>AER</tt> <span class="citation">(Christian Kleiber &amp; Zeileis, <a href="#ref-R-AER">2017</a>)</span> and <tt>stargazer</tt> <span class="citation">(Hlavac, <a href="#ref-R-stargazer">2018</a>)</span> are required for reproducing the code presented in this chapter. Check whether the code chunk below executes without any error messages.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(AER)
<span class="kw">library</span>(stargazer)</code></pre></div>
<div id="TIVEWASRAASI" class="section level2">
<h2><span class="header-section-number">12.1</span> The IV Estimator with a Single Regressor and a Single Instrument</h2>
<p>Consider the simple regression model</p>
<span class="math display" id="eq:srm12">\[\begin{align}
  Y_i = \beta_0 + \beta_1 X_i + u_i \ \ , \ \ i=1,\dots,n  \tag{12.1}
\end{align}\]</span>
<p>where the error term <span class="math inline">\(u_i\)</span> is correlated with the regressor <span class="math inline">\(X_i\)</span> (<span class="math inline">\(X\)</span> is <em>endogenous</em>) such that OLS is inconsistent for the true <span class="math inline">\(\beta_1\)</span>. In the most simple case, IV regression uses a single instrumental variable <span class="math inline">\(Z\)</span> to obtain a consistent estimator for <span class="math inline">\(\beta_1\)</span>.</p>
<p><span class="math inline">\(Z\)</span> must satisfy two conditions to be a valid instrument:</p>
<p><strong>1. Instrument relevance condition</strong>:</p>
<center>
<span class="math inline">\(X\)</span> and its instrument <span class="math inline">\(Z\)</span> <em>must be</em> correlated: <span class="math inline">\(\rho_{Z_i,X_i} \neq 0\)</span>.
</center>
<p><strong>2. Instrument exogeneity condition</strong>:</p>
<center>
The instrument <span class="math inline">\(Z\)</span> <em>must not be</em> correlated with the error term <span class="math inline">\(u\)</span>: <span class="math inline">\(\rho_{Z_i,u_i} = 0\)</span>.
</center>
<div id="the-two-stage-least-squares-estimator" class="section level4 unnumbered">
<h4>The Two-Stage Least Squares Estimator</h4>
<p>As can be guessed from its name, TSLS proceeds in two stages. In the first stage, the variation in the endogenous regressor <span class="math inline">\(X\)</span> is decomposed into a problem-free component that is explained by the instrument <span class="math inline">\(Z\)</span> and a problematic component that is correlated with the error <span class="math inline">\(u_i\)</span>. The second stage uses the problem-free component of the variation in <span class="math inline">\(X\)</span> to estimate <span class="math inline">\(\beta_1\)</span>.</p>
<p>The first stage regression model is <span class="math display">\[X_i = \pi_0 + \pi_1 Z_i + \nu_i,\]</span> where <span class="math inline">\(\pi_0 + \pi_1 Z_i\)</span> is the component of <span class="math inline">\(X_i\)</span> that is explained by <span class="math inline">\(Z_i\)</span> while <span class="math inline">\(\nu_i\)</span> is the component that cannot be explained by <span class="math inline">\(Z_i\)</span> and exhibits correlation with <span class="math inline">\(u_i\)</span>.</p>
<p>Using the OLS estimates <span class="math inline">\(\widehat{\pi}_0\)</span> and <span class="math inline">\(\widehat{\pi}_1\)</span> we obtain predicted values <span class="math inline">\(\widehat{X}_i, \ \ i=1,\dots,n\)</span>. If <span class="math inline">\(Z\)</span> is a valid instrument, the <span class="math inline">\(\widehat{X}_i\)</span> are problem-free in the sense that <span class="math inline">\(\widehat{X}\)</span> is exogenous in a regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(\widehat{X}\)</span> which is done in the second stage regression. The second stage produces <span class="math inline">\(\widehat{\beta}_0^{TSLS}\)</span> and <span class="math inline">\(\widehat{\beta}_1^{TSLS}\)</span>, the TSLS estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<p>For the case of a single instrument one can show that the TSLS estimator of <span class="math inline">\(\beta_1\)</span> is</p>
<span class="math display" id="eq:simpletsls">\[\begin{align}
\widehat{\beta}_1^{TSLS} = \frac{s_{ZY}}{s_{ZX}} = \frac{\frac{1}{n-1}\sum_{i=1}^n(Y_i - \overline{Y})(Z_i - \overline{Z})}{\frac{1}{n-1}\sum_{i=1}^n(X_i - \overline{X})(Z_i - \overline{Z})}, \tag{12.2}
\end{align}\]</span>
<p>which is nothing but the ratio of the sample covariance between <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span> to the sample covariance between <span class="math inline">\(Z\)</span> and <span class="math inline">\(X\)</span>.</p>
<p>As shown in Appendix 12.3 of the book, <a href="ivr.html#eq:simpletsls">(12.2)</a> is a consistent estimator for <span class="math inline">\(\beta_1\)</span> in <a href="ivr.html#eq:srm12">(12.1)</a> under the assumption that <span class="math inline">\(Z\)</span> is a valid instrument. Just as for every other OLS estimator we have considered so far, the CLT implies that the distribution of <span class="math inline">\(\widehat{\beta}_1^{TSLS}\)</span> can be approximated by a normal distribution if the sample size is large. This allows us to use <span class="math inline">\(t\)</span>-statistics and confidence intervals which are also computed by certain <tt>R</tt> functions. A more detailed argument on the large-sample distribution of the TSLS estimator is sketched in Appendix 12.3 of the book.</p>
</div>
<div id="application-to-the-demand-for-cigarettes" class="section level4 unnumbered">
<h4>Application to the Demand For Cigarettes</h4>
<p>The relation between the demand for and the price of commodities is a simple yet widespread problem in economics. Health economics is concerned with the study of how health-affecting behavior of individuals is influenced by the health-care system and regulation policy. Probably the most prominent example in public policy debates is smoking as it is related to many illnesses and negative externalities.</p>
<p>It is plausible that cigarette consumption can be reduced by taxing cigarettes more heavily. The question is by <em>how much</em> taxes must be increased to reach a certain reduction in cigarette consumption. Economists use elasticities to answer this kind of question. Since the price elasticity for the demand of cigarettes is unknown, it must be estimated. As discussed in the box <em>Who Invented Instrumental Variables Regression</em> presented in Chapter 12.1 of the book, an OLS regression of log quantity on log price cannot be used to estimate the effect of interest since there is simultaneous causality between demand and supply. Instead, IV regression can be used.</p>
<p>We use the data set <tt>CigarettesSW</tt> which comes with the package <tt>AER</tt>. It is a panel data set that contains observations on cigarette consumption and several economic indicators for all 48 continental federal states of the U.S. from 1985 to 1995. Following the book we consider data for the cross section of states in 1995 only.</p>
<p>We start by loading the package, attaching the data set and getting an overview.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the data set and get an overview</span>
<span class="kw">library</span>(AER)
<span class="kw">data</span>(<span class="st">&quot;CigarettesSW&quot;</span>)
<span class="kw">summary</span>(CigarettesSW)</code></pre></div>
<pre><code>##      state      year         cpi          population      
##  AL     : 2   1985:48   Min.   :1.076   Min.   :  478447  
##  AR     : 2   1995:48   1st Qu.:1.076   1st Qu.: 1622606  
##  AZ     : 2             Median :1.300   Median : 3697472  
##  CA     : 2             Mean   :1.300   Mean   : 5168866  
##  CO     : 2             3rd Qu.:1.524   3rd Qu.: 5901500  
##  CT     : 2             Max.   :1.524   Max.   :31493524  
##  (Other):84                                               
##      packs            income               tax            price       
##  Min.   : 49.27   Min.   :  6887097   Min.   :18.00   Min.   : 84.97  
##  1st Qu.: 92.45   1st Qu.: 25520384   1st Qu.:31.00   1st Qu.:102.71  
##  Median :110.16   Median : 61661644   Median :37.00   Median :137.72  
##  Mean   :109.18   Mean   : 99878736   Mean   :42.68   Mean   :143.45  
##  3rd Qu.:123.52   3rd Qu.:127313964   3rd Qu.:50.88   3rd Qu.:176.15  
##  Max.   :197.99   Max.   :771470144   Max.   :99.00   Max.   :240.85  
##                                                                       
##       taxs       
##  Min.   : 21.27  
##  1st Qu.: 34.77  
##  Median : 41.05  
##  Mean   : 48.33  
##  3rd Qu.: 59.48  
##  Max.   :112.63  
## </code></pre>
<p>Use <code>?CigarettesSW</code> for a detailed description of the variables.</p>
<p>We are interested in estimating <span class="math inline">\(\beta_1\)</span> in</p>
<span class="math display" id="eq:cigstsls">\[\begin{align}
  \log(Q_i^{cigarettes}) = \beta_0 + \beta_1 \log(P_i^{cigarettes}) + u_i, \tag{12.3}
\end{align}\]</span>
<p>where <span class="math inline">\(Q_i^{cigarettes}\)</span> is the number of cigarette packs per capita sold and <span class="math inline">\(P_i^{cigarettes}\)</span> is the after-tax average real price per pack of cigarettes in state <span class="math inline">\(i\)</span>.</p>
<p>The instrumental variable we are going to use for instrumenting the endogenous regressor <span class="math inline">\(\log(P_i^{cigarettes})\)</span> is <span class="math inline">\(SalesTax\)</span>, the portion of taxes on cigarettes arising from the general sales tax. <span class="math inline">\(SalesTax\)</span> is measured in dollars per pack. The idea is that <span class="math inline">\(SalesTax\)</span> is a relevant instrument as it is included in the after-tax average price per pack. Also, it is plausible that <span class="math inline">\(SalesTax\)</span> is exogenous since the sales tax does not influence quantity sold directly but indirectly through the price.</p>
<p>We perform some transformations in order to obtain deflated cross section data for the year 1995.</p>
<p>We also compute the sample correlation between the sales tax and price per pack. The sample correlation is a consistent estimator of the population correlation. The estimate of approximately <span class="math inline">\(0.614\)</span> indicates that <span class="math inline">\(SalesTax\)</span> and <span class="math inline">\(P_i^{cigarettes}\)</span> exhibit positive correlation which meets our expectations: higher sales taxes lead to higher prices. However, a correlation analysis like this is not sufficient for checking whether the instrument is relevant. We will later come back to the issue of checking whether an instrument is relevant and exogenous.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute real per capita prices</span>
CigarettesSW<span class="op">$</span>rprice &lt;-<span class="st"> </span><span class="kw">with</span>(CigarettesSW, price <span class="op">/</span><span class="st"> </span>cpi)

<span class="co">#  compute the sales tax</span>
CigarettesSW<span class="op">$</span>salestax &lt;-<span class="st"> </span><span class="kw">with</span>(CigarettesSW, (taxs <span class="op">-</span><span class="st"> </span>tax) <span class="op">/</span><span class="st"> </span>cpi)

<span class="co"># check the correlation between sales tax and price</span>
<span class="kw">cor</span>(CigarettesSW<span class="op">$</span>salestax, CigarettesSW<span class="op">$</span>price)</code></pre></div>
<pre><code>## [1] 0.6141228</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate a subset for the year 1995</span>
c1995 &lt;-<span class="st"> </span><span class="kw">subset</span>(CigarettesSW, year <span class="op">==</span><span class="st"> &quot;1995&quot;</span>)</code></pre></div>
<p>The first stage regression is <span class="math display">\[\log(P_i^{cigarettes}) = \pi_0 + \pi_1 SalesTax_i + \nu_i.\]</span> We estimate this model in <tt>R</tt> using <tt>lm()</tt>. In the second stage we run a regression of <span class="math inline">\(\log(Q_i^{cigarettes})\)</span> on <span class="math inline">\(\widehat{\log(P_i^{cigarettes})}\)</span> to obtain <span class="math inline">\(\widehat{\beta}_0^{TSLS}\)</span> and <span class="math inline">\(\widehat{\beta}_1^{TSLS}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># perform the first stage regression</span>
cig_s1 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(rprice) <span class="op">~</span><span class="st"> </span>salestax, <span class="dt">data =</span> c1995)

<span class="kw">coeftest</span>(cig_s1, <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##              Estimate Std. Error  t value  Pr(&gt;|t|)    
## (Intercept) 4.6165463  0.0289177 159.6444 &lt; 2.2e-16 ***
## salestax    0.0307289  0.0048354   6.3549 8.489e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The first stage regression is <span class="math display">\[\widehat{\log(P_i^{cigarettes})} = \underset{(0.03)}{4.62} + \underset{(0.005)}{0.031} SalesTax_i\]</span> which predicts the relation between sales tax price per cigarettes to be positive. How much of the observed variation in <span class="math inline">\(\log(P^{cigarettes})\)</span> is explained by the instrument <span class="math inline">\(SalesTax\)</span>? This can be answered by looking at the regression’s <span class="math inline">\(R^2\)</span> which states that about <span class="math inline">\(47\%\)</span> of the variation in after tax prices is explained by the variation of the sales tax across states.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># inspect the R^2 of the first stage regression</span>
<span class="kw">summary</span>(cig_s1)<span class="op">$</span>r.squared</code></pre></div>
<pre><code>## [1] 0.4709961</code></pre>
<p>We next store <span class="math inline">\(\widehat{\log(P_i^{cigarettes})}\)</span>, the fitted values obtained by the first stage regression <tt>cig_s1</tt>, in the variable <tt>lcigp_pred</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># store the predicted values</span>
lcigp_pred &lt;-<span class="st"> </span>cig_s1<span class="op">$</span>fitted.values</code></pre></div>
<p>Next, we run the second stage regression which gives us the TSLS estimates we seek.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># run the stage 2 regression</span>
cig_s2 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(c1995<span class="op">$</span>packs) <span class="op">~</span><span class="st"> </span>lcigp_pred)
<span class="kw">coeftest</span>(cig_s2, <span class="dt">vcov =</span> vcovHC)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  9.71988    1.70304  5.7074 7.932e-07 ***
## lcigp_pred  -1.08359    0.35563 -3.0469  0.003822 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Thus estimating the model <a href="ivr.html#eq:cigstsls">(12.3)</a> using TSLS yields</p>
<span class="math display" id="eq:ecigstsls">\[\begin{align}
  \widehat{\log(Q_i^{cigarettes})} = \underset{(1.70)}{9.72} + \underset{(0.36)}{1.08} \log(P_i^{cigarettes}), \tag{12.4}
\end{align}\]</span>
<p>where we write <span class="math inline">\(\log(P_i^{cigarettes})\)</span> instead of <span class="math inline">\(\widehat{\log(P_i^{cigarettes})}\)</span> for consistency with the book.</p>
<p>The function <tt>ivreg()</tt> from the package <tt>AER</tt> carries out TSLS procedure automatically. It is used similarly as <tt>lm()</tt>. Instruments can be added to the usual specification of the regression formula using a vertical bar separating the model equation from the instruments. Thus, for the regression at hand the correct formula is <tt>log(packs) ~ log(rprice) | salestax</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># perform TSLS using &#39;ivreg()&#39;</span>
cig_ivreg &lt;-<span class="st"> </span><span class="kw">ivreg</span>(<span class="kw">log</span>(packs) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(rprice) <span class="op">|</span><span class="st"> </span>salestax, <span class="dt">data =</span> c1995)

<span class="kw">coeftest</span>(cig_ivreg, <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  9.71988    1.52832  6.3598 8.346e-08 ***
## log(rprice) -1.08359    0.31892 -3.3977  0.001411 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We find that the coefficient estimates coincide for both approaches.</p>
<p><strong>Two Notes on the Computation of TSLS Standard Errors</strong></p>
<ol style="list-style-type: decimal">
<li><p>We have demonstrated that running the individual regressions for each stage of TSLS using <tt>lm()</tt> leads to the same coefficient estimates as when using <tt>ivreg()</tt>. However, the standard errors reported for the second-stage regression, e.g., by <tt>coeftest()</tt> or <tt>summary()</tt>, are <em>invalid</em>: neither adjusts for using predictions from the first-stage regression as regressors in the second-stage regression. Fortunately, <tt>ivreg()</tt> performs the necessary adjustment automatically. This is another advantage over manual step-by-step estimation which we have done above for demonstrating the mechanics of the procedure.</p></li>
<li><p>Just like in multiple regression it is important to compute heteroskedasticity-robust standard errors as we have done above using <tt>vcovHC()</tt>.</p></li>
</ol>
<p>The TSLS estimate for <span class="math inline">\(\beta_1\)</span> in <a href="ivr.html#eq:ecigstsls">(12.4)</a> suggests that an increase in cigarette prices by one percent reduces cigarette consumption by roughly <span class="math inline">\(1.08\)</span> percentage points, which is fairly elastic. However, we should keep in mind that this estimate might not be trustworthy even though we used IV estimation: there still might be a bias due to omitted variables. Thus a multiple IV regression approach is needed.</p>
</div>
</div>
<div id="TGIVRM" class="section level2">
<h2><span class="header-section-number">12.2</span> The General IV Regression Model</h2>
<p>The simple IV regression model is easily extended to a multiple regression model which we refer to as the general IV regression model. In this model we distinguish between four types of variables: the dependent variable, included exogenous variables, included endogenous variables and instrumental variables. Key Concept 12.1 summarizes the model and the common terminology. See Chapter 12.2 of the book for a more comprehensive discussion of the individual components of the general model.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 12.1
</h3>
<h3 class="left">
The General Instrumental Variables Regression Model and Terminology
</h3>
<span class="math display" id="eq:givmodel">\[\begin{align}
  Y_i = \beta_0 + \beta_1 X_{1i} + \dots + \beta_k X_{ki} + \beta_{k+1} W_{1i} + \dots + \beta_{k+r} W_{ri} + u_i, \tag{12.5}
\end{align}\]</span>
<p>with <span class="math inline">\(i=1,\dots,n\)</span> is the general instrumental variables regression model where</p>
<ul>
<li><p><span class="math inline">\(Y_i\)</span> is the dependent variable</p></li>
<li><p><span class="math inline">\(\beta_0,\dots,\beta_{k+1}\)</span> are <span class="math inline">\(1+k+r\)</span> unknown regression coefficients</p></li>
<li><p><span class="math inline">\(X_{1i},\dots,X_{ki}\)</span> are <span class="math inline">\(k\)</span> endogenous regressors</p></li>
<li><p><span class="math inline">\(W_{1i},\dots,W_{ri}\)</span> are <span class="math inline">\(r\)</span> exogenous regressors which are uncorrelated with <span class="math inline">\(u_i\)</span></p></li>
<li><p><span class="math inline">\(u_i\)</span> is the error term</p></li>
<li><p><span class="math inline">\(Z_{1i},\dots,Z_{mi}\)</span> are <span class="math inline">\(m\)</span> instrumental variables</p></li>
</ul>
<p>The coefficients are overidentified if <span class="math inline">\(m&gt;k\)</span>. If <span class="math inline">\(m&lt;k\)</span>, the coefficients are underidentified and when <span class="math inline">\(m=k\)</span> they are exactly identified. For estimation of the IV regression model we require exact identification or overidentification.</p>
</div>
<p>While computing both stages of TSLS individually is not a big deal in <a href="ivr.html#eq:srm12">(12.1)</a>, the simple regression model with a single endogenous regressor, Key Concept 12.2 clarifies why resorting to TSLS functions like <tt>ivreg()</tt> are more convenient when the set of potentially endogenous regressors (and instruments) is large.</p>
<p>Estimating regression models with TSLS using multiple instruments by means of <tt>ivreg()</tt> is straightforward. There are, however, some subtleties in correctly specifying the regression formula.</p>
<p>Assume that you want to estimate the model <span class="math display">\[Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + W_{1i} + u_i\]</span> where <span class="math inline">\(X_{1i}\)</span> and <span class="math inline">\(X_{2i}\)</span> are endogenous regressors that shall be instrumented by <span class="math inline">\(Z_{1i}\)</span>, <span class="math inline">\(Z_{2i}\)</span> and <span class="math inline">\(Z_{3i}\)</span> and <span class="math inline">\(W_{1i}\)</span> is an exogenous regressor. The corresponding data is available in a <tt>data.frame</tt> with column names <tt>y</tt>, <tt>x1</tt>, <tt>x1</tt>, <tt>w1</tt>, <tt>z1</tt>, <tt>z2</tt> and <tt>z3</tt>. It might be tempting to specify the argument <tt>formula</tt> in your call of <tt>ivreg()</tt> as <tt>y ~ x1 + x2 + w1 | z1 + z2 + z3</tt> which is wrong. As explained in the documentation of <tt>ivreg()</tt> (see <code>?ivreg</code>), it is necessary to list <em>all</em> exogenous variables as instruments too, that is joining them by <tt>+</tt>’s on the right of the vertical bar: <tt>y ~ x1 + x2 + w1 | w1 + z1 + z2 + z3</tt> where <tt>w1</tt> is “instrumenting itself”.</p>
<p>If there is a large number of exogenous variables it may be convenient to provide an update formula with a <tt>.</tt> (this includes all variables except for the dependent variable) right after the <tt>|</tt> and to exclude all endogenous variables using a <tt>-</tt>. For example, if there is one exogenous regressor <tt>w1</tt> and one endogenous regressor <tt>x1</tt> with instrument <tt>z1</tt>, the appropriate formula would be <tt>y ~ w1 + x1 | w1 + z1</tt> which is equivalent to <tt>y ~ w1 + x1 | . - x1 + z1</tt>.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 12.2
</h3>
<h3 class="left">
Two-Stage Least Squares
</h3>
<p>Similarly to the simple IV regression model, the general IV model <a href="ivr.html#eq:givmodel">(12.5)</a> can be estimated using the two-stage least squares estimator:</p>
<ol style="list-style-type: decimal">
<li><p><strong>First-stage regression(s)</strong></p>
<p>Run an OLS regression for each of the endogenous variables (<span class="math inline">\(X_{1i},\dots,X_{ki}\)</span>) on all instrumental variables (<span class="math inline">\(Z_{1i},\dots,Z_{mi}\)</span>), all exogenous variables (<span class="math inline">\(W_{1i},\dots,W_{ri}\)</span>) and an intercept. Compute the fitted values (<span class="math inline">\(\widehat{X}_{1i},\dots,\widehat{X}_{ki}\)</span>).</p></li>
<li><p><strong>Second-stage regression</strong></p>
Regress the dependent variable on the predicted values of all endogenous regressors, all exogenous variables and an intercept using OLS. This gives <span class="math inline">\(\widehat{\beta}_{0}^{TSLS},\dots,\widehat{\beta}_{k+r}^{TSLS}\)</span>, the TSLS estimates of the model coefficients.</li>
</ol>
</div>
<p>In the general IV regression model, the instrument relevance and instrument exogeneity assumptions are the same as in the simple regression model with a single endogenous regressor and only one instrument. See Key Concept 12.3 for a recap using the terminology of general IV regression.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 12.3
</h3>
<h3 class="left">
Two Conditions for Valid Instruments
</h3>
<p>For <span class="math inline">\(Z_{1i},\dots,Z_{mi}\)</span> to be a set of valid instruments, the following two conditions must be fulfilled:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Instrument Relevance</strong>:</p>
<p>if there are <span class="math inline">\(k\)</span> endogenous variables, <span class="math inline">\(r\)</span> exogenous variables and <span class="math inline">\(m\geq k\)</span> instruments <span class="math inline">\(Z\)</span> and the <span class="math inline">\(\widehat{X}_{1i}^*,\dots,\widehat{X}_{ki}^*\)</span> are the predicted values from the <span class="math inline">\(k\)</span> population first stage regressions, it must hold that <span class="math display">\[(\widehat{X}_{1i}^*,\dots,\widehat{X}_{ki}^*, W_{1i}, \dots, W_{ri},1)\]</span> are not perfectly multicollinear. <span class="math inline">\(1\)</span> denotes the constant regressor which equals <span class="math inline">\(1\)</span> for all observations.</p>
<p><em>Note</em>: If there is only one endogenous regressor <span class="math inline">\(X_i\)</span>, there must be at least one non-zero coefficient on the <span class="math inline">\(Z\)</span> and the <span class="math inline">\(W\)</span> in the population regression for this condition to be valid: if all of the coefficients are zero, all the <span class="math inline">\(\widehat{X}^*_i\)</span> are just the mean of <span class="math inline">\(X\)</span> such that there is perfect multicollinearity.</p></li>
<li><p><strong>Instrument Exogeneity</strong>:</p>
<p>All <span class="math inline">\(m\)</span> instruments must be uncorrelated with the error term,</p>
<p><span class="math display">\[\rho_{Z_{1i},u_i} = 0,\dots,\rho_{Z_{mi},u_i} = 0.\]</span></p></li>
</ol>
</div>
<p>One can show that if the IV regression assumptions presented in Key Concept 12.4 hold, the TSLS estimator in <a href="ivr.html#eq:givmodel">(12.5)</a> is consistent and normally distributed when the sample size is large. Appendix 12.3 of the book deals with a proof in the special case with a single regressor, a single instrument and no exogenous variables. The reasoning behind this carries over to the general IV model. Chapter 18 of the book proves a more complicated explanation for the general case.</p>
<p>For our purposes it is sufficient to bear in mind that validity of the assumptions stated in Key Concept 12.4 allows us to obtain valid statistical inference using <tt>R</tt> functions which compute <span class="math inline">\(t\)</span>-Tests, <span class="math inline">\(F\)</span>-Tests and confidence intervals for model coefficients.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 12.4
</h3>
<h3 class="left">
The IV Regression Assumptions
</h3>
<p>For the general IV regression model in Key Concept 12.1 we assume the following:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(E(u_i\vert W_{1i}, \dots, W_{ri}) = 0.\)</span></p></li>
<li><p><span class="math inline">\((X_{1i},\dots,X_{ki},W_{1i},\dots,W_{ri},Z_{1i},\dots,Z_{mi})\)</span> are i.i.d. draws from their joint distribution.</p></li>
<li><p>All variables have nonzero finite fourth moments, i.e., outliers are unlikely.</p></li>
<li><p>The <span class="math inline">\(Z\)</span>s are valid instruments (see Key Concept 12.3).</p></li>
</ol>
</div>
<div id="application-to-the-demand-for-cigarettes-1" class="section level4 unnumbered">
<h4>Application to the Demand for Cigarettes</h4>
<p>The estimated elasticity of the demand for cigarettes in <a href="ivr.html#eq:srm12">(12.1)</a> is <span class="math inline">\(1.08\)</span>. Although <a href="ivr.html#eq:srm12">(12.1)</a> was estimated using IV regression it is plausible that this IV estimate is biased: in this model, the TSLS estimator is inconsistent for the true <span class="math inline">\(\beta_1\)</span> if the instrument (the real sales tax per pack) correlates with the error term. This is likely to be the case since there are economic factors, like state income, which impact the demand for cigarettes and correlate with the sales tax. States with high personal income tend to generate tax revenues by income taxes and less by sales taxes. Consequently, state income should be included in the regression model.</p>
<span class="math display" id="eq:mcigstsls1">\[\begin{align}
  \log(Q_i^{cigarettes}) = \beta_0 + \beta_1 \log(P_i^{cigarettes}) + \beta_2 \log(income_i) + u_i \tag{12.6}
\end{align}\]</span>
<p>Before estimating <a href="ivr.html#eq:mcigstsls1">(12.6)</a> using <tt>ivreg()</tt> we define <span class="math inline">\(income\)</span> as real per capita income <tt>rincome</tt> and append it to the data set <tt>CigarettesSW</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># add rincome to the dataset</span>
CigarettesSW<span class="op">$</span>rincome &lt;-<span class="st"> </span><span class="kw">with</span>(CigarettesSW, income <span class="op">/</span><span class="st"> </span>population <span class="op">/</span><span class="st"> </span>cpi)

c1995 &lt;-<span class="st"> </span><span class="kw">subset</span>(CigarettesSW, year <span class="op">==</span><span class="st"> &quot;1995&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the model</span>
cig_ivreg2 &lt;-<span class="st"> </span><span class="kw">ivreg</span>(<span class="kw">log</span>(packs) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(rprice) <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(rincome) <span class="op">|</span><span class="st"> </span><span class="kw">log</span>(rincome) <span class="op">+</span><span class="st"> </span>
<span class="st">                    </span>salestax, <span class="dt">data =</span> c1995)

<span class="kw">coeftest</span>(cig_ivreg2, <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)   9.43066    1.25939  7.4883 1.935e-09 ***
## log(rprice)  -1.14338    0.37230 -3.0711  0.003611 ** 
## log(rincome)  0.21452    0.31175  0.6881  0.494917    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We obtain</p>
<span class="math display" id="eq:emcigstsls2">\[\begin{align}
  \widehat{\log(Q_i^{cigarettes})} = \underset{(1.26)}{9.42} - \underset{(0.37)}{1.14} \log(P_i^{cigarettes}) + \underset{(0.31)}{0.21} \log(income_i). \tag{12.7}
\end{align}\]</span>
<p>Following the book we add the cigarette-specific taxes (<span class="math inline">\(cigtax_i\)</span>) as a further instrumental variable and estimate again using TSLS.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># add cigtax to the data set</span>
CigarettesSW<span class="op">$</span>cigtax &lt;-<span class="st"> </span><span class="kw">with</span>(CigarettesSW, tax<span class="op">/</span>cpi)

c1995 &lt;-<span class="st"> </span><span class="kw">subset</span>(CigarettesSW, year <span class="op">==</span><span class="st"> &quot;1995&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the model</span>
cig_ivreg3 &lt;-<span class="st"> </span><span class="kw">ivreg</span>(<span class="kw">log</span>(packs) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(rprice) <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(rincome) <span class="op">|</span><span class="st"> </span>
<span class="st">                    </span><span class="kw">log</span>(rincome) <span class="op">+</span><span class="st"> </span>salestax <span class="op">+</span><span class="st"> </span>cigtax, <span class="dt">data =</span> c1995)

<span class="kw">coeftest</span>(cig_ivreg3, <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)   9.89496    0.95922 10.3157 1.947e-13 ***
## log(rprice)  -1.27742    0.24961 -5.1177 6.211e-06 ***
## log(rincome)  0.28040    0.25389  1.1044    0.2753    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Using the two instruments <span class="math inline">\(salestax_i\)</span> and <span class="math inline">\(cigtax_i\)</span> we have <span class="math inline">\(m=2\)</span> and <span class="math inline">\(k=1\)</span> so the coefficient on the endogenous regressor <span class="math inline">\(\log(P_i^{cigarettes})\)</span> is <em>overidentified</em>. The TSLS estimate of <a href="ivr.html#eq:mcigstsls1">(12.6)</a> is</p>
<span class="math display" id="eq:emcigstsls3">\[\begin{align}
  \widehat{\log(Q_i^{cigarettes})} = \underset{(0.96)}{9.89} - \underset{(0.25)}{1.28} \log(P_i^{cigarettes}) + \underset{(0.25)}{0.28} \log(income_i). \tag{12.8}
\end{align}\]</span>
<p>Should we trust the estimates presented in <a href="ivr.html#eq:emcigstsls2">(12.7)</a> or rather rely on <a href="ivr.html#eq:emcigstsls3">(12.8)</a>? The estimates obtained using both instruments are more precise since in <a href="ivr.html#eq:emcigstsls3">(12.8)</a> all standard errors reported are smaller than in <a href="ivr.html#eq:emcigstsls2">(12.7)</a>. In fact, the standard error for the estimate of the demand elasticity is only two thirds of the standard error when the sales tax is the only instrument used. This is due to more information being used in estimation <a href="ivr.html#eq:emcigstsls3">(12.8)</a>. <em>If</em> the instruments are valid, <a href="ivr.html#eq:emcigstsls3">(12.8)</a> can be considered more reliable.</p>
<p>However, without insights regarding the validity of the instruments it is not sensible to make such a statement. This stresses why checking instrument validity is essential. Chapter <a href="ivr.html#civ">12.3</a> briefly discusses guidelines in checking instrument validity and presents approaches that allow to test for instrument relevance and exogeneity under certain conditions. These are then used in an application to the demand for cigarettes in Chapter <a href="ivr.html#attdfc">12.4</a>.</p>
</div>
</div>
<div id="civ" class="section level2">
<h2><span class="header-section-number">12.3</span> Checking Instrument Validity</h2>
<div id="instrument-relevance" class="section level4 unnumbered">
<h4>Instrument Relevance</h4>
<p>Instruments that explain little variation in the endogenous regressor <span class="math inline">\(X\)</span> are called <em>weak instruments</em>. Weak instruments provide little information about the variation in <span class="math inline">\(X\)</span> that is exploited by IV regression to estimate the effect of interest: the estimate of the coefficient on the endogenous regressor is estimated inaccurately. Moreover, weak instruments cause the distribution of the estimator to deviate considerably from a normal distribution even in large samples such that the usual methods for obtaining inference about the true coefficient on <span class="math inline">\(X\)</span> may produce wrong results. See Chapter 12.3 and Appendix 12.4 of the book for a more detailed argument on the undesirable consequences of using weak instruments in IV regression.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 12.5
</h3>
<h3 class="left">
A Rule of Thumb for Checking for Weak Instruments
</h3>
<p>Consider the case of a single endogenous regressor <span class="math inline">\(X\)</span> and <span class="math inline">\(m\)</span> instruments <span class="math inline">\(Z_1,\dots,Z_m\)</span>. If the coefficients on all instruments in the population first-stage regression of a TSLS estimation are zero, the instruments do not explain any of the variation in the <span class="math inline">\(X\)</span> which clearly violates assumption 1 of Key Concept 12.2. Although the latter case is unlikely to be encountered in practice, we should ask ourselves “to what extent” the assumption of instrument relevance should be fulfilled.</p>
<p>While this is hard to answer for general IV regression, in the case of a <em>single</em> endogenous regressor <span class="math inline">\(X\)</span> one may use the following rule of thumb:</p>
<p>Compute the <span class="math inline">\(F\)</span>-statistic which corresponds to the hypothesis that the coefficients on <span class="math inline">\(Z_1,\dots,Z_m\)</span> are all zero in the first-stage regression. If the <span class="math inline">\(F\)</span>-statistic is less than <span class="math inline">\(10\)</span>, the instruments are weak such that the TSLS estimate of the coefficient on <span class="math inline">\(X\)</span> is biased and no valid statistical inference about its true value can be made. See also Appendix 12.5 of the book.</p>
</div>
<p>The rule of thumb of Key Concept 12.5 is easily implemented in <tt>R</tt>. Run the first-stage regression using <tt>lm()</tt> and subsequently compute the heteroskedasticity-robust <span class="math inline">\(F\)</span>-statistic by means of <tt>linearHypothesis()</tt>. This is part of the application to the demand for cigarettes discussed in Chapter <a href="ivr.html#attdfc">12.4</a>.</p>
</div>
<div id="if-instruments-are-weak" class="section level4 unnumbered">
<h4>If Instruments are Weak</h4>
<p>There are two ways to proceed if instruments are weak:</p>
<ol style="list-style-type: decimal">
<li><p>Discard the weak instruments and/or find stronger instruments. While the former is only an option if the unknown coefficients remain identified when the weak instruments are discarded, the latter can be very difficult and even may require a redesign of the whole study.</p></li>
<li><p>Stick with the weak instruments but use methods that improve upon TSLS in this scenario, for example limited information maximum likelihood estimation, see Appendix 12.5 of the book.</p></li>
</ol>
</div>
<div id="when-the-assumption-of-instrument-exogeneity-is-violated" class="section level4 unnumbered">
<h4>When the Assumption of Instrument Exogeneity is Violated</h4>
<p>If there is correlation between an instrument and the error term, IV regression is not consistent (this is shown in Appendix 12.4 of the book). The overidentifying restrictions test (also called the <span class="math inline">\(J\)</span>-test) is an approach to test the hypothesis that <em>additional</em> instruments are exogenous. For the <span class="math inline">\(J\)</span>-test to be applicable there need to be <em>more</em> instruments than endogenous regressors. The <span class="math inline">\(J\)</span>-test is summarized in Key Concept 12.5.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 12.6
</h3>
<h3 class="left">
<span class="math inline">\(J\)</span>-Statistic / Overidentifying Restrictions Test
</h3>
<p>Take <span class="math inline">\(\widehat{u}_i^{TSLS} \ , \ i = 1,\dots,n\)</span>, the residuals of the TSLS estimation of the general IV regression model <a href="ivr.html#eq:givmodel">(12.5)</a>. Run the OLS regression</p>
<span class="math display" id="eq:jstatreg">\[\begin{align}
  \widehat{u}_i^{TSLS} =&amp; \, \delta_0 + \delta_1 Z_{1i} + \dots + \delta_m Z_{mi} + \delta_{m+1} W_{1i} + \dots + \delta_{m+r} W_{ri} + e_i \tag{12.9}
\end{align}\]</span>
<p>and test the joint hypothesis <span class="math display">\[H_0: \delta_1 = 0, \dots, \delta_{m} = 0\]</span> which states that all instruments are exogenous. This can be done using the corresponding <span class="math inline">\(F\)</span>-statistic by computing <span class="math display">\[J = mF.\]</span> This test is the overidentifying restrictions test and the statistic is called the <span class="math inline">\(J\)</span>-statistic with <span class="math display">\[J \sim \chi^2_{m-k}\]</span> in large samples under the null and the assumption of homoskedasticity. The degrees of freedom <span class="math inline">\(m-k\)</span> state the degree of overidentification since this is the number of instruments <span class="math inline">\(m\)</span> minus the number of endogenous regressors <span class="math inline">\(k\)</span>.</p>
</div>
<p>It is important to note that the <span class="math inline">\(J\)</span>-statistic discussed in Key Concept 12.6 is only <span class="math inline">\(\chi^2_{m-k}\)</span> distributed when the error term <span class="math inline">\(e_i\)</span> in the regression <a href="ivr.html#eq:jstatreg">(12.9)</a> is homoskedastic. A discussion of the heteroskedasticity-robust <span class="math inline">\(J\)</span>-statistic is beyond the scope of this chapter. We refer to Section 18.7 of the book for a theoretical argument.</p>
<p>As for the procedure shown in Key Concept 12.6, the application in the next section shows how to apply the <span class="math inline">\(J\)</span>-test using <tt>linearHypothesis()</tt>.</p>
</div>
</div>
<div id="attdfc" class="section level2">
<h2><span class="header-section-number">12.4</span> Application to the Demand for Cigarettes</h2>
<p>Are the general sales tax and the cigarette-specific tax valid instruments? If not, TSLS is not helpful to estimate the demand elasticity for cigarettes discussed in Chapter <a href="ivr.html#TGIVRM">12.2</a>. As discussed in Chapter <a href="ivr.html#TIVEWASRAASI">12.1</a>, both variables are likely to be relevant but whether they are exogenous is a different question.</p>
<p>The book argues that cigarette-specific taxes could be endogenous because there might be state specific historical factors like economic importance of the tobacco farming and cigarette production industry that lobby for low cigarette specific taxes. Since it is plausible that tobacco growing states have higher rates of smoking than others, this would lead to endogeneity of cigarette specific taxes. If we had data on the size on the tobacco and cigarette industry, we could solve this potential issue by including the information in the regression. Unfortunately, this is not the case.</p>
<p>However, since the role of the tobacco and cigarette industry is a factor that can be assumed to differ across states but not over time we may exploit the panel structure of <tt>CigarettesSW</tt> instead: as shown in Chapter <a href="rwpd.html#PDWTTP">10.2</a>, regression using data on <em>changes</em> between two time periods eliminates such state specific and time invariant effects. Following the book we consider changes in variables between 1985 and 1995. That is, we are interested in estimating the <em>long-run elasticity</em> of the demand for cigarettes.</p>
<p>The model to be estimated by TSLS using the general sales tax and the cigarette-specific sales tax as instruments hence is</p>
<span class="math display" id="eq:diffivreg">\[\begin{align}
\begin{split}
  \log(Q_{i,1995}^{cigarettes}) - \log(Q_{i,1995}^{cigarettes}) =&amp; \, \beta_0 + \beta_1 \left[\log(P_{i,1995}^{cigarettes}) - \log(P_{i,1985}^{cigarettes}) \right] \\ &amp;+ \beta_2 \left[\log(income_{i,1995}) - \log(income_{i,1985})\right] + u_i. \end{split}\tag{12.10}
\end{align}\]</span>
<p>We first create differences from 1985 to 1995 for the dependent variable, the regressors and both instruments.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># subset data for year 1985</span>
c1985 &lt;-<span class="st"> </span><span class="kw">subset</span>(CigarettesSW, year <span class="op">==</span><span class="st"> &quot;1985&quot;</span>)

<span class="co"># define differences in variables</span>
packsdiff &lt;-<span class="st"> </span><span class="kw">log</span>(c1995<span class="op">$</span>packs) <span class="op">-</span><span class="st"> </span><span class="kw">log</span>(c1985<span class="op">$</span>packs)

pricediff &lt;-<span class="st"> </span><span class="kw">log</span>(c1995<span class="op">$</span>price<span class="op">/</span>c1995<span class="op">$</span>cpi) <span class="op">-</span><span class="st"> </span><span class="kw">log</span>(c1985<span class="op">$</span>price<span class="op">/</span>c1985<span class="op">$</span>cpi)

incomediff &lt;-<span class="st"> </span><span class="kw">log</span>(c1995<span class="op">$</span>income<span class="op">/</span>c1995<span class="op">$</span>population<span class="op">/</span>c1995<span class="op">$</span>cpi) <span class="op">-</span>
<span class="kw">log</span>(c1985<span class="op">$</span>income<span class="op">/</span>c1985<span class="op">$</span>population<span class="op">/</span>c1985<span class="op">$</span>cpi)

salestaxdiff &lt;-<span class="st"> </span>(c1995<span class="op">$</span>taxs <span class="op">-</span><span class="st"> </span>c1995<span class="op">$</span>tax)<span class="op">/</span>c1995<span class="op">$</span>cpi <span class="op">-</span><span class="st"> </span>(c1985<span class="op">$</span>taxs <span class="op">-</span><span class="st"> </span>c1985<span class="op">$</span>tax)<span class="op">/</span>c1985<span class="op">$</span>cpi

cigtaxdiff &lt;-<span class="st"> </span>c1995<span class="op">$</span>tax<span class="op">/</span>c1995<span class="op">$</span>cpi <span class="op">-</span><span class="st"> </span>c1985<span class="op">$</span>tax<span class="op">/</span>c1985<span class="op">$</span>cpi</code></pre></div>
<p>We now perform three different IV estimations of <a href="ivr.html#eq:diffivreg">(12.10)</a> using <tt>ivreg()</tt>:</p>
<ol style="list-style-type: decimal">
<li><p>TSLS using only the difference in the sales taxes between 1985 and 1995 as the instrument.</p></li>
<li><p>TSLS using only the difference in the cigarette-specific sales taxes 1985 and 1995 as the instrument.</p></li>
<li><p>TSLS using both the difference in the sales taxes 1985 and 1995 and the difference in the cigarette-specific sales taxes 1985 and 1995 as instruments.</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the three models</span>
cig_ivreg_diff1 &lt;-<span class="st"> </span><span class="kw">ivreg</span>(packsdiff <span class="op">~</span><span class="st"> </span>pricediff <span class="op">+</span><span class="st"> </span>incomediff <span class="op">|</span><span class="st"> </span>incomediff <span class="op">+</span><span class="st"> </span>
<span class="st">                         </span>salestaxdiff)

cig_ivreg_diff2 &lt;-<span class="st"> </span><span class="kw">ivreg</span>(packsdiff <span class="op">~</span><span class="st"> </span>pricediff <span class="op">+</span><span class="st"> </span>incomediff <span class="op">|</span><span class="st"> </span>incomediff <span class="op">+</span><span class="st"> </span>
<span class="st">                         </span>cigtaxdiff)

cig_ivreg_diff3 &lt;-<span class="st"> </span><span class="kw">ivreg</span>(packsdiff <span class="op">~</span><span class="st"> </span>pricediff <span class="op">+</span><span class="st"> </span>incomediff <span class="op">|</span><span class="st"> </span>incomediff <span class="op">+</span><span class="st"> </span>
<span class="st">                         </span>salestaxdiff <span class="op">+</span><span class="st"> </span>cigtaxdiff)</code></pre></div>
<p>As usual we use <tt>coeftest()</tt> in conjunction with <tt>vcovHC()</tt> to obtain robust coefficient summaries for all models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># robust coefficient summary for 1.</span>
<span class="kw">coeftest</span>(cig_ivreg_diff1, <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -0.117962   0.068217 -1.7292   0.09062 .  
## pricediff   -0.938014   0.207502 -4.5205 4.454e-05 ***
## incomediff   0.525970   0.339494  1.5493   0.12832    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># robust coefficient summary for 2.</span>
<span class="kw">coeftest</span>(cig_ivreg_diff2, <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -0.017049   0.067217 -0.2536    0.8009    
## pricediff   -1.342515   0.228661 -5.8712 4.848e-07 ***
## incomediff   0.428146   0.298718  1.4333    0.1587    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># robust coefficient summary for 3.</span>
<span class="kw">coeftest</span>(cig_ivreg_diff3, <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) -0.052003   0.062488 -0.8322    0.4097    
## pricediff   -1.202403   0.196943 -6.1053 2.178e-07 ***
## incomediff   0.462030   0.309341  1.4936    0.1423    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We proceed by generating a tabulated summary of the estimation results using <tt>stargazer()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># gather robust standard errors in a list</span>
rob_se &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">vcovHC</span>(cig_ivreg_diff1, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))),
               <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">vcovHC</span>(cig_ivreg_diff2, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))),
               <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">vcovHC</span>(cig_ivreg_diff3, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))))

<span class="co"># generate table</span>
<span class="kw">stargazer</span>(cig_ivreg_diff1, cig_ivreg_diff2,cig_ivreg_diff3,
  <span class="dt">header =</span> <span class="ot">FALSE</span>, 
  <span class="dt">type =</span> <span class="st">&quot;html&quot;</span>,
  <span class="dt">omit.table.layout =</span> <span class="st">&quot;n&quot;</span>,
  <span class="dt">digits =</span> <span class="dv">3</span>, 
  <span class="dt">column.labels =</span> <span class="kw">c</span>(<span class="st">&quot;IV: salestax&quot;</span>, <span class="st">&quot;IV: cigtax&quot;</span>, <span class="st">&quot;IVs: salestax, cigtax&quot;</span>),
  <span class="dt">dep.var.labels.include =</span> <span class="ot">FALSE</span>,
  <span class="dt">dep.var.caption =</span> <span class="st">&quot;Dependent Variable: 1985-1995 Difference in Log per Pack Price&quot;</span>,
  <span class="dt">se =</span> rob_se)</code></pre></div>



<table style="text-align:center"><tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"></td><td colspan="3">Dependent variable: 1985-1995 difference in log per pack price</td></tr>
<tr><td></td><td colspan="3" style="border-bottom: 1px solid black"></td></tr>
<tr><td style="text-align:left"></td><td>IV: salestax</td><td>IV: cigtax</td><td>IVs: salestax, cigtax</td></tr>
<tr><td style="text-align:left"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>
<tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">pricediff</td><td>-0.938<sup>***</sup></td><td>-1.343<sup>***</sup></td><td>-1.202<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.208)</td><td>(0.229)</td><td>(0.197)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">incomediff</td><td>0.526</td><td>0.428</td><td>0.462</td></tr>
<tr><td style="text-align:left"></td><td>(0.339)</td><td>(0.299)</td><td>(0.309)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">Constant</td><td>-0.118<sup>*</sup></td><td>-0.017</td><td>-0.052</td></tr>
<tr><td style="text-align:left"></td><td>(0.068)</td><td>(0.067)</td><td>(0.062)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td></tr>
<tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">Observations</td><td>48</td><td>48</td><td>48</td></tr>
<tr><td style="text-align:left">R<sup>2</sup></td><td>0.550</td><td>0.520</td><td>0.547</td></tr>
<tr><td style="text-align:left">Adjusted R<sup>2</sup></td><td>0.530</td><td>0.498</td><td>0.526</td></tr>
<tr><td style="text-align:left">Residual Std. Error (df = 45)</td><td>0.091</td><td>0.094</td><td>0.091</td></tr>
<tr><td colspan="4" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"><em>Note:</em></td><td colspan="3" style="text-align:right"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>
</table>
<caption><p style='text-align:center'><span id="tab:tslseotlteotdfcupd">Table 12.1: </span> TSLS Estimates of the Long-Term Elasticity of the Demand for Cigarettes using Panel Data</p></caption>


<p>Table <a href="ivr.html#tab:tslseotlteotdfcupd">12.1</a> reports negative estimates of the coefficient on <tt>pricediff</tt> that are quite different in magnitude. Which one should we trust? This hinges on the validity of the instruments used. To assess this we compute <span class="math inline">\(F\)</span>-statistics for the first-stage regressions of all three models to check instrument relevance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># first-stage regressions</span>
mod_relevance1 &lt;-<span class="st"> </span><span class="kw">lm</span>(pricediff <span class="op">~</span><span class="st"> </span>salestaxdiff <span class="op">+</span><span class="st"> </span>incomediff)
mod_relevance2 &lt;-<span class="st"> </span><span class="kw">lm</span>(pricediff <span class="op">~</span><span class="st"> </span>cigtaxdiff <span class="op">+</span><span class="st"> </span>incomediff)
mod_relevance3 &lt;-<span class="st"> </span><span class="kw">lm</span>(pricediff <span class="op">~</span><span class="st"> </span>incomediff <span class="op">+</span><span class="st"> </span>salestaxdiff <span class="op">+</span><span class="st"> </span>cigtaxdiff)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># check instrument relevance for model (1)</span>
<span class="kw">linearHypothesis</span>(mod_relevance1, 
                 <span class="st">&quot;salestaxdiff = 0&quot;</span>, 
                 <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## salestaxdiff = 0
## 
## Model 1: restricted model
## Model 2: pricediff ~ salestaxdiff + incomediff
## 
## Note: Coefficient covariance matrix supplied.
## 
##   Res.Df Df      F    Pr(&gt;F)    
## 1     46                        
## 2     45  1 28.445 3.009e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># check instrument relevance for model (2)</span>
<span class="kw">linearHypothesis</span>(mod_relevance2, 
                 <span class="st">&quot;cigtaxdiff = 0&quot;</span>, 
                 <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## cigtaxdiff = 0
## 
## Model 1: restricted model
## Model 2: pricediff ~ cigtaxdiff + incomediff
## 
## Note: Coefficient covariance matrix supplied.
## 
##   Res.Df Df      F   Pr(&gt;F)    
## 1     46                       
## 2     45  1 98.034 7.09e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># check instrument relevance for model (3)</span>
<span class="kw">linearHypothesis</span>(mod_relevance3, 
                 <span class="kw">c</span>(<span class="st">&quot;salestaxdiff = 0&quot;</span>, <span class="st">&quot;cigtaxdiff = 0&quot;</span>), 
                 <span class="dt">vcov =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## salestaxdiff = 0
## cigtaxdiff = 0
## 
## Model 1: restricted model
## Model 2: pricediff ~ incomediff + salestaxdiff + cigtaxdiff
## 
## Note: Coefficient covariance matrix supplied.
## 
##   Res.Df Df      F    Pr(&gt;F)    
## 1     46                        
## 2     44  2 76.916 4.339e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We also conduct the overidentifying restrictions test for model three which is the only model where the coefficient on the difference in log prices is overidentified (<span class="math inline">\(m=2\)</span>, <span class="math inline">\(k=1\)</span>) such that the <span class="math inline">\(J\)</span>-statistic can be computed. To do this we take the residuals stored in <tt>cig_ivreg_diff3</tt> and regress them on both instruments and the presumably exogenous regressor <tt>incomediff</tt>. We again use <tt>linearHypothesis()</tt> to test whether the coefficients on both instruments are zero which is necessary for the exogeneity assumption to be fulfilled. Note that with <tt>test = “Chisq”</tt> we obtain a chi-squared distributed test statistic instead of an <span class="math inline">\(F\)</span>-statistic.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute the J-statistic</span>
cig_iv_OR &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">residuals</span>(cig_ivreg_diff3) <span class="op">~</span><span class="st"> </span>incomediff <span class="op">+</span><span class="st"> </span>salestaxdiff <span class="op">+</span><span class="st"> </span>cigtaxdiff)

cig_OR_test &lt;-<span class="st"> </span><span class="kw">linearHypothesis</span>(cig_iv_OR, 
                               <span class="kw">c</span>(<span class="st">&quot;salestaxdiff = 0&quot;</span>, <span class="st">&quot;cigtaxdiff = 0&quot;</span>), 
                               <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)
cig_OR_test</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## salestaxdiff = 0
## cigtaxdiff = 0
## 
## Model 1: restricted model
## Model 2: residuals(cig_ivreg_diff3) ~ incomediff + salestaxdiff + cigtaxdiff
## 
##   Res.Df     RSS Df Sum of Sq Chisq Pr(&gt;Chisq)  
## 1     46 0.37472                                
## 2     44 0.33695  2  0.037769 4.932    0.08492 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><strong>Caution</strong>: In this case the <span class="math inline">\(p\)</span>-Value reported by <tt>linearHypothesis()</tt> is wrong because the degrees of freedom are set to <span class="math inline">\(2\)</span>. This differs from the degree of overidentification (<span class="math inline">\(m-k=2-1=1\)</span>) so the <span class="math inline">\(J\)</span>-statistic is <span class="math inline">\(\chi^2_1\)</span> distributed instead of following a <span class="math inline">\(\chi^2_2\)</span> distribution as assumed defaultly by <tt>linearHypothesis()</tt>. We may compute the correct <span class="math inline">\(p\)</span>-Value using <tt>pchisq()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute correct p-value for J-statistic</span>
<span class="kw">pchisq</span>(cig_OR_test[<span class="dv">2</span>, <span class="dv">5</span>], <span class="dt">df =</span> <span class="dv">1</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## [1] 0.02636406</code></pre>
<p>Since this value is smaller than <span class="math inline">\(0.05\)</span> we reject the hypothesis that both instruments are exogenous at the level of <span class="math inline">\(5\%\)</span>. This means one of the following:</p>
<ol style="list-style-type: decimal">
<li>The sales tax is an invalid instrument for the per-pack price.</li>
<li>The cigarettes-specific sales tax is an invalid instrument for the per-pack price.</li>
<li>Both instruments are invalid.</li>
</ol>
<p>The book argues that the assumption of instrument exogeneity is more likely to hold for the general sales tax (see Chapter 12.4 of the book) such that the IV estimate of the long-run elasticity of demand for cigarettes we consider the most trustworthy is <span class="math inline">\(-0.94\)</span>, the TSLS estimate obtained using the general sales tax as the only instrument.</p>
<p>The interpretation of this estimate is that over a 10-year period, an increase in the average price per package by one percent is expected to decrease consumption by about <span class="math inline">\(0.94\)</span> percentage points. This suggests that, in the long run, price increases can reduce cigarette consumption considerably.</p>
</div>
<div id="where-do-valid-instruments-come-from" class="section level2">
<h2><span class="header-section-number">12.5</span> Where Do Valid Instruments Come From?</h2>
<p>Chapter 12.5 of the book presents a comprehensive discussion of approaches to find valid instruments in practice by the example of three research questions:</p>
<ul>
<li>Does putting criminals in jail reduce crime?</li>
<li>Does cutting class sizes increase test scores?</li>
<li>Does aggressive treatment of heart attacks prolong lives?</li>
</ul>
<p>This section is not directly related to applications in <tt>R</tt> which is why we do not discuss the contents here. We encourage you to work through this on your own.</p>
<div id="summary-4" class="section level4 unnumbered">
<h4>Summary</h4>
<p><tt>ivreg()</tt> from the package <tt>AER</tt> provides convenient functionalities to estimate IV regression models in <tt>R</tt>. It is an implementation of the TSLS estimation approach.</p>
<p>Besides treating IV estimation, we have also discussed how to test for weak instruments and how to conduct an overidentifying restrictions test when there are more instruments than endogenous regressors using <tt>R</tt>.</p>
<p>An empirical application has shown how <tt>ivreg()</tt> can be used to estimate the long-run elasticity of demand for cigarettes based on <tt>CigarettesSW</tt>, a panel data set on cigarette consumption and economic indicators for all 48 continental U.S. states for 1985 and 1995. Different sets of instruments were used and it has been argued why using the general sales tax as the only instrument is the preferred choice. The estimate of the demand elasticity deemed the most trustworthy is <span class="math inline">\(-0.94\)</span>. This estimate suggests that there is a remarkable negative long-run effect on cigarette consumption of increasing prices.</p>
</div>
</div>
<div id="exercises-9" class="section level2">
<h2><span class="header-section-number">12.6</span> Exercises</h2>
<div class="DCexercise">
<h4 id="the-college-distance-data" class="unnumbered">1. The College Distance Data</h4>
<p>There are many studies in labor economics which deal with the issue of estimating human capital earnings functions which state how wage income is determined by education and working experience. A prominent example is <span class="citation">Card (<a href="#ref-card1993">1993</a>)</span> who investigates the economic return to schooling and uses college proximity as an instrumental variable.</p>
<p>The exercises in this chapter deal with the dataset <tt>CollegeDistance</tt> which is similar to the data used by <span class="citation">Card (<a href="#ref-card1993">1993</a>)</span>. It stems from a survey of high school graduates with variables coded for wages, education, average tuition and a number of socio-economic measures. The data set also includes the distance from a college while the survey participants were in high school. <tt>CollegeDistance</tt> comes with the <tt>AER</tt> package.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Attach the <tt>AER</tt> package and load the <tt>CollegeDistance</tt> data.</p></li>
<li><p>Get an overview over the data set.</p></li>
<li><p>The variable <tt>distance</tt> (the distance to the closest 4-year college in 10 miles) will serve as an instrument in later exercises. Use a histogram to visualize the distribution of <tt>distance</tt>.</p></li>
</ul>
<iframe src="DCL/ex12_1.html" frameborder="0" scrolling="no" style="width:100%;height:330px">
</iframe>
<p><strong>Hints:</strong></p>
<ul>
<li><p>Use <tt>data()</tt> to attach the data set.</p></li>
<li><p>The function <tt>hist()</tt> can be used to generate histograms.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="the-selection-problem" class="unnumbered">2. The Selection Problem</h4>
<p>Regressing <tt>wage</tt> on <tt>education</tt> and control variables to estimate the human capital earnings function is problematic because education is not randomly assigned across the surveyed: individuals make their own education choices and so measured differences in earnings between individuals with different levels of education depend on how these choices are made. In the literature this is referred to as a <em>selection problem</em>. This selection problem implies that <tt>education</tt> is <em>endogenous</em> so the OLS estimate will be biased and we cannot make valid inference regarding the true coefficient.</p>
<p>In this exercise you are asked to estimate two regressions which both do not yield trustworthy estimates of the coefficient on education due to the issue sketched above. Later you will compare the results to those obtained using the instrumental variables approach applied by <span class="citation">Card (<a href="#ref-card1993">1993</a>)</span>.</p>
<p>The <tt>AER</tt> package has been attached. The data set <tt>CollegeDistance</tt> is available in your global environment.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Regress the <em>logarithm</em> of <tt>wage</tt> on <tt>education</tt>, that is, estimate the model <span class="math display">\[\log(wage_i) = \beta_0 + \beta_1 education_i + u_i\]</span> Save the result to <tt>wage_mod_1</tt>.</p></li>
<li><p>Augment the model by including the regressors <tt>unemp</tt>, <tt>hispanic</tt>, <tt>af-am</tt>, <tt>female</tt> and <tt>urban</tt>. Save the result to <tt>wage_mod_2</tt></p></li>
<li><p>Obtain summaries on the estimated coefficients in both models.</p></li>
</ul>
<iframe src="DCL/ex12_2.html" frameborder="0" scrolling="no" style="width:100%;height:330px">
</iframe>
</div>
<div class="DCexercise">
<h4 id="instrumental-variables-regression-approaches-i" class="unnumbered">3. Instrumental Variables Regression Approaches — I</h4>
<p>The above discussed selection problem renders the regression estimates in Exercise 2 implausible which is why <span class="citation">Card (<a href="#ref-card1993">1993</a>)</span> suggests instrumental variables regression that uses college distance as an instrument for education.</p>
<p>Why use college distance as an instrument? The logic behind this is that distance from a college will be correlated to the decision to pursue a college degree (relevance) but may not predict wages apart from increased education (exogeneity) so college proximity could be considered a valid instrument (recall the definition of a valid instrument stated at the beginning of Chapter <a href="ivr.html#TIVEWASRAASI">12.1</a>).</p>
<p>The <tt>AER</tt> package has been attached. The data set <tt>CollegeDistance</tt> is available in your global environment.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Compute the correlations of the instrument <tt>distance</tt> with the edogenous regressor <tt>education</tt> and the dependent variable <tt>wage</tt>.</p></li>
<li><p>How much of the variation in <tt>education</tt> is explained by the <em>first-stage regression</em> which uses <tt>distance</tt> as a regressor? Save the result to <tt>R2</tt>.</p></li>
<li><p>Repeat Exercise 2 with IV regression, i.e., employ <tt>distance</tt> as an instrument for <tt>education</tt> in both regressions using <tt>ivreg()</tt>. Save the results to <tt>wage_mod_iv1</tt> and <tt>wage_mod_iv2</tt>. Obtain robust coefficient summaries for both models.</p></li>
</ul>
<iframe src="DCL/ex12_3.html" frameborder="0" scrolling="no" style="width:100%;height:410px">
</iframe>
</div>
<div class="DCexercise">
<h4 id="instrumental-variables-regression-approaches-ii" class="unnumbered">4. Instrumental Variables Regression Approaches — II</h4>
<p>Convince yourself that <tt>ivreg()</tt> works as expected by implementing the TSLS algorithm presented in Key Concept 12.2 for a single instrument, see Chapter <a href="ivr.html#TGIVRM">12.2</a>.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Complete the function <tt>TSLS()</tt> such that it implements the TSLS estimator.</p></li>
<li><p>Use <tt>TSLS()</tt> to reproduce the coefficient estimates obtained using <tt>ivreg()</tt> for both models of Exercise 3.</p></li>
</ul>
<iframe src="DCL/ex12_4.html" frameborder="0" scrolling="no" style="width:100%;height:460px">
</iframe>
<p><strong>Hints:</strong></p>
<ul>
<li><p>Completion of the function boils down to replacing the <tt>. . .</tt> by appropriate arguments.</p></li>
<li>Besides the data set (<tt>data</tt>), the function expects the dependent variable (<tt>Y</tt>), exogenous regressors (<tt>W</tt>), the endogenous regressors (<tt>X</tt>) and an instrument (<tt>Z</tt>) as arguments. All of these should be of class <tt>character</tt>.</li>
<li><p>Including <tt>W = NULL</tt> in the head of the function definition ensures that the set of exogenous variables is empty, by default.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="should-we-trust-the-results" class="unnumbered">5. Should we trust the Results?</h4>
<p>This is not a real code exercise (there are no submission correctness tests for checking your code). Instead we would like you to use the widget below to compare the results obtained using the OLS regressions of Exercise 2 with those of the IV regressions of Exercise 3.</p>
<p>The data set <tt>CollegeDistance</tt> and all model objects from Exercises 2 and 3 are available in the global environment.</p>
<p><strong>Instructions:</strong></p>
<p>Convince yourself of the following:</p>
<ol style="list-style-type: decimal">
<li><p>It is likely that the bias of the estimated coefficient on <tt>education</tt> in the simple regression model <tt>wage_mod_1</tt> is subtantial because the regressor is endogenous due to omitting variables from the model which correlate with <tt>education</tt> and impact wage income.</p></li>
<li><p>Due to the selection problem in described in Exercise 2, the estimate of the coefficient of interest is not trustworthy even in the multiple regression model <tt>wage_mod_2</tt> which includes several socio-economic control variables. The coeffiecient on <tt>education</tt> is not significant and its estimate is close to zero).</p></li>
<li><p>Instrumenting education by the college distance as done in <tt>wage_mod_iv1</tt> yields the IV estimate of the coefficient of interest. The result should, however, not be considered reliable because this simple model probably suffers from omitted variables bias just as the multiple regression model <tt>wage_mod_2</tt> from Exercise 2, see 1. Again, the coeffiecient on <tt>education</tt> is not significant its estimate is quite small.</p></li>
<li><p><tt>wage_mod_iv2</tt>, the multiple regression model where we include demographic control variables and instrumend <tt>education</tt> by <tt>distance</tt> delivers the most reliable estimate of the impact of education on wage income among all the models considered. The coefficient is highly significant and the estimate is about <span class="math inline">\(0.067\)</span>. Following Key Concept 8.2, the interpretation is that an additional year of schooling is expected to increases wage income by roughly <span class="math inline">\(0.067 \cdot 100\% = 6.7\%\)</span>.</p></li>
<li><p>Is the estimate of the coefficient on education reported by <tt>wage_mod_iv2</tt> trustworthy? This question is not easy to answer. In any case, we should bear in mind that using an instrumental variables approach is problematic when the instrument is <em>weak</em>. This could be the case here: Families with strong preference for education may move into neighborhoods close to colleges. Furthermore, neighborhoods close to colleges may have stronger job markets reflected by higher incomes. Such features would render the instrument invalid as they introduce unobserved variables which influence earnings but cannot be captured by years of schooling, our measure of education.</p></li>
</ol>
<iframe src="DCL/ex12_5.html" frameborder="0" scrolling="no" style="width:100%;height:340px">
</iframe>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-AER">
<p>Kleiber, C., &amp; Zeileis, A. (2017). AER: Applied Econometrics with R (Version 1.2-5). Retrieved from <a href="https://CRAN.R-project.org/package=AER" class="uri">https://CRAN.R-project.org/package=AER</a></p>
</div>
<div id="ref-R-stargazer">
<p>Hlavac, M. (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables (Version 5.2.2). Retrieved from <a href="https://CRAN.R-project.org/package=stargazer" class="uri">https://CRAN.R-project.org/package=stargazer</a></p>
</div>
<div id="ref-card1993">
<p>Card, D. (1993). <em>Using geographic variation in college proximity to estimate the return to schooling</em>. National Bureau of Economic Research.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rwabdv.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="eaqe.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": true,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 1
},
"edit": null,
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
