<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Econometrics with R</title>
  <meta name="description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programing and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Econometrics with R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programing and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Econometrics with R" />
  
  <meta name="twitter:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programing and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2018-10-05">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="rmwmr.html">
<link rel="next" href="nrf.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>
<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">

<!-- function to adjust height of iframes automatically depending on content loaded -->

<script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>

<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/default.js"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://www.oek.wiwi.uni-due.de/en/">Chair of Econometrics at UDE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#a-very-short-introduction-to-r-and-rstudio"><i class="fa fa-check"></i><b>1.1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="2.1" data-path="pt.html"><a href="pt.html#random-variables-and-probability-distributions"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pt.html"><a href="pt.html#RSATDOSA"><i class="fa fa-check"></i><b>2.2</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="pt.html"><a href="pt.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pt.html"><a href="pt.html#exercises"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="arosur.html"><a href="arosur.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="3.1" data-path="arosur.html"><a href="arosur.html#estimation-of-the-population-mean"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="arosur.html"><a href="arosur.html#potsm"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="arosur.html"><a href="arosur.html#hypothesis-tests-concerning-the-population-mean"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="arosur.html"><a href="arosur.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="arosur.html"><a href="arosur.html#confidence-intervals-for-the-population-mean"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.5" data-path="arosur.html"><a href="arosur.html#cmfdp"><i class="fa fa-check"></i><b>3.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.6" data-path="arosur.html"><a href="arosur.html#aattggoe"><i class="fa fa-check"></i><b>3.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.7" data-path="arosur.html"><a href="arosur.html#scatterplots-sample-covariance-and-sample-correlation"><i class="fa fa-check"></i><b>3.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.8" data-path="arosur.html"><a href="arosur.html#exercises-1"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lrwor.html"><a href="lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="4.1" data-path="lrwor.html"><a href="lrwor.html#simple-linear-regression"><i class="fa fa-check"></i><b>4.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="4.2" data-path="lrwor.html"><a href="lrwor.html#estimating-the-coefficients-of-the-linear-regression-model"><i class="fa fa-check"></i><b>4.2</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="lrwor.html"><a href="lrwor.html#measures-of-fit"><i class="fa fa-check"></i><b>4.3</b> Measures of Fit</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="lrwor.html"><a href="lrwor.html#tlsa"><i class="fa fa-check"></i><b>4.4</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="lrwor.html"><a href="lrwor.html#tsdotoe"><i class="fa fa-check"></i><b>4.5</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="lrwor.html"><a href="lrwor.html#exercises-2"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="htaciitslrm.html"><a href="htaciitslrm.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="5.1" data-path="htaciitslrm.html"><a href="htaciitslrm.html#testing-two-sided-hypotheses-concerning-the-slope-coefficient"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="5.2" data-path="htaciitslrm.html"><a href="htaciitslrm.html#cifrc"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="htaciitslrm.html"><a href="htaciitslrm.html#rwxiabv"><i class="fa fa-check"></i><b>5.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="htaciitslrm.html"><a href="htaciitslrm.html#hah"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="htaciitslrm.html"><a href="htaciitslrm.html#the-gauss-markov-theorem"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="htaciitslrm.html"><a href="htaciitslrm.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="htaciitslrm.html"><a href="htaciitslrm.html#using-the-t-statistic-in-regression-when-the-sample-size-is-small"><i class="fa fa-check"></i><b>5.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="5.7" data-path="htaciitslrm.html"><a href="htaciitslrm.html#exercises-3"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="rmwmr.html"><a href="rmwmr.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="6.1" data-path="rmwmr.html"><a href="rmwmr.html#omitted-variable-bias"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="rmwmr.html"><a href="rmwmr.html#tmrm"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="rmwmr.html"><a href="rmwmr.html#mofimr"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="rmwmr.html"><a href="rmwmr.html#ols-assumptions-in-multiple-regression"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="rmwmr.html"><a href="rmwmr.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="rmwmr.html"><a href="rmwmr.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="rmwmr.html"><a href="rmwmr.html#the-distribution-of-the-ols-estimators-in-multiple-regression"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="6.6" data-path="rmwmr.html"><a href="rmwmr.html#exercises-4"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="htaciimr.html"><a href="htaciimr.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence Intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="htaciimr.html"><a href="htaciimr.html#hypothesis-tests-and-confidence-intervals-for-a-single-coefficient"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="htaciimr.html"><a href="htaciimr.html#an-application-to-test-scores-and-the-student-teacher-ratio"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="htaciimr.html"><a href="htaciimr.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="htaciimr.html"><a href="htaciimr.html#joint-hypothesis-testing-using-the-f-statistic"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the F-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="htaciimr.html"><a href="htaciimr.html#confidence-sets-for-multiple-coefficients"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="htaciimr.html"><a href="htaciimr.html#model-specification-for-multiple-regression"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="htaciimr.html"><a href="htaciimr.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="htaciimr.html"><a href="htaciimr.html#analysis-of-the-test-score-data-set"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="7.7" data-path="htaciimr.html"><a href="htaciimr.html#exercises-5"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nrf.html"><a href="nrf.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="8.1" data-path="nrf.html"><a href="nrf.html#a-general-strategy-for-modelling-nonlinear-regression-functions"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="nrf.html"><a href="nrf.html#nfoasiv"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="nrf.html"><a href="nrf.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="nrf.html"><a href="nrf.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="nrf.html"><a href="nrf.html#interactions-between-independent-variables"><i class="fa fa-check"></i><b>8.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="nrf.html"><a href="nrf.html#nonlinear-effects-on-test-scores-of-the-student-teacher-ratio"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
<li class="chapter" data-level="8.5" data-path="nrf.html"><a href="nrf.html#exercises-6"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="asbomr.html"><a href="asbomr.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="asbomr.html"><a href="asbomr.html#internal-and-external-validity"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="asbomr.html"><a href="asbomr.html#ttivomra"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="asbomr.html"><a href="asbomr.html#internal-and-external-validity-when-the-regression-is-used-for-forecasting"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity when the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="asbomr.html"><a href="asbomr.html#etsacs"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
<li class="chapter" data-level="9.5" data-path="asbomr.html"><a href="asbomr.html#exercises-7"><i class="fa fa-check"></i><b>9.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="rwpd.html"><a href="rwpd.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="10.1" data-path="rwpd.html"><a href="rwpd.html#panel-data"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="rwpd.html"><a href="rwpd.html#PDWTTP"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="rwpd.html"><a href="rwpd.html#fixed-effects-regression"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="rwpd.html"><a href="rwpd.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="rwpd.html"><a href="rwpd.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="rwpd.html"><a href="rwpd.html#regression-with-time-fixed-effects"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="rwpd.html"><a href="rwpd.html#tferaaseffer"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="rwpd.html"><a href="rwpd.html#drunk-driving-laws-and-traffic-deaths"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="rwabdv.html"><a href="rwabdv.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="11.1" data-path="rwabdv.html"><a href="rwabdv.html#binary-dependent-variables-and-the-linear-probability-model"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="rwabdv.html"><a href="rwabdv.html#palr"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="rwabdv.html"><a href="rwabdv.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="rwabdv.html"><a href="rwabdv.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="rwabdv.html"><a href="rwabdv.html#estimation-and-inference-in-the-logit-and-probit-models"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="rwabdv.html"><a href="rwabdv.html#application-to-the-boston-hmda-data"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
<li class="chapter" data-level="11.5" data-path="rwabdv.html"><a href="rwabdv.html#exercises-8"><i class="fa fa-check"></i><b>11.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ivr.html"><a href="ivr.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="ivr.html"><a href="ivr.html#TIVEWASRAASI"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="ivr.html"><a href="ivr.html#TGIVRM"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="ivr.html"><a href="ivr.html#civ"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="ivr.html"><a href="ivr.html#attdfc"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="ivr.html"><a href="ivr.html#where-do-valid-instruments-come-from"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
<li class="chapter" data-level="12.6" data-path="ivr.html"><a href="ivr.html#exercises-9"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="eaqe.html"><a href="eaqe.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="13.1" data-path="eaqe.html"><a href="eaqe.html#potential-outcomes-causal-effects-and-idealized-experiments"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="eaqe.html"><a href="eaqe.html#threats-to-validity-of-experiments"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="eaqe.html"><a href="eaqe.html#experimental-estimates-of-the-effect-of-class-size-reductions"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="eaqe.html"><a href="eaqe.html#quasi-experiments"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="eaqe.html"><a href="eaqe.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ittsraf.html"><a href="ittsraf.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="14.1" data-path="ittsraf.html"><a href="ittsraf.html#using-regression-models-for-forecasting"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="ittsraf.html"><a href="ittsraf.html#tsdasc"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="ittsraf.html"><a href="ittsraf.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="ittsraf.html"><a href="ittsraf.html#autoregressions"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a><ul>
<li><a href="ittsraf.html#autoregressive-models-of-order-p">Autoregressive Models of Order <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ittsraf.html"><a href="ittsraf.html#cybtmpi"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="ittsraf.html"><a href="ittsraf.html#apatadlm"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="ittsraf.html"><a href="ittsraf.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="ittsraf.html"><a href="ittsraf.html#llsuic"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="ittsraf.html"><a href="ittsraf.html#nit"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="ittsraf.html"><a href="ittsraf.html#niib"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="ittsraf.html"><a href="ittsraf.html#can-you-beat-the-market-part-ii"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="eodce.html"><a href="eodce.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="15.1" data-path="eodce.html"><a href="eodce.html#the-orange-juice-data"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="eodce.html"><a href="eodce.html#dynamic-causal-effects"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="eodce.html"><a href="eodce.html#dynamic-multipliers-and-cumulative-dynamic-multipliers"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="eodce.html"><a href="eodce.html#hac-standard-errors"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="eodce.html"><a href="eodce.html#estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="eodce.html"><a href="eodce.html#orange-juice-prices-and-cold-weather"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="atitsr.html"><a href="atitsr.html"><i class="fa fa-check"></i><b>16</b> Additional Topics in Time Series Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="atitsr.html"><a href="atitsr.html#vector-autoregressions"><i class="fa fa-check"></i><b>16.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="16.2" data-path="atitsr.html"><a href="atitsr.html#ooiatdfglsurt"><i class="fa fa-check"></i><b>16.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="16.3" data-path="atitsr.html"><a href="atitsr.html#cointegration"><i class="fa fa-check"></i><b>16.3</b> Cointegration</a></li>
<li class="chapter" data-level="16.4" data-path="atitsr.html"><a href="atitsr.html#volatility-clustering-and-autoregressive-conditional-heteroskedasticity"><i class="fa fa-check"></i><b>16.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a><ul>
<li class="chapter" data-level="" data-path="atitsr.html"><a href="atitsr.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="atitsr.html"><a href="atitsr.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
<li class="chapter" data-level="" data-path="atitsr.html"><a href="atitsr.html#summary-8"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Econometrics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. You can also see the annotations of others: click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="htaciimr" class="section level1">
<h1><span class="header-section-number">7</span> Hypothesis Tests and Confidence Intervals in Multiple Regression</h1>
<p>This chapter discusses methods that allow to quantify the sampling uncertainty in the OLS estimator of the coefficients in multiple regression models. The basis for this are hypothesis tests and confidence intervals which, just as for the simple linear regression model, can be computed using basic <tt>R</tt> functions. We will also tackle the issue of testing joint hypotheses on these coefficients.</p>
<p>Make sure the packages <tt>AER</tt> <span class="citation">(Christian Kleiber &amp; Zeileis, <a href="#ref-R-AER">2017</a>)</span> and <tt>stargazer</tt> <span class="citation">(Hlavac, <a href="#ref-R-stargazer">2018</a>)</span> are installed before you go ahead and replicate the examples. The safest way to do so is by checking whether the following code chunk executes without any issues.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(AER)
<span class="kw">library</span>(stargazer)</code></pre></div>
<div id="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient" class="section level2">
<h2><span class="header-section-number">7.1</span> Hypothesis Tests and Confidence Intervals for a Single Coefficient</h2>
<p>We first discuss how to compute standard errors, how to test hypotheses and how to construct confidence intervals for a single regression coefficient <span class="math inline">\(\beta_j\)</span> in a multiple regression model. The basic idea is summarized in Key Concept 7.1.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 7.1
</h3>
<h3 class="left">
Testing the Hypothesis <span class="math inline">\(\beta_j = \beta_{j,0}\)</span> <br> Against the Alternative <span class="math inline">\(\beta_j \neq \beta_{j,0}\)</span>
</h3>
<p>
<ol style="list-style-type: decimal">
<li>Compute the standard error of <span class="math inline">\(\hat{\beta_j}\)</span></li>
<li>Compute the <span class="math inline">\(t\)</span>-statistic, <span class="math display">\[t^{act} = \frac{\hat{\beta}_j - \beta_{j,0}} {SE(\hat{\beta_j})}\]</span></li>
<li>Compute the <span class="math inline">\(p\)</span>-value, <span class="math display">\[p\text{-value} = 2 \Phi(-|t^{act}|)\]</span></li>
</ol>
where <span class="math inline">\(t^{act}\)</span> is the value of the <span class="math inline">\(t\)</span>-statistic actually computed. Reject the hypothesis at the <span class="math inline">\(5\%\)</span> significance level if the <span class="math inline">\(p\)</span>-value is less than <span class="math inline">\(0.05\)</span> or, equivalently, if <span class="math inline">\(|t^{act}| &gt; 1.96\)</span>. The standard error and (typically) the <span class="math inline">\(t\)</span>-statistic and the corresponding <span class="math inline">\(p\)</span>-value for testing <span class="math inline">\(\beta_j = 0\)</span> are computed automatically by suitable <tt>R</tt> functions, e.g., by <tt>summary</tt>.
</p>
</div>
<p>Testing a single hypothesis about the significance of a coefficient in the multiple regression model proceeds as in in the simple regression model.</p>
<p>You can easily see this by inspecting the coefficient summary of the regression model</p>
<p><span class="math display">\[ TestScore = \beta_0 + \beta_1 \times size  \beta_2 \times english + u \]</span></p>
<p>already discussed in Chapter <a href="rmwmr.html#rmwmr">6</a>. Let us review this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english, <span class="dt">data =</span> CASchools)
<span class="kw">coeftest</span>(model, <span class="dt">vcov. =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##               Estimate Std. Error  t value Pr(&gt;|t|)    
## (Intercept) 686.032245   8.728225  78.5993  &lt; 2e-16 ***
## size         -1.101296   0.432847  -2.5443  0.01131 *  
## english      -0.649777   0.031032 -20.9391  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>You may check that these quantities are computed as in the simple regression model by computing the <span class="math inline">\(t\)</span>-statistics or <span class="math inline">\(p\)</span>-values by hand using the output above and <tt>R</tt> as a calculator.</p>
<p>For example, using the definition of the <span class="math inline">\(p\)</span>-value for a two-sided test as given in Key Concept 7.1, we can confirm the <span class="math inline">\(p\)</span>-value for a test of the hypothesis that the coefficient <span class="math inline">\(\beta_1\)</span>, the coefficient on <tt>size</tt>, to be approximately zero.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute two-sided p-value</span>
<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pt</span>(<span class="kw">abs</span>(<span class="kw">coeftest</span>(model, <span class="dt">vcov. =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)[<span class="dv">2</span>, <span class="dv">3</span>]),
            <span class="dt">df =</span> model<span class="op">$</span>df.residual))</code></pre></div>
<pre><code>## [1] 0.01130921</code></pre>
<div class="keyconcept">
<h3 class="right">
Key Concept 7.2
</h3>
<h3 class="left">
Confidence Intervals for a Single Coefficient in Multiple Regression
</h3>
<p>
A <span class="math inline">\(95\%\)</span> two-sided confidence interval for the coefficient <span class="math inline">\(\beta_j\)</span> is an interval that contains the true value of <span class="math inline">\(\beta_j\)</span> with a <span class="math inline">\(95 \%\)</span> probability; that is, it contains the true value of <span class="math inline">\(\beta_j\)</span> in <span class="math inline">\(95 \%\)</span> of all repeated samples. Equivalently, it is the set of values of <span class="math inline">\(\beta_j\)</span> that cannot be rejected by a <span class="math inline">\(5 \%\)</span> two-sided hypothesis test. When the sample size is large, the <span class="math inline">\(95 \%\)</span> confidence interval for <span class="math inline">\(\beta_j\)</span> is <span class="math display">\[\left[\hat{\beta_j}- 1.96 \times SE(\hat{\beta}_j), \hat{\beta_j} + 1.96 \times SE(\hat{\beta_j})\right].\]</span>
</p>
</div>
</div>
<div id="an-application-to-test-scores-and-the-student-teacher-ratio" class="section level2">
<h2><span class="header-section-number">7.2</span> An Application to Test Scores and the Student-Teacher Ratio</h2>
<p>Let us take a look at the regression from Section <a href="rmwmr.html#mofimr">6.3</a> again.</p>
<p>Computing confidence intervals for individual coefficients in the multiple regression model proceeds as in the simple regression model using the function <tt>confint()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english, <span class="dt">data =</span> CASchools)
<span class="kw">confint</span>(model)</code></pre></div>
<pre><code>##                   2.5 %      97.5 %
## (Intercept) 671.4640580 700.6004311
## size         -1.8487969  -0.3537944
## english      -0.7271113  -0.5724424</code></pre>
<p>To obtain confidence intervals at another level, say <span class="math inline">\(90\%\)</span>, just set the argument <tt>level</tt> in our call of <tt>confint()</tt> accordingly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model, <span class="dt">level =</span> <span class="fl">0.9</span>)</code></pre></div>
<pre><code>##                     5 %        95 %
## (Intercept) 673.8145793 698.2499098
## size         -1.7281904  -0.4744009
## english      -0.7146336  -0.5849200</code></pre>
<p>The output now reports the desired <span class="math inline">\(90\%\)</span> confidence intervals for all coefficients.</p>
<p>A disadvantage of <tt>confint()</tt> is that is does not use robust standard errors to compute the confidence interval. For large-sample confidence intervals, this is quickly done manually as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute robust standard errors</span>
rob_se &lt;-<span class="st"> </span><span class="kw">diag</span>(<span class="kw">vcovHC</span>(model, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))<span class="op">^</span><span class="fl">0.5</span>

<span class="co"># compute robust 95% confidence intervals</span>
<span class="kw">rbind</span>(<span class="st">&quot;lower&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(model) <span class="op">-</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>rob_se,
      <span class="st">&quot;upper&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(model) <span class="op">+</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>rob_se)</code></pre></div>
<pre><code>##       (Intercept)       size    english
## lower    668.9252 -1.9496606 -0.7105980
## upper    703.1393 -0.2529307 -0.5889557</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute robust 90% confidence intervals</span>

<span class="kw">rbind</span>(<span class="st">&quot;lower&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(model) <span class="op">-</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.95</span>) <span class="op">*</span><span class="st"> </span>rob_se,
      <span class="st">&quot;upper&quot;</span> =<span class="st"> </span><span class="kw">coef</span>(model) <span class="op">+</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.95</span>) <span class="op">*</span><span class="st"> </span>rob_se)</code></pre></div>
<pre><code>##       (Intercept)       size    english
## lower    671.6756 -1.8132659 -0.7008195
## upper    700.3889 -0.3893254 -0.5987341</code></pre>
<p>Knowing how to use <tt>R</tt> to make inference about the coefficients in multiple regression models, you can now answer the following question:</p>
<p>Can the null hypothesis that a change in the student-teacher ratio, <tt>size</tt>, has no significant influence on test scores, <tt>scores</tt>, — if we control for the percentage of students learning English in the district, <tt>english</tt>, — be rejected at the <span class="math inline">\(10\%\)</span> and the <span class="math inline">\(5\%\)</span> level of significance?</p>
<p>The output above shows that zero is not an element of the confidence interval for the coefficient on <tt>size</tt> such that we can reject the null hypothesis at significance levels of <span class="math inline">\(5\%\)</span> and <span class="math inline">\(10\%\)</span>. The same conclusion can be made via the <span class="math inline">\(p\)</span>-value for <tt>size</tt>: <span class="math inline">\(0.00398 &lt; 0.05 = \alpha\)</span>.</p>
<p>Note that rejection at the <span class="math inline">\(5\%\)</span>-level implies rejection at the <span class="math inline">\(10\%\)</span> level (why?).</p>
<p>Recall from Chapter <a href="htaciitslrm.html#cifrc">5.2</a> the <span class="math inline">\(95\%\)</span> confidence interval computed above <em>does not</em> tell us that a one-unit decrease in the student-teacher ratio has an effect on test scores that lies in the interval with a lower bound of <span class="math inline">\(-1.9497\)</span> and an upper bound of <span class="math inline">\(-0.2529\)</span>. Once a confidence interval has been computed, a probabilistic statement like this is wrong: either the interval contains the true parameter or it does not. We do not know which is true.</p>
<div id="another-augmentation-of-the-model" class="section level3 unnumbered">
<h3>Another Augmentation of the Model</h3>
<p>What is the average effect on test scores of reducing the student-teacher ratio when the expenditures per pupil and the percentage of english learning pupils are held constant?</p>
<p>Let us augment our model by an additional regressor that is a measure for expenditure per pupil. Using <tt>?CASchools</tt> we find that <tt>CASchools</tt> contains the variable <tt>expenditure</tt>, which provides expenditure per student.</p>
<p>Our model now is <span class="math display">\[ TestScore = \beta_0 + \beta_1 \times size + \beta_2 \times english + \beta_3 \times expenditure + u \]</span></p>
<p>with <span class="math inline">\(expenditure\)</span> the total amount of expenditure per pupil in the district (thousands of dollars).</p>
<p>Let us now estimate the model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># scale expenditure to thousands of dollars</span>
CASchools<span class="op">$</span>expenditure &lt;-<span class="st"> </span>CASchools<span class="op">$</span>expenditure<span class="op">/</span><span class="dv">1000</span>

<span class="co"># estimate the model</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>expenditure, <span class="dt">data =</span> CASchools)
<span class="kw">coeftest</span>(model, <span class="dt">vcov. =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##               Estimate Std. Error  t value Pr(&gt;|t|)    
## (Intercept) 649.577947  15.458344  42.0212  &lt; 2e-16 ***
## size         -0.286399   0.482073  -0.5941  0.55277    
## english      -0.656023   0.031784 -20.6398  &lt; 2e-16 ***
## expenditure   3.867901   1.580722   2.4469  0.01482 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The estimated effect of a one unit change in the student-teacher ratio on test scores with expenditure and the share of english learning pupils held constant is <span class="math inline">\(-0.29\)</span>, which is rather small. What is more, the coefficient on <span class="math inline">\(size\)</span> is not significantly different from zero anymore even at <span class="math inline">\(10\%\)</span> since <span class="math inline">\(p\text{-value}=0.55\)</span>. Can you come up with an interpretation for these findings (see Chapter 7.1 of the book)? The insignificance of <span class="math inline">\(\hat\beta_1\)</span> could be due to a larger standard error of <span class="math inline">\(\hat{\beta}_1\)</span> resulting from adding <span class="math inline">\(expenditure\)</span> to the model so that we estimate the coefficient on <span class="math inline">\(size\)</span> less precisely. This illustrates the issue of strongly correlated regressors (imperfect multicollinearity). The correlation between <span class="math inline">\(size\)</span> and <span class="math inline">\(expenditure\)</span> can be computed using <tt>cor()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute the sample correlation between &#39;size&#39; and &#39;expenditure&#39;</span>
<span class="kw">cor</span>(CASchools<span class="op">$</span>size, CASchools<span class="op">$</span>expenditure)</code></pre></div>
<pre><code>## [1] -0.6199822</code></pre>
<p>Altogether, we conclude that the new model provides no evidence that changing the student-teacher ratio, e.g., by hiring new teachers, has any effect on the test scores while keeping expenditures per student and the share of English learners constant.</p>
</div>
</div>
<div id="joint-hypothesis-testing-using-the-f-statistic" class="section level2">
<h2><span class="header-section-number">7.3</span> Joint Hypothesis Testing Using the F-Statistic</h2>
<p>The estimated model is</p>
<p><span class="math display">\[ \widehat{TestScore} = \underset{(15.21)}{649.58} -\underset{(0.48)}{0.29} \times size - \underset{(0.04)}{0.66} \times english + \underset{(1.41)}{3.87} \times expenditure. \]</span></p>
<p>Now, can we reject the hypothesis that the coefficient on <span class="math inline">\(size\)</span> <em>and</em> the coefficient on <span class="math inline">\(expenditure\)</span> are zero? To answer this, we have to resort to joint hypothesis tests. A joint hypothesis imposes restrictions on multiple regression coefficients. This is different from conducting individual <span class="math inline">\(t\)</span>-tests where a restriction is imposed on a single coefficient. Chapter 7.2 of the book explains why testing hypotheses about the model coefficients one at a time is different from testing them jointly.</p>
<p>The homoskedasticity-only <span class="math inline">\(F\)</span>-Statistic is given by</p>
<p><span class="math display">\[ F = \frac{(SSR_{\text{restricted}} - SSR_{\text{unrestricted}})/q}{SSR_{\text{unrestricted}} / (n-k-1)} \]</span></p>
<p>with <span class="math inline">\(SSR_{restricted}\)</span> being the sum of squared residuals from the restricted regression, i.e., the regression where we impose the restriction. <span class="math inline">\(SSR_{unrestricted}\)</span> is the sum of squared residuals from the full model, <span class="math inline">\(q\)</span> is the number of restrictions under the null and <span class="math inline">\(k\)</span> is the number of regressors in the unrestricted regression.</p>
<p>It is fairly easy to conduct <span class="math inline">\(F\)</span>-tests in <tt>R</tt>. We can use the function <tt>linearHypothesis()</tt>contained in the package <tt>car</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the multiple regression model</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>expenditure, <span class="dt">data =</span> CASchools)

<span class="co"># execute the function on the model object and provide both linear restrictions </span>
<span class="co"># to be tested as strings</span>
<span class="kw">linearHypothesis</span>(model, <span class="kw">c</span>(<span class="st">&quot;size=0&quot;</span>, <span class="st">&quot;expenditure=0&quot;</span>))</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## size = 0
## expenditure = 0
## 
## Model 1: restricted model
## Model 2: score ~ size + english + expenditure
## 
##   Res.Df   RSS Df Sum of Sq      F   Pr(&gt;F)    
## 1    418 89000                                 
## 2    416 85700  2    3300.3 8.0101 0.000386 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The output reveals that the <span class="math inline">\(F\)</span>-statistic for this joint hypothesis test is about <span class="math inline">\(8.01\)</span> and the corresponding <span class="math inline">\(p\)</span>-value is <span class="math inline">\(0.0004\)</span>. Thus, we can reject the null hypothesis that both coefficients are zero at any level of significance commonly used in practice.</p>
<p>A heteroskedasticity-robust version of this <span class="math inline">\(F\)</span>-test (which leads to the same conclusion) can be conducted as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># heteroskedasticity-robust F-test</span>
<span class="kw">linearHypothesis</span>(model, <span class="kw">c</span>(<span class="st">&quot;size=0&quot;</span>, <span class="st">&quot;expenditure=0&quot;</span>), <span class="dt">white.adjust =</span> <span class="st">&quot;hc1&quot;</span>)</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## size = 0
## expenditure = 0
## 
## Model 1: restricted model
## Model 2: score ~ size + english + expenditure
## 
## Note: Coefficient covariance matrix supplied.
## 
##   Res.Df Df      F   Pr(&gt;F)   
## 1    418                      
## 2    416  2 5.4337 0.004682 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The standard output of a model summary also reports an <span class="math inline">\(F\)</span>-statistic and the corresponding <span class="math inline">\(p\)</span>-value. The null hypothesis belonging to this <span class="math inline">\(F\)</span>-test is that <em>all</em> of the population coefficients in the model except for the intercept are zero, so the hypotheses are <span class="math display">\[H_0: \beta_1=0, \ \beta_2 =0, \ \beta_3 =0 \quad \text{vs.} \quad H_1: \beta_j \neq 0 \ \text{for at least one} \ j=1,2,3.\]</span></p>
<p>This is also called the <em>overall regression <span class="math inline">\(F\)</span>-statistic</em> and the null hypothesis is obviously different from testing if only <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_3\)</span> are zero.</p>
<p>We now check whether the <span class="math inline">\(F\)</span>-statistic belonging to the <span class="math inline">\(p\)</span>-value listed in the model’s summary coincides with the result reported by <tt>linearHypothesis()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># execute the function on the model object and provide the restrictions </span>
<span class="co"># to be tested as a character vector</span>
<span class="kw">linearHypothesis</span>(model, <span class="kw">c</span>(<span class="st">&quot;size=0&quot;</span>, <span class="st">&quot;english=0&quot;</span>, <span class="st">&quot;expenditure=0&quot;</span>))</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## size = 0
## english = 0
## expenditure = 0
## 
## Model 1: restricted model
## Model 2: score ~ size + english + expenditure
## 
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    419 152110                                  
## 2    416  85700  3     66410 107.45 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Access the overall F-statistic from the model&#39;s summary</span>
<span class="kw">summary</span>(model)<span class="op">$</span>fstatistic</code></pre></div>
<pre><code>##    value    numdf    dendf 
## 107.4547   3.0000 416.0000</code></pre>
<p>The entry <tt>value</tt> is the overall <span class="math inline">\(F\)</span>-statistics and it equals the result of <tt>linearHypothesis()</tt>. The <span class="math inline">\(F\)</span>-test rejects the null hypothesis that the model has no power in explaining test scores. It is important to know that the <span class="math inline">\(F\)</span>-statistic reported by <tt>summary</tt> is <em>not</em> robust to heteroskedasticity!</p>
</div>
<div id="confidence-sets-for-multiple-coefficients" class="section level2">
<h2><span class="header-section-number">7.4</span> Confidence Sets for Multiple Coefficients</h2>
<p>Based on the <span class="math inline">\(F\)</span>-statistic that we have previously encountered, we can specify confidence sets. Confidence sets are analogous to confidence intervals for single coefficients. As such, confidence sets consist of <em>combinations</em> of coefficients that contain the true combination of coefficients in, say, <span class="math inline">\(95\%\)</span> of all cases if we could repeatedly draw random samples, just like in the univariate case. Put differently, a confidence set is the set of all coefficient combinations for which we cannot reject the corresponding joint null hypothesis tested using an <span class="math inline">\(F\)</span>-test.</p>
<p>The confidence set for two coefficients an ellipse which is centered around the point defined by both coefficient estimates. Again, there is a very convenient way to plot the confidence set for two coefficients of model objects, namely the function <tt>confidenceEllipse()</tt> from the <tt>car</tt> package.</p>
<p>We now plot the <span class="math inline">\(95\%\)</span> confidence ellipse for the coefficients on <tt>size</tt> and <tt>expenditure</tt> from the regression conducted above. By specifying the additional argument <tt>fill</tt>, the confidence set is colored.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># draw the 95% confidence set for coefficients on size and expenditure</span>
<span class="kw">confidenceEllipse</span>(model, 
                  <span class="dt">fill =</span> T,
                  <span class="dt">lwd =</span> <span class="dv">0</span>,
                  <span class="dt">which.coef =</span> <span class="kw">c</span>(<span class="st">&quot;size&quot;</span>, <span class="st">&quot;expenditure&quot;</span>),
                  <span class="dt">main =</span> <span class="st">&quot;95% Confidence Set&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-293-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>We see that the ellipse is centered around <span class="math inline">\((-0.29, 3.87)\)</span>, the pair of coefficients estimates on <span class="math inline">\(size\)</span> and <span class="math inline">\(expenditure\)</span>. What is more, <span class="math inline">\((0,0)\)</span> is not element of the <span class="math inline">\(95\%\)</span> confidence set so that we can reject <span class="math inline">\(H_0: \beta_1 = 0, \ \beta_3 = 0\)</span>.</p>
<p>By default, <tt>confidenceEllipse()</tt> uses homoskedasticity-only standard errors. The following code chunk shows how compute a robust confidence ellipse and how to overlay it with the previous plot.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># draw the robust 95% confidence set for coefficients on size and expenditure </span>
<span class="kw">confidenceEllipse</span>(model, 
                  <span class="dt">fill =</span> T,
                  <span class="dt">lwd =</span> <span class="dv">0</span>,
                  <span class="dt">which.coef =</span> <span class="kw">c</span>(<span class="st">&quot;size&quot;</span>, <span class="st">&quot;expenditure&quot;</span>),
                  <span class="dt">main =</span> <span class="st">&quot;95% Confidence Sets&quot;</span>,
                  <span class="dt">vcov. =</span> <span class="kw">vcovHC</span>(model, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>),
                  <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
                  
<span class="co"># draw the 95% confidence set for coefficients on size and expenditure</span>
<span class="kw">confidenceEllipse</span>(model, 
                  <span class="dt">fill =</span> T,
                  <span class="dt">lwd =</span> <span class="dv">0</span>,
                  <span class="dt">which.coef =</span> <span class="kw">c</span>(<span class="st">&quot;size&quot;</span>, <span class="st">&quot;expenditure&quot;</span>),
                  <span class="dt">add =</span> T)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-294-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>As the robust standard errors are slightly larger than those valid under homoskedasticity only in this case, the robust confidence set is slightly larger. This is analogous to the confidence intervals for the individual coefficients.</p>
</div>
<div id="model-specification-for-multiple-regression" class="section level2">
<h2><span class="header-section-number">7.5</span> Model Specification for Multiple Regression</h2>
<p>Choosing a regression specification, i.e., selecting the variables to be included in a regression model, is a difficult task. However, there are some guidelines on how to proceed. The goal is clear: obtaining an unbiased and precise estimate of the causal effect of interest. As a starting point, think about omitted variables, that is, to avoid possible bias by using suitable control variables. Omitted variables bias in the context of multiple regression is explained in Key Concept 7.3. A second step could be to compare different specifications by measures of fit. However, as we shall see one should not rely solely on <span class="math inline">\(\bar{R}^2\)</span>.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 7.3
</h3>
<h3 class="left">
Omitted Variable Bias in Multiple Regression
</h3>
<p>
<p>Omitted variable bias is the bias in the OLS estimator that arises when regressors correlate with an omitted variable. For omitted variable bias to arise, two things must be true:</p>
<ol style="list-style-type: decimal">
<li>At least one of the included regressors must be correlated with the omitted variable.</li>
<li>The omitted variable must be a determinant of the dependent variable, <span class="math inline">\(Y\)</span>.</li>
</ol>
</p>
</div>
<p>We now discuss an example were we face a potential omitted variable bias in a multiple regression model:</p>
<p>Consider again the estimated regression equation</p>
<p><span class="math display">\[ \widehat{TestScore} = \underset{(8.7)}{686.0} - \underset{(0.43)}{1.10} \times size - \underset{(0.031)}{0.650} \times english. \]</span></p>
<p>We are interested in estimating the causal effect of class size on test score. There might be a bias due to omitting “outside learning opportunities” from our regression since such a measure could be a determinant of the students’ test scores and could also be correlated with both regressors already included in the model (so that both conditions of Key Concept 7.3 are fulfilled). “Outside learning opportunities” are a complicated concept that is difficult to quantify. A surrogate we can consider instead is the students’ economic background which likely are strongly related to outside learning opportunities: think of wealthy parents that are able to provide time and/or money for private tuition of their children. We thus augment the model with the variable <tt>lunch</tt>, the percentage of students that qualify for a free or subsidized lunch in school due to family incomes below a certain threshold, and reestimate the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the model and print the summary to console</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>lunch, <span class="dt">data =</span> CASchools)
<span class="kw">coeftest</span>(model, <span class="dt">vcov. =</span> vcovHC, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##               Estimate Std. Error  t value  Pr(&gt;|t|)    
## (Intercept) 700.149957   5.568453 125.7351 &lt; 2.2e-16 ***
## size         -0.998309   0.270080  -3.6963 0.0002480 ***
## english      -0.121573   0.032832  -3.7029 0.0002418 ***
## lunch        -0.547345   0.024107 -22.7046 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Thus, the estimated regression line is</p>
<p><span class="math display">\[ \widehat{TestScore} = \underset{(5.56)}{700.15} - \underset{(0.27)}{1.00} \times size - \underset{(0.03)}{0.12} \times english - \underset{(0.02)}{0.55} \times lunch. \]</span></p>
<p>We observe no substantial changes in the conclusion about the effect of <span class="math inline">\(size\)</span> on <span class="math inline">\(TestScore\)</span>: the coefficient on <span class="math inline">\(size\)</span> changes by only <span class="math inline">\(0.1\)</span> and retains its significance.</p>
<p>Although the difference in estimated coefficients is not big in this case, it is useful to keep <tt>lunch</tt> to make the assumption of conditional mean independence more credible (see Chapter 7.5 of the book).</p>
<div id="model-specification-in-theory-and-in-practice" class="section level3 unnumbered">
<h3>Model Specification in Theory and in Practice</h3>
<p>Key Concept 7.4 lists some common pitfalls when using <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\bar{R}^2\)</span> to evaluate the predictive ability of regression models.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 7.4
</h3>
<h3 class="left">
<span class="math inline">\(R^2\)</span> and <span class="math inline">\(\bar{R}^2\)</span>: what they tell you — and what they do not
</h3>
<p>
<p>The <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\bar{R}^2\)</span> tell you whether the regressors are good at explaining the variation of the independent variable in the sample. If the <span class="math inline">\(R^2\)</span> (or <span class="math inline">\(\bar{R}^2\)</span>) is nearly <span class="math inline">\(1\)</span>, then the regressors produce a good prediction of the dependent variable in that sample, in the sense that the variance of OLS residuals is small compared to the variance of the dependent variable. If the <span class="math inline">\(R^2\)</span> (or <span class="math inline">\(\bar{R}^2\)</span>) is nearly <span class="math inline">\(0\)</span>, the opposite is true.</p>
<p>The <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\bar{R}^2\)</span> do <em>not</em> tell you whether:</p>
<ol style="list-style-type: decimal">
<li>An included variable is statistically significant.</li>
<li>The regressors are the true cause of the movements in the dependent variable.</li>
<li>There is omitted variable bias.</li>
<li>You have chosen the most appropriate set of regressors.</li>
</ol>
</p>
</div>
<p>For example, think of regressing <span class="math inline">\(TestScore\)</span> on <span class="math inline">\(PLS\)</span> which measures the available parking lot space in thousand square feet. You are likely to observe a significant coefficient of reasonable magnitude and moderate to high values for <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\bar{R}^2\)</span>. The reason for this is that parking lot space is correlated with many determinants of the test score like location, class size, financial endowment and so on. Although we do not have observations on <span class="math inline">\(PLS\)</span>, we can use <tt>R</tt> to generate some relatively realistic data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set seed for reproducibility</span>
<span class="kw">set.seed</span>(<span class="dv">1</span>)

<span class="co"># generate observations for parking lot space</span>
CASchools<span class="op">$</span>PLS &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">22</span> <span class="op">*</span><span class="st"> </span>CASchools<span class="op">$</span>income 
                   <span class="op">-</span><span class="st"> </span><span class="dv">15</span> <span class="op">*</span><span class="st"> </span>CASchools<span class="op">$</span>size 
                   <span class="op">+</span><span class="st"> </span><span class="fl">0.2</span> <span class="op">*</span><span class="st"> </span>CASchools<span class="op">$</span>expenditure
                   <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">nrow</span>(CASchools), <span class="dt">sd =</span> <span class="dv">80</span>) <span class="op">+</span><span class="st"> </span><span class="dv">3000</span>)</code></pre></div>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot parking lot space against test score</span>
<span class="kw">plot</span>(CASchools<span class="op">$</span>PLS, 
     CASchools<span class="op">$</span>score,
     <span class="dt">xlab =</span> <span class="st">&quot;Parking Lot Space&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Test Score&quot;</span>,
     <span class="dt">pch =</span> <span class="dv">20</span>,
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-301-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># regress test score on PLS</span>
<span class="kw">summary</span>(<span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>PLS, <span class="dt">data =</span> CASchools))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ PLS, data = CASchools)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -42.608 -11.049   0.342  12.558  37.105 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 4.897e+02  1.227e+01   39.90   &lt;2e-16 ***
## PLS         4.002e-02  2.981e-03   13.43   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 15.95 on 418 degrees of freedom
## Multiple R-squared:  0.3013, Adjusted R-squared:  0.2996 
## F-statistic: 180.2 on 1 and 418 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<span class="math inline">\(PLS\)</span> is generated as a linear function of <span class="math inline">\(expenditure\)</span>, <span class="math inline">\(income\)</span>, <span class="math inline">\(size\)</span> and a random disturbance. Therefore the data suggest that there is some positive relationship between parking lot space and test score. In fact, when estimating the model
<span class="math display" id="eq:plsmod">\[\begin{align}
TestScore = \beta_0 + \beta_1 \times PLS + u \tag{7.1} 
\end{align}\]</span>
<p>using <tt>lm()</tt> we find that the coefficient on <span class="math inline">\(PLS\)</span> is positive and significantly different from zero. Also <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\bar{R}^2\)</span> are about <span class="math inline">\(0.3\)</span> which is a lot more than the roughly <span class="math inline">\(0.05\)</span> observed when regressing the test scores on the class sizes only. This suggests that increasing the parking lot space boosts a school’s test scores and that model <a href="htaciimr.html#eq:plsmod">(7.1)</a> does even better in explaining heterogeneity in the dependent variable than a model with <span class="math inline">\(size\)</span> as the only regressor. Keeping in mind how <span class="math inline">\(PLS\)</span> is constructed this comes as no surprise. It is evident that the high <span class="math inline">\(R^2\)</span> <it>cannot</it> be used to the conclude that the estimated relation between parking lot space and test scores is causal: the (relatively) high <span class="math inline">\(R^2\)</span> is due to correlation between <span class="math inline">\(PLS\)</span> and other determinants and/or control variables. Increasing parking lot space is <em>not</em> an appropriate measure to generate more learning success!</p>
</div>
</div>
<div id="analysis-of-the-test-score-data-set" class="section level2">
<h2><span class="header-section-number">7.6</span> Analysis of the Test Score Data Set</h2>
<p>Chapter <a href="rmwmr.html#rmwmr">6</a> and some of the previous sections have stressed that it is important to include control variables in regression models if it is plausible that there are omitted factors. In our example of test scores we want to estimate the causal effect of a change in the student-teacher ratio on test scores. We now provide an example how to use multiple regression in order to alleviate omitted variable bias and demonstrate how to report results using <tt>R</tt>.</p>
<p>So far we have considered two variables that control for unobservable student characteristics which correlate with the student-teacher ratio <em>and</em> are assumed to have an impact on test scores:</p>
<ul>
<li><p><span class="math inline">\(English\)</span>, the percentage of English learning students</p></li>
<li><p><span class="math inline">\(lunch\)</span>, the share of students that qualify for a subsidized or even a free lunch at school</p></li>
</ul>
<p>Another new variable provided with <tt>CASchools</tt> is <tt>calworks</tt>, the percentage of students that qualify for the <em>CalWorks</em> income assistance program. Students eligible for <em>CalWorks</em> live in families with a total income below the threshold for the subsidized lunch program so both variables are indicators for the share of economically disadvantaged children. Both indicators are highly correlated:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the correlation between &#39;calworks&#39; and &#39;lunch&#39;</span>
<span class="kw">cor</span>(CASchools<span class="op">$</span>calworks, CASchools<span class="op">$</span>lunch)</code></pre></div>
<pre><code>## [1] 0.7394218</code></pre>
<p>There is no unambiguous way to proceed when deciding which variable to use. In any case it may not a good idea to use both variables as regressors in view of collinearity. Therefore, we also consider alternative model specifications.</p>
<p>For a start, we plot student characteristics against test scores.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set up arrangement of plots</span>
m &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">0</span>))
graphics<span class="op">::</span><span class="kw">layout</span>(<span class="dt">mat =</span> m)

<span class="co"># scatterplots</span>
<span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>english, 
     <span class="dt">data =</span> CASchools, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">pch =</span> <span class="dv">20</span>, 
     <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">100</span>),
     <span class="dt">cex.main =</span> <span class="fl">0.9</span>,
     <span class="dt">main =</span> <span class="st">&quot;Percentage of English language learners&quot;</span>)

<span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>lunch, 
     <span class="dt">data =</span> CASchools, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">pch =</span> <span class="dv">20</span>,
     <span class="dt">cex.main =</span> <span class="fl">0.9</span>,
     <span class="dt">main =</span> <span class="st">&quot;Percentage qualifying for reduced price lunch&quot;</span>)

<span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>calworks, 
     <span class="dt">data =</span> CASchools, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">pch =</span> <span class="dv">20</span>, 
     <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">100</span>),
     <span class="dt">cex.main =</span> <span class="fl">0.9</span>,
     <span class="dt">main =</span> <span class="st">&quot;Percentage qualifying for income assistance&quot;</span>)</code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-303-1.png" width="672" /></p>
<p>We divide the plotting area up using <tt>layout()</tt>. The matrix <tt>m</tt> specifies the location of the plots, see <code>?layout</code>.</p>
<p>We see that all relationships are negative. Here are the correlation coefficients.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate correlation between student characteristics and test scores</span>
<span class="kw">cor</span>(CASchools<span class="op">$</span>score, CASchools<span class="op">$</span>english)</code></pre></div>
<pre><code>## [1] -0.6441238</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(CASchools<span class="op">$</span>score, CASchools<span class="op">$</span>lunch)</code></pre></div>
<pre><code>## [1] -0.868772</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(CASchools<span class="op">$</span>score, CASchools<span class="op">$</span>calworks)</code></pre></div>
<pre><code>## [1] -0.6268533</code></pre>
<p>We shall consider five different model equations:</p>
<span class="math display">\[\begin{align*}
  (I) \quad TestScore=&amp; \, \beta_0 + \beta_1 \times size + u, \\
  (II) \quad TestScore=&amp; \, \beta_0 + \beta_1 \times size + \beta_2 \times english + u, \\
  (III) \quad TestScore=&amp; \, \beta_0 + \beta_1 \times size + \beta_2 \times english + \beta_3 \times lunch + u, \\
  (IV) \quad TestScore=&amp; \, \beta_0 + \beta_1 \times size + \beta_2 \times english + \beta_4 \times calworks + u, \\
  (V) \quad TestScore=&amp; \, \beta_0 + \beta_1 \times size + \beta_2 \times english + \beta_3 \times lunch + \beta_4 \times calworks + u
\end{align*}\]</span>
<p>The best way to communicate regression results is in a table. The <tt>stargazer</tt> package is very convenient for this purpose. It provides a function that generates professionally looking HTML and LaTeX tables that satisfy scientific standards. One simply has to provide one or multiple object(s) of class <tt>lm</tt>. The rest is done by the function <tt>stargazer()</tt>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the stargazer library</span>
<span class="kw">library</span>(stargazer)

<span class="co"># estimate different model specifications</span>
spec1 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size, <span class="dt">data =</span> CASchools)
spec2 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english, <span class="dt">data =</span> CASchools)
spec3 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>lunch, <span class="dt">data =</span> CASchools)
spec4 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>calworks, <span class="dt">data =</span> CASchools)
spec5 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>lunch <span class="op">+</span><span class="st"> </span>calworks, <span class="dt">data =</span> CASchools)

<span class="co"># gather robust standard errors in a list</span>
rob_se &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">vcovHC</span>(spec1, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))),
               <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">vcovHC</span>(spec2, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))),
               <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">vcovHC</span>(spec3, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))),
               <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">vcovHC</span>(spec4, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))),
               <span class="kw">sqrt</span>(<span class="kw">diag</span>(<span class="kw">vcovHC</span>(spec5, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))))

<span class="co"># generate a LaTeX table using stargazer</span>
<span class="kw">stargazer</span>(spec1, spec2, spec3, spec4, spec5,
          <span class="dt">se =</span> rob_se,
          <span class="dt">digits =</span> <span class="dv">3</span>,
          <span class="dt">header =</span> F,
          <span class="dt">column.labels =</span> <span class="kw">c</span>(<span class="st">&quot;(I)&quot;</span>, <span class="st">&quot;(II)&quot;</span>, <span class="st">&quot;(III)&quot;</span>, <span class="st">&quot;(IV)&quot;</span>, <span class="st">&quot;(V)&quot;</span>))</code></pre></div>



<table style="text-align:center"><tr><td colspan="6" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"></td><td colspan="5">Dependent Variable: Test Score</td></tr>
<tr><td></td><td colspan="5" style="border-bottom: 1px solid black"></td></tr>
<tr><td style="text-align:left"></td><td colspan="5">score</td></tr>
<tr><td style="text-align:left"></td><td>(I)</td><td>(II)</td><td>(III)</td><td>(IV)</td><td>(V)</td></tr>
<tr><td style="text-align:left"></td><td>spec1</td><td>spec2</td><td>spec3</td><td>spec4</td><td>spec5</td></tr>
<tr><td colspan="6" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">size</td><td>-2.280<sup>***</sup></td><td>-1.101<sup>**</sup></td><td>-0.998<sup>***</sup></td><td>-1.308<sup>***</sup></td><td>-1.014<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.519)</td><td>(0.433)</td><td>(0.270)</td><td>(0.339)</td><td>(0.269)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">english</td><td></td><td>-0.650<sup>***</sup></td><td>-0.122<sup>***</sup></td><td>-0.488<sup>***</sup></td><td>-0.130<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td></td><td>(0.031)</td><td>(0.033)</td><td>(0.030)</td><td>(0.036)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">lunch</td><td></td><td></td><td>-0.547<sup>***</sup></td><td></td><td>-0.529<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td>(0.024)</td><td></td><td>(0.038)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">calworks</td><td></td><td></td><td></td><td>-0.790<sup>***</sup></td><td>-0.048</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td>(0.068)</td><td>(0.059)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">Constant</td><td>698.933<sup>***</sup></td><td>686.032<sup>***</sup></td><td>700.150<sup>***</sup></td><td>697.999<sup>***</sup></td><td>700.392<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(10.364)</td><td>(8.728)</td><td>(5.568)</td><td>(6.920)</td><td>(5.537)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td colspan="6" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">Observations</td><td>420</td><td>420</td><td>420</td><td>420</td><td>420</td></tr>
<tr><td style="text-align:left">R<sup>2</sup></td><td>0.051</td><td>0.426</td><td>0.775</td><td>0.629</td><td>0.775</td></tr>
<tr><td style="text-align:left">Adjusted R<sup>2</sup></td><td>0.049</td><td>0.424</td><td>0.773</td><td>0.626</td><td>0.773</td></tr>
<tr><td style="text-align:left">Residual Std. Error</td><td>18.581 (df = 418)</td><td>14.464 (df = 417)</td><td>9.080 (df = 416)</td><td>11.654 (df = 416)</td><td>9.084 (df = 415)</td></tr>
<tr><td style="text-align:left">F Statistic</td><td>22.575<sup>***</sup> (df = 1; 418)</td><td>155.014<sup>***</sup> (df = 2; 417)</td><td>476.306<sup>***</sup> (df = 3; 416)</td><td>234.638<sup>***</sup> (df = 3; 416)</td><td>357.054<sup>***</sup> (df = 4; 415)</td></tr>
<tr><td colspan="6" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"><em>Note:</em></td><td colspan="5" style="text-align:right"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>
</table>
<caption><p style='text-align:center'><span id="tab:rotsostracv">Table 7.1: </span> Regressions of Test Scores on the Student-Teacher Ratio and Control Variables</p></caption>


<p>Table <a href="htaciimr.html#tab:rotsostracv">7.1</a> states that <span class="math inline">\(score\)</span> is the dependent variable and that we consider five models. We see that the columns of Table <a href="htaciimr.html#tab:rotsostracv">7.1</a> contain most of the information provided by <tt>coeftest()</tt> and <tt>summary()</tt> for the regression models under consideration: the coefficients estimates equipped with significance codes (the asterisks) and standard errors in parentheses below. Although there are no <span class="math inline">\(t\)</span>-statistics, it is straightforward for the reader to compute them simply by dividing a coefficient estimate by the corresponding standard error. The bottom of the table reports summary statistics for each model and a legend. For an in-depth discussion of the tabular presentation of regression results, see Chapter 7.6 of the book.</p>
<p>What can we conclude from the model comparison?</p>
<ol style="list-style-type: decimal">
<li><p>We see that adding control variables roughly halves the coefficient on <tt>size</tt>. Also, the estimate is not sensitive to the set of control variables used. The conclusion is that decreasing the student-teacher ratio ceteris paribus by one unit leads to an estimated average increase in test scores of about <span class="math inline">\(1\)</span> point.</p></li>
<li><p>Adding student characteristics as controls increases <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\bar{R}^2\)</span> from <span class="math inline">\(0.049\)</span> (<tt>spec1</tt>) up to <span class="math inline">\(0.773\)</span> (<tt>spec3</tt> and <tt>spec5</tt>), so we can consider these variables as suitable predictors for test scores. Moreover, the estimated coefficients on all control variables are consistent with the impressions gained from Figure 7.2 of the book.</p></li>
<li><p>We see that the control variables are not statistically significant in all models. For example in <tt>spec5</tt>, the coefficient on <span class="math inline">\(calworks\)</span> is not significantly different from zero at <span class="math inline">\(5\%\)</span> since <span class="math inline">\(\lvert-0.048/0.059\rvert=0.81 &lt; 1.64\)</span>. We also observe that the effect on the estimate (and its standard error) of the coefficient on <span class="math inline">\(size\)</span> of adding <span class="math inline">\(calworks\)</span> to the base specification <tt>spec3</tt> is negligible. We can therefore consider <tt>calworks</tt> as a superfluous control variable, given the inclusion of <tt>lunch</tt> in this model.</p></li>
</ol>
</div>
<div id="exercises-5" class="section level2">
<h2><span class="header-section-number">7.7</span> Exercises</h2>
<div class="DCexercise">
<h4 id="hypothesis-testing-in-a-multiple-regression-model-t-statistics-and-p-values" class="unnumbered">1. Hypothesis Testing in a Multiple Regression Model — <span class="math inline">\(t\)</span>-statistics and <span class="math inline">\(p\)</span>-values</h4>
<p>Reconsider the <tt>Boston</tt> data set and the following estimated model (homoscedasticity-only standard errors in parentheses) from the previous chapter:</p>
<p><span class="math display">\[\widehat{medv}_i = \underset{(0.75)}{32.828} -\underset{(0.05)}{0.994} \times lstat_i -\underset{(0.04)}{0.083} \times crim_i + \underset{(0.01)}{0.038} \times age_i.\]</span></p>
<p>Just as in the simple linear regression framework we can conduct hypothesis tests about the coefficients in multiple regression models. The most common hypothesis is <span class="math inline">\(H_0:\beta_j=0\)</span> against the alternative <span class="math inline">\(H_1:\beta_j\ne 0\)</span> for some <span class="math inline">\(j\)</span> in <span class="math inline">\(0,1,\dots,k\)</span>.</p>
<p>The packages <tt>AER</tt> and <tt>MASS</tt> have been loaded. The coefficient estimates as well as the corresponding standard errors are available in <tt>coefs</tt> and <tt>SEs</tt>, respectively.</p>
<p><strong>Instructions:</strong></p>
<p>Use vector arithmetics to solve the following tasks:</p>
<ul>
<li><p>Compute <span class="math inline">\(t\)</span>-statistics for each coefficient by using the predefined objects <tt>coefs</tt> and <tt>SEs</tt>. Assign them to <tt>tstats</tt>.</p></li>
<li><p>Compute <span class="math inline">\(p\)</span>-values for each coefficient and assign them to <tt>pval</tt>.</p></li>
<li><p>Check with the help of logical operators whether the hypotheses are rejected at the <span class="math inline">\(1\%\)</span> significance level.</p></li>
</ul>
<iframe src="DCL/ex7_1.html" frameborder="0" scrolling="no" style="width:100%;height:340px">
</iframe>
<p><strong>Hints:</strong></p>
<ul>
<li><p>The <span class="math inline">\(t\)</span>-statistic for each coefficient is defined as <span class="math inline">\(t=\frac{\widehat{\beta}_j-\beta_{j,0}}{SE(\widehat{\beta}_j)}\)</span>.</p></li>
<li><p>The <span class="math inline">\(p\)</span>-value for a two-sided test using is computed as <span class="math inline">\(2\cdot\Phi(-|t^{act}|)\)</span> where <span class="math inline">\(t^{act}\)</span> denotes the computed <span class="math inline">\(t\)</span>-statistic.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="hypothesis-testing-in-a-multiple-regression-model---confidence-intervals" class="unnumbered">2. Hypothesis Testing in a Multiple Regression Model - Confidence Intervals</h4>
<p>Consider again the estimated model</p>
<p><span class="math display">\[\widehat{medv}_i = \underset{(0.75)}{32.828} -\underset{(0.05)}{0.994} \times lstat_i -\underset{(0.04)}{0.083} \times crim_i + \underset{(0.01)}{0.038} \times age_i.\]</span></p>
<p>which is available as the object <tt>mod</tt> in your working environment. The packages <tt>AER</tt> and <tt>MASS</tt> have been loaded.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li>Construct <span class="math inline">\(99\%\)</span> confidence intervals for all model coefficients. Use the intervals to decide whether the individual null hypotheses <span class="math inline">\(H_0:\beta_j=0\)</span>, <span class="math inline">\(j=0,1,2,3,4\)</span> are rejected at the <span class="math inline">\(1\%\)</span> level.</li>
</ul>
<iframe src="DCL/ex7_2.html" frameborder="0" scrolling="no" style="width:100%;height:340px">
</iframe>
<p><strong>Hint:</strong></p>
<ul>
<li>You may use <tt>confint()</tt> to construct confidence intervals. The confidence level can be set via the argument <tt>level</tt>.</li>
</ul>
</div>
<div class="DCexercise">
<h4 id="robust-hypothesis-testing-in-multiple-regression-models" class="unnumbered">3. Robust Hypothesis Testing in Multiple Regression Models</h4>
<p>The <tt>lm</tt> object <tt>mod</tt> from the previous exercises is available in your working environment. The packages <tt>AER</tt> and <tt>MASS</tt> have been loaded.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Print a coefficient summary that reports heteroscedasticity-robust standard errors.</p></li>
<li><p>Access entries of the matrix generated by <tt>coeftest()</tt> to check whether the hypotheses are rejected at a 1% significance level. Use logical operators <tt>&lt;,&gt;</tt>.</p></li>
</ul>
<iframe src="DCL/ex7_3.html" frameborder="0" scrolling="no" style="width:100%;height:340px">
</iframe>
<p><strong>Hints:</strong></p>
<ul>
<li><p>Using the argument <tt>vcov.</tt> in <tt>coeftest()</tt> forces the function to use robust standard errors.</p></li>
<li><p>The <span class="math inline">\(p\)</span>-values are contained in the fourth column of the output generated by <tt>coeftest()</tt>. Use square brackets to subset the matrix accordingly.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="joint-hypothesis-testing-f-test-i" class="unnumbered">4. Joint Hypothesis Testing — <span class="math inline">\(F\)</span>-Test I</h4>
<p>Sometimes we are interested in testing joint hypotheses which impose restrictions on <em>multiple</em> regression coefficients. For example, in the model</p>
<p><span class="math display">\[medv_i = \beta_0 + \beta_1\times lstat_i + \beta_2\times crim_i + \beta_3\times age_i + u_i\]</span></p>
<p>we may test the null <span class="math inline">\(H_0: \beta_2=\beta_3\)</span> vs. the alternative <span class="math inline">\(H_1: \beta_2\ne\beta_3\)</span> (which is a joint hypothesis as we impose a restriction on <em>two</em> regression coefficients).</p>
<p>The basic idea behind testing such a hypothesis is to conduct two regressions and to compare the outcomes: for one of the regressions we impose the restrictions of formalized by the null (we call this the restricted regression model), whereas for the other regression the restriction is left out (we call this the unrestricted model). From this starting point we construct a test-statistic which, under the null, follows a well known distribution, an <span class="math inline">\(F\)</span> distribution (see the next exercise).</p>
<p>However, in this exercise we start with the initial computations necessary to construct the test statistic.</p>
<p>The packages <tt>AER</tt> and <tt>MASS</tt> have been loaded.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Estimate the restricted model, that is, the model where the restriction formalized by <span class="math inline">\(H_0: \beta_2=\beta_3\)</span> is assumed to be true. Save the model in <tt>model_res</tt>.</p></li>
<li><p>Compute the <span class="math inline">\(SSR\)</span> of the restricted model and assign it to <tt>RSSR</tt>.</p></li>
<li><p>Estimate the unrestricted model, that is, the model where the restriction is assumed to be false. Save it in <tt>model_unres</tt>.</p></li>
<li><p>Compute the <span class="math inline">\(SSR\)</span> of the unrestricted model and assign it to <tt>USSR</tt>.</p></li>
</ul>
<iframe src="DCL/ex7_4.html" frameborder="0" scrolling="no" style="width:100%;height:340px">
</iframe>
<p><strong>Hints:</strong></p>
<ul>
<li><p>The restricted model can be written as <span class="math display">\[medv_i = \beta_0 + \beta_1\times lstat_i + \beta_2\times crim_i + \beta_2\times age_i + u_i\]</span> which, after rearranging, can be expressed as <span class="math display">\[medv_i = \beta_0 + \beta_1\times lstat_i + \beta_2\times(crim_i+age_i) + u_i.\]</span></p></li>
<li><p>The <span class="math inline">\(SSR\)</span> is defined as the sum of the squared residuals.</p></li>
<li><p>Note that the residuals of a regression model are available as <tt>residuals</tt> in the corresponding <tt>lm</tt> object. So you can access them as usual via the <tt>$</tt>-operator.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="joint-hypothesis-testing-f-test-ii" class="unnumbered">5. Joint Hypothesis Testing — F-Test II</h4>
<p>After estimating the models and computing the <span class="math inline">\(SSR\)</span>s you now have to compute the test-statistic and conduct the <span class="math inline">\(F\)</span>-test. As mentioned in the last exercise, the test-statistic follows an <span class="math inline">\(F\)</span> distribution. More precisely, we deal with the <span class="math inline">\(F_{q,n-k-1}\)</span> distribution where <span class="math inline">\(q\)</span> denotes the number of restrictions under the null and <span class="math inline">\(k\)</span> is the of regressors in the unrestricted model, excluding the intercept.</p>
<p>The packages <tt>AER</tt> and <tt>MASS</tt> have been loaded. Both models (<tt>model_res</tt> and <tt>model_unres</tt>) as well as their SSR (<tt>RSSR</tt> and <tt>USSR</tt>) are available in your working environment.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Compute the <span class="math inline">\(F\)</span>-statistic and assign it to <tt>Fstat</tt>.</p></li>
<li><p>Compute the <span class="math inline">\(p\)</span>-value and assign it to <tt>pval</tt>.</p></li>
<li><p>Check whether the null is rejected at the <span class="math inline">\(1\%\)</span> level using logical operators.</p></li>
<li><p>Verify your result by using <tt>linearHypothesis()</tt> and printing the results.</p></li>
</ul>
<iframe src="DCL/ex7_5.html" frameborder="0" scrolling="no" style="width:100%;height:340px">
</iframe>
<p><strong>Hints:</strong></p>
<ul>
<li><p>The <span class="math inline">\(F\)</span>-statistic is defined as <span class="math inline">\(\frac{RSSR-USSR/q}{USSR/(n-k-1)}\)</span>.</p></li>
<li><p>The <span class="math inline">\(p\)</span>-value can be computed as <span class="math inline">\(1-F_{q,n-k-1}(F^{act})\)</span> where <span class="math inline">\(F_{q,n-k-1}\)</span> denotes the CDF of the <span class="math inline">\(F\)</span>-distribution (<tt>pf()</tt>) with degrees of freedom <span class="math inline">\(q\)</span> and <span class="math inline">\(n-k-1\)</span> and <span class="math inline">\(F^{act}\)</span> the computed <span class="math inline">\(F\)</span>-statistic.</p></li>
<li><p><tt>linearHypothesis()</tt> expects the unrestricted model as well as the null hypothesis as arguments.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="joint-hypothesis-testing---confidence-set" class="unnumbered">6. Joint Hypothesis Testing - Confidence Set</h4>
<p>As you know from previous chapters constructing a confidence set for a single regression coefficient results in a simple confidence interval on the real line. However if we consider <span class="math inline">\(n\)</span> regression coefficients jointly (as we do in a joint hypothesis testing setting) we move from <span class="math inline">\(\mathbb{R}\)</span> to <span class="math inline">\(\mathbb{R}^n\)</span> resulting in a n-dimensional confidence set. For the sake of illustration we then often choose <span class="math inline">\(n=2\)</span>, so that we end up with a representable two-dimensional plane.</p>
<p>Recall the estimated model</p>
<p><span class="math display">\[\widehat{medv}_i = \underset{(0.75)}{32.828} -\underset{(0.05)}{0.994} \times lstat_i -\underset{(0.04)}{0.083} \times crim_i + \underset{(0.01)}{0.038} \times age_i.\]</span></p>
<p>which is available as <tt>mod</tt> in your working environment. Assume you want to test the null <span class="math inline">\(H_0: \beta_2=\beta_3=0\)</span> vs. <span class="math inline">\(H_1: \beta_2\ne 0\)</span> or <span class="math inline">\(\beta_3\ne 0\)</span>.</p>
<p>The packages <tt>AER</tt> and <tt>MASS</tt> have been loaded.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Construct a <span class="math inline">\(99\%\)</span> confidence set for the coefficients of <tt>crim</tt> and <tt>lstat</tt>, that is a two-dimensional confidence set. Can you reject the null stated above?</p></li>
<li><p>Verify your visual inspection by conducting a corresponding <span class="math inline">\(F\)</span>-test.</p></li>
</ul>
<iframe src="DCL/ex7_6.html" frameborder="0" scrolling="no" style="width:100%;height:340px">
</iframe>
<p><strong>Hints:</strong></p>
<ul>
<li><p>Use <tt>confidenceEllipse()</tt> to construct a two-dimensional confidence set. Besides the coefficients for which the confidence set shall be constructed (<tt>which.coef</tt>), you have to specify the confidence level (<tt>levels</tt>).</p></li>
<li><p>As usual you can use <tt>linearHypothesis()</tt> to conduct the <span class="math inline">\(F\)</span>-test. Note that there are two restrictions now, hence you have to pass a vector containing both restrictions.</p></li>
</ul>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-AER">
<p>Kleiber, C., &amp; Zeileis, A. (2017). AER: Applied Econometrics with R (Version 1.2-5). Retrieved from <a href="https://CRAN.R-project.org/package=AER" class="uri">https://CRAN.R-project.org/package=AER</a></p>
</div>
<div id="ref-R-stargazer">
<p>Hlavac, M. (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables (Version 5.2.2). Retrieved from <a href="https://CRAN.R-project.org/package=stargazer" class="uri">https://CRAN.R-project.org/package=stargazer</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rmwmr.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nrf.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": true,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 1
},
"edit": null,
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
