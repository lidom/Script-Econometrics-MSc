<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.4 Heteroskedasticity and Homoskedasticity | Advanced Regression Analysis</title>
  <meta name="description" content="4.4 Heteroskedasticity and Homoskedasticity | Advanced Regression Analysis" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="4.4 Heteroskedasticity and Homoskedasticity | Advanced Regression Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/mylogo.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.4 Heteroskedasticity and Homoskedasticity | Advanced Regression Analysis" />
  
  
  <meta name="twitter:image" content="images/mylogo.png" />

<meta name="author" content="Dominik Liebl" />


<meta name="date" content="2020-09-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="4-3-rwxiabv.html"/>
<link rel="next" href="4-5-the-gauss-markov-theorem.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><a href="https://www.example.com/"><img src="images/mylogo.png" alt="logo" width="100%" height="100%"style="margin: 15px 0 0 0"></a></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="0-1-a-very-short-introduction-to-r-and-rstudio.html"><a href="0-1-a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>0.1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-pt.html"><a href="1-pt.html"><i class="fa fa-check"></i><b>1</b> Probability Theory</a><ul>
<li class="chapter" data-level="1.1" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>1.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-2-RSATDOSA.html"><a href="1-2-RSATDOSA.html"><i class="fa fa-check"></i><b>1.2</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="1-2-RSATDOSA.html"><a href="1-2-RSATDOSA.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="1-2-RSATDOSA.html"><a href="1-2-RSATDOSA.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-3-exercises-2.html"><a href="1-3-exercises-2.html"><i class="fa fa-check"></i><b>1.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-arosur.html"><a href="2-arosur.html"><i class="fa fa-check"></i><b>2</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="2.1" data-path="2-1-estimation-of-the-population-mean.html"><a href="2-1-estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>2.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="2.2" data-path="2-2-potsm.html"><a href="2-2-potsm.html"><i class="fa fa-check"></i><b>2.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="2.3" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>2.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-4-confidence-intervals-for-the-population-mean.html"><a href="2-4-confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>2.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="2.5" data-path="2-5-cmfdp.html"><a href="2-5-cmfdp.html"><i class="fa fa-check"></i><b>2.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="2.6" data-path="2-6-aattggoe.html"><a href="2-6-aattggoe.html"><i class="fa fa-check"></i><b>2.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="2.7" data-path="2-7-scatterplots-sample-covariance-and-sample-correlation.html"><a href="2-7-scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>2.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="2.8" data-path="2-8-exercises-3.html"><a href="2-8-exercises-3.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-lrwor.html"><a href="3-lrwor.html"><i class="fa fa-check"></i><b>3</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="3.1" data-path="3-1-simple-linear-regression.html"><a href="3-1-simple-linear-regression.html"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="3.2" data-path="3-2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="3-2-estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>3.2</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="3-2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="3-2-estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-3-measures-of-fit.html"><a href="3-3-measures-of-fit.html"><i class="fa fa-check"></i><b>3.3</b> Measures of Fit</a><ul>
<li class="chapter" data-level="" data-path="3-3-measures-of-fit.html"><a href="3-3-measures-of-fit.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="3-3-measures-of-fit.html"><a href="3-3-measures-of-fit.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="3-3-measures-of-fit.html"><a href="3-3-measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-4-tlsa.html"><a href="3-4-tlsa.html"><i class="fa fa-check"></i><b>3.4</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="3-4-tlsa.html"><a href="3-4-tlsa.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="3-4-tlsa.html"><a href="3-4-tlsa.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="3-4-tlsa.html"><a href="3-4-tlsa.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-5-tsdotoe.html"><a href="3-5-tsdotoe.html"><i class="fa fa-check"></i><b>3.5</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="3-5-tsdotoe.html"><a href="3-5-tsdotoe.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="3-5-tsdotoe.html"><a href="3-5-tsdotoe.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="3-5-tsdotoe.html"><a href="3-5-tsdotoe.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3-6-exercises-4.html"><a href="3-6-exercises-4.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-htaciitslrm.html"><a href="4-htaciitslrm.html"><i class="fa fa-check"></i><b>4</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="4.1" data-path="4-1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="4-1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>4.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="4.2" data-path="4-2-cifrc.html"><a href="4-2-cifrc.html"><i class="fa fa-check"></i><b>4.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="4-2-cifrc.html"><a href="4-2-cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-3-rwxiabv.html"><a href="4-3-rwxiabv.html"><i class="fa fa-check"></i><b>4.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="4.4" data-path="4-4-hah.html"><a href="4-4-hah.html"><i class="fa fa-check"></i><b>4.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="4-4-hah.html"><a href="4-4-hah.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="4-4-hah.html"><a href="4-4-hah.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="4-4-hah.html"><a href="4-4-hah.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-5-the-gauss-markov-theorem.html"><a href="4-5-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>4.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="4-5-the-gauss-markov-theorem.html"><a href="4-5-the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4-6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="4-6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>4.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="4.7" data-path="4-7-exercises-5.html"><a href="4-7-exercises-5.html"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-rmwmr.html"><a href="5-rmwmr.html"><i class="fa fa-check"></i><b>5</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="5.1" data-path="5-1-omitted-variable-bias.html"><a href="5-1-omitted-variable-bias.html"><i class="fa fa-check"></i><b>5.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="5.2" data-path="5-2-tmrm.html"><a href="5-2-tmrm.html"><i class="fa fa-check"></i><b>5.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="5.3" data-path="5-3-mofimr.html"><a href="5-3-mofimr.html"><i class="fa fa-check"></i><b>5.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="5.4" data-path="5-4-ols-assumptions-in-multiple-regression.html"><a href="5-4-ols-assumptions-in-multiple-regression.html"><i class="fa fa-check"></i><b>5.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="5-4-ols-assumptions-in-multiple-regression.html"><a href="5-4-ols-assumptions-in-multiple-regression.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="5-4-ols-assumptions-in-multiple-regression.html"><a href="5-4-ols-assumptions-in-multiple-regression.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="5-5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><a href="5-5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><i class="fa fa-check"></i><b>5.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="5.6" data-path="5-6-exercises-6.html"><a href="5-6-exercises-6.html"><i class="fa fa-check"></i><b>5.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-htaciimr.html"><a href="6-htaciimr.html"><i class="fa fa-check"></i><b>6</b> Hypothesis Tests and Confidence Intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="6-1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><a href="6-1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><i class="fa fa-check"></i><b>6.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="6.2" data-path="6-2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="6-2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>6.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="6-2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="6-2-an-application-to-test-scores-and-the-student-teacher-ratio.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-3-joint-hypothesis-testing-using-the-f-statistic.html"><a href="6-3-joint-hypothesis-testing-using-the-f-statistic.html"><i class="fa fa-check"></i><b>6.3</b> Joint Hypothesis Testing Using the F-Statistic</a></li>
<li class="chapter" data-level="6.4" data-path="6-4-confidence-sets-for-multiple-coefficients.html"><a href="6-4-confidence-sets-for-multiple-coefficients.html"><i class="fa fa-check"></i><b>6.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="6.5" data-path="6-5-model-specification-for-multiple-regression.html"><a href="6-5-model-specification-for-multiple-regression.html"><i class="fa fa-check"></i><b>6.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="6-5-model-specification-for-multiple-regression.html"><a href="6-5-model-specification-for-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="6-6-analysis-of-the-test-score-data-set.html"><a href="6-6-analysis-of-the-test-score-data-set.html"><i class="fa fa-check"></i><b>6.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="6.7" data-path="6-7-exercises-7.html"><a href="6-7-exercises-7.html"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-nrf.html"><a href="7-nrf.html"><i class="fa fa-check"></i><b>7</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="7.1" data-path="7-1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><a href="7-1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>7.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="7.2" data-path="7-2-nfoasiv.html"><a href="7-2-nfoasiv.html"><i class="fa fa-check"></i><b>7.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="7-2-nfoasiv.html"><a href="7-2-nfoasiv.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="7-2-nfoasiv.html"><a href="7-2-nfoasiv.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-3-interactions-between-independent-variables.html"><a href="7-3-interactions-between-independent-variables.html"><i class="fa fa-check"></i><b>7.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="7.4" data-path="7-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="7-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>7.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
<li class="chapter" data-level="7.5" data-path="7-5-exercises-8.html"><a href="7-5-exercises-8.html"><i class="fa fa-check"></i><b>7.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-asbomr.html"><a href="8-asbomr.html"><i class="fa fa-check"></i><b>8</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="8.1" data-path="8-1-internal-and-external-validity.html"><a href="8-1-internal-and-external-validity.html"><i class="fa fa-check"></i><b>8.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="8.2" data-path="8-2-ttivomra.html"><a href="8-2-ttivomra.html"><i class="fa fa-check"></i><b>8.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="8.3" data-path="8-3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><a href="8-3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><i class="fa fa-check"></i><b>8.3</b> Internal and External Validity when the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="8.4" data-path="8-4-etsacs.html"><a href="8-4-etsacs.html"><i class="fa fa-check"></i><b>8.4</b> Example: Test Scores and Class Size</a></li>
<li class="chapter" data-level="8.5" data-path="8-5-exercises-9.html"><a href="8-5-exercises-9.html"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-rwpd.html"><a href="9-rwpd.html"><i class="fa fa-check"></i><b>9</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="9.1" data-path="9-1-panel-data.html"><a href="9-1-panel-data.html"><i class="fa fa-check"></i><b>9.1</b> Panel Data</a></li>
<li class="chapter" data-level="9.2" data-path="9-2-PDWTTP.html"><a href="9-2-PDWTTP.html"><i class="fa fa-check"></i><b>9.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="9.3" data-path="9-3-fixed-effects-regression.html"><a href="9-3-fixed-effects-regression.html"><i class="fa fa-check"></i><b>9.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="9-3-fixed-effects-regression.html"><a href="9-3-fixed-effects-regression.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="9-3-fixed-effects-regression.html"><a href="9-3-fixed-effects-regression.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-4-regression-with-time-fixed-effects.html"><a href="9-4-regression-with-time-fixed-effects.html"><i class="fa fa-check"></i><b>9.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="9.5" data-path="9-5-tferaaseffer.html"><a href="9-5-tferaaseffer.html"><i class="fa fa-check"></i><b>9.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="9.6" data-path="9-6-drunk-driving-laws-and-traffic-deaths.html"><a href="9-6-drunk-driving-laws-and-traffic-deaths.html"><i class="fa fa-check"></i><b>9.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
<li class="chapter" data-level="9.7" data-path="9-7-exercises-10.html"><a href="9-7-exercises-10.html"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-rwabdv.html"><a href="10-rwabdv.html"><i class="fa fa-check"></i><b>10</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="10.1" data-path="10-1-binary-dependent-variables-and-the-linear-probability-model.html"><a href="10-1-binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>10.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="10.2" data-path="10-2-palr.html"><a href="10-2-palr.html"><i class="fa fa-check"></i><b>10.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="10-2-palr.html"><a href="10-2-palr.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="10-2-palr.html"><a href="10-2-palr.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10-3-estimation-and-inference-in-the-logit-and-probit-models.html"><a href="10-3-estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>10.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="10.4" data-path="10-4-application-to-the-boston-hmda-data.html"><a href="10-4-application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>10.4</b> Application to the Boston HMDA Data</a></li>
<li class="chapter" data-level="10.5" data-path="10-5-exercises-11.html"><a href="10-5-exercises-11.html"><i class="fa fa-check"></i><b>10.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-ivr.html"><a href="11-ivr.html"><i class="fa fa-check"></i><b>11</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="11.1" data-path="11-1-TIVEWASRAASI.html"><a href="11-1-TIVEWASRAASI.html"><i class="fa fa-check"></i><b>11.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="11.2" data-path="11-2-TGIVRM.html"><a href="11-2-TGIVRM.html"><i class="fa fa-check"></i><b>11.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="11.3" data-path="11-3-civ.html"><a href="11-3-civ.html"><i class="fa fa-check"></i><b>11.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="11.4" data-path="11-4-attdfc.html"><a href="11-4-attdfc.html"><i class="fa fa-check"></i><b>11.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="11.5" data-path="11-5-where-do-valid-instruments-come-from.html"><a href="11-5-where-do-valid-instruments-come-from.html"><i class="fa fa-check"></i><b>11.5</b> Where Do Valid Instruments Come From?</a></li>
<li class="chapter" data-level="11.6" data-path="11-6-exercises-12.html"><a href="11-6-exercises-12.html"><i class="fa fa-check"></i><b>11.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-eaqe.html"><a href="12-eaqe.html"><i class="fa fa-check"></i><b>12</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="12.1" data-path="12-1-poceaie.html"><a href="12-1-poceaie.html"><i class="fa fa-check"></i><b>12.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="12.2" data-path="12-2-threats-to-validity-of-experiments.html"><a href="12-2-threats-to-validity-of-experiments.html"><i class="fa fa-check"></i><b>12.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="12.3" data-path="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><i class="fa fa-check"></i><b>12.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="12-4-qe.html"><a href="12-4-qe.html"><i class="fa fa-check"></i><b>12.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="12-4-qe.html"><a href="12-4-qe.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="12-4-qe.html"><a href="12-4-qe.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="12-5-exercises-13.html"><a href="12-5-exercises-13.html"><i class="fa fa-check"></i><b>12.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-ittsraf.html"><a href="13-ittsraf.html"><i class="fa fa-check"></i><b>13</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="13.1" data-path="13-1-using-regression-models-for-forecasting.html"><a href="13-1-using-regression-models-for-forecasting.html"><i class="fa fa-check"></i><b>13.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="13.2" data-path="13-2-tsdasc.html"><a href="13-2-tsdasc.html"><i class="fa fa-check"></i><b>13.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="13-2-tsdasc.html"><a href="13-2-tsdasc.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="13-3-autoregressions.html"><a href="13-3-autoregressions.html"><i class="fa fa-check"></i><b>13.3</b> Autoregressions</a><ul>
<li><a href="13-3-autoregressions.html#autoregressive-models-of-order-p">Autoregressive Models of Order <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="13-4-cybtmpi.html"><a href="13-4-cybtmpi.html"><i class="fa fa-check"></i><b>13.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="13.5" data-path="13-5-apatadlm.html"><a href="13-5-apatadlm.html"><i class="fa fa-check"></i><b>13.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="13-5-apatadlm.html"><a href="13-5-apatadlm.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="13-6-llsuic.html"><a href="13-6-llsuic.html"><i class="fa fa-check"></i><b>13.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="13.7" data-path="13-7-nit.html"><a href="13-7-nit.html"><i class="fa fa-check"></i><b>13.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="13.8" data-path="13-8-niib.html"><a href="13-8-niib.html"><i class="fa fa-check"></i><b>13.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="13.9" data-path="13-9-can-you-beat-the-market-part-ii.html"><a href="13-9-can-you-beat-the-market-part-ii.html"><i class="fa fa-check"></i><b>13.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-eodce.html"><a href="14-eodce.html"><i class="fa fa-check"></i><b>14</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="14.1" data-path="14-1-the-orange-juice-data.html"><a href="14-1-the-orange-juice-data.html"><i class="fa fa-check"></i><b>14.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="14.2" data-path="14-2-dynamic-causal-effects.html"><a href="14-2-dynamic-causal-effects.html"><i class="fa fa-check"></i><b>14.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="14.3" data-path="14-3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><a href="14-3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><i class="fa fa-check"></i><b>14.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="14.4" data-path="14-4-hac-standard-errors.html"><a href="14-4-hac-standard-errors.html"><i class="fa fa-check"></i><b>14.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="14.5" data-path="14-5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><a href="14-5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><i class="fa fa-check"></i><b>14.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="14.6" data-path="14-6-orange-juice-prices-and-cold-weather.html"><a href="14-6-orange-juice-prices-and-cold-weather.html"><i class="fa fa-check"></i><b>14.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-atitsr.html"><a href="15-atitsr.html"><i class="fa fa-check"></i><b>15</b> Additional Topics in Time Series Regression</a><ul>
<li class="chapter" data-level="15.1" data-path="15-1-vector-autoregressions.html"><a href="15-1-vector-autoregressions.html"><i class="fa fa-check"></i><b>15.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="15.2" data-path="15-2-ooiatdfglsurt.html"><a href="15-2-ooiatdfglsurt.html"><i class="fa fa-check"></i><b>15.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="15.3" data-path="15-3-cointegration.html"><a href="15-3-cointegration.html"><i class="fa fa-check"></i><b>15.3</b> Cointegration</a></li>
<li class="chapter" data-level="15.4" data-path="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><i class="fa fa-check"></i><b>15.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a><ul>
<li class="chapter" data-level="" data-path="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
<li class="chapter" data-level="" data-path="7-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="7-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Regression Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hah" class="section level2">
<h2><span class="header-section-number">4.4</span> Heteroskedasticity and Homoskedasticity</h2>
<p>All inference made in the previous chapters relies on the assumption that the error variance does not vary as regressor values change. But this will often not be the case in empirical applications.</p>
<div id="KC5.4" class="keyconcept">
<h3 class="right">
Key Concept 5.4
</h3>
<h3 class="left">
Heteroskedasticity and Homoskedasticity
</h3>
<ul>
<li><p>The error term of our regression model is homoskedastic if the variance of the conditional distribution of <span class="math inline">\(u_i\)</span> given <span class="math inline">\(X_i\)</span>, <span class="math inline">\(Var(u_i|X_i=x)\)</span>, is constant <em>for all</em> observations in our sample:
<span class="math display">\[ \text{Var}(u_i|X_i=x) = \sigma^2 \ \forall \ i=1,\dots,n. \]</span></p></li>
<li><p>If instead there is dependence of the conditional variance of <span class="math inline">\(u_i\)</span> on <span class="math inline">\(X_i\)</span>, the error term is said to be heteroskedastic. We then write
<span class="math display">\[ \text{Var}(u_i|X_i=x) = \sigma_i^2 \ \forall \ i=1,\dots,n. \]</span></p></li>
<li>Homoskedasticity is a <em>special case</em> of heteroskedasticity.</li>
</ul>
</div>
<p>For a better understanding of heteroskedasticity, we generate some bivariate heteroskedastic data, estimate a linear regression model and then use box plots to depict the conditional distributions of the residuals.</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" data-line-number="1"><span class="co"># load scales package for adjusting color opacities</span></a>
<a class="sourceLine" id="cb122-2" data-line-number="2"><span class="kw">library</span>(scales)</a>
<a class="sourceLine" id="cb122-3" data-line-number="3"></a>
<a class="sourceLine" id="cb122-4" data-line-number="4"><span class="co"># generate some heteroskedastic data:</span></a>
<a class="sourceLine" id="cb122-5" data-line-number="5"></a>
<a class="sourceLine" id="cb122-6" data-line-number="6"><span class="co"># set seed for reproducibility</span></a>
<a class="sourceLine" id="cb122-7" data-line-number="7"><span class="kw">set.seed</span>(<span class="dv">123</span>) </a>
<a class="sourceLine" id="cb122-8" data-line-number="8"></a>
<a class="sourceLine" id="cb122-9" data-line-number="9"><span class="co"># set up vector of x coordinates</span></a>
<a class="sourceLine" id="cb122-10" data-line-number="10">x &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>), <span class="dt">each =</span> <span class="dv">25</span>)</a>
<a class="sourceLine" id="cb122-11" data-line-number="11"></a>
<a class="sourceLine" id="cb122-12" data-line-number="12"><span class="co"># initialize vector of errors</span></a>
<a class="sourceLine" id="cb122-13" data-line-number="13">e &lt;-<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb122-14" data-line-number="14"></a>
<a class="sourceLine" id="cb122-15" data-line-number="15"><span class="co"># sample 100 errors such that the variance increases with x</span></a>
<a class="sourceLine" id="cb122-16" data-line-number="16">e[<span class="dv">1</span><span class="op">:</span><span class="dv">25</span>] &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">25</span>, <span class="dt">sd =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb122-17" data-line-number="17">e[<span class="dv">26</span><span class="op">:</span><span class="dv">50</span>] &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">25</span>, <span class="dt">sd =</span> <span class="dv">15</span>)</a>
<a class="sourceLine" id="cb122-18" data-line-number="18">e[<span class="dv">51</span><span class="op">:</span><span class="dv">75</span>] &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">25</span>, <span class="dt">sd =</span> <span class="dv">20</span>)</a>
<a class="sourceLine" id="cb122-19" data-line-number="19">e[<span class="dv">76</span><span class="op">:</span><span class="dv">100</span>] &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">25</span>, <span class="dt">sd =</span> <span class="dv">25</span>)</a>
<a class="sourceLine" id="cb122-20" data-line-number="20"></a>
<a class="sourceLine" id="cb122-21" data-line-number="21"><span class="co"># set up y</span></a>
<a class="sourceLine" id="cb122-22" data-line-number="22">y &lt;-<span class="st"> </span><span class="dv">720</span> <span class="op">-</span><span class="st"> </span><span class="fl">3.3</span> <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>e</a>
<a class="sourceLine" id="cb122-23" data-line-number="23"></a>
<a class="sourceLine" id="cb122-24" data-line-number="24"><span class="co"># Estimate the model </span></a>
<a class="sourceLine" id="cb122-25" data-line-number="25">mod &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x)</a>
<a class="sourceLine" id="cb122-26" data-line-number="26"></a>
<a class="sourceLine" id="cb122-27" data-line-number="27"><span class="co"># Plot the data</span></a>
<a class="sourceLine" id="cb122-28" data-line-number="28"><span class="kw">plot</span>(<span class="dt">x =</span> x, </a>
<a class="sourceLine" id="cb122-29" data-line-number="29">     <span class="dt">y =</span> y, </a>
<a class="sourceLine" id="cb122-30" data-line-number="30">     <span class="dt">main =</span> <span class="st">&quot;An Example of Heteroskedasticity&quot;</span>,</a>
<a class="sourceLine" id="cb122-31" data-line-number="31">     <span class="dt">xlab =</span> <span class="st">&quot;Student-Teacher Ratio&quot;</span>,</a>
<a class="sourceLine" id="cb122-32" data-line-number="32">     <span class="dt">ylab =</span> <span class="st">&quot;Test Score&quot;</span>,</a>
<a class="sourceLine" id="cb122-33" data-line-number="33">     <span class="dt">cex =</span> <span class="fl">0.5</span>, </a>
<a class="sourceLine" id="cb122-34" data-line-number="34">     <span class="dt">pch =</span> <span class="dv">19</span>, </a>
<a class="sourceLine" id="cb122-35" data-line-number="35">     <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">8</span>, <span class="dv">27</span>), </a>
<a class="sourceLine" id="cb122-36" data-line-number="36">     <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">600</span>, <span class="dv">710</span>))</a>
<a class="sourceLine" id="cb122-37" data-line-number="37"></a>
<a class="sourceLine" id="cb122-38" data-line-number="38"><span class="co"># Add the regression line to the plot</span></a>
<a class="sourceLine" id="cb122-39" data-line-number="39"><span class="kw">abline</span>(mod, <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>)</a>
<a class="sourceLine" id="cb122-40" data-line-number="40"></a>
<a class="sourceLine" id="cb122-41" data-line-number="41"><span class="co"># Add boxplots to the plot</span></a>
<a class="sourceLine" id="cb122-42" data-line-number="42"><span class="kw">boxplot</span>(<span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x, </a>
<a class="sourceLine" id="cb122-43" data-line-number="43">        <span class="dt">add =</span> <span class="ot">TRUE</span>, </a>
<a class="sourceLine" id="cb122-44" data-line-number="44">        <span class="dt">at =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>), </a>
<a class="sourceLine" id="cb122-45" data-line-number="45">        <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;gray&quot;</span>, <span class="fl">0.4</span>), </a>
<a class="sourceLine" id="cb122-46" data-line-number="46">        <span class="dt">border =</span> <span class="st">&quot;black&quot;</span>)</a></code></pre></div>
<p><img src="AdvRA_files/figure-html/unnamed-chunk-214-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>We have used the <tt>formula</tt> argument <tt>y ~ x</tt> in <tt>boxplot()</tt> to specify that we want to split up the vector <tt>y</tt> into groups according to <tt>x</tt>. <tt>boxplot(y ~ x)</tt> generates a boxplot for each of the groups in <tt>y</tt> defined by <tt>x</tt>.</p>
<p>For this artificial data it is clear that the conditional error variances differ. Specifically, we observe that the variance in test scores (and therefore the variance of the errors committed) <em>increases</em> with the student teacher ratio.</p>
<div id="a-real-world-example-for-heteroskedasticity" class="section level3 unnumbered">
<h3>A Real-World Example for Heteroskedasticity</h3>
<p>Think about the economic value of education: if there were no expected economic value-added to receiving university education, you probably would not be reading this script right now. A starting point to empirically verify such a relation is to have data on working individuals. More precisely, we need data on wages and education of workers in order to estimate a model like</p>
<p><span class="math display">\[ wage_i = \beta_0 + \beta_1 \cdot education_i + u_i. \]</span></p>
<p>What can be presumed about this relation? It is likely that, on average, higher educated workers earn more than workers with less education, so we expect to estimate an upward sloping regression line. Also, it seems plausible that earnings of better educated workers have a higher dispersion than those of low-skilled workers: solid education is not a guarantee for a high salary so even highly qualified workers take on low-income jobs. However, they are more likely to meet the requirements for the well-paid jobs than workers with less education for whom opportunities in the labor market are much more limited.</p>
<p>To verify this empirically we may use real data on hourly earnings and the number of years of education of employees. Such data can be found in <tt>CPSSWEducation</tt>. This data set is part of the package <tt>AER</tt> and comes from the Current Population Survey (CPS) which is conducted periodically by the <a href="http://www.bls.gov/">Bureau of Labor Statistics</a> in the United States.</p>
<p>The subsequent code chunks demonstrate how to import the data into <tt>R</tt> and how to produce a plot in the fashion of Figure 5.3 in the book.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb123-1" data-line-number="1"><span class="co"># load package and attach data</span></a>
<a class="sourceLine" id="cb123-2" data-line-number="2"><span class="kw">library</span>(AER)</a>
<a class="sourceLine" id="cb123-3" data-line-number="3"><span class="kw">data</span>(<span class="st">&quot;CPSSWEducation&quot;</span>)</a>
<a class="sourceLine" id="cb123-4" data-line-number="4"><span class="kw">attach</span>(CPSSWEducation)</a>
<a class="sourceLine" id="cb123-5" data-line-number="5"></a>
<a class="sourceLine" id="cb123-6" data-line-number="6"><span class="co"># get an overview</span></a>
<a class="sourceLine" id="cb123-7" data-line-number="7"><span class="kw">summary</span>(CPSSWEducation)</a>
<a class="sourceLine" id="cb123-8" data-line-number="8"><span class="co">#&gt;       age          gender        earnings        education    </span></a>
<a class="sourceLine" id="cb123-9" data-line-number="9"><span class="co">#&gt;  Min.   :29.0   female:1202   Min.   : 2.137   Min.   : 6.00  </span></a>
<a class="sourceLine" id="cb123-10" data-line-number="10"><span class="co">#&gt;  1st Qu.:29.0   male  :1748   1st Qu.:10.577   1st Qu.:12.00  </span></a>
<a class="sourceLine" id="cb123-11" data-line-number="11"><span class="co">#&gt;  Median :29.0                 Median :14.615   Median :13.00  </span></a>
<a class="sourceLine" id="cb123-12" data-line-number="12"><span class="co">#&gt;  Mean   :29.5                 Mean   :16.743   Mean   :13.55  </span></a>
<a class="sourceLine" id="cb123-13" data-line-number="13"><span class="co">#&gt;  3rd Qu.:30.0                 3rd Qu.:20.192   3rd Qu.:16.00  </span></a>
<a class="sourceLine" id="cb123-14" data-line-number="14"><span class="co">#&gt;  Max.   :30.0                 Max.   :97.500   Max.   :18.00</span></a>
<a class="sourceLine" id="cb123-15" data-line-number="15"></a>
<a class="sourceLine" id="cb123-16" data-line-number="16"><span class="co"># estimate a simple regression model</span></a>
<a class="sourceLine" id="cb123-17" data-line-number="17">labor_model &lt;-<span class="st"> </span><span class="kw">lm</span>(earnings <span class="op">~</span><span class="st"> </span>education)</a>
<a class="sourceLine" id="cb123-18" data-line-number="18"></a>
<a class="sourceLine" id="cb123-19" data-line-number="19"><span class="co"># plot observations and add the regression line</span></a>
<a class="sourceLine" id="cb123-20" data-line-number="20"><span class="kw">plot</span>(education, </a>
<a class="sourceLine" id="cb123-21" data-line-number="21">     earnings, </a>
<a class="sourceLine" id="cb123-22" data-line-number="22">     <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">150</span>))</a>
<a class="sourceLine" id="cb123-23" data-line-number="23"></a>
<a class="sourceLine" id="cb123-24" data-line-number="24"><span class="kw">abline</span>(labor_model, </a>
<a class="sourceLine" id="cb123-25" data-line-number="25">       <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, </a>
<a class="sourceLine" id="cb123-26" data-line-number="26">       <span class="dt">lwd =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="AdvRA_files/figure-html/unnamed-chunk-215-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The plot reveals that the mean of the distribution of earnings increases with the level of education. This is also supported by a formal analysis: the estimated regression model stored in <tt>labor_mod</tt> shows that there is a positive relation between years of education and earnings.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" data-line-number="1"><span class="co"># print the contents of labor_model to the console</span></a>
<a class="sourceLine" id="cb124-2" data-line-number="2">labor_model</a>
<a class="sourceLine" id="cb124-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb124-4" data-line-number="4"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb124-5" data-line-number="5"><span class="co">#&gt; lm(formula = earnings ~ education)</span></a>
<a class="sourceLine" id="cb124-6" data-line-number="6"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb124-7" data-line-number="7"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb124-8" data-line-number="8"><span class="co">#&gt; (Intercept)    education  </span></a>
<a class="sourceLine" id="cb124-9" data-line-number="9"><span class="co">#&gt;      -3.134        1.467</span></a></code></pre></div>
<p>The estimated regression equation states that, on average, an additional year of education increases a worker’s hourly earnings by about <span class="math inline">\(\$ 1.47\)</span>. Once more we use <tt>confint()</tt> to obtain a <span class="math inline">\(95\%\)</span> confidence interval for both regression coefficients.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb125-1" data-line-number="1"><span class="co"># compute a 95% confidence interval for the coefficients in the model</span></a>
<a class="sourceLine" id="cb125-2" data-line-number="2"><span class="kw">confint</span>(labor_model)</a>
<a class="sourceLine" id="cb125-3" data-line-number="3"><span class="co">#&gt;                 2.5 %    97.5 %</span></a>
<a class="sourceLine" id="cb125-4" data-line-number="4"><span class="co">#&gt; (Intercept) -5.015248 -1.253495</span></a>
<a class="sourceLine" id="cb125-5" data-line-number="5"><span class="co">#&gt; education    1.330098  1.603753</span></a></code></pre></div>
<p>Since the interval is <span class="math inline">\([1.33, 1.60]\)</span> we can reject the hypothesis that the coefficient on <tt>education</tt> is zero at the <span class="math inline">\(5\%\)</span> level.</p>
<p>Furthermore, the plot indicates that there is heteroskedasticity: if we assume the regression line to be a reasonably good representation of the conditional mean function <span class="math inline">\(E(earnings_i\vert education_i)\)</span>, the dispersion of hourly earnings around that function clearly increases with the level of education, i.e., the variance of the distribution of earnings increases. In other words: the variance of the errors (the errors made in explaining earnings by education) increases with education so that the regression errors are heteroskedastic.</p>
<p>This example makes a case that the assumption of homoskedasticity is doubtful in economic applications. Should we care about heteroskedasticity? Yes, we should. As explained in the next section, heteroskedasticity can have serious negative consequences in hypothesis testing, if we ignore it.</p>
</div>
<div id="should-we-care-about-heteroskedasticity" class="section level3 unnumbered">
<h3>Should We Care About Heteroskedasticity?</h3>
<p>To answer the question whether we should worry about heteroskedasticity being present, consider the variance of <span class="math inline">\(\hat\beta_1\)</span> under the assumption of homoskedasticity. In this case we have</p>
<p><span class="math display">\[ \sigma^2_{\hat\beta_1} = \frac{\sigma^2_u}{n \cdot \sigma^2_X} \tag{5.5} \]</span></p>
<p>which is a simplified version of the general equation (<a href="#mjx-eqn-4.1">4.1</a>) presented in Key Concept 4.4. See Appendix 5.1 of the book for details on the derivation. <tt>summary()</tt> estimates (<a href="#mjx-eqn-5.5">5.5</a>) by</p>
<p><span class="math display">\[ \overset{\sim}{\sigma}^2_{\hat\beta_1} = \frac{SER^2}{\sum_{i=1}^n (X_i - \overline{X})^2} \ \ \text{where} \ \ SER=\frac{1}{n-2} \sum_{i=1}^n \hat u_i^2. \]</span></p>
<p>Thus <tt>summary()</tt> estimates the <em>homoskedasticity-only</em> standard error</p>
<p><span class="math display">\[ \sqrt{ \overset{\sim}{\sigma}^2_{\hat\beta_1} } = \sqrt{ \frac{SER^2}{\sum_{i=1}^n(X_i - \overline{X})^2} }. \]</span></p>
<p>This is in fact an estimator for the standard deviation of the estimator <span class="math inline">\(\hat{\beta}_1\)</span> that is <em>inconsistent</em> for the true value <span class="math inline">\(\sigma^2_{\hat\beta_1}\)</span> when there is heteroskedasticity. The implication is that <span class="math inline">\(t\)</span>-statistics computed in the manner of Key Concept 5.1 do not follow a standard normal distribution, even in large samples. This issue may invalidate inference when using the previously treated tools for hypothesis testing: we should be cautious when making statements about the significance of regression coefficients on the basis of <span class="math inline">\(t\)</span>-statistics as computed by <tt>summary()</tt> or confidence intervals produced by <tt>confint()</tt> if it is doubtful for the assumption of homoskedasticity to hold!</p>
<p>We will now use <tt>R</tt> to compute the homoskedasticity-only standard error for <span class="math inline">\(\hat{\beta}_1\)</span> in the test score regression model <tt>labor_model</tt> by hand and see that it matches the value produced by <tt>summary()</tt>.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" data-line-number="1"><span class="co"># Store model summary in &#39;model&#39;</span></a>
<a class="sourceLine" id="cb126-2" data-line-number="2">model &lt;-<span class="st"> </span><span class="kw">summary</span>(labor_model)</a>
<a class="sourceLine" id="cb126-3" data-line-number="3"></a>
<a class="sourceLine" id="cb126-4" data-line-number="4"><span class="co"># Extract the standard error of the regression from model summary</span></a>
<a class="sourceLine" id="cb126-5" data-line-number="5">SER &lt;-<span class="st"> </span>model<span class="op">$</span>sigma</a>
<a class="sourceLine" id="cb126-6" data-line-number="6"></a>
<a class="sourceLine" id="cb126-7" data-line-number="7"><span class="co"># Compute the variation in &#39;education&#39;</span></a>
<a class="sourceLine" id="cb126-8" data-line-number="8">V &lt;-<span class="st"> </span>(<span class="kw">nrow</span>(CPSSWEducation)<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">var</span>(education)</a>
<a class="sourceLine" id="cb126-9" data-line-number="9"></a>
<a class="sourceLine" id="cb126-10" data-line-number="10"><span class="co"># Compute the standard error of the slope parameter&#39;s estimator and print it</span></a>
<a class="sourceLine" id="cb126-11" data-line-number="11">SE.beta_<span class="fl">1.</span>hat &lt;-<span class="st"> </span><span class="kw">sqrt</span>(SER<span class="op">^</span><span class="dv">2</span><span class="op">/</span>V)</a>
<a class="sourceLine" id="cb126-12" data-line-number="12">SE.beta_<span class="fl">1.</span>hat</a>
<a class="sourceLine" id="cb126-13" data-line-number="13"><span class="co">#&gt; [1] 0.06978281</span></a>
<a class="sourceLine" id="cb126-14" data-line-number="14"></a>
<a class="sourceLine" id="cb126-15" data-line-number="15"><span class="co"># Use logical operators to see if the value computed by hand matches the one provided </span></a>
<a class="sourceLine" id="cb126-16" data-line-number="16"><span class="co"># in mod$coefficients. Round estimates to four decimal places</span></a>
<a class="sourceLine" id="cb126-17" data-line-number="17"><span class="kw">round</span>(model<span class="op">$</span>coefficients[<span class="dv">2</span>, <span class="dv">2</span>], <span class="dv">4</span>) <span class="op">==</span><span class="st"> </span><span class="kw">round</span>(SE.beta_<span class="fl">1.</span>hat, <span class="dv">4</span>)</a>
<a class="sourceLine" id="cb126-18" data-line-number="18"><span class="co">#&gt; [1] TRUE</span></a></code></pre></div>
<p>Indeed, the estimated values are equal.</p>
</div>
<div id="computation-of-heteroskedasticity-robust-standard-errors" class="section level3 unnumbered">
<h3>Computation of Heteroskedasticity-Robust Standard Errors</h3>
<p>Consistent estimation of <span class="math inline">\(\sigma_{\hat{\beta}_1}\)</span> under heteroskedasticity is granted when the following <em>robust</em> estimator is used.</p>
<p><span class="math display">\[ SE(\hat{\beta}_1) = \sqrt{ \frac{1}{n} \cdot \frac{ \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2 \hat{u}_i^2 }{ \left[ \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2  \right]^2} } \tag{5.6} \]</span></p>
<p>Standard error estimates computed this way are also referred to as <a href="https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors">Eicker-Huber-White standard errors</a>, the most frequently cited paper on this is <span class="citation">White (<a href="#ref-white1980">1980</a>)</span>.</p>
<p>It can be quite cumbersome to do this calculation by hand. Luckily certain R functions exist, serving that purpose. A convenient one named <tt>vcovHC()</tt> is part of the package <tt>sandwich</tt>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> This function can compute a variety of standard errors. The one brought forward in (<a href="#mjx-eqn-5.6">5.6</a>) is computed when the argument <tt>type</tt> is set to <tt>“HC0”</tt>. Most of the examples presented in the book rely on a slightly different formula which is the default in the statistics package <em>STATA</em>:</p>
<p><span class="math display" id="eq:hc1">\[\begin{align}
SE(\hat{\beta}_1)_{HC1} = \sqrt{ \frac{1}{n} \cdot \frac{ \frac{1}{n-2} \sum_{i=1}^n (X_i - \overline{X})^2 \hat{u}_i^2 }{ \left[ \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2  \right]^2}} \tag{4.2}
\end{align}\]</span></p>
<p>The difference is that we multiply by <span class="math inline">\(\frac{1}{n-2}\)</span> in the numerator of <a href="4-4-hah.html#eq:hc1">(4.2)</a>. This is a degrees of freedom correction and was considered by <span class="citation">MacKinnon and White (<a href="#ref-mackinnon1985">1985</a>)</span>. To get <tt>vcovHC()</tt> to use <a href="4-4-hah.html#eq:hc1">(4.2)</a>, we have to set <tt>type = “HC1”</tt>.</p>
<p>Let us now compute robust standard error estimates for the coefficients in <tt>linear_model</tt>.</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb127-1" data-line-number="1"><span class="co"># compute heteroskedasticity-robust standard errors</span></a>
<a class="sourceLine" id="cb127-2" data-line-number="2">vcov &lt;-<span class="st"> </span><span class="kw">vcovHC</span>(linear_model, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)</a>
<a class="sourceLine" id="cb127-3" data-line-number="3">vcov</a>
<a class="sourceLine" id="cb127-4" data-line-number="4"><span class="co">#&gt;             (Intercept)        STR</span></a>
<a class="sourceLine" id="cb127-5" data-line-number="5"><span class="co">#&gt; (Intercept)  107.419993 -5.3639114</span></a>
<a class="sourceLine" id="cb127-6" data-line-number="6"><span class="co">#&gt; STR           -5.363911  0.2698692</span></a></code></pre></div>
<p>The output of <tt>vcovHC()</tt> is the variance-covariance matrix of coefficient estimates. We are interested in the square root of the diagonal elements of this matrix, i.e., the standard error estimates.</p>

<div class="rmdknit">
<p>When we have k &gt; 1 regressors, writing down the equations for a regression model becomes very messy. A more convinient way to denote and estimate so-called multiple regression models (see Chapter <a href="5-rmwmr.html#rmwmr">5</a>) is by using matrix algebra. This is why functions like <tt>vcovHC()</tt> produce matrices. In the simple linear regression model, the variances and covariances of the estimators can be gathered in the symmetric variance-covariance matrix</p>
<p><span class="math display">\[\begin{equation}
\text{Var}
  \begin{pmatrix}
    \hat\beta_0 \\
    \hat\beta_1
  \end{pmatrix} = 
\begin{pmatrix}
  \text{Var}(\hat\beta_0) &amp; \text{Cov}(\hat\beta_0,\hat\beta_1) \\
\text{Cov}(\hat\beta_0,\hat\beta_1) &amp; \text{Var}(\hat\beta_1)
\end{pmatrix},
\end{equation}\]</span></p>
<p>so <tt>vcovHC()</tt> gives us <span class="math inline">\(\widehat{\text{Var}}(\hat\beta_0)\)</span>, <span class="math inline">\(\widehat{\text{Var}}(\hat\beta_1)\)</span> and <span class="math inline">\(\widehat{\text{Cov}}(\hat\beta_0,\hat\beta_1)\)</span>, but most of the time we are interested in the diagonal elements of the estimated matrix.</p>
</div>

<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" data-line-number="1"><span class="co"># compute the square root of the diagonal elements in vcov</span></a>
<a class="sourceLine" id="cb128-2" data-line-number="2">robust_se &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">diag</span>(vcov))</a>
<a class="sourceLine" id="cb128-3" data-line-number="3">robust_se</a>
<a class="sourceLine" id="cb128-4" data-line-number="4"><span class="co">#&gt; (Intercept)         STR </span></a>
<a class="sourceLine" id="cb128-5" data-line-number="5"><span class="co">#&gt;  10.3643617   0.5194893</span></a></code></pre></div>
<p>Now assume we want to generate a coefficient summary as provided by <tt>summary()</tt> but with <em>robust</em> standard errors of the coefficient estimators, robust <span class="math inline">\(t\)</span>-statistics and corresponding <span class="math inline">\(p\)</span>-values for the regression model <tt>linear_model</tt>. This can be done using <tt>coeftest()</tt> from the package <tt>lmtest</tt>, see <code>?coeftest</code>. Further we specify in the argument <tt>vcov.</tt> that <tt>vcov</tt>, the Eicker-Huber-White estimate of the variance matrix we have computed before, should be used.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb129-1" data-line-number="1"><span class="co"># we invoke the function `coeftest()` on our model</span></a>
<a class="sourceLine" id="cb129-2" data-line-number="2"><span class="kw">coeftest</span>(linear_model, <span class="dt">vcov. =</span> vcov)</a>
<a class="sourceLine" id="cb129-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb129-4" data-line-number="4"><span class="co">#&gt; t test of coefficients:</span></a>
<a class="sourceLine" id="cb129-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb129-6" data-line-number="6"><span class="co">#&gt;              Estimate Std. Error t value  Pr(&gt;|t|)    </span></a>
<a class="sourceLine" id="cb129-7" data-line-number="7"><span class="co">#&gt; (Intercept) 698.93295   10.36436 67.4362 &lt; 2.2e-16 ***</span></a>
<a class="sourceLine" id="cb129-8" data-line-number="8"><span class="co">#&gt; STR          -2.27981    0.51949 -4.3886 1.447e-05 ***</span></a>
<a class="sourceLine" id="cb129-9" data-line-number="9"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb129-10" data-line-number="10"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a></code></pre></div>
<p>We see that the values reported in the column <tt>Std. Error</tt> are equal those from <tt>sqrt(diag(vcov))</tt>.</p>
<p>How severe are the implications of using homoskedasticity-only standard errors in the presence of heteroskedasticity? The answer is: it depends. As mentioned above we face the risk of drawing wrong conclusions when conducting significance tests. <br> Let us illustrate this by generating another example of a heteroskedastic data set and using it to estimate a simple regression model. We take</p>
<p><span class="math display">\[ Y_i = \beta_1 \cdot X_i + u_i \ \ , \ \ u_i \overset{i.i.d.}{\sim} \mathcal{N}(0,0.36 \cdot X_i^2)  \]</span></p>
<p>with <span class="math inline">\(\beta_1=1\)</span> as the data generating process. Clearly, the assumption of homoskedasticity is violated here since the variance of the errors is a nonlinear, increasing function of <span class="math inline">\(X_i\)</span> but the errors have zero mean and are i.i.d. such that the assumptions made in Key Concept 4.3 are not violated. As before, we are interested in estimating <span class="math inline">\(\beta_1\)</span>.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">905</span>)</a>
<a class="sourceLine" id="cb130-2" data-line-number="2"></a>
<a class="sourceLine" id="cb130-3" data-line-number="3"><span class="co"># generate heteroskedastic data </span></a>
<a class="sourceLine" id="cb130-4" data-line-number="4">X &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">500</span></a>
<a class="sourceLine" id="cb130-5" data-line-number="5">Y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">500</span>, <span class="dt">mean =</span> X, <span class="dt">sd =</span> <span class="fl">0.6</span> <span class="op">*</span><span class="st"> </span>X)</a>
<a class="sourceLine" id="cb130-6" data-line-number="6"></a>
<a class="sourceLine" id="cb130-7" data-line-number="7"><span class="co"># estimate a simple regression model</span></a>
<a class="sourceLine" id="cb130-8" data-line-number="8">reg &lt;-<span class="st"> </span><span class="kw">lm</span>(Y <span class="op">~</span><span class="st"> </span>X)</a></code></pre></div>
<p>We plot the data and add the regression line.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb131-1" data-line-number="1"><span class="co"># plot the data</span></a>
<a class="sourceLine" id="cb131-2" data-line-number="2"><span class="kw">plot</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> Y, </a>
<a class="sourceLine" id="cb131-3" data-line-number="3">     <span class="dt">pch =</span> <span class="dv">19</span>, </a>
<a class="sourceLine" id="cb131-4" data-line-number="4">     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, </a>
<a class="sourceLine" id="cb131-5" data-line-number="5">     <span class="dt">cex =</span> <span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb131-6" data-line-number="6"></a>
<a class="sourceLine" id="cb131-7" data-line-number="7"><span class="co"># add the regression line to the plot</span></a>
<a class="sourceLine" id="cb131-8" data-line-number="8"><span class="kw">abline</span>(reg, </a>
<a class="sourceLine" id="cb131-9" data-line-number="9">       <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>, </a>
<a class="sourceLine" id="cb131-10" data-line-number="10">       <span class="dt">lwd =</span> <span class="fl">1.5</span>)</a></code></pre></div>
<p><img src="AdvRA_files/figure-html/unnamed-chunk-223-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The plot shows that the data are heteroskedastic as the variance of <span class="math inline">\(Y\)</span> grows with <span class="math inline">\(X\)</span>. We next conduct a significance test of the (true) null hypothesis <span class="math inline">\(H_0: \beta_1 = 1\)</span> twice, once using the homoskedasticity-only standard error formula and once with the robust version (<a href="#mjx-eqn-5.6">5.6</a>). An easy way to do this in <tt>R</tt> is the function <tt>linearHypothesis()</tt> from the package <tt>car</tt>, see <code>?linearHypothesis</code>. It allows to test linear hypotheses about parameters in linear models in a similar way as done with a <span class="math inline">\(t\)</span>-statistic and offers various robust covariance matrix estimators. We test by comparing the tests’ <span class="math inline">\(p\)</span>-values to the significance level of <span class="math inline">\(5\%\)</span>.</p>

<div class="rmdknit">
<p><tt>linearHypothesis()</tt> computes a test statistic that follows an <span class="math inline">\(F\)</span>-distribution under the null hypothesis. We will not focus on the details of the underlying theory. In general, the idea of the <span class="math inline">\(F\)</span>-test is to compare the fit of different models. When testing a hypothesis about a <em>single</em> coefficient using an <span class="math inline">\(F\)</span>-test, one can show that the test statistic is simply the square of the corresponding <span class="math inline">\(t\)</span>-statistic:</p>
<p><span class="math display">\[F = t^2 = \left(\frac{\hat\beta_i - \beta_{i,0}}{SE(\hat\beta_i)}\right)^2 \sim F_{1,n-k-1}\]</span></p>
In <tt>linearHypothesis()</tt>, there are different ways to specify the hypothesis to be tested, e.g., using a vector of the type <tt>character</tt> (as done in the next code chunk), see <tt>?linearHypothesis</tt> for alternatives. The function returns an object of class <tt>anova</tt> which contains further information on the test that can be accessed using the <tt>$</tt> operator.
</div>

<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" data-line-number="1"><span class="co"># test hypthesis using the default standard error formula</span></a>
<a class="sourceLine" id="cb132-2" data-line-number="2"><span class="kw">linearHypothesis</span>(reg, <span class="dt">hypothesis.matrix =</span> <span class="st">&quot;X = 1&quot;</span>)<span class="op">$</span><span class="st">&#39;Pr(&gt;F)&#39;</span>[<span class="dv">2</span>] <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span></a>
<a class="sourceLine" id="cb132-3" data-line-number="3"><span class="co">#&gt; [1] TRUE</span></a>
<a class="sourceLine" id="cb132-4" data-line-number="4"></a>
<a class="sourceLine" id="cb132-5" data-line-number="5"><span class="co"># test hypothesis using the robust standard error formula</span></a>
<a class="sourceLine" id="cb132-6" data-line-number="6"><span class="kw">linearHypothesis</span>(reg, <span class="dt">hypothesis.matrix =</span> <span class="st">&quot;X = 1&quot;</span>, <span class="dt">white.adjust =</span> <span class="st">&quot;hc1&quot;</span>)<span class="op">$</span><span class="st">&#39;Pr(&gt;F)&#39;</span>[<span class="dv">2</span>] <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span></a>
<a class="sourceLine" id="cb132-7" data-line-number="7"><span class="co">#&gt; [1] FALSE</span></a></code></pre></div>
<p>This is a good example of what can go wrong if we ignore heteroskedasticity: for the data set at hand the default method rejects the null hypothesis <span class="math inline">\(\beta_1 = 1\)</span> although it is true. When using the robust standard error formula the test does not reject the null. Of course, we could think this might just be a coincidence and both tests do equally well in maintaining the type I error rate of <span class="math inline">\(5\%\)</span>. This can be further investigated by computing <em>Monte Carlo</em> estimates of the rejection frequencies of both tests on the basis of a large number of random samples. We proceed as follows:</p>
<ul>
<li>initialize vectors <tt>t</tt> and <tt>t.rob</tt>.</li>
<li>Using a <tt>for()</tt> loop, we generate <span class="math inline">\(10000\)</span> heteroskedastic random samples of size <span class="math inline">\(1000\)</span>, estimate the regression model and check whether the tests falsely reject the null at the level of <span class="math inline">\(5\%\)</span> using comparison operators. The results are stored in the respective vectors <tt>t</tt> and <tt>t.rob</tt>.</li>
<li>After the simulation, we compute the fraction of false rejections for both tests.</li>
</ul>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb133-1" data-line-number="1"></a>
<a class="sourceLine" id="cb133-2" data-line-number="2"><span class="co"># initialize vectors t and t.rob</span></a>
<a class="sourceLine" id="cb133-3" data-line-number="3">t &lt;-<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb133-4" data-line-number="4">t.rob &lt;-<span class="st"> </span><span class="kw">c</span>()</a>
<a class="sourceLine" id="cb133-5" data-line-number="5"></a>
<a class="sourceLine" id="cb133-6" data-line-number="6"><span class="co"># loop sampling and estimation</span></a>
<a class="sourceLine" id="cb133-7" data-line-number="7"><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>) {</a>
<a class="sourceLine" id="cb133-8" data-line-number="8">  </a>
<a class="sourceLine" id="cb133-9" data-line-number="9">  <span class="co"># sample data</span></a>
<a class="sourceLine" id="cb133-10" data-line-number="10">  X &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb133-11" data-line-number="11">  Y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">1000</span>, <span class="dt">mean =</span> X, <span class="dt">sd =</span> <span class="fl">0.6</span> <span class="op">*</span><span class="st"> </span>X)</a>
<a class="sourceLine" id="cb133-12" data-line-number="12"></a>
<a class="sourceLine" id="cb133-13" data-line-number="13">  <span class="co"># estimate regression model</span></a>
<a class="sourceLine" id="cb133-14" data-line-number="14">  reg &lt;-<span class="st"> </span><span class="kw">lm</span>(Y <span class="op">~</span><span class="st"> </span>X)</a>
<a class="sourceLine" id="cb133-15" data-line-number="15"></a>
<a class="sourceLine" id="cb133-16" data-line-number="16">  <span class="co"># homoskedasdicity-only significance test</span></a>
<a class="sourceLine" id="cb133-17" data-line-number="17">  t[i] &lt;-<span class="st"> </span><span class="kw">linearHypothesis</span>(reg, <span class="st">&quot;X = 1&quot;</span>)<span class="op">$</span><span class="st">&#39;Pr(&gt;F)&#39;</span>[<span class="dv">2</span>] <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span></a>
<a class="sourceLine" id="cb133-18" data-line-number="18"></a>
<a class="sourceLine" id="cb133-19" data-line-number="19">  <span class="co"># robust significance test</span></a>
<a class="sourceLine" id="cb133-20" data-line-number="20">  t.rob[i] &lt;-<span class="st"> </span><span class="kw">linearHypothesis</span>(reg, <span class="st">&quot;X = 1&quot;</span>, <span class="dt">white.adjust =</span> <span class="st">&quot;hc1&quot;</span>)<span class="op">$</span><span class="st">&#39;Pr(&gt;F)&#39;</span>[<span class="dv">2</span>] <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span></a>
<a class="sourceLine" id="cb133-21" data-line-number="21"></a>
<a class="sourceLine" id="cb133-22" data-line-number="22">}</a>
<a class="sourceLine" id="cb133-23" data-line-number="23"></a>
<a class="sourceLine" id="cb133-24" data-line-number="24"><span class="co"># compute the fraction of false rejections</span></a>
<a class="sourceLine" id="cb133-25" data-line-number="25"><span class="kw">round</span>(<span class="kw">cbind</span>(<span class="dt">t =</span> <span class="kw">mean</span>(t), <span class="dt">t.rob =</span> <span class="kw">mean</span>(t.rob)), <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb133-26" data-line-number="26"><span class="co">#&gt;          t t.rob</span></a>
<a class="sourceLine" id="cb133-27" data-line-number="27"><span class="co">#&gt; [1,] 0.073  0.05</span></a></code></pre></div>
<p>These results reveal the increased risk of falsely rejecting the null using the homoskedasticity-only standard error for the testing problem at hand: with the common standard error, <span class="math inline">\(7.28\%\)</span> of all tests falsely reject the null hypothesis. In contrast, with the robust test statistic we are closer to the nominal level of <span class="math inline">\(5\%\)</span>.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-mackinnon1985">
<p>MacKinnon, James G, and Halbert White. 1985. “Some heteroskedasticity-consistent covariance matrix estimators with improved finite sample properties.” <em>Journal of Econometrics</em> 29 (3). Elsevier: 305–25.</p>
</div>
<div id="ref-white1980">
<p>White, Halbert. 1980. “A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity.” <em>Econometrica</em> 48 (4). The Econometric Society: pp. 817–38.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>The package <tt>sandwich</tt> is a dependency of the package <tt>AER</tt>, meaning that it is attached automatically if you load <tt>AER</tt>.<a href="4-4-hah.html#fnref4" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="4-3-rwxiabv.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4-5-the-gauss-markov-theorem.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/lidom/AdvRA/edit/master/05-ch5.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
