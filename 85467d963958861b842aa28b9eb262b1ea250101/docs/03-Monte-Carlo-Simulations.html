<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Econometrics M.Sc. - 3&nbsp; Monte Carlo Simulations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04-MultipleReg.html" rel="next">
<link href="./02-Review-Prob_n_Stats.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Monte Carlo Simulations</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./" class="sidebar-logo-link">
      <img src="./images/Uni_Bonn_Logo.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Econometrics M.Sc.</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Organization of the Course</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-Introduction-to-R.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-Review-Prob_n_Stats.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Review: Probability and Statistics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-Monte-Carlo-Simulations.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Monte Carlo Simulations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-MultipleReg.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-Small-Sample-Inference.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Small Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-Asymptotics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Large Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-Instrumental-Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Instrumental Variables Regression</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#estimator-vs.-estimate" id="toc-estimator-vs.-estimate" class="nav-link active" data-scroll-target="#estimator-vs.-estimate"><span class="toc-section-number">3.1</span>  Estimator vs.&nbsp;Estimate</a></li>
  <li><a href="#deriving-the-distribution-of-estimators" id="toc-deriving-the-distribution-of-estimators" class="nav-link" data-scroll-target="#deriving-the-distribution-of-estimators"><span class="toc-section-number">3.2</span>  Deriving the Distribution of Estimators</a></li>
  <li><a href="#assessing-the-quality-of-estimators" id="toc-assessing-the-quality-of-estimators" class="nav-link" data-scroll-target="#assessing-the-quality-of-estimators"><span class="toc-section-number">3.3</span>  Assessing the Quality of Estimators</a></li>
  <li><a href="#approximating-bias-variance-and-mean-squared-error-using-monte-carlo-simulations" id="toc-approximating-bias-variance-and-mean-squared-error-using-monte-carlo-simulations" class="nav-link" data-scroll-target="#approximating-bias-variance-and-mean-squared-error-using-monte-carlo-simulations"><span class="toc-section-number">3.4</span>  Approximating Bias, Variance, and Mean Squared Error using Monte Carlo Simulations</a>
  <ul class="collapse">
  <li><a href="#example-sample-mean" id="toc-example-sample-mean" class="nav-link" data-scroll-target="#example-sample-mean">Example: Sample Mean</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Monte Carlo Simulations</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>In the following parts of the lecture, we will use Monte Carlo simulations in oder to check whether a certain estimator is able to estimate its (usually unknown) target parameter. In this chapter, we will learn what Monte Carlo simulations are and how they can be implemented.</p>
<section id="estimator-vs.-estimate" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="estimator-vs.-estimate"><span class="header-section-number">3.1</span> Estimator vs.&nbsp;Estimate</h2>
<p>Let’s assume that we have an iid random sample <span class="math inline">\(X_1,\dots,X_n\)</span> with <span class="math display">\[
X_i\overset{iid}{\sim} F_X
\]</span> for all <span class="math inline">\(i=1,\dots,n\)</span>, and let <span class="math inline">\(\theta\in\mathbb{R}\)</span> denote some parameter (e.g.&nbsp;the mean or the variance) of the distribution <span class="math inline">\(F_X\)</span>.</p>
<p>An <strong>estimator</strong> <span class="math inline">\(\hat\theta_n\)</span> of <span class="math inline">\(\theta\)</span> is a function of the random sample <span class="math inline">\(X_1,\dots,X_n\)</span>, <span class="math display">\[
\hat\theta_n:=\hat\theta(X_1,\dots,X_n).
\]</span></p>
<p>Since <span class="math inline">\(\hat\theta_n\)</span> is a function of the random variables <span class="math inline">\(X_1,\dots,X_n\)</span>, the estimator <span class="math inline">\(\hat\theta_n\)</span> is itself a <strong>random variable</strong>.</p>
<p>The observed data <span class="math inline">\(X_{1,obs},\dots,X_{n,obs}\)</span> is assumed to be a certain realization of the random sample <span class="math inline">\(X_1,\dots,X_n\)</span>. The corresponding <strong>realization</strong> of the estimator is called an <strong>estimate</strong> of <span class="math inline">\(\theta\)</span> <span class="math display">\[
\hat\theta_{n,obs}=\hat\theta(X_{1,obs},\dots,X_{n,obs}).
\]</span></p>
<p><strong>Note:</strong> Often we do not use a distinguishing notation, but denote both the estimator and its realization as <span class="math inline">\(\hat\theta_{n}\)</span>. This ambiguity is often convenient since both points of views can make sense.</p>
<p><strong>Examples:</strong></p>
<ul>
<li>The sample mean as an estimator of the population mean:</li>
</ul>
<p><span class="math display">\[
\hat\theta_n=\bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i \approx E(X_i) =\theta
\]</span></p>
<ul>
<li>The sample variance as an estimator of the population variance:</li>
</ul>
<p><span class="math display">\[
\hat\theta_n=s_{UB}^2=\frac{1}{n-1}\sum_{i=1}^n\left(X_i - \bar{X}_n\right)^2 \approx Var(X_i) =\theta
\]</span></p>
</section>
<section id="deriving-the-distribution-of-estimators" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="deriving-the-distribution-of-estimators"><span class="header-section-number">3.2</span> Deriving the Distribution of Estimators</h2>
<p>Usually, we do not know the distribution <span class="math inline">\(F_X\)</span> of the random sample <span class="math inline">\(X_1,\dots,X_n\)</span> and thus do not know the distribution of the estimator <span class="math inline">\(\hat\theta_n=\hat\theta(X_1,\dots,X_n)\)</span>. This is a fundamental statistical problem and we need to overcome this problem in order to do statistical inference (hypothesis testing, etc.). There are different possibilities to derive/approximate the distribution of an estimator <span class="math inline">\(\hat\theta_n\)</span>. In times when when computers were expensive, statisticians mainly used mathematical derivations:</p>
<ul>
<li><strong>Mathematical Derivation using Distributional Assumptions.</strong> Assuming a certain distribution <span class="math inline">\(F_X\)</span> for the random sample <span class="math inline">\(X_1,\dots,X_n\)</span> allows us to derive the <em>exact</em> distribution of <span class="math inline">\(\hat\theta_n\)</span> mathematically. (We consider this option in <a href="05-Small-Sample-Inference.html"><span>Chapter&nbsp;5</span></a>.)
<ul>
<li>Pro: If the distributional assumption is correct, one has <em>exact</em> inference for each sample size <span class="math inline">\(n\)</span>.</li>
<li>Con: This option can fail miserably if the distributional assumption on <span class="math inline">\(F_X\)</span> is wrong.</li>
<li>Con: Such mathematical derivations are often only possible for particular distributions <span class="math inline">\(F_X\)</span> like the normal distribution.</li>
</ul></li>
<li><strong>Mathematical Derivation using Asymptotic Statistics.</strong> Large sample <span class="math inline">\((n\to\infty)\)</span> approximations (i.e.&nbsp;laws of large numbers and central limit theorems) allow us to derive the <em>approximate</em> distribution of <span class="math inline">\(\hat\theta_n\)</span>. This option uses mathematical limit considerations by letting the sample size <span class="math inline">\(n\)</span> diverge to infinity. (We consider this option in <a href="06-Asymptotics.html"><span>Chapter&nbsp;6</span></a>.)
<ul>
<li>Pro: Only a few qualitative distributional assumptions are needed.</li>
<li>Con: The derived asymptotic (<span class="math inline">\(n\to\infty\)</span>) distribution is only exact for the practically impossible case where <span class="math inline">\(n=\infty\)</span> and thus can fail to approximate the exact distribution of <span class="math inline">\(\hat\theta_n\)</span> for given (finite) sample sizes <span class="math inline">\(n\)</span>; particularly if <span class="math inline">\(n\)</span> is small.</li>
</ul></li>
</ul>
<p>With computers, we have further options to approximate the exact distribution of estimators using (pseudo-)random number generators. One example are Monte Carlo simulations:</p>
<ul>
<li><p><strong>Monte Carlo Simulations.</strong> Using (pseudo-)random number generators, we can draw <code>B</code> many realizations <span class="math display">\[
(X_{1,1,obs},\dots,X_{n,1,obs}),\; (X_{1,2,obs},\dots,X_{n,2,obs}),\dots, (X_{1,B,obs},\dots,X_{n,B,obs})
\]</span> of the random sample <span class="math inline">\(X_{1},\dots,X_{n}\)</span> from basically any distribution <span class="math inline">\(F_X\)</span> and thus can compute <code>B</code> many realizations <span class="math display">\[
\underbrace{\hat\theta(X_{1,1,obs},\dots,X_{n,1,obs})}_{=\hat\theta_{n,1,obs}},\;\underbrace{\hat\theta(X_{1,2,obs},\dots,X_{n,2,obs})}_{=\hat\theta_{n,2,obs}},\dots,\underbrace{\hat\theta(X_{1,B,obs},\dots,X_{n,B,obs})}_{=\hat\theta_{n,B,obs}}
\]</span> of the estimator <span class="math inline">\(\hat\theta_n\)</span>. This set of realizations <span class="math inline">\(\hat\theta_{n,1,obs},\dots,\hat\theta_{n,B,obs}\)</span> allows us then to approximate the exact distribution of <span class="math inline">\(\hat\theta_n\)</span> for given sample sizes <span class="math inline">\(n\)</span> and given distributions <span class="math inline">\(F_X\)</span>. (We use this option to validate theoretical statements in <a href="05-Small-Sample-Inference.html"><span>Chapter&nbsp;5</span></a> and <a href="06-Asymptotics.html"><span>Chapter&nbsp;6</span></a>.)</p>
<ul>
<li>Pro: Works for basically every distributional assumption.</li>
<li>Con: This option can fail miserably if the distributional assumption on <span class="math inline">\(F_X\)</span> is wrong.</li>
</ul></li>
</ul>
<!-- Monte Carlo Simulations rely on distributional assumptions and thus may fail just as the first option (Mathematical Derivation using Distributional Assumptions). However, Monte Carlo Simulations are much wider applicable than since we can use computers to sample data from basically every distribution.   -->
<p>The following <code>R</code> code generates <code>B</code> many realizations of the sample mean estimator <span class="math inline">\(\hat\theta_n=\bar{X}_n\)</span> using a random sample <span class="math inline">\(X_1,\dots,X_n\)</span>, where <span class="math inline">\(F_X\)</span> is a normal distribution with mean <span class="math inline">\((\theta=)\mu=10\)</span> and variance <span class="math inline">\(\sigma^2=5\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="do">## True parameter value </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>mu            <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Monte Carlo repetitions:</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>B             <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Sequence of different sample sizes:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>n_seq         <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">50</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="do">## ######################################</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 1st Possibility: Using a for() loop ##</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="do">## ######################################</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Set seed for the random number generator to get reproducible results</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Container for the generated estimates:</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>estimates_mat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> B, <span class="at">ncol =</span> <span class="fu">length</span>(n_seq))</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(n_seq)){</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="do">## select the sample size</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> n_seq[j]</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="do">## generate realization of the random sample </span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    X_sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">5</span>))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="do">## compute the sample mean and safe it</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    estimates_mat[b,j] <span class="ot">&lt;-</span> <span class="fu">mean</span>(X_sample)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="do">## #####################################</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="do">## 2nd Possibility: Using replicate() ##</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="do">## #####################################</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="do">## Set seed for the random number generator to get reproducible results</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="do">## Function that generates estimator realizations </span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>my_estimates_generator <span class="ot">&lt;-</span> <span class="cf">function</span>(n){</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>  X_sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">5</span>))</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute the sample mean realization</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">mean</span>(X_sample))</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>estimates_mat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">1</span>])),</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">2</span>])),</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">3</span>]))</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Based on the <code>B</code><span class="math inline">\(=10,000\)</span> realizations of the estimator <span class="math inline">\(\bar{X}_n\)</span>, we can compute histograms and non-parametric density estimates to get an idea about the true distribution of <span class="math inline">\(\bar{X}_n\)</span> for the case of random samples <span class="math inline">\(X_1,\dots,X_n\)</span> from a normal distribution with mean <span class="math inline">\(\mu=10\)</span> and variance <span class="math inline">\(\sigma^2=5\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(estimates_mat[,<span class="dv">1</span>], <span class="at">main=</span><span class="st">"n=5"</span>, <span class="at">xlab=</span><span class="st">""</span>,  <span class="at">xlim =</span> <span class="fu">range</span>(estimates_mat[,<span class="dv">1</span>]), <span class="at">prob =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1.2</span>))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(estimates_mat[,<span class="dv">1</span>], <span class="at">bw =</span> <span class="fu">bw.SJ</span>(estimates_mat[,<span class="dv">1</span>])), <span class="at">col=</span><span class="st">"blue"</span>, <span class="at">lwd=</span><span class="fl">1.5</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(estimates_mat[,<span class="dv">2</span>], <span class="at">main=</span><span class="st">"n=15"</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">xlim =</span> <span class="fu">range</span>(estimates_mat[,<span class="dv">1</span>]), <span class="at">prob =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1.2</span>))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(estimates_mat[,<span class="dv">2</span>], <span class="at">bw =</span> <span class="fu">bw.SJ</span>(estimates_mat[,<span class="dv">3</span>])), <span class="at">col=</span><span class="st">"blue"</span>, <span class="at">lwd=</span><span class="fl">1.5</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(estimates_mat[,<span class="dv">3</span>], <span class="at">main=</span><span class="st">"n=50"</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">xlim =</span> <span class="fu">range</span>(estimates_mat[,<span class="dv">1</span>]), <span class="at">prob =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1.2</span>))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(estimates_mat[,<span class="dv">2</span>], <span class="at">bw =</span> <span class="fu">bw.SJ</span>(estimates_mat[,<span class="dv">3</span>])), <span class="at">col=</span><span class="st">"blue"</span>, <span class="at">lwd=</span><span class="fl">1.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-histdensplots" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-Monte-Carlo-Simulations_files/figure-html/fig-histdensplots-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.1: Histrograms and non-parametric density estimates of the distributions of the sample mean estimator for different sample sizes.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Observations (<a href="#fig-histdensplots">Figure&nbsp;<span>3.1</span></a>):</p>
<ul>
<li><p>At least on average, the estimates <span class="math inline">\(\bar{X}_n\)</span> are close to the target parameter <span class="math inline">\(\mu=10\)</span> for each sample size <span class="math inline">\(n\in\{5,15,50\}\)</span>. This feature of the estimator’s distribution is summarized by the <strong>bias</strong> (see next section) of an estimator.</p></li>
<li><p>As the sample size increases, the distributions of the estimators <span class="math inline">\(\bar{X}_n\)</span> concentrate around the target parameter <span class="math inline">\(\mu=10\)</span>. This feature of the estimator’s distribution is summarized by the <strong>mean squared error</strong> (see next section) of an estimator.</p></li>
</ul>
<p>Thus here the quality of the estimator <span class="math inline">\(\bar{X}_n\)</span> gets better as <span class="math inline">\(n\)</span> gets large. To describe the quality of estimators more compactly, statisticians/econometricians use specific metrics like bias, variance and the mean squared error of the distribution of a estimator <span class="math inline">\(\hat\theta\)</span>.</p>
</section>
<section id="assessing-the-quality-of-estimators" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="assessing-the-quality-of-estimators"><span class="header-section-number">3.3</span> Assessing the Quality of Estimators</h2>
<!-- But how good is a given estimator $\hat\theta_n$ for a given sample size?  -->
<p>Any reasonable estimator <span class="math inline">\(\hat\theta_n\)</span> should be able to approximate the (usually unknown) parameter value <span class="math inline">\(\theta\)</span>, <span class="math display">\[
\hat\theta_n\approx\theta,
\]</span> and the approximation should get better as the sample size increases (i.e.&nbsp;as <span class="math inline">\(n\to\infty\)</span>).</p>
<p>Statisticians and econometricians use different metrics to assess the approximation quality of an estimator <span class="math inline">\(\hat\theta_n\)</span>. The most prominent metrics are bias, variance, and mean squared error.</p>
<div id="def-bias" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.1 (Bias of <span class="math inline">\(\theta\)</span>) </strong></span>The <strong>bias</strong> of an estimator <span class="math inline">\(\hat\theta_n\)</span> is defined as</p>
<p><span class="math display">\[
\operatorname{Bias}\left(\hat\theta_n\right) = E\left(\hat\theta_n\right) - \theta.
\]</span></p>
</div>
<p>We would like to have unbiased estimators <span class="math inline">\(\operatorname{Bias}\left(\hat\theta_n\right)=0\)</span> or at least asymptotically unbiased estimators <span class="math inline">\(\lim_{n\to\infty}\operatorname{Bias}\left(\hat\theta_n\right)=0\)</span>. If the bias of an estimator is small (or zero), we know that the estimator will have a distribution that is centered around the true (usually unknown) parameter <span class="math inline">\(\theta\)</span>; however, such an estimator may still vary a lot around <span class="math inline">\(\theta\)</span>. Therefore, is is also important to assess the variance of the estimator.</p>
<div id="def-var" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.2 (Variance and Standard Error of <span class="math inline">\(\theta\)</span>) </strong></span>The <strong>variance</strong> of an estimator <span class="math inline">\(\hat\theta_n\)</span> is defined equivalently to the variance of any other random variable</p>
<p><span class="math display">\[
Var\left(\hat\theta_n\right) = E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right].
\]</span> The square root of the variance of an estimator is called <strong>standard error</strong> (not standard deviation) of <span class="math inline">\(\hat\theta_n\)</span>, <span class="math display">\[
\operatorname{SE}\left(\hat\theta_n\right) = \sqrt{Var\left(\hat\theta_n\right)}.
\]</span></p>
</div>
<p>We would like to have estimators with a small as possible variance, and the variance should decline as the sample size increases, such that <span class="math inline">\(\lim_{n\to\infty}Var\left(\hat\theta_n\right)=0\)</span>.</p>
<div id="def-mse" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.3 (Mean Squared Error of <span class="math inline">\(\theta\)</span>) </strong></span>The <strong>mean squared error</strong> of an estimator <span class="math inline">\(\hat\theta_n\)</span> is defined as</p>
<p><span class="math display">\[
\operatorname{MSE}\left(\hat\theta_n\right) =  E\left[\left(\hat\theta_n - \theta\right)^2\right].
\]</span></p>
</div>
<p>We would like to have estimators with a small as possible mean squared error, and the mean squared error should decline as the sample size increases, such that <span class="math inline">\(\lim_{n\to\infty}\operatorname{MSE}\left(\hat\theta_n\right)=0\)</span>.</p>
<p>The following holds true:</p>
<ul>
<li>The mean squared error equals the sum of the squared bias and the variance:</li>
</ul>
<p><span class="math display">\[
\operatorname{MSE}\left(\hat\theta_n\right) = \left(\operatorname{Bias}\left(\hat\theta_n\right)\right)^2 +  Var\left(\hat\theta_n\right)
\]</span></p>
<ul>
<li>For unbiased estimators (i.e.&nbsp;<span class="math inline">\(E(\hat\theta_n)=\theta\)</span>) the mean squared error equals the variance, i.e.</li>
</ul>
<p><span class="math display">\[
\underbrace{E\left[\left(\hat\theta_n - \theta\right)^2\right]}_{\operatorname{MSE}\left(\hat\theta_n\right)} = \underbrace{E\left[\left(\hat\theta_n - E\left(\hat\theta_n\right)\right)^2\right]}_{ Var\left(\hat\theta_n\right)}
\]</span></p>
<p>Unfortunately, it is often difficult to derive the above assessment metrics for given sample sizes <span class="math inline">\(n\)</span> and given data distributions <span class="math inline">\(F_X\)</span>. Monte Carlo simulations allow us to solve this issue.</p>
</section>
<section id="approximating-bias-variance-and-mean-squared-error-using-monte-carlo-simulations" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="approximating-bias-variance-and-mean-squared-error-using-monte-carlo-simulations"><span class="header-section-number">3.4</span> Approximating Bias, Variance, and Mean Squared Error using Monte Carlo Simulations</h2>
<p>We can use Monte Carlo simulations to approximate the assessment metrics <span class="math inline">\(\operatorname{Bias}\left(\hat\theta_n\right),\)</span> <span class="math inline">\(Var\left(\hat\theta_n\right),\)</span> and <span class="math inline">\(\operatorname{MSE}\left(\hat\theta_n\right)\)</span> for given sample sizes <span class="math inline">\(n\)</span> and given data distributions <span class="math inline">\(F_X\)</span> with arbitrary precision.</p>
<p>Any of the the above assessment metrics require us to compute means of random variables:</p>
<ul>
<li><p>For the <span class="math inline">\(\operatorname{Bias}\left(\hat\theta_n\right)\)</span> we need to compute <span class="math inline">\(E\left(\hat\theta_n\right)-\theta\)</span></p></li>
<li><p>For the <span class="math inline">\(Var\left(\hat\theta_n\right)\)</span> we need to compute <span class="math inline">\(E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right]\)</span>.</p></li>
<li><p>For the <span class="math inline">\(\operatorname{MSE}\left(\hat\theta_n\right)\)</span> we need to compute <span class="math inline">\(E\left[\left(\hat\theta_n - \theta\right)^2\right]\)</span>.</p></li>
</ul>
<p>A Monte Carlo simulation can approximate these means by using the <strong>law of large numbers</strong> which states that a sample mean over iid random variables is able to approximate the population mean of these random variables as the number of random variables to average over get large.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>Thus, to compute a very precise approximation to <span class="math inline">\(E\left(\hat\theta_n\right)-\theta\)</span>, we can use a computer to execute the following algorithm:</p>
<p><strong>Step 1.</strong> Generate <span class="math inline">\(B\)</span> many (e.g.&nbsp;<span class="math inline">\(B=10,000\)</span>) realizations of the iid random sample</p>
<p><span class="math display">\[
(X_{1,1},\dots,X_{n,1}),\; (X_{1,2},\dots,X_{n,2}),\dots, (X_{1,B},\dots,X_{n,B})
\]</span></p>
<p><strong>Step 2.</strong> Compute the corresponding <span class="math inline">\(B\)</span> many realizations of the estimator</p>
<p><span class="math display">\[
\underbrace{\hat\theta(X_{1,1},\dots,X_{n,1})}_{=\hat\theta_{n,1}},\;\underbrace{\hat\theta(X_{1,2},\dots,X_{n,2})}_{=\hat\theta_{n,2}},\dots,\underbrace{\hat\theta(X_{1,B},\dots,X_{n,B})}_{=\hat\theta_{n,B}}
\]</span> <strong>Step 3.</strong> Use the sample mean as an approximation to the population mean</p>
<p><span class="math display">\[
\left(\frac{1}{B}\sum_{b=1}^B \hat\theta_{n,b}\right) - \theta \approx E\left(\hat\theta_n\right)-\theta
\]</span></p>
<p>By law of large numbers this approximation gets arbitrarily precise as <span class="math inline">\(B \to \infty\)</span>.</p>
<ul>
<li>The bias of <span class="math inline">\(\hat\theta_n\)</span> can be approximated by</li>
</ul>
<p><span class="math display">\[
\operatorname{Bias}\left(\hat\theta_n\right)=E\left(\hat\theta_n\right)-\theta\approx\left(\frac{1}{B}\sum_{b=1}^B \hat\theta_{n,b}\right) - \theta = \widehat{\operatorname{Bias}}_{MC}\left(\hat\theta_n\right)
\]</span></p>
<ul>
<li>The variance of <span class="math inline">\(\hat\theta_n\)</span> can be approximated by</li>
</ul>
<p><span class="math display">\[
Var\left(\hat\theta_n\right)=E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right]\approx \frac{1}{B}\sum_{b=1}^B \left(\hat\theta_{n,b} - \left(\frac{1}{B}\sum_{b=1}^B \hat\theta_{n,b}\right)\right)^2 = \widehat{Var}_{MC}\left(\hat\theta_n\right)
\]</span></p>
<ul>
<li>The mean squared error of <span class="math inline">\(\hat\theta_n\)</span> can be approximated by</li>
</ul>
<p><span class="math display">\[
\operatorname{MSE}\left(\hat\theta_n\right)=E\left[\left(\hat\theta_n - \theta\right)^2\right]\approx\frac{1}{B}\sum_{b=1}^B \left(\hat\theta_{n,b} - \theta\right)^2 = \widehat{\operatorname{MSE}}_{MC}\left(\hat\theta_n\right)
\]</span></p>
<section id="example-sample-mean" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="example-sample-mean">Example: Sample Mean</h3>
<p>The following <code>R</code> code contains a Monte Carlo simulation ( <code>B = 10000</code> replications) computing the bias, variance, and means squared error for the sample mean <span class="math inline">\((\hat\theta_n=)\bar{X}_n=\sum_{i=1}^nX_i\)</span> as the estimator of the population mean <span class="math inline">\((\theta=)\mu\)</span>. The random sample <span class="math inline">\(X_i\overset{iid}{\sim}F_X\)</span>, <span class="math inline">\(i=1,\dots,n\)</span>, is drawn from a normal distribution <span class="math inline">\(F_X=\mathcal{N}(\mu,\sigma^2)\)</span> with mean <span class="math inline">\(\mu=10\)</span> and variance <span class="math inline">\(\sigma^2=5\)</span>. We investigate the accuracy of the estimator for different sample sizes <span class="math inline">\(n\in\{5,15,50\}\)</span>. <!-- The following `R` codes generated `B = 10000` realizations of the estimator $\bar{X}_n$ for each sample size $n\in\{5,15,50\}$ and stores all these realizations in a $10000\times 3$ matrix `estimates_mat`: --></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Set seed for the random number generator to get reproducible results</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="do">## True parameter value ('theta' here 'mu')</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>mu            <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Monte Carlo repetitions:</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>B             <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Sequence of different sample sizes:</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>n_seq         <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">50</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Function that generates estimator realizations </span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>my_estimates_generator <span class="ot">&lt;-</span> <span class="cf">function</span>(n){</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  X_sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">5</span>))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute the sample mean realization</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">mean</span>(X_sample))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>estimates_mat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">1</span>])),</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">2</span>])),</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">3</span>]))</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following <code>R</code> code computes the Monte Carlo (MC) approximations for the bias, variance, and mean squared error of <span class="math inline">\(\bar{X}_n\)</span>. The results should capture our observations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Bias of the sample mean for different sample sizes n</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>MC_Bias_n_seq <span class="ot">&lt;-</span> <span class="fu">apply</span>(estimates_mat, <span class="dv">2</span>, mean) <span class="sc">-</span> mu</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Variance of the sample mean for different sample sizes n</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>MC_Var_n_seq  <span class="ot">&lt;-</span> <span class="fu">apply</span>(estimates_mat, <span class="dv">2</span>, var)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Mean squared error of the sample mean for different sample sizes n</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>MC_MSE_n_seq  <span class="ot">&lt;-</span> <span class="fu">apply</span>(estimates_mat, <span class="dv">2</span>, <span class="cf">function</span>(x){<span class="fu">mean</span>((x <span class="sc">-</span> mu)<span class="sc">^</span><span class="dv">2</span>)})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The table shows the numerical values of the Monte Carlo <em>approximations</em> for the true bias, true variance, and true mean squared error of <span class="math inline">\(\bar{X}_n\)</span>:</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-mcbvmse" class="anchored">

<table class="table" style="margin-left: auto; margin-right: auto;"><caption>Table&nbsp;3.1:  Monte Carlo approximations for the true bias, true variance, and true mean squared error of sample mean. </caption>
 <thead>
  <tr>
   <th style="text-align:right;"> n </th>
   <th style="text-align:right;"> Bias (MC-Sim)  </th>
   <th style="text-align:right;"> Variance (MC-Sim) </th>
   <th style="text-align:right;"> MSE (MC-Sim)  </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> -0.001 </td>
   <td style="text-align:right;"> 1.02 </td>
   <td style="text-align:right;"> 1.02 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 0.000 </td>
   <td style="text-align:right;"> 0.33 </td>
   <td style="text-align:right;"> 0.33 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 50 </td>
   <td style="text-align:right;"> 0.001 </td>
   <td style="text-align:right;"> 0.10 </td>
   <td style="text-align:right;"> 0.10 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p>These Monte Carlo approximations (<a href="#tbl-mcbvmse">Table&nbsp;<span>3.1</span></a>) indicate that:</p>
<ul>
<li>The true bias <span class="math inline">\(\operatorname{Bias}(\bar{X}_n)\)</span> is very likely zero for all sample sizes <span class="math inline">\(n\in\{5,15,50\}\)</span></li>
</ul>
<!-- , and thus $Var(\bar{X}_n)\approx \operatorname{MSE}(\bar{X}_n)$ for all sample sizes $n\in\{5,15,50\}$. -->
<ul>
<li>The true mean squared error <span class="math inline">\(\operatorname{MSE}(\bar{X}_n)\)</span> is very likely decreasing as the sample size <span class="math inline">\(n\)</span> get larger.</li>
</ul>
<!-- The sample mean $\bar{X}_n$ is known to be a very good estimator of the population mean $\mu$ and the above simulation results conform this.  -->
<p>Since this example is chosen to be an extremely simple one, we can easily derive the <em>true</em> bias, variance and mean squared error values and compare them with their Monte Carlo approximations:</p>
<ul>
<li>True bias of <span class="math inline">\(\bar{X}_n\)</span>:</li>
</ul>
<p><span class="math display">\[
\operatorname{Bias}\left(\bar{X}_n\right)=E\left(\frac{1}{n}\sum_{i=1}^nX_i\right) - \mu = \left(\frac{1}{n}\sum_{i=1}^nE(X_i)\right) -\mu = \frac{n}{n}\mu-\mu =0,
\]</span> thus the mean squared error of <span class="math inline">\(\bar{X}_n\)</span> equals the variance of <span class="math inline">\(\bar{X}_n\)</span>.</p>
<ul>
<li>True variance of <span class="math inline">\(\bar{X}_n\)</span>:</li>
</ul>
<p><span class="math display">\[
Var\left(\bar{X}_n\right)=Var\left(\frac{1}{n}\sum_{i=1}^nX_i\right) = \frac{1}{n^2} \sum_{i=1}^nVar\left(X_i\right) = \frac{n}{n^2}\sigma^2 = \frac{5}{n}
\]</span> The following table shows the true bias, true variance and true mean squared error values:</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-truebvmse" class="anchored">

<table class="table" style="margin-left: auto; margin-right: auto;"><caption>Table&nbsp;3.2:  True bias, true variance, and true mean squared error of sample mean. (Only computable in simple special cases.) </caption>
 <thead>
  <tr>
   <th style="text-align:right;"> n </th>
   <th style="text-align:right;"> Bias (true)  </th>
   <th style="text-align:right;"> Variance (true) </th>
   <th style="text-align:right;"> MSE (true)  </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 1.00 </td>
   <td style="text-align:right;"> 1.00 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 0.33 </td>
   <td style="text-align:right;"> 0.33 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 50 </td>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 0.10 </td>
   <td style="text-align:right;"> 0.10 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Obviously, the Monte Carlo approximations (<a href="#tbl-mcbvmse">Table&nbsp;<span>3.1</span></a>) for these true values (<a href="#tbl-truebvmse">Table&nbsp;<span>3.2</span></a>) are very good. If we would further increase the number of Monte Carlo repetitions <code>B</code>, the Monte Carlo approximations would get even more precise since we can make them arbitrarily precise by letting <code>B</code><span class="math inline">\(\to\infty\)</span> using the law of large numbers.</p>
<!-- ```{r, fig.align="center"} -->
<!-- par(mfrow=c(1,3)) -->
<!-- plot(x = n_seq, y = Bias_n_seq, type = "b", ylim = c(-0.2, 0.2),  -->
<!--      main="Bias", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- plot(x = n_seq, y = Var_n_seq, type = "b", ylim = c(0, 1.5), -->
<!--      main="Variance", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- plot(x = n_seq, y = MSE_n_seq, type = "b", ylim = c(0, 1.5), -->
<!--      main="MSE", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- ``` -->
<!-- like, for instance, the arithmetic mean   -->
<!-- $$ -->
<!-- \bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i -->
<!-- $$ -->
<!-- as an estimator of the population mean value $\mu$.  -->


</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>See <a href="06-Asymptotics.html#thm-SLLN1">Theorem&nbsp;<span>6.2</span></a> in <a href="06-Asymptotics.html"><span>Chapter&nbsp;6</span></a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-Review-Prob_n_Stats.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Review: Probability and Statistics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./04-MultipleReg.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>