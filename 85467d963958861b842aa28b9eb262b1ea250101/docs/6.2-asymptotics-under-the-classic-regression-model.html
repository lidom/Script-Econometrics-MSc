<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.2 Asymptotics under the Classic Regression Model | Econometrics (M.Sc.)</title>
  <meta name="description" content="6.2 Asymptotics under the Classic Regression Model | Econometrics (M.Sc.)" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="6.2 Asymptotics under the Classic Regression Model | Econometrics (M.Sc.)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/mylogo.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.2 Asymptotics under the Classic Regression Model | Econometrics (M.Sc.)" />
  
  
  <meta name="twitter:image" content="/images/mylogo.png" />

<meta name="author" content="Prof. Dr. Dominik Liebl" />


<meta name="date" content="2021-10-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="6.1-tools-for-asymptotic-statistics.html"/>
<link rel="next" href="6.3-robust-confidence-intervals.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="organization-of-the-course.html"><a href="organization-of-the-course.html"><i class="fa fa-check"></i>Organization of the Course</a></li>
<li class="chapter" data-level="" data-path="literature.html"><a href="literature.html"><i class="fa fa-check"></i>Literature</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-introduction-to-r.html"><a href="1-introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-short-glossary.html"><a href="1.1-short-glossary.html"><i class="fa fa-check"></i><b>1.1</b> Short Glossary</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-first-steps.html"><a href="1.2-first-steps.html"><i class="fa fa-check"></i><b>1.2</b> First Steps</a></li>
<li class="chapter" data-level="1.3" data-path="1.3-further-data-objects.html"><a href="1.3-further-data-objects.html"><i class="fa fa-check"></i><b>1.3</b> Further Data Objects</a></li>
<li class="chapter" data-level="1.4" data-path="1.4-simple-regression-analysis-using-r.html"><a href="1.4-simple-regression-analysis-using-r.html"><i class="fa fa-check"></i><b>1.4</b> Simple Regression Analysis using R</a></li>
<li class="chapter" data-level="1.5" data-path="1.5-programming-in-r.html"><a href="1.5-programming-in-r.html"><i class="fa fa-check"></i><b>1.5</b> Programming in R</a></li>
<li class="chapter" data-level="1.6" data-path="1.6-r-packages.html"><a href="1.6-r-packages.html"><i class="fa fa-check"></i><b>1.6</b> R-packages</a></li>
<li class="chapter" data-level="1.7" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html"><i class="fa fa-check"></i><b>1.7</b> Tidyverse</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#tidyverse-plotting-basics"><i class="fa fa-check"></i><b>1.7.1</b> Tidyverse: Plotting Basics</a></li>
<li class="chapter" data-level="1.7.2" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#tidyverse-data-wrangling-basics"><i class="fa fa-check"></i><b>1.7.2</b> Tidyverse: Data Wrangling Basics</a></li>
<li class="chapter" data-level="1.7.3" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#the-pipe-operator"><i class="fa fa-check"></i><b>1.7.3</b> The pipe operator <code>%&gt;%</code></a></li>
<li class="chapter" data-level="1.7.4" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#the-group_by-function"><i class="fa fa-check"></i><b>1.7.4</b> The <code>group_by()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="1.8-further-links.html"><a href="1.8-further-links.html"><i class="fa fa-check"></i><b>1.8</b> Further Links</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="1.8-further-links.html"><a href="1.8-further-links.html#further-r-intros"><i class="fa fa-check"></i><b>1.8.1</b> Further R-Intros</a></li>
<li class="chapter" data-level="1.8.2" data-path="1.8-further-links.html"><a href="1.8-further-links.html#version-control-gitgithub"><i class="fa fa-check"></i><b>1.8.2</b> Version Control (Git/GitHub)</a></li>
<li class="chapter" data-level="1.8.3" data-path="1.8-further-links.html"><a href="1.8-further-links.html#r-ladies"><i class="fa fa-check"></i><b>1.8.3</b> R-Ladies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-review-probability-and-statistics.html"><a href="2-review-probability-and-statistics.html"><i class="fa fa-check"></i><b>2</b> Review: Probability and Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html"><i class="fa fa-check"></i><b>2.1</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>2.1.1</b> Sample Spaces and Events</a></li>
<li class="chapter" data-level="2.1.2" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#probability"><i class="fa fa-check"></i><b>2.1.2</b> Probability</a></li>
<li class="chapter" data-level="2.1.3" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#independent-events"><i class="fa fa-check"></i><b>2.1.3</b> Independent Events</a></li>
<li class="chapter" data-level="2.1.4" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>2.1.4</b> Conditional Probability</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html"><i class="fa fa-check"></i><b>2.2</b> Random Variables</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#univariate-distribution-and-probability-functions"><i class="fa fa-check"></i><b>2.2.1</b> Univariate Distribution and Probability Functions</a></li>
<li class="chapter" data-level="2.2.2" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#multivariate-distribution-and-probability-functions"><i class="fa fa-check"></i><b>2.2.2</b> Multivariate Distribution and Probability Functions</a></li>
<li class="chapter" data-level="2.2.3" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#means-and-moments"><i class="fa fa-check"></i><b>2.2.3</b> Means and Moments</a></li>
<li class="chapter" data-level="2.2.4" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#unconditional-means"><i class="fa fa-check"></i><b>2.2.4</b> Unconditional Means</a></li>
<li class="chapter" data-level="2.2.5" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#conditional-means"><i class="fa fa-check"></i><b>2.2.5</b> Conditional Means</a></li>
<li class="chapter" data-level="2.2.6" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#means-of-transformed-random-variables-and-moments"><i class="fa fa-check"></i><b>2.2.6</b> Means of Transformed Random Variables and Moments</a></li>
<li class="chapter" data-level="2.2.7" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>2.2.7</b> Independent Random Variables</a></li>
<li class="chapter" data-level="2.2.8" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#i.i.d.-samples"><i class="fa fa-check"></i><b>2.2.8</b> I.I.D. Samples</a></li>
<li class="chapter" data-level="2.2.9" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#some-important-discrete-random-variables"><i class="fa fa-check"></i><b>2.2.9</b> Some Important Discrete Random Variables</a></li>
<li class="chapter" data-level="2.2.10" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#some-important-continuous-random-variables"><i class="fa fa-check"></i><b>2.2.10</b> Some Important Continuous Random Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-ch:SLR.html"><a href="3-ch:SLR.html"><i class="fa fa-check"></i><b>3</b> Review: Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html"><i class="fa fa-check"></i><b>3.1</b> The Simple Linear Regression Model</a>
<ul>
<li class="chapter" data-level="" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#the-data-generating-process"><i class="fa fa-check"></i>The Data-Generating Process</a></li>
<li class="chapter" data-level="3.1.1" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#assumptions-about-the-error-term"><i class="fa fa-check"></i><b>3.1.1</b> Assumptions About the Error Term</a></li>
<li class="chapter" data-level="3.1.2" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#the-population-regression-line"><i class="fa fa-check"></i><b>3.1.2</b> The Population Regression Line</a></li>
<li class="chapter" data-level="3.1.3" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#terminology-estimates-versus-estimators"><i class="fa fa-check"></i><b>3.1.3</b> Terminology: Estimates versus Estimators</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html"><i class="fa fa-check"></i><b>3.2</b> Ordinary Least Squares Estimation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html#terminology-sample-regression-line-prediction-and-residuals"><i class="fa fa-check"></i><b>3.2.1</b> Terminology: Sample Regression Line, Prediction and Residuals</a></li>
<li class="chapter" data-level="3.2.2" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html#sec:SLROLS"><i class="fa fa-check"></i><b>3.2.2</b> Deriving the Expression of the OLS Estimator</a></li>
<li class="chapter" data-level="3.2.3" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html#behavior-of-the-ols-estimates-for-resampled-data-conditionally-on-x_i"><i class="fa fa-check"></i><b>3.2.3</b> Behavior of the OLS Estimates for Resampled Data (conditionally on <span class="math inline">\(X_i\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html"><i class="fa fa-check"></i><b>3.3</b> Properties of the OLS Estimator</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html#mean-and-bias-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.1</b> Mean and Bias of the OLS Estimator</a></li>
<li class="chapter" data-level="3.3.2" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html#variance-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.2</b> Variance of the OLS Estimator</a></li>
<li class="chapter" data-level="3.3.3" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html#consistency-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.3</b> Consistency of the OLS Estimator</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-ch:MLR.html"><a href="4-ch:MLR.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-assumptions.html"><a href="4.1-assumptions.html"><i class="fa fa-check"></i><b>4.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="4.1-assumptions.html"><a href="4.1-assumptions.html#some-implications-of-the-exogeneity-assumption"><i class="fa fa-check"></i><b>4.1.1</b> Some Implications of the Exogeneity Assumption</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4.2-deriving-the-expression-of-the-ols-estimator.html"><a href="4.2-deriving-the-expression-of-the-ols-estimator.html"><i class="fa fa-check"></i><b>4.2</b> Deriving the Expression of the OLS Estimator</a></li>
<li class="chapter" data-level="4.3" data-path="4.3-some-quantities-of-interest.html"><a href="4.3-some-quantities-of-interest.html"><i class="fa fa-check"></i><b>4.3</b> Some Quantities of Interest</a></li>
<li class="chapter" data-level="4.4" data-path="4.4-method-of-moments-estimator.html"><a href="4.4-method-of-moments-estimator.html"><i class="fa fa-check"></i><b>4.4</b> Method of Moments Estimator</a></li>
<li class="chapter" data-level="4.5" data-path="4.5-unbiasedness-of-hatbetax.html"><a href="4.5-unbiasedness-of-hatbetax.html"><i class="fa fa-check"></i><b>4.5</b> Unbiasedness of <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="4.6" data-path="4.6-ch:VarEstBeta.html"><a href="4.6-ch:VarEstBeta.html"><i class="fa fa-check"></i><b>4.6</b> Variance of <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="4.7" data-path="4.7-the-gauss-markov-theorem.html"><a href="4.7-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>4.7</b> The Gauss-Markov Theorem</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-ch:SSINF.html"><a href="5-ch:SSINF.html"><i class="fa fa-check"></i><b>5</b> Small Sample Inference</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5.1-ch:testmultp.html"><a href="5.1-ch:testmultp.html"><i class="fa fa-check"></i><b>5.1</b> Hypothesis Tests about Multiple Parameters</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="5.1-ch:testmultp.html"><a href="5.1-ch:testmultp.html#the-test-statistic-and-its-null-distribution"><i class="fa fa-check"></i><b>5.1.1</b> The Test Statistic and its Null Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5.2-ch:testingsinglep.html"><a href="5.2-ch:testingsinglep.html"><i class="fa fa-check"></i><b>5.2</b> Tests about One Parameter</a></li>
<li class="chapter" data-level="5.3" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html"><i class="fa fa-check"></i><b>5.3</b> Testtheory</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html#significance-level"><i class="fa fa-check"></i><b>5.3.1</b> Significance Level</a></li>
<li class="chapter" data-level="5.3.2" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html#critical-value-for-the-f-test"><i class="fa fa-check"></i><b>5.3.2</b> Critical Value for the <span class="math inline">\(F\)</span>-Test</a></li>
<li class="chapter" data-level="5.3.3" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html#critical-values-for-the-t-test"><i class="fa fa-check"></i><b>5.3.3</b> Critical Value(s) for the <span class="math inline">\(t\)</span>-Test</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5.4-type-ii-error-and-power.html"><a href="5.4-type-ii-error-and-power.html"><i class="fa fa-check"></i><b>5.4</b> Type II Error and Power</a></li>
<li class="chapter" data-level="5.5" data-path="5.5-p-value.html"><a href="5.5-p-value.html"><i class="fa fa-check"></i><b>5.5</b> <span class="math inline">\(p\)</span>-Value</a></li>
<li class="chapter" data-level="5.6" data-path="5.6-CIsmallsample.html"><a href="5.6-CIsmallsample.html"><i class="fa fa-check"></i><b>5.6</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.7" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html"><i class="fa fa-check"></i><b>5.7</b> Practice: Small Sample Inference</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html#normally-distributed-hatbetax"><i class="fa fa-check"></i><b>5.7.1</b> Normally Distributed <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="5.7.2" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html#testing-multiple-parameters"><i class="fa fa-check"></i><b>5.7.2</b> Testing Multiple Parameters</a></li>
<li class="chapter" data-level="5.7.3" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html#dualty-of-confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>5.7.3</b> Dualty of Confidence Intervals and Hypothesis Tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-ch:LSINF.html"><a href="6-ch:LSINF.html"><i class="fa fa-check"></i><b>6</b> Large Sample Inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html"><i class="fa fa-check"></i><b>6.1</b> Tools for Asymptotic Statistics</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#modes-of-convergence"><i class="fa fa-check"></i><b>6.1.1</b> Modes of Convergence</a></li>
<li class="chapter" data-level="" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#four-important-modes-of-convergence"><i class="fa fa-check"></i>Four Important Modes of Convergence</a></li>
<li class="chapter" data-level="" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#relations-among-modes-of-convergence"><i class="fa fa-check"></i>Relations among Modes of Convergence</a></li>
<li class="chapter" data-level="6.1.2" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#continuous-mapping-theorem-cmt"><i class="fa fa-check"></i><b>6.1.2</b> Continuous Mapping Theorem (CMT)</a></li>
<li class="chapter" data-level="6.1.3" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#slutsky-theorem"><i class="fa fa-check"></i><b>6.1.3</b> Slutsky Theorem</a></li>
<li class="chapter" data-level="6.1.4" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#law-of-large-numbers-lln-and-central-limit-theorem-clt"><i class="fa fa-check"></i><b>6.1.4</b> Law of Large Numbers (LLN) and Central Limit Theorem (CLT)</a></li>
<li class="chapter" data-level="6.1.5" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#estimators-as-a-sequences-of-random-variables"><i class="fa fa-check"></i><b>6.1.5</b> Estimators as a Sequences of Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6.2-asymptotics-under-the-classic-regression-model.html"><a href="6.2-asymptotics-under-the-classic-regression-model.html"><i class="fa fa-check"></i><b>6.2</b> Asymptotics under the Classic Regression Model</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="6.2-asymptotics-under-the-classic-regression-model.html"><a href="6.2-asymptotics-under-the-classic-regression-model.html#the-case-of-heteroscedasticity"><i class="fa fa-check"></i><b>6.2.1</b> The Case of Heteroscedasticity</a></li>
<li class="chapter" data-level="6.2.2" data-path="6.2-asymptotics-under-the-classic-regression-model.html"><a href="6.2-asymptotics-under-the-classic-regression-model.html#hypothesis-testing-and-confidence-intervals"><i class="fa fa-check"></i><b>6.2.2</b> Hypothesis Testing and Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6.3-robust-confidence-intervals.html"><a href="6.3-robust-confidence-intervals.html"><i class="fa fa-check"></i><b>6.3</b> Robust Confidence Intervals</a></li>
<li class="chapter" data-level="6.4" data-path="6.4-practice-large-sample-inference.html"><a href="6.4-practice-large-sample-inference.html"><i class="fa fa-check"></i><b>6.4</b> Practice: Large Sample Inference</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="6.4-practice-large-sample-inference.html"><a href="6.4-practice-large-sample-inference.html#normally-distributed-hatbeta-for-ntoinfty"><i class="fa fa-check"></i><b>6.4.1</b> Normally Distributed <span class="math inline">\(\hat\beta\)</span> for <span class="math inline">\(n\to\infty\)</span></a></li>
<li class="chapter" data-level="6.4.2" data-path="6.4-practice-large-sample-inference.html"><a href="6.4-practice-large-sample-inference.html#testing-multiple-and-single-parameters"><i class="fa fa-check"></i><b>6.4.2</b> Testing Multiple and Single Parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-maximum-likelihood.html"><a href="7-maximum-likelihood.html"><i class="fa fa-check"></i><b>7</b> Maximum Likelihood</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7.1-likelihood-principle.html"><a href="7.1-likelihood-principle.html"><i class="fa fa-check"></i><b>7.1</b> Likelihood Principle</a></li>
<li class="chapter" data-level="7.2" data-path="7.2-properties-of-maximum-likelihood-estimators.html"><a href="7.2-properties-of-maximum-likelihood-estimators.html"><i class="fa fa-check"></i><b>7.2</b> Properties of Maximum Likelihood Estimators</a></li>
<li class="chapter" data-level="7.3" data-path="7.3-the-log-likelihood-function.html"><a href="7.3-the-log-likelihood-function.html"><i class="fa fa-check"></i><b>7.3</b> The (Log-)Likelihood Function</a></li>
<li class="chapter" data-level="7.4" data-path="7.4-optimization-non-analytical-solutions.html"><a href="7.4-optimization-non-analytical-solutions.html"><i class="fa fa-check"></i><b>7.4</b> Optimization: Non-Analytical Solutions</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="7.4-optimization-non-analytical-solutions.html"><a href="7.4-optimization-non-analytical-solutions.html#newton-raphson-optimization"><i class="fa fa-check"></i><b>7.4.1</b> Newton-Raphson Optimization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="7.5-ols-estimation-as-ml-estimation.html"><a href="7.5-ols-estimation-as-ml-estimation.html"><i class="fa fa-check"></i><b>7.5</b> OLS-Estimation as ML-Estimation</a></li>
<li class="chapter" data-level="7.6" data-path="7.6-variance-of-ml-estimators-hatbeta_ml-and-s2_ml.html"><a href="7.6-variance-of-ml-estimators-hatbeta_ml-and-s2_ml.html"><i class="fa fa-check"></i><b>7.6</b> Variance of ML-Estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}\)</span></a></li>
<li class="chapter" data-level="7.7" data-path="7.7-consistency-of-hatbeta_ml-and-s_ml2.html"><a href="7.7-consistency-of-hatbeta_ml-and-s_ml2.html"><i class="fa fa-check"></i><b>7.7</b> Consistency of <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s_{ML}^2\)</span></a></li>
<li class="chapter" data-level="7.8" data-path="7.8-asymptotic-theory-of-maximum-likelihood-estimators.html"><a href="7.8-asymptotic-theory-of-maximum-likelihood-estimators.html"><i class="fa fa-check"></i><b>7.8</b> Asymptotic Theory of Maximum-Likelihood Estimators</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-ivr.html"><a href="8-ivr.html"><i class="fa fa-check"></i><b>8</b> Instrumental Variables Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8.1-TIVEWASRAASI.html"><a href="8.1-TIVEWASRAASI.html"><i class="fa fa-check"></i><b>8.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="8.1-TIVEWASRAASI.html"><a href="8.1-TIVEWASRAASI.html#the-two-stage-least-squares-estimator"><i class="fa fa-check"></i><b>8.1.1</b> The Two-Stage Least Squares Estimator</a></li>
<li class="chapter" data-level="8.1.2" data-path="8.1-TIVEWASRAASI.html"><a href="8.1-TIVEWASRAASI.html#application-demand-for-cigarettes-12"><i class="fa fa-check"></i><b>8.1.2</b> Application: Demand For Cigarettes (1/2)</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8.2-TGIVRM.html"><a href="8.2-TGIVRM.html"><i class="fa fa-check"></i><b>8.2</b> The General IV Regression Model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8.2-TGIVRM.html"><a href="8.2-TGIVRM.html#application-demand-for-cigarettes-22"><i class="fa fa-check"></i><b>8.2.1</b> Application: Demand for Cigarettes (2/2)</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8.3-civ.html"><a href="8.3-civ.html"><i class="fa fa-check"></i><b>8.3</b> Checking Instrument Validity</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="8.3-civ.html"><a href="8.3-civ.html#instrument-relevance"><i class="fa fa-check"></i><b>8.3.1</b> Instrument Relevance</a></li>
<li class="chapter" data-level="8.3.2" data-path="8.3-civ.html"><a href="8.3-civ.html#instrument-validity"><i class="fa fa-check"></i><b>8.3.2</b> Instrument Validity</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8.4-attdfc.html"><a href="8.4-attdfc.html"><i class="fa fa-check"></i><b>8.4</b> Application to the Demand for Cigarettes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Econometrics (M.Sc.)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="asymptotics-under-the-classic-regression-model" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Asymptotics under the Classic Regression Model</h2>
<p>Given the above introduced machinery on asymptotic concepts and results, we can now proof that the OLS estimators <span class="math inline">\(\hat\beta\)</span> and <span class="math inline">\(s_{UB}^2\)</span> applied to the classic regression model (defined by Assumptions 1-4) are consistent and asymptotically normal distributed estimators as <span class="math inline">\(n\to\infty\)</span>. That is, we can drop the unrealistic normality and spherical errors assumption (Assumption 4<span class="math inline">\(^\ast\)</span>), but still use the usual test statistics (t-test, F-test); as long as the sample size <span class="math inline">\(n\)</span> is </p>
<p>However, before we can formally state the asymptotic properties, we first need to adjust our  assumption (Assumption 1) such that we can apply Kolmogorov’s strong LLN and Lindeberg-Levy’s CLT. Second, we need to adjust the rank assumption (Assumption 3), such that the full column rank of <span class="math inline">\(X\)</span> is guaranteed for the limiting case as <span class="math inline">\(n\to\infty\)</span>, too. Assumptions 2 and 4 from Chapter  are assumed to hold.</p>
<p>Assumption 1 applies, but  we assume that <span class="math inline">\((X_i,\eps_i)\)</span> (or equivalently <span class="math inline">\((Y_i,X_i)\)</span>) is i.i.d. for all <span class="math inline">\(i=1,\dots,n\)</span>, with existing and finite second moments for <span class="math inline">\(X_i\)</span> and fourth moments for <span class="math inline">\(\eps_i\)</span>. (Note: The fourth moment of <span class="math inline">\(\eps_i\)</span> is actually only needed for Theorem ; for the rest two moments are sufficient.)</p>
<p>The above adjustment of Assumption 1 is far less restrictive than assuming that the error-terms are normally distributed (as it’s necessary for small samples).</p>
<p>The <span class="math inline">\((K\times K)\)</span> limiting matrix <span class="math inline">\(\Sigma_{X&#39;X}=E(S_{X&#39;X})=E(X_iX_i&#39;)\)</span> in
<span class="math display">\[
n^{-1}X&#39;X=S_{X&#39;X}\toprob\Sigma_{X&#39;X}\quad\text{as}\quad n\to\infty
\]</span>
has full rank <span class="math inline">\(K\)</span>; i.e., <span class="math inline">\(\Sigma_{X&#39;X}\)</span> therefore, is nonsingular and invertible. (Note, this assumption does not assume that <span class="math inline">\(S_{X&#39;X}\toprob\Sigma_{X&#39;X}\)</span>, but if this convergence hold, it assumes that the limiting matrix is of full rank <span class="math inline">\(K\)</span>.)</p>
<p>The crucial part of Assumption 3<span class="math inline">\(^\ast\)</span> is that the limit matrix has full rank <span class="math inline">\(K\)</span>. The convergence in probability statement (<span class="math inline">\(S_{X&#39;X}\toprob\Sigma_{X&#39;X}\)</span>) follows already from Assumption 1<span class="math inline">\(^\ast\)</span>.</p>
<p>Assumption 3<span class="math inline">\(^\ast\)</span> implies the existence and finiteness of the first two moments of <span class="math inline">\(X_i\)</span> (even without Assumption 1<span class="math inline">\(^\ast\)</span>).</p>
<!-- % Under the Assumptions 1$^\ast$, 2, 3$^\ast$, and 4, we can show the following results. -->
<p>Proof is done in the lecture.</p>
<p>Proof is done in the lecture.</p>
<p>Furthermore, we can show that the appropriately scaled (by <span class="math inline">\(\sqrt{n}\)</span>) sampling error <span class="math inline">\(\hat\beta-\beta\)</span> of the OLS estimator is asymptotically normal distributed.</p>
<p>Proof is done in the lecture.</p>
<p>In principle, we can derive the usual test statistics from the latter result. Though, as long as we do not know (we usually don’t) <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\Sigma_{X&#39;X}\)</span> we need to plug-in the (consistent!) estimators <span class="math inline">\(S_{X&#39;X}^{-1}\)</span> and <span class="math inline">\(s_{UB}^2\)</span>, where the consistency of the former estimator is provided by Prop.  and the consistency of <span class="math inline">\(s_{UB}^2\)</span> is provided by the following result.</p>
<p>Proof is skipped, but a detailed proof can be found here: </p>
<div id="the-case-of-heteroscedasticity" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> The Case of Heteroscedasticity</h3>
<p>Theorem  can also be stated and proofed for conditionally heteroscedastic error terms. In this case one gets
<span class="math display">\[\begin{align}\label{OLSnormality1Rob}
\sqrt{n}(\hat\beta_n-\beta)\todistr \mathcal{N}\left(0,\Sigma_{X&#39;X}^{-1}E(\eps^2_iX_iX_i&#39;)\Sigma_{X&#39;X}^{-1}\right)\quad\text{as}\quad n\to\infty
\end{align}\]</span>
where <span class="math inline">\(\Sigma_{X&#39;X}^{-1}E(\eps_i^2X_iX_i&#39;)\Sigma_{X&#39;X}^{-1}\)</span> (i.e., the asymptotic variance of <span class="math inline">\(\sqrt{n}(\hat\beta_n-\beta)\)</span>) is usually unknown and needs to be estimated from the data by
<span class="math display">\[
S_{X&#39;X}^{-1}\widehat{E}(\eps^2_iX_iX_i&#39;)S^{-1}_{X&#39;X}\toprob \Sigma_{X&#39;X}^{-1}E(\eps^2_iX_iX_i&#39;)\Sigma_{X&#39;X}^{-1}\quad\text{as}\quad n\to\infty,
\]</span>
where <span class="math inline">\(\widehat{E}(\eps^2_iX_iX_i&#39;)\)</span> denotes some consistent estimator of <span class="math inline">\(E(\eps^2X_iX_i&#39;)\)</span> such as one of the followingt choices:
<span class="math display">\[\begin{align*}
\hspace*{-2cm}\text{HC0:}\quad &amp; \widehat{E}(\eps^2_iX_iX_i&#39;)=\frac{1}{n}\sum_{i=1}^n\hat\eps_i^2X_iX_i&#39;\\
\text{HC1:}\quad &amp; \widehat{E}(\eps^2_iX_iX_i&#39;)=\frac{1}{n}\sum_{i=1}^n\frac{n}{n-K}\hat\eps_i^2X_iX_i&#39;\\
\text{HC2:}\quad &amp; \widehat{E}(\eps^2_iX_iX_i&#39;)=\frac{1}{n}\sum_{i=1}^n\frac{\hat{\eps}_{i}^{2}}{1-h_{i}}X_iX_i&#39;\\
\text{HC3:}\quad &amp; \widehat{E}(\eps^2_iX_iX_i&#39;)=\frac{1}{n}\sum_{i=1}^n\frac{\hat{\eps}_{i}^{2}}{\left(1-h_{i}\right)^{2}}X_iX_i&#39;\text{\quad($\leftarrow$ Most often used)}\\
\text{HC4:}\quad &amp; \widehat{E}(\eps^2_iX_iX_i&#39;)=\frac{1}{n}\sum_{i=1}^n\frac{\hat{\eps}_{i}^{2}}{\left(1-h_{i}\right)^{\delta_{i}}}X_iX_i&#39;
\end{align*}\]</span>
(These are the heteroscedasticity-consistent robust estimators from Chapter .</p>
<!-- \begin{align*} -->
<!-- \hspace*{-2cm}\text{HC0:}\quad & \hat v_{i}=\hat{\eps}_{i}^{2} \\ -->
<!-- \text{HC1:}\quad & \hat v_{i}=\frac{n}{n-K} \hat{\eps}_{i}^{2} \\ -->
<!-- \text{HC2:}\quad & \hat v_{i}=\frac{\hat{\eps}_{i}^{2}}{1-h_{i}} \\ -->
<!-- \text{HC3:}\quad & \hat v_{i}=\frac{\hat{\eps}_{i}^{2}}{\left(1-h_{i}\right)^{2}}\text{\quad($\leftarrow$ Most often used)} \\ -->
<!-- \text{HC4:}\quad & \hat v_{i}=\frac{\hat{\eps}_{i}^{2}}{\left(1-h_{i}\right)^{\delta_{i}}} -->
<!-- \end{align*} -->
<p>In order to show that any of the above versions (HC0-4) of <span class="math inline">\(\widehat{E}(\eps^2_iX_iX_i&#39;)\)</span> is a consistent estimator of <span class="math inline">\(E(\eps^2_iX_iX_i&#39;)\)</span> we actually need to assume that the explanatory variables in <span class="math inline">\(X\)</span> have finite  moments . So, for this, we would need to make our Assumption 1<span class="math inline">\(^\ast\)</span> more restrictive (only two moments are assumed for <span class="math inline">\(X\)</span>).</p>
<!-- see Hayashi  Chapter 2.5 -->
</div>
<div id="hypothesis-testing-and-confidence-intervals" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Hypothesis Testing and Confidence Intervals</h3>
<p>From our asymptotic results under the classic regression model (Assumptions 1<span class="math inline">\(^\ast\)</span>, 2, 3<span class="math inline">\(^\ast\)</span>, and 4) we get the following results important for testing statistical hypothesis.</p>
<div id="robust-hypothesis-testing-multiple-parameters" class="section level4" number="6.2.2.1">
<h4><span class="header-section-number">6.2.2.1</span> Robust Hypothesis Testing: Multiple Parameters</h4>
<p>Let us reconsider the following system of <span class="math inline">\(q\)</span>-many null hypotheses:
<span class="math display">\[\begin{align*}
H_0: \underset{(q\times K)}{R}\underset{(K\times 1)}{\beta} - \underset{(q\times 1)}{r} = \underset{(q\times 1)}{0},
\end{align*}\]</span>
where the <span class="math inline">\((q \times K)\)</span> matrix <span class="math inline">\(R\)</span> and the <span class="math inline">\(q\)</span>-vector <span class="math inline">\(r=(r_{1},\dots,r_{q})&#39;\)</span> are chosen by the statistician to specify her/his null hypothesis about the unknown true parameter vector <span class="math inline">\(\beta\)</span>. To make sure that there are no redundant equations, it is required that <span class="math inline">\(\rank(R)=q\)</span>.</p>
<p>By contrast to the multiple parameter tests for small samples (see Chapter ), we can work here with a heterosedasticity robust test statistic which is applicable for heteroscedastic error terms:
<span class="math display">\[\begin{equation}\label{Ftestasymp}
W=n(R\hat\beta_n -r)&#39;[R\,S_{X&#39;X}^{-1}\widehat{E}(\eps^2_iX_iX_i&#39;)S^{-1}_{X&#39;X}\,R&#39;]^{-1}(R\hat\beta_n-r)\overset{H_0}{\to}_d\chi^2(q)
\end{equation}\]</span>
as <span class="math inline">\(n\to\infty\)</span>. The price to pay is that the distribution of the test statistic under the null hypothesis is only valid asymptotically for large <span class="math inline">\(n\)</span>. That is, the critical values taken from the asymptotic distribution will be useful only for  samples sizes. In case of homoscedastic error terms, one can substitute <span class="math inline">\(S_{X&#39;X}^{-1}\widehat{E}(\eps^2_iX_iX_i&#39;)S^{-1}_{X&#39;X}\)</span> by <span class="math inline">\(s_{UB}^2S_{X&#39;X}^{-1}\)</span>.</p>
<p>In order to improve the finite-sample performance of this test, one usually uses the <span class="math inline">\(F_{q,n-K}\)</span> distribution with <span class="math inline">\(q\)</span> and <span class="math inline">\(n-K\)</span> degrees of freedoms instead of the <span class="math inline">\(\chi^2(q)\)</span> distribution. Asymptotically (<span class="math inline">\(n\to\infty\)</span>) <span class="math inline">\(F_{q,n-K}\)</span> is equivalent to <span class="math inline">\(\chi^2(q)\)</span>. However, for finite sample sizes <span class="math inline">\(n\)</span> (i.e., the practically relevant case) <span class="math inline">\(F_{q,n-K}\)</span> leads to larger critical values which helps to account for the estimation errors in <span class="math inline">\(S_{X&#39;X}^{-1}\widehat{E}(\eps^2_iX_iX_i&#39;)S^{-1}_{X&#39;X}\)</span> (or in <span class="math inline">\(s_{UB}^2S_{X&#39;X}^{-1}\)</span>) which are otherwise neglected by the pure asymptotic perspective.</p>
</div>
<div id="robust-hypothesis-testing-single-parameters" class="section level4" number="6.2.2.2">
<h4><span class="header-section-number">6.2.2.2</span> Robust Hypothesis Testing: Single Parameters</h4>
<p>Let us reconsider the case of hypotheses about only one parameter <span class="math inline">\(\beta_k\)</span>, with <span class="math inline">\(k=1,\dots,K\)</span>
<span class="math display">\[\begin{equation*}
\begin{array}{ll}
H_0: &amp; \beta_k=r\\
H_A: &amp; \beta_k\ne r\\
\end{array}
\end{equation*}\]</span>
We can selecting the <span class="math inline">\(k\)</span>th diagonal element of the test-statistic in  and taking the square root yields
<span class="math display">\[
t=\frac{\sqrt{n}\left(\hat{\beta}_k-r\right)}{\sqrt{\left[S_{X&#39;X}^{-1}\widehat{E}(\eps^2_iX_iX_i&#39;)S^{-1}_{X&#39;X}\right]_{kk}}}\overset{H_0}{\to}_d\mathcal{N}(0,1).
\]</span>
This <span class="math inline">\(t\)</span> test statistic allows for heteroscedastic error terms. In case of homoscedastic error terms, one can substitute <span class="math inline">\([S_{X&#39;X}^{-1}\widehat{E}(\eps^2_iX_iX_i&#39;)S^{-1}_{X&#39;X}]_{kk}\)</span> by <span class="math inline">\(s_{UB}^2[S_{X&#39;X}^{-1}]_{kk}\)</span>.</p>
<p>In order to improve the finite-sample performance of this <span class="math inline">\(t\)</span> test, one usually uses the <span class="math inline">\(t_{(n-K)}\)</span> distribution with <span class="math inline">\(n-K\)</span> degrees of freedoms instead of the <span class="math inline">\(\mathcal{N}(0,1)\)</span> distribution. Asymptotically (<span class="math inline">\(n\to\infty\)</span>) <span class="math inline">\(t_{(n-K)}\)</span> is equivalent to <span class="math inline">\(\mathcal{N}(0,1)\)</span>. However, for finite sample sizes <span class="math inline">\(n\)</span> (i.e., the practically relevant case) <span class="math inline">\(t_{n-K}\)</span> leads to larger critical values which helps to account for the estimation errors in <span class="math inline">\([S_{X&#39;X}^{-1}\widehat{E}(\eps^2_iX_iX_i&#39;)S^{-1}_{X&#39;X}]_{kk}\)</span> (or in <span class="math inline">\(s_{UB}^2[S_{X&#39;X}^{-1}]_{kk}\)</span>) which are otherwise neglected by the pure asymptotic perspective.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="6.1-tools-for-asymptotic-statistics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="6.3-robust-confidence-intervals.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Script_Econometrics_MSc.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
