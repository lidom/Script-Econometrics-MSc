<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Econometrics M.Sc. - 2&nbsp; Review: Probability</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03-Monte-Carlo-Simulations.html" rel="next">
<link href="./01-Introduction-to-R.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Review: Probability</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./" class="sidebar-logo-link">
      <img src="./images/Uni_Bonn_Logo.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Econometrics M.Sc.</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Organization of the Course</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-Introduction-to-R.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-Review-Prob_n_Stats.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Review: Probability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-Monte-Carlo-Simulations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Monte Carlo Simulations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-MultipleReg.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-Small-Sample-Inference.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Small Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-Asymptotics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Large Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-Instrumental-Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Instrumental Variables Regression</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#basics-in-probability-theory" id="toc-basics-in-probability-theory" class="nav-link active" data-scroll-target="#basics-in-probability-theory"><span class="toc-section-number">2.1</span>  Basics in Probability Theory</a>
  <ul class="collapse">
  <li><a href="#sample-spaces-and-elementary-events" id="toc-sample-spaces-and-elementary-events" class="nav-link" data-scroll-target="#sample-spaces-and-elementary-events"><span class="toc-section-number">2.1.1</span>  Sample Spaces and (Elementary) Events</a></li>
  <li><a href="#probability" id="toc-probability" class="nav-link" data-scroll-target="#probability"><span class="toc-section-number">2.1.2</span>  Probability</a></li>
  <li><a href="#independent-events" id="toc-independent-events" class="nav-link" data-scroll-target="#independent-events"><span class="toc-section-number">2.1.3</span>  Independent Events</a></li>
  <li><a href="#conditional-probability" id="toc-conditional-probability" class="nav-link" data-scroll-target="#conditional-probability"><span class="toc-section-number">2.1.4</span>  Conditional Probability</a></li>
  </ul></li>
  <li><a href="#random-variables" id="toc-random-variables" class="nav-link" data-scroll-target="#random-variables"><span class="toc-section-number">2.2</span>  Random Variables</a>
  <ul class="collapse">
  <li><a href="#univariate-distribution-and-probability-functions" id="toc-univariate-distribution-and-probability-functions" class="nav-link" data-scroll-target="#univariate-distribution-and-probability-functions"><span class="toc-section-number">2.2.1</span>  Univariate Distribution and Probability Functions</a></li>
  <li><a href="#multivariate-distribution-and-probability-functions" id="toc-multivariate-distribution-and-probability-functions" class="nav-link" data-scroll-target="#multivariate-distribution-and-probability-functions"><span class="toc-section-number">2.2.2</span>  Multivariate Distribution and Probability Functions</a></li>
  <li><a href="#means-and-moments" id="toc-means-and-moments" class="nav-link" data-scroll-target="#means-and-moments"><span class="toc-section-number">2.2.3</span>  Means and Moments</a></li>
  <li><a href="#unconditional-means" id="toc-unconditional-means" class="nav-link" data-scroll-target="#unconditional-means"><span class="toc-section-number">2.2.4</span>  Unconditional Means</a></li>
  <li><a href="#conditional-means" id="toc-conditional-means" class="nav-link" data-scroll-target="#conditional-means"><span class="toc-section-number">2.2.5</span>  Conditional Means</a></li>
  <li><a href="#means-of-transformed-random-variables-and-moments" id="toc-means-of-transformed-random-variables-and-moments" class="nav-link" data-scroll-target="#means-of-transformed-random-variables-and-moments"><span class="toc-section-number">2.2.6</span>  Means of Transformed Random Variables and Moments</a></li>
  <li><a href="#independent-random-variables" id="toc-independent-random-variables" class="nav-link" data-scroll-target="#independent-random-variables"><span class="toc-section-number">2.2.7</span>  Independent Random Variables</a></li>
  <li><a href="#random-samples" id="toc-random-samples" class="nav-link" data-scroll-target="#random-samples"><span class="toc-section-number">2.2.8</span>  Random Samples</a></li>
  <li><a href="#some-important-discrete-random-variables" id="toc-some-important-discrete-random-variables" class="nav-link" data-scroll-target="#some-important-discrete-random-variables"><span class="toc-section-number">2.2.9</span>  Some Important Discrete Random Variables</a></li>
  <li><a href="#some-important-continuous-random-variables" id="toc-some-important-continuous-random-variables" class="nav-link" data-scroll-target="#some-important-continuous-random-variables"><span class="toc-section-number">2.2.10</span>  Some Important Continuous Random Variables</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="toc-section-number">2.3</span>  Exercises</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="ReviewStats" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Review: Probability</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>The content of this chapter follows closely (often verbatim) the fantastic book by <span class="citation" data-cites="Wasserman2004">Wasserman (<a href="#ref-Wasserman2004" role="doc-biblioref">2004</a>)</span>.</p>
<section id="basics-in-probability-theory" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="basics-in-probability-theory"><span class="header-section-number">2.1</span> Basics in Probability Theory</h2>
<p>Probability is the mathematical language for quantifying uncertainty. We can apply probability theory to a diverse set of problems, from coin flipping to the analysis of econometric problems. The starting point is to specify the <strong>sample space</strong>, that is, the set of possible outcomes.</p>
<section id="sample-spaces-and-elementary-events" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="sample-spaces-and-elementary-events"><span class="header-section-number">2.1.1</span> Sample Spaces and (Elementary) Events</h3>
<p>The <strong>sample space</strong> <span class="math inline">\(\Omega,\)</span> is the set of possible outcomes of an experiment. Points <span class="math inline">\(\omega\)</span> in <span class="math inline">\(\Omega\)</span> are called <strong>sample outcomes</strong> or <strong>realizations</strong> or <strong>elementary events</strong>. <strong>Events</strong> are subsets of <span class="math inline">\(\Omega\)</span>.</p>
<p><strong>Example:</strong> If we toss a coin twice then <span class="math inline">\(\Omega=\{H H, H T, T H, T T\}.\)</span> The event that the first toss is heads is <span class="math inline">\(A=\{H H, H T\}.\)</span></p>
<p><strong>Example:</strong> Let <span class="math inline">\(\omega\)</span> be the outcome of a measurement of some physical quantity, for example, temperature. Then <span class="math inline">\(\Omega=\mathbb{R}=(-\infty, \infty).\)</span> The event that the measurement is larger than 10 but less than or equal to 23 is <span class="math inline">\(A=(10,23].\)</span></p>
<p><strong>Example:</strong> If we toss a coin forever then the sample space is the infinite set <span class="math inline">\(\Omega=\left\{\omega=\left(\omega_{1}, \omega_{2}, \omega_{3}, \ldots,\right)|\omega_{i} \in\{H, T\}\right\}\)</span> Let <span class="math inline">\(A\)</span> be the event that the first head appears on the third toss. Then <span class="math inline">\(A=\left\{\left(\omega_{1}, \omega_{2}, \omega_{3}, \ldots,\right)| \omega_{1}=T, \omega_{2}=T, \omega_{3}=H, \omega_{i} \in\{H, T\} \text { for } i&gt;3\right\}.\)</span></p>
<p>Given an event <span class="math inline">\(A,\)</span> let <span class="math inline">\(A^{c}=\{\omega \in \Omega ; \omega \notin A\}\)</span> denote the <strong>complement</strong> of <span class="math inline">\(A\)</span>. Informally, <span class="math inline">\(A^{c}\)</span> can be read as “not <span class="math inline">\(A\)</span>.” The complement of <span class="math inline">\(\Omega\)</span> is the empty set <span class="math inline">\(\emptyset\)</span>. The <strong>union</strong> of events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is defined as <span class="math display">\[
A\cup B=\{\omega \in \Omega|\omega\in A\text{ or }\omega \in B\text{ or }\omega\in\text{ both}\}
\]</span> which can be thought of as “<span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span>.” If <span class="math inline">\(A_{1}, A_{2}, \ldots\)</span> is a sequence of sets then <span class="math display">\[
\bigcup_{i=1}^{\infty} A_{i}=\left\{\omega \in \Omega: \omega \in A_{i} \text { for at least one i }\right\}.
\]</span> The <strong>intersection</strong> of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is defined as <span class="math display">\[
A \cap B=\{\omega \in \Omega ; \omega \in A\text{ and }\omega \in B\}
\]</span> which reads as “<span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.” Often <span class="math inline">\(A \cap B\)</span> is also written shortly as <span class="math inline">\(AB\)</span> or as <span class="math inline">\(A,B.\)</span></p>
<p>If <span class="math inline">\(A_{1}, A_{2}, \ldots\)</span> is a sequence of sets then <span class="math display">\[
\bigcap_{i=1}^{\infty} A_{i}=\left\{\omega \in \Omega: \omega \in A_{i} \text { for all i }\right\}.
\]</span></p>
<p>If every element of <span class="math inline">\(A\)</span> is also contained in <span class="math inline">\(B\)</span> we write <span class="math inline">\(A \subset B\)</span> or, equivalently, <span class="math inline">\(B \supset A\)</span>. If <span class="math inline">\(A\)</span> is a finite set, let <span class="math inline">\(|A|\)</span> denote the number of elements in <span class="math inline">\(A .\)</span> We say that <span class="math inline">\(A_{1}, A_{2}, \ldots\)</span> are <strong>disjoint</strong> or <strong>mutually exclusive</strong> if <span class="math inline">\(A_{i} \cap A_{j}=\emptyset\)</span> whenever <span class="math inline">\(i \neq j\)</span>. For example, <span class="math inline">\(A_{1}=[0,1), A_{2}=[1,2), A_{3}=[2,3), \ldots\)</span> are disjoint. A <strong>partition</strong> of <span class="math inline">\(\Omega\)</span> is a sequence of disjoint sets <span class="math inline">\(A_{1}, A_{2}, \ldots\)</span> such that <span class="math inline">\(\bigcup_{i=1}^{\infty} A_{i}=\Omega\)</span>.</p>
<p><strong>Summary:</strong> Sample space and events</p>
<p><span class="math display">\[
\begin{array}{ll}
\Omega &amp; \text { sample space } \\
\omega &amp; \text { outcome, elementary event, realization}\\
A      &amp; \text { event (subset of } \Omega) \\
|A|    &amp; \text { number of points in } A \text { (if } A \text { is finite) }\\
A^{c}  &amp; \text { complement of } A (\operatorname{not} A)\\
A \cup B &amp;\text{ union }(A\text{ or }B)\\
A \cap B &amp;\text{ intersection }(A \text { and } B);\text{ short notations: }AB\text{ or }A,B\\
A \subset B &amp;\text{ set inclusion }(A \text{ is a subset of or equal to }B)\\
\emptyset   &amp;\text{ null event (always false)}\\
\Omega      &amp;\text{ true event (always true)}
\end{array}
\]</span></p>
<!-- Given an event $A,$ define the indicator function of $A$ by -->
<!-- $$ -->
<!-- I_{A}(\omega)=I(\omega \in A)=\left\{\begin{array}{ll} -->
<!-- 1 & \text { if } \omega \in A \\ -->
<!-- 0 & \text { if } \omega \notin A -->
<!-- \end{array}\right. -->
<!-- $$ -->
<!-- A sequence of sets $A_{1}, A_{2}, \ldots$ is monotone increasing if $A_{1} \subset A_{2} \subset$ -->
<!-- $\cdots$ and we define $\lim _{n \rightarrow \infty} A_{n}=\bigcup_{i=1}^{\infty} A_{i} .$ A sequence of sets $A_{1}, A_{2}, \ldots$ is -->
<!-- monotone decreasing if $A_{1} \supset A_{2} \supset \cdots$ and then we define $\lim _{n \rightarrow \infty} A_{n}=$ -->
<!-- $\bigcap_{i=1}^{\infty} A_{i} .$ In either case, we will write $A_{n} \rightarrow A$ -->
<!-- Example 2.4 Let $\Omega=\mathbb{R}$ and let $A_{i}=[0,1 / i)$ for $i=1,2, \ldots$ Then $\bigcup_{i=1}^{\infty} A_{i}=$ [0,1) and $\bigcap_{i=1}^{\infty} A_{i}=\{0\} .$ If instead we define $A_{i}=(0,1 / i)$ then $\bigcup_{i=1}^{\infty} A_{i}=$ -->
<!-- (0,1) and $\bigcap_{i=1}^{\infty} A_{i}=\emptyset$ -->
</section>
<section id="probability" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="probability"><span class="header-section-number">2.1.2</span> Probability</h3>
<p>We want to assign a real number <span class="math inline">\(P(A)\)</span> to every event <span class="math inline">\(A,\)</span> called the <strong>probability</strong> of <span class="math inline">\(A .\)</span> We also call <span class="math inline">\(P\)</span> a <strong>probability distribution</strong> or a <strong>probability measure</strong>. To qualify as a probability, <span class="math inline">\(P\)</span> has to satisfy three axioms. That is, a function <span class="math inline">\(P\)</span> that assigns a real number <span class="math inline">\(P(A)\in[0,1]\)</span> to each event <span class="math inline">\(A\)</span> is a <strong>probability distribution</strong> or a <strong>probability measure</strong> if it satisfies the following three axioms:</p>
<ul>
<li><strong>Axiom 1:</strong> <span class="math inline">\(P(A) \geq 0\)</span> for every <span class="math inline">\(A\)</span></li>
<li><strong>Axiom 2:</strong> <span class="math inline">\(P(\Omega)=1\)</span></li>
<li><strong>Axiom 3:</strong> If <span class="math inline">\(A_{1}, A_{2}, \ldots\)</span> are disjoint then</li>
</ul>
<p><span class="math display">\[
P\left(\bigcup_{i=1}^{\infty} A_{i}\right)=\sum_{i=1}^{\infty} P\left(A_{i}\right).
\]</span></p>
<p><strong>Note:</strong> It is not always possible to assign a probability to <em>every</em> event <span class="math inline">\(A\)</span> if the sample space is large. For instance, in the case of <span class="math inline">\(\Omega=\mathbb{R}\)</span> strange things can happen. There are pathological sets (e.g.&nbsp;Vitali sets) that simply break down the mathematics since they are non-measurable (i.e.&nbsp;we cannot assign probabilities to them). Therefore, in cases like <span class="math inline">\(\Omega=\mathbb{R}\)</span>, we assign probabilities to a <em>limited</em> class of sets called a <strong><span class="math inline">\(\sigma\)</span>-field</strong> or <strong><span class="math inline">\(\sigma\)</span>-algebra</strong>. For <span class="math inline">\(\Omega=\mathbb{R}\)</span>, the canonical <strong><span class="math inline">\(\sigma\)</span>-algebra</strong> is the <strong>Borel <span class="math inline">\(\sigma\)</span>-algebra</strong>. The Borel <span class="math inline">\(\sigma\)</span>-algebra on <span class="math inline">\(\mathbb{R}\)</span> is generated by the collection of all open subsets of <span class="math inline">\(\mathbb{R}\)</span>. In this course, we use the Borel <span class="math inline">\(\sigma\)</span>-algebra and fortunately we do not have to bother with it any further. It’s there lurking in the background making things work for us.</p>
<p>One can derive many properties of <span class="math inline">\(P\)</span> from the axioms. Here are a few:</p>
<ul>
<li><span class="math inline">\(P(\emptyset)=0\)</span></li>
<li><span class="math inline">\(A \subset B\Rightarrow P(A) \leq P(B)\)</span></li>
<li><span class="math inline">\(0 \leq P(A) \leq 1\)</span></li>
<li><span class="math inline">\(P\left(A^{c}\right)=1-P(A)\)</span></li>
<li><span class="math inline">\(A \cap B=\emptyset \Rightarrow P(A \cup B)=P(A)+P(B)\)</span></li>
</ul>
<p>A less obvious property is given in the following: For any events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> we have that,</p>
<p><span class="math display">\[
P(A \cup B)=P(A)+P(B)-P(A B).
\]</span></p>
<p><strong>Example:</strong> Two consecutive coin tosses. Let <span class="math inline">\(H_{1}\)</span> be the event that heads occurs on toss 1 and let <span class="math inline">\(H_{2}\)</span> be the event that heads occurs on toss 2. If all outcomes are equally likely, that is, <span class="math display">\[
P\left(\left\{H_{1}, H_{2}\right\}\right)=P\left(\left\{H_{1}, T_{2}\right\}\right)=P\left(\left\{T_{1}, H_{2}\right\}\right)=P\left(\left\{T_{1}, T_{2}\right\}\right)=1 / 4,
\]</span> then <span class="math display">\[
P\left(H_{1} \cup H_{2}\right)=P\left(H_{1}\right)+P\left(H_{2}\right)-P\left(H_{1} H_{2}\right)=\frac{1}{2}+\frac{1}{2}-\frac{1}{4}=\frac{3}{4}.
\]</span></p>
<section id="probabilities-as-frequencies" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="probabilities-as-frequencies">Probabilities as frequencies</h4>
<p>One can interpret <span class="math inline">\(P(A)\)</span> in terms of <strong>frequencies</strong>. That is, <span class="math inline">\(P(A)\)</span> is the (infinitely) long run proportion of times that <span class="math inline">\(A\)</span> is true in repetitions. For example, if we say that the probability of heads is <span class="math inline">\(1 / 2\)</span>, i.e <span class="math inline">\(P(H)=1/2\)</span> we mean that if we flip the coin many times then the proportion of times we get heads tends to <span class="math inline">\(1 / 2\)</span> as the number of tosses increases. An infinitely long, unpredictable sequence of tosses whose limiting proportion tends to a constant is an idealization, much like the idea of a straight line in geometry.</p>
<p>The following <code>R</code> codes approximates the probability <span class="math inline">\(P(H)=1/2\)</span> using 5, 50 and 5,000 many (pseudo) random coin flips:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">869</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="do">## 1 (fair) coin-flip:</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="st">"H"</span>, <span class="st">"T"</span>), <span class="at">size =</span> <span class="dv">5</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Relative frequency of "H" in 5 coin-flips</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(results[results<span class="sc">==</span><span class="st">"H"</span>])<span class="sc">/</span><span class="dv">5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 10 (fair) coin-flips:</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="st">"H"</span>, <span class="st">"T"</span>), <span class="at">size =</span> <span class="dv">50</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Relative frequency of "H" in 50 coin-flips</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(results[results<span class="sc">==</span><span class="st">"H"</span>])<span class="sc">/</span><span class="dv">50</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.52</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 100000 (fair) coin-flips:</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="st">"H"</span>, <span class="st">"T"</span>), <span class="at">size =</span> <span class="dv">5000</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Relative frequency of "H" in 5000 coin-flips</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(results[results<span class="sc">==</span><span class="st">"H"</span>])<span class="sc">/</span><span class="dv">5000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5024</code></pre>
</div>
</div>
</section>
</section>
<section id="independent-events" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3" class="anchored" data-anchor-id="independent-events"><span class="header-section-number">2.1.3</span> Independent Events</h3>
<p>If we flip a fair coin twice, then the probability of two heads is <span class="math inline">\(\frac{1}{2} \times \frac{1}{2}\)</span>. We multiply the probabilities because we regard the two tosses as independent. Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are called <strong>independent</strong> if</p>
<p><span class="math display">\[
P(A B)=P(A) P(B).
\]</span></p>
<p>Or more generally, a whole set of events <span class="math inline">\(\{A_i|i\in I\}\)</span> is independent if</p>
<p><span class="math display">\[
P\left(\bigcap_{i \in J} A_{i}\right)=\prod_{i \in J}P\left(A_{i}\right)
\]</span> for every finite subset <span class="math inline">\(J\)</span> of <span class="math inline">\(I\)</span>, where <span class="math inline">\(I\)</span> denotes the not necessarily finite index set (e.g.&nbsp;<span class="math inline">\(I=\{1,2,\dots\}\)</span>).</p>
<p>Independence can arise in two distinct ways. Sometimes, we <strong>explicitly assume</strong> that two events are independent. For example, in tossing a coin twice, we usually assume the tosses are independent which reflects the fact that the coin has no memory of the first toss.</p>
<p>In other instances, we <strong>derive</strong> independence by verifying that the definition of independence <span class="math inline">\(P(A B)=P(A)P(B)\)</span> holds. For example, in tossing a fair die , let <span class="math inline">\(A=\{2,4,6\}\)</span> be the event of observing an even number and let <span class="math inline">\(B=\{1,2,3,4\}\)</span> be the event of observing no <span class="math inline">\(5\)</span> and no <span class="math inline">\(6\)</span>. Then, <span class="math inline">\(A \cap B=\{2,4\}\)</span> is the event of observing either a <span class="math inline">\(2\)</span> or a <span class="math inline">\(4\)</span>. Are the events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> independent?<br>
<span class="math display">\[
P(A B)=\frac{2}{6}=P(A)P(B)=\frac{1}{2}\cdot \frac{2}{3}
\]</span> and so <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent. In this case, we didn’t assume that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent it just turned out that they were.</p>
<p><strong>Cautionary Note:</strong> Suppose that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>disjoint events</strong>, i.e.&nbsp;<span class="math inline">\(AB=\emptyset,\)</span> each with positive probability <span class="math inline">\(P(A)&gt;0\)</span> and <span class="math inline">\(P(B)&gt;0.\)</span> Can they be independent? No! This follows since</p>
<p><span class="math display">\[
P(A B)=P(\emptyset)=0\neq P(A)P(B)&gt;0.
\]</span> Except in this special case, there is no way to judge (in-)dependence by looking at the sets in a Venn diagram.</p>
<p><strong>Summary:</strong> Independent Events</p>
<ol type="1">
<li><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if <span class="math inline">\(P(A B)=P(A) P(B)\)</span>.</li>
<li>Independence is sometimes assumed and sometimes derived.</li>
<li>Disjoint events with strictly positive probabilities are not independent.</li>
</ol>
</section>
<section id="conditional-probability" class="level3" data-number="2.1.4">
<h3 data-number="2.1.4" class="anchored" data-anchor-id="conditional-probability"><span class="header-section-number">2.1.4</span> Conditional Probability</h3>
<p>If <span class="math inline">\(P(B)&gt;0\)</span> then the <strong>conditional probability</strong> of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span> is <span class="math display">\[
P(A \mid B)=\frac{P(A B)}{P(B)}.
\]</span> Think of <span class="math inline">\(P(A \mid B)\)</span> as the fraction of times <span class="math inline">\(A\)</span> occurs among those in which <span class="math inline">\(B\)</span> occurs. Here are some facts about conditional probabilities:</p>
<ul>
<li>The rules of probability apply to events on the left of the bar “<span class="math inline">\(\mid\)</span>”. That is, for any fixed <span class="math inline">\(B\)</span> such that <span class="math inline">\(P(B)&gt;0,\)</span> <span class="math inline">\(P(\cdot \mid B)\)</span> is a probability, i.e., it satisfies the three axioms of probability:
<ul>
<li><span class="math inline">\(P(A \mid B) \geq 0\)</span></li>
<li><span class="math inline">\(P(\Omega \mid B)=1\)</span></li>
<li>If <span class="math inline">\(A_{1}, A_{2}, \ldots\)</span> are disjoint then <span class="math inline">\(P\left(\bigcup_{i=1}^{\infty} A_{i} \mid B\right)=\sum_{i=1}^{\infty} P\left(A_{i} \mid B\right).\)</span></li>
</ul></li>
<li>But it’s generally <strong>not true</strong> that <span class="math inline">\(P(A \mid B \cup C)=P(A \mid B)+P(A \mid C).\)</span></li>
</ul>
<p>In general it is also not the case that <span class="math inline">\(P(A \mid B)=P(B \mid A)\)</span>. People get this confused all the time. For example, the probability of spots given you have measles is 1 but the probability that you have measles given that you have spots is not <span class="math inline">\(1 .\)</span> In this case, the difference between <span class="math inline">\(P(A \mid B)\)</span> and <span class="math inline">\(P(B \mid A)\)</span> is obvious but there are cases where it is less obvious. This mistake is made often enough in legal cases that it is sometimes called the <strong>“prosecutor’s fallacy”</strong>.</p>
<p><strong>Example:</strong> A medical test for a disease <span class="math inline">\(D\)</span> has outcomes <span class="math inline">\(+\)</span> and <span class="math inline">\(-.\)</span> The probabilities are:</p>
<p><span class="math display">\[
\begin{array}{c|cc|c}
&amp; D &amp; D^{c} \\
\hline
+ &amp; .0081 &amp; .0900 &amp;  .0981\\
- &amp; .0009 &amp; .9010 &amp;  .9019\\
\hline
  &amp; .0090 &amp; .9910 &amp;  1
\end{array}
\]</span> From the definition of conditional probability, we have:</p>
<ul>
<li>Sensitivity of the test: <span class="math display">\[P(+\mid D)=P(+\cap D) / P(D)=0.0081 /(0.0081+0.0009)=0.9\]</span></li>
<li>Specificity of the test: <span class="math display">\[P(-\mid D^{c})=P(-\cap D^{c}) / P(D^{c})=0.9010/(0.9010+0.0900)\approx 0.9\]</span></li>
</ul>
<p>Apparently, the test is fairly accurate. Sick people yield a positive test result 90 percent of the time and healthy people yield a negative test result about 90 percent of the time. Suppose you go for a test and get a positive result. What is the probability you have the disease? Most people answer <span class="math inline">\(0.90=90\%\)</span>. The correct answer is <span class="math inline">\(P(D \mid+)=P(+\cap D) / P(+)=0.0081 /(0.0081+0.0900)=0.08.\)</span> The lesson here is that you need to compute the answer numerically. Don’t trust your intuition.</p>
<section id="independence-via-conditional-probabilities" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="independence-via-conditional-probabilities">Independence via Conditional Probabilities</h4>
<p>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent events</strong> then <span class="math display">\[
P(A \mid B)=\frac{P(A B)}{P(B)}=\frac{P(A) P(B)}{P(B)}=P(A)
\]</span> So another <strong>interpretation of independence</strong> is that knowing <span class="math inline">\(B\)</span> doesn’t change the probability of <span class="math inline">\(A\)</span>.</p>
<p>From the definition of conditional probability we can write <span class="math display">\[
P(A B)=P(A \mid B) P(B)
\]</span> and also <span class="math display">\[
P(A B)=P(B \mid A) P(A).
\]</span> Often, these formulas give us a convenient way to compute <span class="math inline">\(P(A B)\)</span> when <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not independent.</p>
<p><strong>Example:</strong> Draw two cards from a deck, without replacement. Let <span class="math inline">\(A\)</span> be the event that the first draw is Ace of Clubs and let <span class="math inline">\(B\)</span> be the event that the second draw is Queen of Diamonds. Then <span class="math inline">\(P(A, B)=P(A) P(B \mid A)=(1 / 52) \times(1 / 51)\)</span></p>
<p><strong>Summary:</strong> Conditional Probability</p>
<ol type="1">
<li>If <span class="math inline">\(P(B)&gt;0\)</span> then <span class="math inline">\(P(A \mid B)=P(A B)/P(B)\)</span></li>
<li><span class="math inline">\(P(\cdot \mid B)\)</span> satisfies the axioms of probability, for fixed <span class="math inline">\(B\)</span>. In general, <span class="math inline">\(P(A \mid \cdot)\)</span> does not satisfy the axioms of probability, for fixed <span class="math inline">\(A\)</span>.</li>
<li>In general, <span class="math inline">\(P(A \mid B) \neq P(B \mid A)\)</span>.</li>
<li><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if and only if <span class="math inline">\(P(A \mid B)=P(A)\)</span>.</li>
</ol>
</section>
</section>
</section>
<section id="random-variables" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="random-variables"><span class="header-section-number">2.2</span> Random Variables</h2>
<p>Statistics and econometrics are concerned with data. How do we link sample spaces, events and probabilities to data? The link is provided by the concept of a <strong>random variable</strong>. A real-valued <strong>random variable</strong> is a mapping <span class="math inline">\(X: \Omega \rightarrow \mathbb{R}\)</span> that assigns a real number <span class="math inline">\(X(\omega)\in\mathbb{R}\)</span> to each outcome <span class="math inline">\(\omega\)</span>.</p>
<p>At a certain point in most statistics/econometrics courses, the sample space, <span class="math inline">\(\Omega\)</span>, is rarely mentioned and we work directly with random variables. But you should keep in mind that the sample space is really there, lurking in the background.</p>
<p><strong>Example:</strong> Flip a coin ten times. Let <span class="math inline">\(X(\omega)\)</span> be the number of heads in the sequence <span class="math inline">\(\omega.\)</span> For example, if <span class="math inline">\(\omega=\text{HHTHHTHHTT}\)</span> then <span class="math inline">\(X(\omega)=6\)</span>.</p>
<p><strong>Example:</strong> Let <span class="math inline">\(\Omega=\left\{(x, y)|x^{2}+y^{2} \leq 1\right\}\)</span> be the unit disc. Consider drawing a point “at random” from <span class="math inline">\(\Omega\)</span>. A typical outcome is then of the form <span class="math inline">\(\omega=(x, y) .\)</span> Some examples of random variables are <span class="math inline">\(X(\omega)=x, Y(\omega)=y, Z(\omega)=x+y, W(\omega)=\sqrt{x^{2}+y^{2}}\)</span>.</p>
<p>Given a real-valued random variable <span class="math inline">\(X\in\mathbb{R}\)</span> and a subset <span class="math inline">\(A\)</span> of the real line (<span class="math inline">\(A\subset\mathbb{R}\)</span>), define <span class="math inline">\(X^{-1}(A)=\{\omega \in \Omega|X(\omega) \in A\}\)</span>. This allows us to link the probabilities on the random variable <span class="math inline">\(X\)</span>, i.e.&nbsp;the probabilities we are usually working with, to the underlying probabilities on the events, i.e.&nbsp;the probabilities lurking in the background.</p>
<p><strong>Example:</strong> Flip a coin twice and let <span class="math inline">\(X\)</span> be the number of heads. Then, <span class="math inline">\(P_X(X=0)=P(\{T T\})=1 / 4\)</span>, <span class="math inline">\(P_X(X=1)=P(\{H T, T H\})=1 / 2\)</span> and <span class="math inline">\(P_X(X=2)=P(\{H H\})=1 / 4\)</span>. Thus, the events and their associated probability distribution, <span class="math inline">\(P\)</span>, and the random variable <span class="math inline">\(X\)</span> and its distribution, <span class="math inline">\(P_X\)</span>, can be summarized as follows:</p>
<table class="table">
<thead>
<tr class="header">
<th><span class="math inline">\(\omega\)</span></th>
<th><span class="math inline">\(P(\{\omega\})\)</span></th>
<th><span class="math inline">\(X(\omega)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(T T\)</span></td>
<td><span class="math inline">\(1 / 4\)</span></td>
<td>0</td>
</tr>
<tr class="even">
<td><span class="math inline">\(T H\)</span></td>
<td><span class="math inline">\(1 / 4\)</span></td>
<td>1</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(H T\)</span></td>
<td><span class="math inline">\(1 / 4\)</span></td>
<td>1</td>
</tr>
<tr class="even">
<td><span class="math inline">\(H H\)</span></td>
<td><span class="math inline">\(1 / 4\)</span></td>
<td>2</td>
</tr>
</tbody>
</table>
<table class="table">
<thead>
<tr class="header">
<th><span class="math inline">\(x\)</span></th>
<th><span class="math inline">\(P_X(X=x)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td><span class="math inline">\(1 / 4\)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td><span class="math inline">\(1 / 2\)</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math inline">\(1 / 4\)</span></td>
</tr>
</tbody>
</table>
<!-- Try generalizing this to $n$ flips. -->
<p>Here, <span class="math inline">\(P_{X}\)</span> is not the same probability function as <span class="math inline">\(P\)</span>, because <span class="math inline">\(P\)</span> maps from the sample space events, <span class="math inline">\(\omega\)</span>, to <span class="math inline">\([0,1]\)</span>, while <span class="math inline">\(P_X\)</span> maps from the random-variable events, <span class="math inline">\(X(\omega)\)</span>, to <span class="math inline">\([0,1]\)</span>. We will typically forget about the sample space <span class="math inline">\(\Omega\)</span> and just think of the random variable as an experiment with real-valued (possible multivariate) outcomes. We will therefore write <span class="math inline">\(P\left(X=x_{k}\right)\)</span> instead of <span class="math inline">\(P_{X}\left(X=x_{k}\right)\)</span> to simplify the notation.</p>
<section id="univariate-distribution-and-probability-functions" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="univariate-distribution-and-probability-functions"><span class="header-section-number">2.2.1</span> Univariate Distribution and Probability Functions</h3>
<section id="cumulative-distribution-function" class="level4" data-number="2.2.1.1">
<h4 data-number="2.2.1.1" class="anchored" data-anchor-id="cumulative-distribution-function"><span class="header-section-number">2.2.1.1</span> Cumulative Distribution Function</h4>
<p>The <strong>cumulative distribution function (cdf)</strong> <span class="math display">\[F_{X}: \mathbb{R} \rightarrow [0,1]\]</span> of a real-valued random variable <span class="math inline">\(X\in\mathbb{R}\)</span> is defined by <span class="math display">\[
F_{X}(x)=\mathbb{P}(X \leq x).
\]</span></p>
<p>You might wonder why we bother to define the cdf. The reason is that it effectively contains all the information about the random variable. Indeed, let <span class="math inline">\(X\in\mathbb{R}\)</span> have cdf <span class="math inline">\(F\)</span> and let <span class="math inline">\(Y\in\mathbb{R}\)</span> have cdf <span class="math inline">\(G\)</span>. If <span class="math inline">\(F(x)=G(x)\)</span> for all <span class="math inline">\(x\in\mathbb{R}\)</span> then <span class="math inline">\(P(X \in A)=P(Y \in A)\)</span> for all <span class="math inline">\(A\subset\mathbb{R}\)</span>. In order to denote that two random variables, here <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, have the same distribution, one can write shortly <span class="math inline">\(X\overset{d}{=}Y\)</span>.</p>
<!-- **Caution:** Equality in distribution, $X\overset{d}{=}Y$, does generally **not** mean equality in realizations, that is $X\overset{d}{=}Y \not\Rightarrow X(\omega)=Y(\omega)$ for all $\omega\in\Omega$.  -->
<p><strong>The defining properties of a cdf:</strong> A function <span class="math inline">\(F\)</span> mapping the real line to <span class="math inline">\([0,1]\)</span>, short <span class="math inline">\(F:\mathbb{R}\to[0,1],\)</span> is called a cdf for some probability measure <span class="math inline">\(P\)</span> if and only if it satisfies the following three properties:</p>
<ol type="1">
<li><p><span class="math inline">\(F\)</span> is non-decreasing i.e.&nbsp;<span class="math inline">\(x_{1}&lt;x_{2}\)</span> implies that <span class="math inline">\(F\left(x_{1}\right) \leq F\left(x_{2}\right)\)</span>.</p></li>
<li><p><span class="math inline">\(F\)</span> is normalized: <span class="math inline">\(\lim_{x\rightarrow-\infty} F(x)=0\)</span> and <span class="math inline">\(\lim_{x \rightarrow \infty} F(x)=1\)</span></p></li>
<li><p><span class="math inline">\(F\)</span> is right-continuous, i. e. <span class="math inline">\(F(x)=F\left(x^{+}\right)\)</span> for all <span class="math inline">\(x\)</span>, where <span class="math display">\[
  F\left(x^{+}\right)=\lim_{y\to x, y&gt;x} F(y).
  \]</span></p></li>
</ol>
<p>Alternatively to cumulative distribution functions one can use <strong>probability (mass) functions</strong> in order to describe the probability law of <strong>discrete</strong> random variables and <strong>density functions</strong> in order to describe the probability law of <strong>continuous</strong> random variables.</p>
</section>
<section id="probability-functions-for-discrete-random-variables" class="level4" data-number="2.2.1.2">
<h4 data-number="2.2.1.2" class="anchored" data-anchor-id="probability-functions-for-discrete-random-variables"><span class="header-section-number">2.2.1.2</span> Probability Functions for Discrete Random Variables</h4>
<p>A random variable <span class="math inline">\(X\)</span> is if it takes only countably many values <span class="math display">\[
X\in\{x_{1}, x_{2}, \ldots\}.
\]</span> For instance, <span class="math inline">\(X\in\{1,2,3\}\)</span> or <span class="math inline">\(X\in\{2,4,6,\dots\}\)</span> or <span class="math inline">\(X\in\mathbb{Z}\)</span> or <span class="math inline">\(X\in\mathbb{Q}\)</span>.</p>
<p>We define the <strong>probability function</strong> or <strong>probability mass function (pmf)</strong> for <span class="math inline">\(X\)</span> by <span class="math display">\[
f_{X}(x)=\mathbb{P}(X=x)\quad\text{for all}\quad x\in\{x_1,x_2,\dots\}
\]</span></p>
</section>
<section id="density-functions-for-continuous-random-variables" class="level4" data-number="2.2.1.3">
<h4 data-number="2.2.1.3" class="anchored" data-anchor-id="density-functions-for-continuous-random-variables"><span class="header-section-number">2.2.1.3</span> Density Functions for Continuous Random Variables</h4>
<p>A random variable <span class="math inline">\(X\)</span> is if there exists a function <span class="math inline">\(f_{X}\)</span> such that</p>
<ul>
<li><span class="math inline">\(f_{X}(x)\geq 0\)</span> for all <span class="math inline">\(x\)</span></li>
<li><span class="math inline">\(\int_{-\infty}^{\infty}f_{X}(x)dx=1\)</span> and</li>
<li><span class="math inline">\(\mathbb{P}(a&lt;X&lt;b)=\int_{a}^{b} f_{X}(x) dx\)</span> for every <span class="math inline">\(a\leq b\)</span>.</li>
</ul>
<p>The function <span class="math inline">\(f_{X}\)</span> is called the <strong>probability density function (pdf)</strong> or short <strong>density function</strong>.</p>
<p>For density functions, we have that <span class="math display">\[
F_{X}(x)=\int_{-\infty}^{x} f_{X}(t) dt\quad\text{and}\quad f_{X}(x)=F_{X}^{\prime}(x)
\]</span> at all points <span class="math inline">\(x\)</span> at which <span class="math inline">\(F_{X}\)</span> is differentiable.</p>
</section>
</section>
<section id="multivariate-distribution-and-probability-functions" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="multivariate-distribution-and-probability-functions"><span class="header-section-number">2.2.2</span> Multivariate Distribution and Probability Functions</h3>
<p>A <span class="math inline">\(d\)</span>-dimensional random vector is a column-vector <span class="math inline">\(X=(X_1,\dots,X_d)^\prime\)</span>, where each element is a univariate random variable.</p>
<section id="multidimensional-distribution-function" class="level4" data-number="2.2.2.1">
<h4 data-number="2.2.2.1" class="anchored" data-anchor-id="multidimensional-distribution-function"><span class="header-section-number">2.2.2.1</span> Multidimensional Distribution Function</h4>
<p>The <strong>multivariate distribution function</strong> <span class="math inline">\(F\)</span> is given by <span class="math display">\[F(a_1,\dots,a_d)=P(X_1\le a_1,\dots,X_d\le a_d).\]</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Install the package if not installed yet</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("mnormt")</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mnormt)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>x     <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="fl">0.25</span>) </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>y     <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="fl">0.25</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>f     <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y) <span class="fu">pmnorm</span>(<span class="fu">cbind</span>(x, y), mu, sigma)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>z     <span class="ot">&lt;-</span> <span class="fu">outer</span>(x, y, f)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="fu">persp</span>(x, y, z, <span class="at">theta =</span> <span class="sc">-</span><span class="dv">30</span>, <span class="at">phi =</span> <span class="dv">25</span>, </span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">shade =</span> <span class="fl">0.75</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">expand =</span> <span class="fl">0.5</span>, <span class="at">r =</span> <span class="dv">2</span>, </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">ltheta =</span> <span class="dv">25</span>, <span class="at">ticktype =</span> <span class="st">"detailed"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="02-Review-Prob_n_Stats_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="multidimensional-probability-function" class="level4" data-number="2.2.2.2">
<h4 data-number="2.2.2.2" class="anchored" data-anchor-id="multidimensional-probability-function"><span class="header-section-number">2.2.2.2</span> Multidimensional Probability Function</h4>
<p><strong>Discrete random vectors:</strong> <span class="math inline">\(X\)</span> takes only countably many (i.e.&nbsp;discrete) values <span class="math inline">\(\mathbf{x}_1,\mathbf{x}_2,\dots\in\mathbb{R}^d\)</span> and has a <strong>multidimensional probability function</strong> <span class="math inline">\(p(\mathbf{x}_i)=P(X=\mathbf{x}_i)\)</span> for <span class="math inline">\(i=1,2,\dots\)</span>. That is, <span class="math display">\[\begin{align*}
P(X\in [a_1,b_1]\times\dots\times [a_d,b_d])=
\sum_{\mathbf{x}_i\in [a_1,b_1]\times\dots\times [a_d,b_d]}p(\mathbf{x}_i).
\end{align*}\]</span></p>
</section>
<section id="multidimensional-density-function" class="level4" data-number="2.2.2.3">
<h4 data-number="2.2.2.3" class="anchored" data-anchor-id="multidimensional-density-function"><span class="header-section-number">2.2.2.3</span> Multidimensional Density Function</h4>
<p><strong>Continuous random vectors:</strong> <span class="math inline">\(X\)</span> takes values in <span class="math inline">\(\mathbb{R}^d\)</span> and has a <strong>multidimensional density function</strong> <span class="math inline">\(f(x_1,\dots,x_d)\)</span>. That is, <span class="math display">\[\begin{align*}
P(X\in [a_1,b_1]\times\dots\times [a_d,b_d])=\int\limits_{a_d}^{b_d}\dots \int\limits _{a_1}^{b_1}f(x_1,\dots,x_d)dx_1\dots dx_d.
\end{align*}\]</span> In the following we focus only on continuous random vectors, but the discrete cases are treated analogously. Properties of <strong>multivariate density</strong> functions:</p>
<ul>
<li><span class="math inline">\(\displaystyle f(x_1,\dots,x_d)\geq 0\)</span></li>
<li><span class="math inline">\(\displaystyle \int_{-\infty}^{\infty}\dots \int_{-\infty}^{\infty}f(x_1,\dots,x_d)dx_1\dots dx_d=1\)</span></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Load the package</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mnormt)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>x     <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="fl">0.25</span>) </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>y     <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="fl">0.25</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>f     <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y) <span class="fu">dmnorm</span>(<span class="fu">cbind</span>(x, y), mu, sigma)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>z     <span class="ot">&lt;-</span> <span class="fu">outer</span>(x, y, f)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="fu">persp</span>(x, y, z, <span class="at">theta =</span> <span class="sc">-</span><span class="dv">30</span>, <span class="at">phi =</span> <span class="dv">25</span>, </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">shade =</span> <span class="fl">0.75</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">expand =</span> <span class="fl">0.5</span>, <span class="at">r =</span> <span class="dv">2</span>, </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">ltheta =</span> <span class="dv">25</span>, <span class="at">ticktype =</span> <span class="st">"detailed"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="02-Review-Prob_n_Stats_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="marginal-distribution-functions-and-marginal-density-functions" class="level4" data-number="2.2.2.4">
<h4 data-number="2.2.2.4" class="anchored" data-anchor-id="marginal-distribution-functions-and-marginal-density-functions"><span class="header-section-number">2.2.2.4</span> Marginal Distribution Functions and Marginal Density Functions</h4>
<p>Each random element, <span class="math inline">\(X_j\)</span>, with <span class="math inline">\(j=1,\dots,d\)</span>, of the random vector <span class="math inline">\(X\)</span> has its own <strong>marginal distribution</strong> <span class="math inline">\(F_j\)</span>. This is just the univariate distribution of <span class="math inline">\(X_j\)</span> when ignoring all other random variables in <span class="math inline">\(X\)</span>. Formally we have:</p>
<ul>
<li><strong>Marginal distribution function:</strong> <span class="math inline">\(F_j(x)=P(X_j\leq x)\)</span></li>
<li><strong>Marginal density function:</strong> <span class="math inline">\(f_j\)</span>, for instance, for <span class="math inline">\(j=1\)</span>:</li>
</ul>
<p><span class="math display">\[
f_1({\color{blue}x_1})=\int_{-\infty}^{\infty}\dots \int_{-\infty}^{\infty}f({\color{blue}x_1},x_2\dots,
x_d)dx_2\dots  dx_d
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="02-Review-Prob_n_Stats_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-condDistr" class="level4" data-number="2.2.2.5">
<h4 data-number="2.2.2.5" class="anchored" data-anchor-id="sec-condDistr"><span class="header-section-number">2.2.2.5</span> Conditional Distributions</h4>
<p>Often, we are interested in the <strong>conditional distribution</strong> of <span class="math inline">\(X_j\)</span> given certain values of all other random variables</p>
<p><span class="math display">\[
X_1=x_1,\ldots, X_{j-1}=x_{j-1}, X_{j+1}=x_{j+1},\ldots,X_d=x_d.
\]</span> That is, the distribution of <span class="math inline">\(X_j\)</span> when fixing the values of<br>
<span class="math inline">\(X_1=x_1,\ldots,\)</span> <span class="math inline">\(X_{j-1}=x_{j-1},\)</span> <span class="math inline">\(X_{j+1}=x_{j+1},\ldots, X_d=x_d\)</span>. An important tool is here the <strong>conditional density</strong> of, for instance, <span class="math inline">\(X_1\)</span> given <span class="math inline">\(X_2=x_2,\ldots,X_d=x_d\)</span>: <span class="math display">\[
f(x_1\mid x_2,\ldots,x_d)=\frac{f(x_1,x_2,\ldots,x_d)}{f_{X_{2},\ldots,X_{d}}(x_2,\ldots,x_d)},
\]</span> where <span class="math inline">\(f_{X_{2},\ldots,X_{d}}\)</span> denotes the joint density of <span class="math inline">\(X_2,\ldots,X_d\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="02-Review-Prob_n_Stats_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="means-and-moments" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="means-and-moments"><span class="header-section-number">2.2.3</span> Means and Moments</h3>
</section>
<section id="unconditional-means" class="level3" data-number="2.2.4">
<h3 data-number="2.2.4" class="anchored" data-anchor-id="unconditional-means"><span class="header-section-number">2.2.4</span> Unconditional Means</h3>
<p>The <strong>unconditional mean</strong> of <span class="math inline">\(X_1\)</span> is given by <span class="math display">\[
E(X_1)= \int x f_{X_1}(x)dx.
\]</span> The unconditional mean of a random vector <span class="math inline">\(X=(X_1,\dots,X_d)'\)</span> is given by the vector of element-wise means <span class="math display">\[
E(X)=(E(X_1),\dots,E(X_d))'.
\]</span></p>
</section>
<section id="conditional-means" class="level3" data-number="2.2.5">
<h3 data-number="2.2.5" class="anchored" data-anchor-id="conditional-means"><span class="header-section-number">2.2.5</span> Conditional Means</h3>
<p>Of central importance in <strong>regression analysis</strong> is the <strong>conditional mean</strong>. The conditional mean of <span class="math inline">\(X_1\)</span> for given values <span class="math inline">\(X_2=x_2,\ldots,X_d=x_d\)</span>: <span class="math display">\[\begin{align*}
  m(x_2,\dots,x_d):&amp;=E(X_1|X_2=x_2,\ldots,X_d=x_d)\\
                   &amp;= \int x_1 f(x_1\mid x_2,\ldots,x_d)dx_1,
\end{align*}\]</span><br>
where <span class="math inline">\(m(x_2,\dots,x_d)\)</span> denotes the <strong>regression function</strong>.</p>
</section>
<section id="means-of-transformed-random-variables-and-moments" class="level3" data-number="2.2.6">
<h3 data-number="2.2.6" class="anchored" data-anchor-id="means-of-transformed-random-variables-and-moments"><span class="header-section-number">2.2.6</span> Means of Transformed Random Variables and Moments</h3>
<p>The <strong>mean of a transformed random variable</strong> <span class="math inline">\(r(X)\)</span> is given by <span class="math display">\[
E(r(X))=\int r(x) f_{X}(x)dx.
\]</span> Typical transformations are, for instance</p>
<ul>
<li>centering <span class="math inline">\(r(x)=x-E(X)\)</span>,</li>
<li>centering and scaling <span class="math inline">\(r(x)=(x-E(X))/\sqrt{Var(X)}\)</span>,</li>
<li>or <span class="math inline">\(r(x)=(x - E(X))^2\)</span>,</li>
</ul>
<p>where the latter transformation leads to the <strong>second central moment</strong>, i.e.&nbsp;the variance of <span class="math inline">\(X\)</span>, <span class="math inline">\(Var(X)=\int (x - E(X))^2 f_{X}(x)dx\)</span>.</p>
<ul>
<li><p>The <span class="math inline">\(k\)</span>th, <span class="math inline">\(k&gt;0\)</span>, moment is given by <span class="math display">\[
\mu_{k}=\mathrm{E}\left[X^{k}\right]=\int_{-\infty}^{+\infty}x^{k} f_X(x)d x.
\]</span></p></li>
<li><p>The <span class="math inline">\(k\)</span>th, <span class="math inline">\(k&gt;1\)</span>, central moment is given by <span class="math display">\[
\mu^c_{k}=\mathrm{E}\left[(X-\mathrm{E}[X])^{k}\right]=\int_{-\infty}^{+\infty}(x-\mu)^{k} f_X(x)d x,
\]</span> where <span class="math inline">\(\mu=E(X)\)</span>.</p></li>
</ul>
<p><strong>Note:</strong> Moments determine the tail of a distribution (but not much else); see <span class="citation" data-cites="LB2000">Lindsay and Basak (<a href="#ref-LB2000" role="doc-biblioref">2000</a>)</span>. Roughly: The more moments a distribution has the faster converge the tails to zero. Distributions with compact supports (e.g.&nbsp;the uniform distribution <span class="math inline">\(U[a,b]\)</span>) have infinitely many moments. The Normal distribution has also infinitely many moments, even though this distribution has not a compact support since <span class="math inline">\(\phi(x)&gt;0\)</span> for all <span class="math inline">\(x\in\mathbb{R}\)</span>.</p>
<section id="law-of-total-expectation" class="level4" data-number="2.2.6.1">
<h4 data-number="2.2.6.1" class="anchored" data-anchor-id="law-of-total-expectation"><span class="header-section-number">2.2.6.1</span> Law of Total Expectation</h4>
<p>As long as we do not fix the values of the conditioning variables, <span class="math inline">\(X_2,\dots,X_d\)</span>, they are random variables. Consequently, the conditional mean is generally itself a random variable <span class="math display">\[
E(X_1|X_2,\ldots,X_d)=\int x_1 f(x_1\mid X_2,\ldots,X_d)dx_1
\]</span> due to the randomness in <span class="math inline">\(X_2,\ldots,X_d\)</span>.</p>
<p>Note that <span class="math inline">\(f(x_1\mid X_2,\ldots,X_d)\)</span> is just a transformation of the random variables <span class="math inline">\(X_2,\dots,X_d\)</span>. So we can easily compute the unconditional mean <span class="math inline">\(E(X_1)\)</span> by taking the mean of <span class="math inline">\(E(X_1|X_2,\ldots,X_d)\)</span> as following, <span class="math display">\[\begin{align*}
&amp;E\big({\color{RedViolet}E(X_1|X_2,\ldots,X_d)}\big)=\\
&amp;=\int\dots\int\;{\color{RedViolet}\int x_1 f(x_1\mid x_2,\ldots,x_d)dx_1}\;f_{X_2,\dots,X_d}(x_2,\ldots,x_d)dx_2\dots dx_d\\
&amp;=\int x_1 \left({\color{blue}\int\dots\int f(x_1,x_2,\ldots,x_d)dx_2\dots dx_d}\right)dx_1\\
&amp;=\int x_1 {\color{blue}f_{X_1}(x_1)}dx_1\\
&amp;=E(X_1).
\end{align*}\]</span></p>
<p>The result that <span class="math display">\[
E\big(E(X_1|X_2,\ldots,X_d)\big)=E(X_1)
\]</span> is called <strong>law of total expectation</strong> or <strong>law of iterated expectation</strong>.</p>
</section>
</section>
<section id="independent-random-variables" class="level3" data-number="2.2.7">
<h3 data-number="2.2.7" class="anchored" data-anchor-id="independent-random-variables"><span class="header-section-number">2.2.7</span> Independent Random Variables</h3>
<p>Random variables <span class="math inline">\(X_1,\dots,X_d\)</span> are mutually <strong>independent</strong> if for all <span class="math inline">\(x=(x_1,\dots,x_d)^\prime\)</span> it is true that <span class="math display">\[\begin{align*}
  F(x_1,\dots,x_d)&amp;=F_1(x_1)\cdot F_2(x_2)\cdot\ldots\cdot F_d(x_d)\\
  f(x_1,\dots,x_d)&amp;=f_1(x_1)\cdot f_2(x_2)\cdot\ldots\cdot f_d(x_d)
\end{align*}\]</span></p>
<p>The following holds true:</p>
<ul>
<li>Two real-valued random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent from each other the marginal density of <span class="math inline">\(X\)</span> equals the conditional density of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=y\)</span> for all <span class="math inline">\(y\in\mathbb{R}\)</span>, <span class="math display">\[f_X(x)=f_{X|Y}(x\mid y)\quad \text{ for all } y\in\mathbb{R}.\]</span> Of course, the same statement applies to the marginal density of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span> for all <span class="math inline">\(x\in\mathbb{R}\)</span>. That is, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are two independent real-valued random variables <span class="math inline">\(f_Y(y)=f_{Y|X}(y\mid x)\)</span> for all <span class="math inline">\(x\in\mathbb{R}.\)</span></li>
<li>If a real-valued random variable <span class="math inline">\(X\)</span> is independent from a real-valued random variable <span class="math inline">\(Y\)</span>, then the conditional mean of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=y\)</span> equals the unconditional mean of <span class="math inline">\(X\)</span> for all <span class="math inline">\(y\in\mathbb{R}\)</span> <span class="math display">\[
E(X\mid Y=y)=E(X)
\]</span> and likewise <span class="math display">\[
E(Y\mid X=x)=E(Y)
\]</span> for all <span class="math inline">\(x\in\mathbb{R}\)</span>.</li>
</ul>
<p><strong>Note:</strong> The properties that <span class="math inline">\(E(X\mid Y=y)=E(X)\)</span> for all <span class="math inline">\(y\in\mathbb{R}\)</span> or that <span class="math inline">\(E(Y\mid X=x)=E(Y)\)</span> for all <span class="math inline">\(x\in\mathbb{R}\)</span>, do <strong>not</strong> imply that <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are independent. It only means that <span class="math inline">\(Y\)</span> has no effect on the mean of <span class="math inline">\(X\)</span>, but it may have, for instance, an effect on the variance of <span class="math inline">\(X\)</span>.</p>
</section>
<section id="random-samples" class="level3" data-number="2.2.8">
<h3 data-number="2.2.8" class="anchored" data-anchor-id="random-samples"><span class="header-section-number">2.2.8</span> Random Samples</h3>
<p>Tradition dictates that the sample size is denoted by the natural number <span class="math inline">\(n\in\{1,2,\dots\}\)</span>. A collection of random variables <span class="math inline">\((X_{1}, \ldots, X_{n})\)</span> is called a <strong>random sample</strong> if its random variables are <strong>i.i.d. (independent and identically distributed)</strong>, i.e., if</p>
<ol type="1">
<li><span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> are all <strong>independent</strong> from each other and</li>
<li><span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> have <strong>identical</strong> marginal distributions, i.e., <span class="math inline">\(X_i\sim F_X\)</span> for all <span class="math inline">\(i=1,\dots,n\)</span>.</li>
</ol>
<p>In micro-econometrics, random samples are the default sampling scheme. That is, we consider the collected data as a realization of an underlying random sample.</p>
</section>
<section id="some-important-discrete-random-variables" class="level3" data-number="2.2.9">
<h3 data-number="2.2.9" class="anchored" data-anchor-id="some-important-discrete-random-variables"><span class="header-section-number">2.2.9</span> Some Important Discrete Random Variables</h3>
<!-- ### The point mass distribution {-}  -->
<!-- $X$ has a point mass distribution at $a$, written $X \sim \delta_{a},$ if $P(X=a)=1$ in which case -->
<!-- $$ -->
<!-- F(x)=\left\{\begin{array}{ll} -->
<!-- 0 & x<a \\ -->
<!-- 1 & x \geq a -->
<!-- \end{array}\right. -->
<!-- $$ -->
<!-- The probability function is $f(x)=1$ for $x=a$ and $0$ otherwise. -->
<section id="the-discrete-uniform-distribution" class="level4" data-number="2.2.9.1">
<h4 data-number="2.2.9.1" class="anchored" data-anchor-id="the-discrete-uniform-distribution"><span class="header-section-number">2.2.9.1</span> The Discrete Uniform Distribution</h4>
<p>Let <span class="math inline">\(k&gt;1\)</span> be a given integer. Suppose that <span class="math inline">\(X\)</span> has probability mass function given by <span class="math display">\[
f(x)=\left\{\begin{array}{ll}
1 / k &amp; \text { for } x=1, \ldots, k \\
0 &amp; \text { otherwise. }
\end{array}\right.
\]</span> We say that <span class="math inline">\(X\)</span> has a uniform distribution on <span class="math inline">\(\{1, \ldots, k\}\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">51</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Set the parameter k</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Draw one realization from the discrete uniform distribution</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>k, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7</code></pre>
</div>
</div>
</section>
<section id="the-bernoulli-distribution" class="level4" data-number="2.2.9.2">
<h4 data-number="2.2.9.2" class="anchored" data-anchor-id="the-bernoulli-distribution"><span class="header-section-number">2.2.9.2</span> The Bernoulli Distribution</h4>
<p>Let <span class="math inline">\(X\)</span> represent a possibly unfair coin flip. Then <span class="math inline">\(P(X=1)=p\)</span> and <span class="math inline">\(P(X=0)=1-p\)</span> for some <span class="math inline">\(p \in[0,1]\)</span>. We say that <span class="math inline">\(X\)</span> has a Bernoulli distribution written <span class="math inline">\(X\sim\operatorname{Bernoulli }(p)\)</span>. The probability function is <span class="math inline">\(f(x)=p^{x}(1-p)^{1-x}\)</span> for <span class="math inline">\(x \in\{0,1\}\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">51</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Set the parameter p</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.25</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Draw n realization from the discrete uniform distribution</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">size =</span> n, <span class="at">prob =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">-</span>p, p), <span class="at">replace=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 0 0 1 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Alternatively:</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="do">## (Bernoulli(p) equals Binomial(1,p))</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="at">n =</span> n, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 1 0 1 0</code></pre>
</div>
</div>
</section>
<section id="the-binomial-distribution" class="level4" data-number="2.2.9.3">
<h4 data-number="2.2.9.3" class="anchored" data-anchor-id="the-binomial-distribution"><span class="header-section-number">2.2.9.3</span> The Binomial Distribution</h4>
<p>Suppose we have a coin which falls heads with probability <span class="math inline">\(p\)</span> for some <span class="math inline">\(p\in[0,1]\)</span>. Flip the coin <span class="math inline">\(n\)</span> times and let <span class="math inline">\(X\)</span> be the number of heads (or successes). Assume that the tosses are independent. Let <span class="math inline">\(f(x)=P(X=x)\)</span> be the mass function. It can be shown that <span class="math display">\[
f(x)=\left\{
\begin{array}{ll}
\left(\begin{array}{l}
n \\
x
\end{array}\right) p^{x}(1-p)^{n-x} &amp; \text { for } x=0, \ldots, n \\
0 &amp; \text { otherwise. }
\end{array}\right.
\]</span> A random variable with this mas function is called a <strong>binomial random variable</strong> and we write <span class="math inline">\(X \sim \operatorname{Binomial}(n, p)\)</span>. If <span class="math inline">\(X_{1} \sim\)</span> Binomial <span class="math inline">\(\left(n_1, p1\right)\)</span> and <span class="math inline">\(X_{2} \sim\)</span> Binomial<span class="math inline">\(\left(n_2, p\right)\)</span> and if <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent, then <span class="math inline">\(X_{1}+X_{2} \sim \operatorname{Binomial}\left(n_1+n_2, p\right)\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">51</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Set the parameters n and p</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>size <span class="ot">&lt;-</span>   <span class="dv">10</span> <span class="co"># number of trials</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>p    <span class="ot">&lt;-</span> <span class="fl">0.25</span> <span class="co"># prob of success</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Draw n realization from the binomial distribution:</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="at">n =</span> n, <span class="at">size =</span> size, <span class="at">prob =</span> p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4 1 2 6 1</code></pre>
</div>
</div>
</section>
</section>
<section id="some-important-continuous-random-variables" class="level3" data-number="2.2.10">
<h3 data-number="2.2.10" class="anchored" data-anchor-id="some-important-continuous-random-variables"><span class="header-section-number">2.2.10</span> Some Important Continuous Random Variables</h3>
<section id="the-uniform-distribution" class="level4" data-number="2.2.10.1">
<h4 data-number="2.2.10.1" class="anchored" data-anchor-id="the-uniform-distribution"><span class="header-section-number">2.2.10.1</span> The Uniform Distribution</h4>
<p><span class="math inline">\(X\)</span> has a <span class="math inline">\(\operatorname{Uniform}(a, b)\)</span> distribution, written <span class="math inline">\(X\sim \operatorname{Uniform}(a, b),\)</span> if <span class="math display">\[
f(x)=\left\{\begin{array}{ll}
\frac{1}{b-a} &amp; \text { for } x \in[a, b] \\
0 &amp; \text { otherwise }
\end{array}\right.
\]</span> where <span class="math inline">\(a&lt;b\)</span>. The distribution function is <span class="math display">\[
F(x)=\left\{\begin{array}{ll}
0 &amp; x&lt;a \\
\frac{x-a}{b-a} &amp; x \in[a, b] \\
1 &amp; x&gt;b
\end{array}\right.
\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Drawing from the uniform distribution:</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> a, <span class="at">max =</span> b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 0.83442365 0.75138318 0.40601047 0.97101998 0.11233151 0.50750617
 [7] 0.69714201 0.17104008 0.25448233 0.01813812</code></pre>
</div>
</div>
</section>
<section id="the-normal-or-gaussian-distribution" class="level4" data-number="2.2.10.2">
<h4 data-number="2.2.10.2" class="anchored" data-anchor-id="the-normal-or-gaussian-distribution"><span class="header-section-number">2.2.10.2</span> The Normal (or Gaussian) Distribution</h4>
<p><span class="math inline">\(X\)</span> has a Normal (or Gaussian) distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma,\)</span> denoted by <span class="math inline">\(X \sim N\left(\mu, \sigma^{2}\right),\)</span> if <span class="math display">\[
f(x)=\frac{1}{\sigma \sqrt{2 \pi}} \exp \left\{-\frac{1}{2 \sigma^{2}}(x-\mu)^{2}\right\}, \quad x \in \mathbb{R}
\]</span> where <span class="math inline">\(\mu \in \mathbb{R}\)</span> and <span class="math inline">\(\sigma&gt;0.\)</span> Later we shall see that <span class="math inline">\(\mu\)</span> is the “center” (or mean of the distribution and <span class="math inline">\(\sigma\)</span> is the “spread” (or standard deviation) of the distribution. The Normal plays an important role in probability and statistics. Many phenomena in nature have approximately Normal distributions. The <strong>Central Limit Theorem</strong> gives a special role to the Normal distribution by stating that the distribution of averages of random variables can be approximated by a Normal distribution.</p>
<p>We say that <span class="math inline">\(X\)</span> has a standard Normal distribution if <span class="math inline">\(\mu=0\)</span> and <span class="math inline">\(\sigma=1\)</span>. Tradition dictates that a standard Normal random variable is denoted by <span class="math inline">\(Z\)</span>. The PDF and CDF of a standard Normal are denoted by <span class="math inline">\(\phi(z)\)</span> and <span class="math inline">\(\Phi(z)\)</span>. There is no closed-form expression for <span class="math inline">\(\Phi\)</span>. Here are some useful facts:</p>
<ol type="i">
<li><p>If <span class="math inline">\(X \sim N\left(\mu, \sigma^{2}\right)\)</span> then <span class="math inline">\(Z=(X-\mu) / \sigma \sim N(0,1)\)</span></p></li>
<li><p>If <span class="math inline">\(Z \sim N(0,1)\)</span> then <span class="math inline">\(X=\mu+\sigma Z \sim N\left(\mu, \sigma^{2}\right)\)</span></p></li>
<li><p>If <span class="math inline">\(X_{i} \sim N\left(\mu_{i}, \sigma_{i}^{2}\right), i=1, \ldots, n\)</span> are independent then <span class="math display">\[
\sum_{i=1}^{n} X_{i} \sim N\left(\sum_{i=1}^{n} \mu_{i}, \sum_{i=1}^{n} \sigma_{i}^{2}\right).
\]</span></p></li>
</ol>
<p>The following <code>R</code>-codes plots the standard Normal density function:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># draw a plot of the N(0,1) PDF</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x),</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>),</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">"Density"</span>, </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Standard Normal Density Function"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="02-Review-Prob_n_Stats_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>This is how you can draw realizations from pseudo random Normal variables:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Drawing from the uniform distribution:</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>n     <span class="ot">&lt;-</span> <span class="dv">12</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1]  0.085602504 -0.695791615 -1.364410561 -0.183503290 -1.675347076
 [6]  0.007303551  0.346965187  0.037914318  0.881345676 -0.882815597
[11] -0.883560071 -0.795629557</code></pre>
</div>
</div>
<p>An extension of the normal distribution in a univariate setting is the multivariate normal distribution. Let <span class="math inline">\(X=(X_1,\dots,X_k)'\)</span> be a <span class="math inline">\(k\)</span>-dimensional normal variable, short <span class="math inline">\(X\sim N_k(\mu,\Sigma)\)</span> with mean vector <span class="math inline">\(E(X)=\mu\in\mathbb{R}^k\)</span> and covariance matrix <span class="math inline">\(\operatorname{Cov}(X)=\Sigma\)</span>. The joint density function or <strong>probability density function (pdf)</strong> of the <span class="math inline">\(k\)</span>-dimensional multivariate normal distribution is <span class="math display">\[
f_{X}\left(x_{1}, \ldots, x_{k}\right)=\frac{\exp \left(-\frac{1}{2}(x-\mu)' \Sigma^{-1}(x-\mu)\right)}{\sqrt{(2 \pi)^{k}|\Sigma|}},
\]</span> where <span class="math inline">\(|\Sigma|\)</span> denotes the determinant of <span class="math inline">\(\Sigma\)</span>. For <span class="math inline">\(k=2\)</span> we have the bivariate pdf of two random normal variables, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> say <span class="math display">\[\begin{align*}
&amp;g_{X,Y}(x,y) = \frac{1}{2\pi\sigma_X\sigma_Y\sqrt{1-\rho_{XY}^2}} \\
&amp; \cdot \, \exp \left\{ \frac{1}{-2(1-\rho_{XY}^2)} \left[ \left( \frac{x-\mu_x}{\sigma_X} \right)^2 - 2\rho_{XY}\left( \frac{x-\mu_X}{\sigma_X} \right)\left( \frac{y-\mu_Y}{\sigma_Y} \right) + \left( \frac{y-\mu_Y}{\sigma_Y} \right)^2 \right]  \right\}.
\end{align*}\]</span> Lets consider the special case where <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent standard normal random variables with densities <span class="math inline">\(f_X(x)\)</span> and <span class="math inline">\(f_Y(y)\)</span>. We then have the parameters <span class="math inline">\(\sigma_X = \sigma_Y = 1\)</span>, <span class="math inline">\(\mu_X=\mu_Y=0\)</span> (due to marginal standard normality) and correlation <span class="math inline">\(\rho_{XY}=0\)</span> (due to independence). The joint density of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> then becomes <span class="math display">\[
g_{X,Y}(x,y) = f_X(x) f_Y(y) = \frac{1}{2\pi} \cdot \exp \left\{ -\frac{1}{2}\left[x^2 + y^2\right]\right\}.
\]</span></p>
</section>
<section id="sec-chisqdist" class="level4" data-number="2.2.10.3">
<h4 data-number="2.2.10.3" class="anchored" data-anchor-id="sec-chisqdist"><span class="header-section-number">2.2.10.3</span> The Chi-Squared Distribution</h4>
<p>The chi-squared distribution is another distribution relevant in econometrics. It is often needed when testing special types of hypotheses frequently encountered when dealing with regression models.</p>
<p>The sum of <span class="math inline">\(M\)</span> squared <em>independent standard normal</em> distributed random variables, <span class="math inline">\(Z_1,\dots,Z_M\)</span> follows a chi-squared distribution with <span class="math inline">\(M\)</span> degrees of freedom: <span class="math display">\[\begin{align*}
Z_1^2 + \dots + Z_M^2 = \sum_{m=1}^M Z_m^2 \sim \chi^2_M.
\end{align*}\]</span> A <span class="math inline">\(\chi^2\)</span> distributed random variable with <span class="math inline">\(M\)</span> degrees of freedom has expectation <span class="math inline">\(M\)</span>, mode at <span class="math inline">\(M-2\)</span> for <span class="math inline">\(M \geq 2\)</span> and variance <span class="math inline">\(2 \cdot M\)</span>.</p>
<p>Using the code below, we can display the pdf and the distribution function or <strong>cumulated density function (cdf)</strong> of a <span class="math inline">\(\chi^2_3\)</span> random variable in a single plot. This is achieved by setting the argument <code>add = TRUE"</code> in the second call of <code>"curve()"</code>. Further we adjust limits of both axes using <code>"xlim"</code> and <code>"ylim"</code> and choose different colors to make both functions better distinguishable. The plot is completed by adding a legend with help of <code>"legend()"</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the PDF</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dchisq</span>(x, <span class="at">df =</span> <span class="dv">3</span>), </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">"blue"</span>,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">""</span>,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"pdf and cdf of Chi-Squared Distribution, M = 3"</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># add the CDF to the plot</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">pchisq</span>(x, <span class="at">df =</span> <span class="dv">3</span>), </span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), </span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">add =</span> <span class="cn">TRUE</span>, </span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co"># add a legend to the plot</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, </span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">"PDF"</span>, <span class="st">"CDF"</span>), </span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"red"</span>), </span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="02-Review-Prob_n_Stats_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Since the outcomes of a <span class="math inline">\(\chi^2_M\)</span> distributed random variable are always positive, the support of the related PDF and CDF is <span class="math inline">\(\mathbb{R}_{\geq0}\)</span>.</p>
<p>As expectation and variance depend (solely!) on the degrees of freedom, the distribution’s shape changes drastically if we vary the number of squared standard normals that are summed up. This relation is often depicted by overlaying densities for different <span class="math inline">\(M\)</span>, see the <a href="https://en.wikipedia.org/wiki/Chi-squared_distribution">Wikipedia Article</a>.</p>
<p>We reproduce this here by plotting the density of the <span class="math inline">\(\chi_1^2\)</span> distribution on the interval <span class="math inline">\([0,15]\)</span> with <code>"curve()"</code>. In the next step, we loop over degrees of freedom <span class="math inline">\(M=2,...,7\)</span> and add a density curve for each <span class="math inline">\(M\)</span> to the plot. We also adjust the line color for each iteration of the loop by setting <code>"col = M"</code>. At last, we add a legend that displays degrees of freedom and the associated colors.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the density for M=1</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dchisq</span>(x, <span class="at">df =</span> <span class="dv">1</span>), </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">15</span>), </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">"x"</span>, </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">"Density"</span>, </span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Chi-Square Distributed Random Variables"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># add densities for M=2,...,7 to the plot using a 'for()' loop </span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (M <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>) {</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">curve</span>(<span class="fu">dchisq</span>(x, <span class="at">df =</span> M),</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">15</span>), </span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">add =</span> T, </span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> M)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co"># add a legend</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, </span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>       <span class="fu">as.character</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>), </span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span> , </span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="dv">1</span>, </span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">"D.F."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="02-Review-Prob_n_Stats_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Increasing the degrees of freedom shifts the distribution to the right (the mode becomes larger) and increases the dispersion (the distribution’s variance grows).</p>
</section>
<section id="the-student-t-distribution" class="level4" data-number="2.2.10.4">
<h4 data-number="2.2.10.4" class="anchored" data-anchor-id="the-student-t-distribution"><span class="header-section-number">2.2.10.4</span> The Student t Distribution</h4>
<p>Let <span class="math inline">\(Z\)</span> be a standard normal random variable, <span class="math inline">\(W\)</span> a <span class="math inline">\(\chi^2_\nu\)</span> random variable and further assume that <span class="math inline">\(Z\)</span> and <span class="math inline">\(W\)</span> are independent. Then it holds that <span class="math display">\[
\frac{Z}{\sqrt{W/\nu}} =:X \sim t_\nu
\]</span> and <span class="math inline">\(X\)</span> follows a <em>Student <span class="math inline">\(t\)</span> distribution</em> (or simply <span class="math inline">\(t\)</span> distribution) with <span class="math inline">\(\nu\)</span> degrees of freedom.</p>
<p>The shape of a <span class="math inline">\(t_\nu\)</span> distribution depends on <span class="math inline">\(\nu\)</span>. <span class="math inline">\(t\)</span> distributions are symmetric, bell-shaped and look similar to a normal distribution, especially when <span class="math inline">\(\nu\)</span> is large. This is not a coincidence: for a sufficiently large <span class="math inline">\(\nu\)</span>, the <span class="math inline">\(t_\nu\)</span> distribution can be approximated by the standard normal distribution. This approximation works reasonably well for <span class="math inline">\(\nu\geq 30\)</span>.</p>
<p>A <span class="math inline">\(t_\nu\)</span> distributed random variable <span class="math inline">\(X\)</span> has an expectation if <span class="math inline">\(\nu&gt;1\)</span> and it has a variance if <span class="math inline">\(\nu&gt;2\)</span>. <span class="math display">\[\begin{align*}
  E(X) =&amp; 0, \ M&gt;1 \\
  \text{Var}(X) =&amp; \frac{M}{M-2}, \ M&gt;2
\end{align*}\]</span></p>
<p>Let us plot some <span class="math inline">\(t\)</span> distributions with different degrees of freedoms <span class="math inline">\(\nu\)</span> and compare them to the standard normal distribution.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the standard normal density</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x), </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), </span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">"x"</span>, </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">lty =</span> <span class="dv">2</span>, </span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">"Density"</span>, </span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Densities of t Distributions"</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the t density for M=2</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">2</span>), </span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), </span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="dv">2</span>, </span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">add =</span> T)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the t density for M=4</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">4</span>), </span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), </span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="dv">3</span>, </span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">add =</span> T)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the t density for M=25</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">25</span>), </span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), </span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="dv">4</span>, </span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>      <span class="at">add =</span> T)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a><span class="co"># add a legend</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, </span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">"N(0, 1)"</span>, <span class="st">"M=2"</span>, <span class="st">"M=4"</span>, <span class="st">"M=25"</span>), </span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, </span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="02-Review-Prob_n_Stats_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The plot illustrates that as the degrees of freedom increase, the shape of the <span class="math inline">\(t\)</span> distribution comes closer to that of a standard normal bell curve. Already for <span class="math inline">\(\nu=25\)</span> we find little difference to the standard normal density. If <span class="math inline">\(\nu\)</span> is small, we find the distribution to have heavier tails than a standard normal.</p>
</section>
<section id="cauchy-distribution" class="level4" data-number="2.2.10.5">
<h4 data-number="2.2.10.5" class="anchored" data-anchor-id="cauchy-distribution"><span class="header-section-number">2.2.10.5</span> Cauchy Distribution</h4>
<p>The Cauchy distribution is a special case of the <span class="math inline">\(t\)</span> distribution corresponding to <span class="math inline">\(\nu=1\)</span>. The density is <span class="math display">\[
f(x)=\frac{1}{\pi\left(1+x^{2}\right)}.
\]</span> <!-- To see that this is indeed a density, let's do the integral: --> <!-- $$ --> <!-- \begin{aligned} --> <!-- \int_{-\infty}^{\infty} f(x) d x &=\frac{1}{\pi} \int_{-\infty}^{\infty} \frac{d x}{1+x^{2}}=\frac{1}{\pi} \int_{-\infty}^{\infty} \frac{d \tan ^{-1}}{d x} \\ --> <!-- &=\frac{1}{\pi}\left[\tan ^{-1}(\infty)-\tan ^{-1}(-\infty)\right]=\frac{1}{\pi}\left[\frac{\pi}{2}-\left(-\frac{\pi}{2}\right)\right]=1 --> <!-- \end{aligned} --> <!-- $$ --></p>
<p>For the Cauchy distribution, the <strong>expectation does not exist</strong> – that is, it has no mean. Let’s try to compute the mean of a Cauchy distribution and see what goes wrong. Its mean should be <span class="math display">\[
\mu=E(X)=\int_{-\infty}^{\infty} \frac{x d x}{\pi\left(1+x^{2}\right)}.
\]</span> In order for this improper integral to exist, we need both integrals <span class="math inline">\(\int_{-\infty}^{0}\)</span> and <span class="math inline">\(\int_{0}^{\infty}\)</span> to be finite. Let’s look at the second integral. <span class="math display">\[
\int_{0}^{\infty} \frac{x d x}{\pi\left(1+x^{2}\right)}=\left.\frac{1}{2 \pi} \log \left(1+x^{2}\right)\right|_{0} ^{\infty}=\infty
\]</span> Similarly, the other integral, <span class="math inline">\(\int_{-\infty}^{0},\)</span> is <span class="math inline">\(-\infty\)</span>. Since they’re not both finite, the integral <span class="math inline">\(\int_{-\infty}^{\infty}\)</span> doesn’t exist. In other words <span class="math inline">\(\infty-\infty\)</span> is not a number. Thus, the Cauchy distribution has no mean.</p>
<p>What this means in practice is that if you take a sample <span class="math inline">\(x_{1}, x_{2}, \ldots, x_{n}\)</span> from the Cauchy distribution, then the average <span class="math inline">\(\bar{x}\)</span> does not tend to a particular number. Instead, every so often you will get such a huge number, either positive or negative, that the average is overwhelmed by it.</p>
</section>
<section id="sec-Fdist" class="level4" data-number="2.2.10.6">
<h4 data-number="2.2.10.6" class="anchored" data-anchor-id="sec-Fdist"><span class="header-section-number">2.2.10.6</span> The F Distribution</h4>
<p>Another ratio of random variables important to econometricians is the ratio of two independent <span class="math inline">\(\chi^2\)</span> distributed random variables that are divided by their degrees of freedom <span class="math inline">\(M\)</span> and <span class="math inline">\(n\)</span>. The quantity</p>
<p><span class="math display">\[ \frac{W/M}{V/n} \sim F_{M,n} \ \ \text{with} \ \ W \sim \chi^2_M \ \ , \ \ V \sim \chi^2_n \]</span> follows an <span class="math inline">\(F\)</span> distribution with numerator degrees of freedom <span class="math inline">\(M\)</span> and denominator degrees of freedom <span class="math inline">\(n\)</span>, denoted <span class="math inline">\(F_{M,n}\)</span>. The distribution was first derived by George Snedecor but was named in honor of <a href="https://en.wikipedia.org/wiki/Ronald_Fisher">Sir Ronald Fisher</a>.</p>
<p>By definition, the support of both PDF and CDF of an <span class="math inline">\(F_{M,n}\)</span> distributed random variable is <span class="math inline">\(\mathbb{R}_{\geq0}\)</span>.</p>
<p>Say we have an <span class="math inline">\(F\)</span> distributed random variable <span class="math inline">\(Y\)</span> with numerator degrees of freedom <span class="math inline">\(3\)</span> and denominator degrees of freedom <span class="math inline">\(14\)</span> and are interested in <span class="math inline">\(P(Y \geq 2)\)</span>. This can be computed with help of the function <code>"pf()"</code>. By setting the argument <code>"lower.tail"</code> to <code>"FALSE"</code> we ensure that <code>R</code> computes <span class="math inline">\(1- P(Y \leq 2)\)</span>, i.e,the probability mass in the tail right of <span class="math inline">\(2\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pf</span>(<span class="dv">2</span>, <span class="at">df1 =</span> <span class="dv">3</span>, <span class="at">df2 =</span> <span class="dv">14</span>, <span class="at">lower.tail =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1603538</code></pre>
</div>
</div>
<p>We can visualize this probability by drawing a line plot of the related density and adding a color shading with <code>"polygon()"</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define coordinate vectors for vertices of the polygon</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.01</span>), <span class="dv">10</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">df</span>(<span class="fu">seq</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.01</span>), <span class="dv">3</span>, <span class="dv">14</span>), <span class="dv">0</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># draw density of F_{3, 14}</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">df</span>(x ,<span class="dv">3</span> ,<span class="dv">14</span>), </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.8</span>), </span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), </span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">"Density"</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">"Density Function"</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co"># draw the polygon</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(x, y, <span class="at">col =</span> <span class="st">"orange"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="02-Review-Prob_n_Stats_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The <span class="math inline">\(F\)</span> distribution is related to many other distributions. An important special case encountered in econometrics arises if the denominator degrees of freedom are large such that the <span class="math inline">\(F_{M,n}\)</span> distribution can be approximated by the <span class="math inline">\(F_{M,\infty}\)</span> distribution which turns out to be simply the distribution of a <span class="math inline">\(\chi^2_M\)</span> random variable divided by its degrees of freedom <span class="math inline">\(M\)</span>, i.e.&nbsp; <span class="math display">\[
W/M \sim F_{M,\infty} \quad\text{with}\quad W \sim \chi^2_M.
\]</span></p>
</section>
</section>
</section>
<section id="exercises" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="exercises"><span class="header-section-number">2.3</span> Exercises</h2>
<p>The following link downloads a PDF-file containing the exercises for this chapter.</p>
<p><a href="%22Exercises/Ch2_Exercises.pdf%22">Exercises of Chapter 2</a></p>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-LB2000" class="csl-entry" role="doc-biblioentry">
Lindsay, Bruce G., and Prasanta Basak. 2000. <span>“Moments Determine the Tail of a Distribution (but Not Much Else).”</span> <em>The American Statistician</em> 54 (4): 248–51.
</div>
<div id="ref-Wasserman2004" class="csl-entry" role="doc-biblioentry">
Wasserman, Larry. 2004. <em>All of Statistics: A Concise Course in Statistical Inference</em>. Vol. 26. Springer.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01-Introduction-to-R.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to R</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03-Monte-Carlo-Simulations.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Monte Carlo Simulations</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>