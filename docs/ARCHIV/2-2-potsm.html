<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.2 Properties of the Sample Mean | Advanced Regression Analysis</title>
  <meta name="description" content="2.2 Properties of the Sample Mean | Advanced Regression Analysis" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="2.2 Properties of the Sample Mean | Advanced Regression Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/mylogo.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.2 Properties of the Sample Mean | Advanced Regression Analysis" />
  
  
  <meta name="twitter:image" content="images/mylogo.png" />

<meta name="author" content="Dominik Liebl" />


<meta name="date" content="2020-09-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="2-1-estimation-of-the-population-mean.html"/>
<link rel="next" href="2-3-hypothesis-tests-concerning-the-population-mean.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><a href="https://www.example.com/"><img src="images/mylogo.png" alt="logo" width="100%" height="100%"style="margin: 15px 0 0 0"></a></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="0-1-a-very-short-introduction-to-r-and-rstudio.html"><a href="0-1-a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>0.1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-pt.html"><a href="1-pt.html"><i class="fa fa-check"></i><b>1</b> Probability Theory</a><ul>
<li class="chapter" data-level="1.1" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>1.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="1-1-random-variables-and-probability-distributions.html"><a href="1-1-random-variables-and-probability-distributions.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-2-RSATDOSA.html"><a href="1-2-RSATDOSA.html"><i class="fa fa-check"></i><b>1.2</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="1-2-RSATDOSA.html"><a href="1-2-RSATDOSA.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="1-2-RSATDOSA.html"><a href="1-2-RSATDOSA.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-3-exercises-2.html"><a href="1-3-exercises-2.html"><i class="fa fa-check"></i><b>1.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-arosur.html"><a href="2-arosur.html"><i class="fa fa-check"></i><b>2</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="2.1" data-path="2-1-estimation-of-the-population-mean.html"><a href="2-1-estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>2.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="2.2" data-path="2-2-potsm.html"><a href="2-2-potsm.html"><i class="fa fa-check"></i><b>2.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="2.3" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>2.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="2-3-hypothesis-tests-concerning-the-population-mean.html"><a href="2-3-hypothesis-tests-concerning-the-population-mean.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-4-confidence-intervals-for-the-population-mean.html"><a href="2-4-confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>2.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="2.5" data-path="2-5-cmfdp.html"><a href="2-5-cmfdp.html"><i class="fa fa-check"></i><b>2.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="2.6" data-path="2-6-aattggoe.html"><a href="2-6-aattggoe.html"><i class="fa fa-check"></i><b>2.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="2.7" data-path="2-7-scatterplots-sample-covariance-and-sample-correlation.html"><a href="2-7-scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>2.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="2.8" data-path="2-8-exercises-3.html"><a href="2-8-exercises-3.html"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-lrwor.html"><a href="3-lrwor.html"><i class="fa fa-check"></i><b>3</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="3.1" data-path="3-1-simple-linear-regression.html"><a href="3-1-simple-linear-regression.html"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="3.2" data-path="3-2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="3-2-estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>3.2</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="3-2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="3-2-estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-3-measures-of-fit.html"><a href="3-3-measures-of-fit.html"><i class="fa fa-check"></i><b>3.3</b> Measures of Fit</a><ul>
<li class="chapter" data-level="" data-path="3-3-measures-of-fit.html"><a href="3-3-measures-of-fit.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="3-3-measures-of-fit.html"><a href="3-3-measures-of-fit.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="3-3-measures-of-fit.html"><a href="3-3-measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-4-tlsa.html"><a href="3-4-tlsa.html"><i class="fa fa-check"></i><b>3.4</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="3-4-tlsa.html"><a href="3-4-tlsa.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="3-4-tlsa.html"><a href="3-4-tlsa.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="3-4-tlsa.html"><a href="3-4-tlsa.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-5-tsdotoe.html"><a href="3-5-tsdotoe.html"><i class="fa fa-check"></i><b>3.5</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="3-5-tsdotoe.html"><a href="3-5-tsdotoe.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="3-5-tsdotoe.html"><a href="3-5-tsdotoe.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="3-5-tsdotoe.html"><a href="3-5-tsdotoe.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3-6-exercises-4.html"><a href="3-6-exercises-4.html"><i class="fa fa-check"></i><b>3.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-htaciitslrm.html"><a href="4-htaciitslrm.html"><i class="fa fa-check"></i><b>4</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="4.1" data-path="4-1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="4-1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>4.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="4.2" data-path="4-2-cifrc.html"><a href="4-2-cifrc.html"><i class="fa fa-check"></i><b>4.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="4-2-cifrc.html"><a href="4-2-cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-3-rwxiabv.html"><a href="4-3-rwxiabv.html"><i class="fa fa-check"></i><b>4.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="4.4" data-path="4-4-hah.html"><a href="4-4-hah.html"><i class="fa fa-check"></i><b>4.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="4-4-hah.html"><a href="4-4-hah.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="4-4-hah.html"><a href="4-4-hah.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="4-4-hah.html"><a href="4-4-hah.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-5-the-gauss-markov-theorem.html"><a href="4-5-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>4.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="4-5-the-gauss-markov-theorem.html"><a href="4-5-the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4-6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="4-6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>4.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="4.7" data-path="4-7-exercises-5.html"><a href="4-7-exercises-5.html"><i class="fa fa-check"></i><b>4.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-rmwmr.html"><a href="5-rmwmr.html"><i class="fa fa-check"></i><b>5</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="5.1" data-path="5-1-omitted-variable-bias.html"><a href="5-1-omitted-variable-bias.html"><i class="fa fa-check"></i><b>5.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="5.2" data-path="5-2-tmrm.html"><a href="5-2-tmrm.html"><i class="fa fa-check"></i><b>5.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="5.3" data-path="5-3-mofimr.html"><a href="5-3-mofimr.html"><i class="fa fa-check"></i><b>5.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="5.4" data-path="5-4-ols-assumptions-in-multiple-regression.html"><a href="5-4-ols-assumptions-in-multiple-regression.html"><i class="fa fa-check"></i><b>5.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="5-4-ols-assumptions-in-multiple-regression.html"><a href="5-4-ols-assumptions-in-multiple-regression.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="5-4-ols-assumptions-in-multiple-regression.html"><a href="5-4-ols-assumptions-in-multiple-regression.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="5-5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><a href="5-5-the-distribution-of-the-ols-estimators-in-multiple-regression.html"><i class="fa fa-check"></i><b>5.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="5.6" data-path="5-6-exercises-6.html"><a href="5-6-exercises-6.html"><i class="fa fa-check"></i><b>5.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-htaciimr.html"><a href="6-htaciimr.html"><i class="fa fa-check"></i><b>6</b> Hypothesis Tests and Confidence Intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="6-1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><a href="6-1-hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><i class="fa fa-check"></i><b>6.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="6.2" data-path="6-2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="6-2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>6.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="6-2-an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="6-2-an-application-to-test-scores-and-the-student-teacher-ratio.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-3-joint-hypothesis-testing-using-the-f-statistic.html"><a href="6-3-joint-hypothesis-testing-using-the-f-statistic.html"><i class="fa fa-check"></i><b>6.3</b> Joint Hypothesis Testing Using the F-Statistic</a></li>
<li class="chapter" data-level="6.4" data-path="6-4-confidence-sets-for-multiple-coefficients.html"><a href="6-4-confidence-sets-for-multiple-coefficients.html"><i class="fa fa-check"></i><b>6.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="6.5" data-path="6-5-model-specification-for-multiple-regression.html"><a href="6-5-model-specification-for-multiple-regression.html"><i class="fa fa-check"></i><b>6.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="6-5-model-specification-for-multiple-regression.html"><a href="6-5-model-specification-for-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="6-6-analysis-of-the-test-score-data-set.html"><a href="6-6-analysis-of-the-test-score-data-set.html"><i class="fa fa-check"></i><b>6.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="6.7" data-path="6-7-exercises-7.html"><a href="6-7-exercises-7.html"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-nrf.html"><a href="7-nrf.html"><i class="fa fa-check"></i><b>7</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="7.1" data-path="7-1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><a href="7-1-a-general-strategy-for-modelling-nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>7.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="7.2" data-path="7-2-nfoasiv.html"><a href="7-2-nfoasiv.html"><i class="fa fa-check"></i><b>7.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="7-2-nfoasiv.html"><a href="7-2-nfoasiv.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="7-2-nfoasiv.html"><a href="7-2-nfoasiv.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-3-interactions-between-independent-variables.html"><a href="7-3-interactions-between-independent-variables.html"><i class="fa fa-check"></i><b>7.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="7.4" data-path="7-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="7-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>7.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
<li class="chapter" data-level="7.5" data-path="7-5-exercises-8.html"><a href="7-5-exercises-8.html"><i class="fa fa-check"></i><b>7.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-asbomr.html"><a href="8-asbomr.html"><i class="fa fa-check"></i><b>8</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="8.1" data-path="8-1-internal-and-external-validity.html"><a href="8-1-internal-and-external-validity.html"><i class="fa fa-check"></i><b>8.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="8.2" data-path="8-2-ttivomra.html"><a href="8-2-ttivomra.html"><i class="fa fa-check"></i><b>8.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="8.3" data-path="8-3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><a href="8-3-internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><i class="fa fa-check"></i><b>8.3</b> Internal and External Validity when the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="8.4" data-path="8-4-etsacs.html"><a href="8-4-etsacs.html"><i class="fa fa-check"></i><b>8.4</b> Example: Test Scores and Class Size</a></li>
<li class="chapter" data-level="8.5" data-path="8-5-exercises-9.html"><a href="8-5-exercises-9.html"><i class="fa fa-check"></i><b>8.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-rwpd.html"><a href="9-rwpd.html"><i class="fa fa-check"></i><b>9</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="9.1" data-path="9-1-panel-data.html"><a href="9-1-panel-data.html"><i class="fa fa-check"></i><b>9.1</b> Panel Data</a></li>
<li class="chapter" data-level="9.2" data-path="9-2-PDWTTP.html"><a href="9-2-PDWTTP.html"><i class="fa fa-check"></i><b>9.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="9.3" data-path="9-3-fixed-effects-regression.html"><a href="9-3-fixed-effects-regression.html"><i class="fa fa-check"></i><b>9.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="9-3-fixed-effects-regression.html"><a href="9-3-fixed-effects-regression.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="9-3-fixed-effects-regression.html"><a href="9-3-fixed-effects-regression.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-4-regression-with-time-fixed-effects.html"><a href="9-4-regression-with-time-fixed-effects.html"><i class="fa fa-check"></i><b>9.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="9.5" data-path="9-5-tferaaseffer.html"><a href="9-5-tferaaseffer.html"><i class="fa fa-check"></i><b>9.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="9.6" data-path="9-6-drunk-driving-laws-and-traffic-deaths.html"><a href="9-6-drunk-driving-laws-and-traffic-deaths.html"><i class="fa fa-check"></i><b>9.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
<li class="chapter" data-level="9.7" data-path="9-7-exercises-10.html"><a href="9-7-exercises-10.html"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-rwabdv.html"><a href="10-rwabdv.html"><i class="fa fa-check"></i><b>10</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="10.1" data-path="10-1-binary-dependent-variables-and-the-linear-probability-model.html"><a href="10-1-binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>10.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="10.2" data-path="10-2-palr.html"><a href="10-2-palr.html"><i class="fa fa-check"></i><b>10.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="10-2-palr.html"><a href="10-2-palr.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="10-2-palr.html"><a href="10-2-palr.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10-3-estimation-and-inference-in-the-logit-and-probit-models.html"><a href="10-3-estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>10.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="10.4" data-path="10-4-application-to-the-boston-hmda-data.html"><a href="10-4-application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>10.4</b> Application to the Boston HMDA Data</a></li>
<li class="chapter" data-level="10.5" data-path="10-5-exercises-11.html"><a href="10-5-exercises-11.html"><i class="fa fa-check"></i><b>10.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-ivr.html"><a href="11-ivr.html"><i class="fa fa-check"></i><b>11</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="11.1" data-path="11-1-TIVEWASRAASI.html"><a href="11-1-TIVEWASRAASI.html"><i class="fa fa-check"></i><b>11.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="11.2" data-path="11-2-TGIVRM.html"><a href="11-2-TGIVRM.html"><i class="fa fa-check"></i><b>11.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="11.3" data-path="11-3-civ.html"><a href="11-3-civ.html"><i class="fa fa-check"></i><b>11.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="11.4" data-path="11-4-attdfc.html"><a href="11-4-attdfc.html"><i class="fa fa-check"></i><b>11.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="11.5" data-path="11-5-where-do-valid-instruments-come-from.html"><a href="11-5-where-do-valid-instruments-come-from.html"><i class="fa fa-check"></i><b>11.5</b> Where Do Valid Instruments Come From?</a></li>
<li class="chapter" data-level="11.6" data-path="11-6-exercises-12.html"><a href="11-6-exercises-12.html"><i class="fa fa-check"></i><b>11.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-eaqe.html"><a href="12-eaqe.html"><i class="fa fa-check"></i><b>12</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="12.1" data-path="12-1-poceaie.html"><a href="12-1-poceaie.html"><i class="fa fa-check"></i><b>12.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="12.2" data-path="12-2-threats-to-validity-of-experiments.html"><a href="12-2-threats-to-validity-of-experiments.html"><i class="fa fa-check"></i><b>12.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="12.3" data-path="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><i class="fa fa-check"></i><b>12.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="12-3-experimental-estimates-of-the-effect-of-class-size-reductions.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="12-4-qe.html"><a href="12-4-qe.html"><i class="fa fa-check"></i><b>12.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="12-4-qe.html"><a href="12-4-qe.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="12-4-qe.html"><a href="12-4-qe.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="12-5-exercises-13.html"><a href="12-5-exercises-13.html"><i class="fa fa-check"></i><b>12.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-ittsraf.html"><a href="13-ittsraf.html"><i class="fa fa-check"></i><b>13</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="13.1" data-path="13-1-using-regression-models-for-forecasting.html"><a href="13-1-using-regression-models-for-forecasting.html"><i class="fa fa-check"></i><b>13.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="13.2" data-path="13-2-tsdasc.html"><a href="13-2-tsdasc.html"><i class="fa fa-check"></i><b>13.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="13-2-tsdasc.html"><a href="13-2-tsdasc.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="13-3-autoregressions.html"><a href="13-3-autoregressions.html"><i class="fa fa-check"></i><b>13.3</b> Autoregressions</a><ul>
<li><a href="13-3-autoregressions.html#autoregressive-models-of-order-p">Autoregressive Models of Order <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="13-4-cybtmpi.html"><a href="13-4-cybtmpi.html"><i class="fa fa-check"></i><b>13.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="13.5" data-path="13-5-apatadlm.html"><a href="13-5-apatadlm.html"><i class="fa fa-check"></i><b>13.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="13-5-apatadlm.html"><a href="13-5-apatadlm.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="13-6-llsuic.html"><a href="13-6-llsuic.html"><i class="fa fa-check"></i><b>13.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="13.7" data-path="13-7-nit.html"><a href="13-7-nit.html"><i class="fa fa-check"></i><b>13.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="13.8" data-path="13-8-niib.html"><a href="13-8-niib.html"><i class="fa fa-check"></i><b>13.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="13.9" data-path="13-9-can-you-beat-the-market-part-ii.html"><a href="13-9-can-you-beat-the-market-part-ii.html"><i class="fa fa-check"></i><b>13.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-eodce.html"><a href="14-eodce.html"><i class="fa fa-check"></i><b>14</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="14.1" data-path="14-1-the-orange-juice-data.html"><a href="14-1-the-orange-juice-data.html"><i class="fa fa-check"></i><b>14.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="14.2" data-path="14-2-dynamic-causal-effects.html"><a href="14-2-dynamic-causal-effects.html"><i class="fa fa-check"></i><b>14.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="14.3" data-path="14-3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><a href="14-3-dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><i class="fa fa-check"></i><b>14.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="14.4" data-path="14-4-hac-standard-errors.html"><a href="14-4-hac-standard-errors.html"><i class="fa fa-check"></i><b>14.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="14.5" data-path="14-5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><a href="14-5-estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><i class="fa fa-check"></i><b>14.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="14.6" data-path="14-6-orange-juice-prices-and-cold-weather.html"><a href="14-6-orange-juice-prices-and-cold-weather.html"><i class="fa fa-check"></i><b>14.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="15-atitsr.html"><a href="15-atitsr.html"><i class="fa fa-check"></i><b>15</b> Additional Topics in Time Series Regression</a><ul>
<li class="chapter" data-level="15.1" data-path="15-1-vector-autoregressions.html"><a href="15-1-vector-autoregressions.html"><i class="fa fa-check"></i><b>15.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="15.2" data-path="15-2-ooiatdfglsurt.html"><a href="15-2-ooiatdfglsurt.html"><i class="fa fa-check"></i><b>15.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="15.3" data-path="15-3-cointegration.html"><a href="15-3-cointegration.html"><i class="fa fa-check"></i><b>15.3</b> Cointegration</a></li>
<li class="chapter" data-level="15.4" data-path="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><i class="fa fa-check"></i><b>15.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a><ul>
<li class="chapter" data-level="" data-path="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="15-4-volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
<li class="chapter" data-level="" data-path="7-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="7-4-nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Regression Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="potsm" class="section level2">
<h2><span class="header-section-number">2.2</span> Properties of the Sample Mean</h2>

<div class="rmdknit">
<p>A more precise way to express consistency of an estimator <span class="math inline">\(\hat\mu\)</span> for a parameter <span class="math inline">\(\mu\)</span> is</p>
<p><span class="math display">\[ P(|\hat{\mu} - \mu|&lt;\epsilon) \xrightarrow[n \rightarrow \infty]{p} 1 \quad \text{for any}\quad\epsilon&gt;0.\]</span></p>
This expression says that the probability of observing a deviation from the true value <span class="math inline">\(\mu\)</span> that is smaller than some arbitrary <span class="math inline">\(\epsilon &gt; 0\)</span> converges to <span class="math inline">\(1\)</span> as <span class="math inline">\(n\)</span> grows. Consistency does not require unbiasedness.
</div>

<p>To examine properties of the sample mean as an estimator for the corresponding population mean, consider the following <tt>R</tt> example.</p>
<p>We generate a population <tt>pop</tt> consisting of observations <span class="math inline">\(Y_i\)</span>, <span class="math inline">\(i=1,\dots,10000\)</span> that origin from a normal distribution with mean <span class="math inline">\(\mu = 10\)</span> and variance <span class="math inline">\(\sigma^2 = 1\)</span>.</p>
<p>To investigate the behavior of the estimator <span class="math inline">\(\hat{\mu} = \bar{Y}\)</span> we can draw random samples from this population and calculate <span class="math inline">\(\bar{Y}\)</span> for each of them. This is easily done by making use of the function <tt>replicate()</tt>. The argument <tt>expr</tt> is evaluated <tt>n</tt> times. In this case we draw samples of sizes <span class="math inline">\(n=5\)</span> and <span class="math inline">\(n=25\)</span>, compute the sample means and repeat this exactly <span class="math inline">\(N=25000\)</span> times.</p>
<p>For comparison purposes we store results for the estimator <span class="math inline">\(Y_1\)</span>, the first observation in a sample for a sample of size <span class="math inline">\(5\)</span>, separately.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" data-line-number="1"><span class="co"># generate a fictious population</span></a>
<a class="sourceLine" id="cb47-2" data-line-number="2">pop &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">10000</span>, <span class="dv">10</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb47-3" data-line-number="3"></a>
<a class="sourceLine" id="cb47-4" data-line-number="4"><span class="co"># sample from the population and estimate the mean</span></a>
<a class="sourceLine" id="cb47-5" data-line-number="5">est1 &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dt">expr =</span> <span class="kw">mean</span>(<span class="kw">sample</span>(<span class="dt">x =</span> pop, <span class="dt">size =</span> <span class="dv">5</span>)), <span class="dt">n =</span> <span class="dv">25000</span>)</a>
<a class="sourceLine" id="cb47-6" data-line-number="6"></a>
<a class="sourceLine" id="cb47-7" data-line-number="7">est2 &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dt">expr =</span> <span class="kw">mean</span>(<span class="kw">sample</span>(<span class="dt">x =</span> pop, <span class="dt">size =</span> <span class="dv">25</span>)), <span class="dt">n =</span> <span class="dv">25000</span>)</a>
<a class="sourceLine" id="cb47-8" data-line-number="8"></a>
<a class="sourceLine" id="cb47-9" data-line-number="9">fo &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dt">expr =</span> <span class="kw">sample</span>(<span class="dt">x =</span> pop, <span class="dt">size =</span> <span class="dv">5</span>)[<span class="dv">1</span>], <span class="dt">n =</span> <span class="dv">25000</span>)</a></code></pre></div>
<p>Check that <tt>est1</tt> and <tt>est2</tt> are vectors of length <span class="math inline">\(25000\)</span>:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1"><span class="co"># check if object type is vector</span></a>
<a class="sourceLine" id="cb48-2" data-line-number="2"><span class="kw">is.vector</span>(est1)</a>
<a class="sourceLine" id="cb48-3" data-line-number="3"><span class="co">#&gt; [1] TRUE</span></a>
<a class="sourceLine" id="cb48-4" data-line-number="4"><span class="kw">is.vector</span>(est2)</a>
<a class="sourceLine" id="cb48-5" data-line-number="5"><span class="co">#&gt; [1] TRUE</span></a>
<a class="sourceLine" id="cb48-6" data-line-number="6"></a>
<a class="sourceLine" id="cb48-7" data-line-number="7"><span class="co"># check length</span></a>
<a class="sourceLine" id="cb48-8" data-line-number="8"><span class="kw">length</span>(est1)</a>
<a class="sourceLine" id="cb48-9" data-line-number="9"><span class="co">#&gt; [1] 25000</span></a>
<a class="sourceLine" id="cb48-10" data-line-number="10"><span class="kw">length</span>(est2)</a>
<a class="sourceLine" id="cb48-11" data-line-number="11"><span class="co">#&gt; [1] 25000</span></a></code></pre></div>
<p>The code chunk below produces a plot of the sampling distributions of the estimators <span class="math inline">\(\bar{Y}\)</span> and <span class="math inline">\(Y_1\)</span> on the basis of the <span class="math inline">\(25000\)</span> samples in each case. We also plot the density function of the <span class="math inline">\(\mathcal{N}(10,1)\)</span> distribution.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1"><span class="co"># plot density estimate Y_1</span></a>
<a class="sourceLine" id="cb49-2" data-line-number="2"><span class="kw">plot</span>(<span class="kw">density</span>(fo), </a>
<a class="sourceLine" id="cb49-3" data-line-number="3">      <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>, </a>
<a class="sourceLine" id="cb49-4" data-line-number="4">      <span class="dt">lwd =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb49-5" data-line-number="5">      <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb49-6" data-line-number="6">      <span class="dt">xlab =</span> <span class="st">&quot;estimates&quot;</span>,</a>
<a class="sourceLine" id="cb49-7" data-line-number="7">      <span class="dt">main =</span> <span class="st">&quot;Sampling Distributions of Unbiased Estimators&quot;</span>)</a>
<a class="sourceLine" id="cb49-8" data-line-number="8"></a>
<a class="sourceLine" id="cb49-9" data-line-number="9"><span class="co"># add density estimate for the distribution of the sample mean with n=5 to the plot</span></a>
<a class="sourceLine" id="cb49-10" data-line-number="10"><span class="kw">lines</span>(<span class="kw">density</span>(est1), </a>
<a class="sourceLine" id="cb49-11" data-line-number="11">     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, </a>
<a class="sourceLine" id="cb49-12" data-line-number="12">     <span class="dt">lwd =</span> <span class="dv">2</span>, </a>
<a class="sourceLine" id="cb49-13" data-line-number="13">     <span class="dt">bty =</span> <span class="st">&quot;l&quot;</span>)</a>
<a class="sourceLine" id="cb49-14" data-line-number="14"></a>
<a class="sourceLine" id="cb49-15" data-line-number="15"><span class="co"># add density estimate for the distribution of the sample mean with n=25 to the plot</span></a>
<a class="sourceLine" id="cb49-16" data-line-number="16"><span class="kw">lines</span>(<span class="kw">density</span>(est2), </a>
<a class="sourceLine" id="cb49-17" data-line-number="17">      <span class="dt">col =</span> <span class="st">&quot;red2&quot;</span>, </a>
<a class="sourceLine" id="cb49-18" data-line-number="18">      <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb49-19" data-line-number="19"></a>
<a class="sourceLine" id="cb49-20" data-line-number="20"><span class="co"># add a vertical line at the true parameter</span></a>
<a class="sourceLine" id="cb49-21" data-line-number="21"><span class="kw">abline</span>(<span class="dt">v =</span> <span class="dv">10</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb49-22" data-line-number="22"></a>
<a class="sourceLine" id="cb49-23" data-line-number="23"><span class="co"># add N(10,1) density to the plot</span></a>
<a class="sourceLine" id="cb49-24" data-line-number="24"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">10</span>), </a>
<a class="sourceLine" id="cb49-25" data-line-number="25">     <span class="dt">lwd =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb49-26" data-line-number="26">     <span class="dt">lty =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb49-27" data-line-number="27">     <span class="dt">add =</span> T)</a>
<a class="sourceLine" id="cb49-28" data-line-number="28"></a>
<a class="sourceLine" id="cb49-29" data-line-number="29"><span class="co"># add a legend</span></a>
<a class="sourceLine" id="cb49-30" data-line-number="30"><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>,</a>
<a class="sourceLine" id="cb49-31" data-line-number="31">       <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;N(10,1)&quot;</span>,</a>
<a class="sourceLine" id="cb49-32" data-line-number="32">                  <span class="kw">expression</span>(Y[<span class="dv">1</span>]),</a>
<a class="sourceLine" id="cb49-33" data-line-number="33">                  <span class="kw">expression</span>(<span class="kw">bar</span>(Y) <span class="op">~</span><span class="st"> </span>n <span class="op">==</span><span class="st"> </span><span class="dv">5</span>),</a>
<a class="sourceLine" id="cb49-34" data-line-number="34">                  <span class="kw">expression</span>(<span class="kw">bar</span>(Y) <span class="op">~</span><span class="st"> </span>n <span class="op">==</span><span class="st"> </span><span class="dv">25</span>)</a>
<a class="sourceLine" id="cb49-35" data-line-number="35">                  ), </a>
<a class="sourceLine" id="cb49-36" data-line-number="36">       <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>), </a>
<a class="sourceLine" id="cb49-37" data-line-number="37">       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;green&quot;</span>, <span class="st">&quot;steelblue&quot;</span>, <span class="st">&quot;red2&quot;</span>),</a>
<a class="sourceLine" id="cb49-38" data-line-number="38">       <span class="dt">lwd =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="AdvRA_files/figure-html/unnamed-chunk-91-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>First, <em>all</em> sampling distributions (represented by the solid lines) are centered around <span class="math inline">\(\mu = 10\)</span>. This is evidence for the <em>unbiasedness</em> of <span class="math inline">\(Y_1\)</span>, <span class="math inline">\(\overline{Y}_{5}\)</span> and <span class="math inline">\(\overline{Y}_{25}\)</span>. Of course, the theoretical density <span class="math inline">\(\mathcal{N}(10,1)\)</span> is centered at <span class="math inline">\(10\)</span>, too.</p>
<p>Next, have a look at the spread of the sampling distributions. Several things are noteworthy:</p>
<ul>
<li><p>The sampling distribution of <span class="math inline">\(Y_1\)</span> (green curve) tracks the density of the <span class="math inline">\(\mathcal{N}(10,1)\)</span> distribution (black dashed line) pretty closely. In fact, the sampling distribution of <span class="math inline">\(Y_1\)</span> is the <span class="math inline">\(\mathcal{N}(10,1)\)</span> distribution. This is less surprising if you keep in mind that the <span class="math inline">\(Y_1\)</span> estimator does nothing but reporting an observation that is randomly selected from a population with <span class="math inline">\(\mathcal{N}(10,1)\)</span> distribution. Hence, <span class="math inline">\(Y_1 \sim \mathcal{N}(10,1)\)</span>. Note that this result does not depend on the sample size <span class="math inline">\(n\)</span>: the sampling distribution of <span class="math inline">\(Y_1\)</span> <em>is always</em> the population distribution, no matter how large the sample is. <span class="math inline">\(Y_1\)</span> is a good a estimate of <span class="math inline">\(\mu_Y\)</span>, but we can do better.</p></li>
<li><p>Both sampling distributions of <span class="math inline">\(\overline{Y}\)</span> show less dispersion than the sampling distribution of <span class="math inline">\(Y_1\)</span>. This means that <span class="math inline">\(\overline{Y}\)</span> has a lower variance than <span class="math inline">\(Y_1\)</span>. In view of Key Concepts 3.2 and 3.3, we find that <span class="math inline">\(\overline{Y}\)</span> is a more efficient estimator than <span class="math inline">\(Y_1\)</span>. In fact, this holds for all <span class="math inline">\(n&gt;1\)</span>.</p></li>
<li><p><span class="math inline">\(\overline{Y}\)</span> shows a behavior illustrating consistency (see Key Concept 3.2). The blue and the red densities are much more concentrated around <span class="math inline">\(\mu=10\)</span> than the green one. As the number of observations is increased from <span class="math inline">\(1\)</span> to <span class="math inline">\(5\)</span>, the sampling distribution tightens around the true parameter. Increasing the sample size to <span class="math inline">\(25\)</span>, this effect becomes more apparent. This implies that the probability of obtaining estimates that are close to the true value increases with <span class="math inline">\(n\)</span>. This is also reflected by the estimated values of the density function close to 10: the larger the sample size, the larger the value of the density.</p></li>
</ul>
<p>We encourage you to go ahead and modify the code. Try out different values for the sample size and see how the sampling distribution of <span class="math inline">\(\overline{Y}\)</span> changes!</p>
<div id="overliney-is-the-least-squares-estimator-of-mu_y" class="section level4 unnumbered">
<h4><span class="math inline">\(\overline{Y}\)</span> is the Least Squares Estimator of <span class="math inline">\(\mu_Y\)</span></h4>
<p>Assume you have some observations <span class="math inline">\(Y_1,\dots,Y_n\)</span> on <span class="math inline">\(Y \sim \mathcal{N}(10,1)\)</span> (which is unknown) and would like to find an estimator <span class="math inline">\(m\)</span> that predicts the observations as well as possible. By good we mean to choose <span class="math inline">\(m\)</span> such that the total squared deviation between the predicted value and the observed values is small. Mathematically, this means we want to find an <span class="math inline">\(m\)</span> that minimizes</p>
<p><span class="math display" id="eq:sqm">\[\begin{equation}
  \sum_{i=1}^n (Y_i - m)^2. \tag{2.1}
\end{equation}\]</span></p>
<p>Think of <span class="math inline">\(Y_i - m\)</span> as the mistake made when predicting <span class="math inline">\(Y_i\)</span> by <span class="math inline">\(m\)</span>. We could also minimize the sum of absolute deviations from <span class="math inline">\(m\)</span> but minimizing the sum of squared deviations is mathematically more convenient (and will lead to a different result). That is why the estimator we are looking for is called the <em>least squares estimator</em>. <span class="math inline">\(m = \overline{Y}\)</span>, the sample mean, is this estimator.</p>
<p>We can show this by generating a random sample and plotting <a href="2-2-potsm.html#eq:sqm">(2.1)</a> as a function of <span class="math inline">\(m\)</span>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1"><span class="co"># define the function and vectorize it</span></a>
<a class="sourceLine" id="cb50-2" data-line-number="2">sqm &lt;-<span class="st"> </span><span class="cf">function</span>(m) {</a>
<a class="sourceLine" id="cb50-3" data-line-number="3"> <span class="kw">sum</span>((y<span class="op">-</span>m)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb50-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb50-5" data-line-number="5">sqm &lt;-<span class="st"> </span><span class="kw">Vectorize</span>(sqm)</a>
<a class="sourceLine" id="cb50-6" data-line-number="6"></a>
<a class="sourceLine" id="cb50-7" data-line-number="7"><span class="co"># draw random sample and compute the mean</span></a>
<a class="sourceLine" id="cb50-8" data-line-number="8">y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="dv">10</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb50-9" data-line-number="9"><span class="kw">mean</span>(y)</a>
<a class="sourceLine" id="cb50-10" data-line-number="10"><span class="co">#&gt; [1] 10.1364</span></a></code></pre></div>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1"><span class="co"># plot the objective function</span></a>
<a class="sourceLine" id="cb51-2" data-line-number="2"><span class="kw">curve</span>(<span class="kw">sqm</span>(x), </a>
<a class="sourceLine" id="cb51-3" data-line-number="3">      <span class="dt">from =</span> <span class="dv">-50</span>, </a>
<a class="sourceLine" id="cb51-4" data-line-number="4">      <span class="dt">to =</span> <span class="dv">70</span>,</a>
<a class="sourceLine" id="cb51-5" data-line-number="5">      <span class="dt">xlab =</span> <span class="st">&quot;m&quot;</span>,</a>
<a class="sourceLine" id="cb51-6" data-line-number="6">      <span class="dt">ylab =</span> <span class="st">&quot;sqm(m)&quot;</span>)</a>
<a class="sourceLine" id="cb51-7" data-line-number="7"></a>
<a class="sourceLine" id="cb51-8" data-line-number="8"><span class="co"># add vertical line at mean(y)</span></a>
<a class="sourceLine" id="cb51-9" data-line-number="9"><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">mean</span>(y), </a>
<a class="sourceLine" id="cb51-10" data-line-number="10">       <span class="dt">lty =</span> <span class="dv">2</span>, </a>
<a class="sourceLine" id="cb51-11" data-line-number="11">       <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>)</a>
<a class="sourceLine" id="cb51-12" data-line-number="12"></a>
<a class="sourceLine" id="cb51-13" data-line-number="13"><span class="co"># add annotation at mean(y)</span></a>
<a class="sourceLine" id="cb51-14" data-line-number="14"><span class="kw">text</span>(<span class="dt">x =</span> <span class="kw">mean</span>(y), </a>
<a class="sourceLine" id="cb51-15" data-line-number="15">     <span class="dt">y =</span> <span class="dv">0</span>, </a>
<a class="sourceLine" id="cb51-16" data-line-number="16">     <span class="dt">labels =</span> <span class="kw">paste</span>(<span class="kw">round</span>(<span class="kw">mean</span>(y), <span class="dv">2</span>)))</a></code></pre></div>
<p><img src="AdvRA_files/figure-html/unnamed-chunk-93-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Notice that <a href="2-2-potsm.html#eq:sqm">(2.1)</a> is a quadratic function so that there is only one minimum. The plot shows that this minimum lies exactly at the sample mean of the sample data.</p>

<div class="rmdknit">
<p>Some <tt>R</tt> functions can only interact with functions that take a vector as an input and evaluate the function body on every entry of the vector, for example <tt>curve()</tt>. We call such functions vectorized functions and it is often a good idea to write vectorized functions yourself, although this is cumbersome in some cases. Having a vectorized function in <tt>R</tt> is never a drawback since these functions work on both single values and vectors.</p>
<p>Let us look at the function <tt>sqm()</tt>, which is non-vectorized:</p>
<p><tt>
sqm &lt;- function(m) {<br />
     sum((y-m)^2) #body of the function<br />
}
</tt></p>
<p>Providing, e.g., <tt>c(1,2,3)</tt> as the argument <tt>m</tt> would cause an error since then the operation <tt>y-m</tt> is invalid: the vectors <tt>y</tt> and <tt>m</tt> are of incompatible dimensions. This is why we cannot use <tt>sqm()</tt> in conjunction with <tt>curve()</tt>.</p>
Here <tt>Vectorize()</tt> comes into play. It generates a vectorized version of a non-vectorized function.
</div>

</div>
<div id="why-random-sampling-is-important" class="section level4 unnumbered">
<h4>Why Random Sampling is Important</h4>
<p>So far, we assumed (sometimes implicitly) that the observed data <span class="math inline">\(Y_1, \dots, Y_n\)</span> are the result of a sampling process that satisfies the assumption of simple random sampling. This assumption often is fulfilled when estimating a population mean using <span class="math inline">\(\overline{Y}\)</span>. If this is not the case, estimates may be biased.</p>
<p>Let us fall back to <tt>pop</tt>, the fictive population of <span class="math inline">\(10000\)</span> observations and compute the population mean <span class="math inline">\(\mu_{\texttt{pop}}\)</span>:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1"><span class="co"># compute the population mean of pop</span></a>
<a class="sourceLine" id="cb52-2" data-line-number="2"><span class="kw">mean</span>(pop)</a>
<a class="sourceLine" id="cb52-3" data-line-number="3"><span class="co">#&gt; [1] 9.992604</span></a></code></pre></div>
<p>Next we sample <span class="math inline">\(10\)</span> observations from <tt>pop</tt> with <tt>sample()</tt> and estimate <span class="math inline">\(\mu_{\texttt{pop}}\)</span> using <span class="math inline">\(\overline{Y}\)</span> repeatedly. However, now we use a sampling scheme that deviates from simple random sampling: instead of ensuring that each member of the population has the same chance to end up in a sample, we assign a higher probability of being sampled to the <span class="math inline">\(2500\)</span> smallest observations of the population by setting the argument <tt>prob</tt> to a suitable vector of probability weights:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" data-line-number="1"><span class="co"># simulate outcomes for the sample mean when the i.i.d. assumption fails</span></a>
<a class="sourceLine" id="cb53-2" data-line-number="2">est3 &lt;-<span class="st">  </span><span class="kw">replicate</span>(<span class="dt">n =</span> <span class="dv">25000</span>, </a>
<a class="sourceLine" id="cb53-3" data-line-number="3">                   <span class="dt">expr =</span> <span class="kw">mean</span>(<span class="kw">sample</span>(<span class="dt">x =</span> <span class="kw">sort</span>(pop), </a>
<a class="sourceLine" id="cb53-4" data-line-number="4">                                      <span class="dt">size =</span> <span class="dv">10</span>, </a>
<a class="sourceLine" id="cb53-5" data-line-number="5">                                      <span class="dt">prob =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">4</span>, <span class="dv">2500</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">7500</span>)))))</a>
<a class="sourceLine" id="cb53-6" data-line-number="6"></a>
<a class="sourceLine" id="cb53-7" data-line-number="7"><span class="co"># compute the sample mean of the outcomes</span></a>
<a class="sourceLine" id="cb53-8" data-line-number="8"><span class="kw">mean</span>(est3)</a>
<a class="sourceLine" id="cb53-9" data-line-number="9"><span class="co">#&gt; [1] 9.444113</span></a></code></pre></div>
<p>Next we plot the sampling distribution of <span class="math inline">\(\overline{Y}\)</span> for this non-i.i.d. case and compare it to the sampling distribution when the i.i.d. assumption holds.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1"><span class="co"># sampling distribution of sample mean, i.i.d. holds, n=25</span></a>
<a class="sourceLine" id="cb54-2" data-line-number="2"><span class="kw">plot</span>(<span class="kw">density</span>(est2), </a>
<a class="sourceLine" id="cb54-3" data-line-number="3">      <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,</a>
<a class="sourceLine" id="cb54-4" data-line-number="4">      <span class="dt">lwd =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb54-5" data-line-number="5">      <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">8</span>, <span class="dv">11</span>),</a>
<a class="sourceLine" id="cb54-6" data-line-number="6">      <span class="dt">xlab =</span> <span class="st">&quot;Estimates&quot;</span>,</a>
<a class="sourceLine" id="cb54-7" data-line-number="7">      <span class="dt">main =</span> <span class="st">&quot;When the i.i.d. Assumption Fails&quot;</span>)</a>
<a class="sourceLine" id="cb54-8" data-line-number="8"></a>
<a class="sourceLine" id="cb54-9" data-line-number="9"><span class="co"># sampling distribution of sample mean, i.i.d. fails, n=25</span></a>
<a class="sourceLine" id="cb54-10" data-line-number="10"><span class="kw">lines</span>(<span class="kw">density</span>(est3),</a>
<a class="sourceLine" id="cb54-11" data-line-number="11">      <span class="dt">col =</span> <span class="st">&quot;red2&quot;</span>,</a>
<a class="sourceLine" id="cb54-12" data-line-number="12">      <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb54-13" data-line-number="13"></a>
<a class="sourceLine" id="cb54-14" data-line-number="14"><span class="co"># add a legend</span></a>
<a class="sourceLine" id="cb54-15" data-line-number="15"><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>,</a>
<a class="sourceLine" id="cb54-16" data-line-number="16">       <span class="dt">legend =</span> <span class="kw">c</span>(<span class="kw">expression</span>(<span class="kw">bar</span>(Y)[n <span class="op">==</span><span class="st"> </span><span class="dv">25</span>]<span class="op">~</span><span class="st">&quot;, i.i.d. fails&quot;</span>),</a>
<a class="sourceLine" id="cb54-17" data-line-number="17">                  <span class="kw">expression</span>(<span class="kw">bar</span>(Y)[n <span class="op">==</span><span class="st"> </span><span class="dv">25</span>]<span class="op">~</span><span class="st">&quot;, i.i.d. holds&quot;</span>)</a>
<a class="sourceLine" id="cb54-18" data-line-number="18">                  ), </a>
<a class="sourceLine" id="cb54-19" data-line-number="19">       <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), </a>
<a class="sourceLine" id="cb54-20" data-line-number="20">       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;red2&quot;</span>, <span class="st">&quot;steelblue&quot;</span>),</a>
<a class="sourceLine" id="cb54-21" data-line-number="21">       <span class="dt">lwd =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="AdvRA_files/figure-html/unnamed-chunk-96-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Here, the failure of the i.i.d. assumption implies that, on average, we <em>underestimate</em> <span class="math inline">\(\mu_Y\)</span> using <span class="math inline">\(\overline{Y}\)</span>: the corresponding distribution of <span class="math inline">\(\overline{Y}\)</span> is shifted to the left. In other words, <span class="math inline">\(\overline{Y}\)</span> is a <em>biased</em> estimator for <span class="math inline">\(\mu_Y\)</span> if the i.i.d. assumption does not hold.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="2-1-estimation-of-the-population-mean.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="2-3-hypothesis-tests-concerning-the-population-mean.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/lidom/AdvRA/edit/master/03-ch3.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
