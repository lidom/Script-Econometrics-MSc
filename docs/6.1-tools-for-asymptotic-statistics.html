<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.1 Tools for Asymptotic Statistics | Econometrics (M.Sc.)</title>
  <meta name="description" content="6.1 Tools for Asymptotic Statistics | Econometrics (M.Sc.)" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="6.1 Tools for Asymptotic Statistics | Econometrics (M.Sc.)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/mylogo.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.1 Tools for Asymptotic Statistics | Econometrics (M.Sc.)" />
  
  
  <meta name="twitter:image" content="/images/mylogo.png" />

<meta name="author" content="Prof. Dr. Dominik Liebl" />


<meta name="date" content="2021-10-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="6-ch:LSINF.html"/>
<link rel="next" href="6.2-asymptotics-under-the-classic-regression-model.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="organization-of-the-course.html"><a href="organization-of-the-course.html"><i class="fa fa-check"></i>Organization of the Course</a></li>
<li class="chapter" data-level="" data-path="literature.html"><a href="literature.html"><i class="fa fa-check"></i>Literature</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-introduction-to-r.html"><a href="1-introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-short-glossary.html"><a href="1.1-short-glossary.html"><i class="fa fa-check"></i><b>1.1</b> Short Glossary</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-first-steps.html"><a href="1.2-first-steps.html"><i class="fa fa-check"></i><b>1.2</b> First Steps</a></li>
<li class="chapter" data-level="1.3" data-path="1.3-further-data-objects.html"><a href="1.3-further-data-objects.html"><i class="fa fa-check"></i><b>1.3</b> Further Data Objects</a></li>
<li class="chapter" data-level="1.4" data-path="1.4-simple-regression-analysis-using-r.html"><a href="1.4-simple-regression-analysis-using-r.html"><i class="fa fa-check"></i><b>1.4</b> Simple Regression Analysis using R</a></li>
<li class="chapter" data-level="1.5" data-path="1.5-programming-in-r.html"><a href="1.5-programming-in-r.html"><i class="fa fa-check"></i><b>1.5</b> Programming in R</a></li>
<li class="chapter" data-level="1.6" data-path="1.6-r-packages.html"><a href="1.6-r-packages.html"><i class="fa fa-check"></i><b>1.6</b> R-packages</a></li>
<li class="chapter" data-level="1.7" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html"><i class="fa fa-check"></i><b>1.7</b> Tidyverse</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#tidyverse-plotting-basics"><i class="fa fa-check"></i><b>1.7.1</b> Tidyverse: Plotting Basics</a></li>
<li class="chapter" data-level="1.7.2" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#tidyverse-data-wrangling-basics"><i class="fa fa-check"></i><b>1.7.2</b> Tidyverse: Data Wrangling Basics</a></li>
<li class="chapter" data-level="1.7.3" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#the-pipe-operator"><i class="fa fa-check"></i><b>1.7.3</b> The pipe operator <code>%&gt;%</code></a></li>
<li class="chapter" data-level="1.7.4" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#the-group_by-function"><i class="fa fa-check"></i><b>1.7.4</b> The <code>group_by()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="1.8-further-links.html"><a href="1.8-further-links.html"><i class="fa fa-check"></i><b>1.8</b> Further Links</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="1.8-further-links.html"><a href="1.8-further-links.html#further-r-intros"><i class="fa fa-check"></i><b>1.8.1</b> Further R-Intros</a></li>
<li class="chapter" data-level="1.8.2" data-path="1.8-further-links.html"><a href="1.8-further-links.html#version-control-gitgithub"><i class="fa fa-check"></i><b>1.8.2</b> Version Control (Git/GitHub)</a></li>
<li class="chapter" data-level="1.8.3" data-path="1.8-further-links.html"><a href="1.8-further-links.html#r-ladies"><i class="fa fa-check"></i><b>1.8.3</b> R-Ladies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-review-probability-and-statistics.html"><a href="2-review-probability-and-statistics.html"><i class="fa fa-check"></i><b>2</b> Review: Probability and Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html"><i class="fa fa-check"></i><b>2.1</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>2.1.1</b> Sample Spaces and Events</a></li>
<li class="chapter" data-level="2.1.2" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#probability"><i class="fa fa-check"></i><b>2.1.2</b> Probability</a></li>
<li class="chapter" data-level="2.1.3" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#independent-events"><i class="fa fa-check"></i><b>2.1.3</b> Independent Events</a></li>
<li class="chapter" data-level="2.1.4" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>2.1.4</b> Conditional Probability</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html"><i class="fa fa-check"></i><b>2.2</b> Random Variables</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#univariate-distribution-and-probability-functions"><i class="fa fa-check"></i><b>2.2.1</b> Univariate Distribution and Probability Functions</a></li>
<li class="chapter" data-level="2.2.2" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#multivariate-distribution-and-probability-functions"><i class="fa fa-check"></i><b>2.2.2</b> Multivariate Distribution and Probability Functions</a></li>
<li class="chapter" data-level="2.2.3" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#means-and-moments"><i class="fa fa-check"></i><b>2.2.3</b> Means and Moments</a></li>
<li class="chapter" data-level="2.2.4" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#unconditional-means"><i class="fa fa-check"></i><b>2.2.4</b> Unconditional Means</a></li>
<li class="chapter" data-level="2.2.5" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#conditional-means"><i class="fa fa-check"></i><b>2.2.5</b> Conditional Means</a></li>
<li class="chapter" data-level="2.2.6" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#means-of-transformed-random-variables-and-moments"><i class="fa fa-check"></i><b>2.2.6</b> Means of Transformed Random Variables and Moments</a></li>
<li class="chapter" data-level="2.2.7" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>2.2.7</b> Independent Random Variables</a></li>
<li class="chapter" data-level="2.2.8" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#i.i.d.-samples"><i class="fa fa-check"></i><b>2.2.8</b> I.I.D. Samples</a></li>
<li class="chapter" data-level="2.2.9" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#some-important-discrete-random-variables"><i class="fa fa-check"></i><b>2.2.9</b> Some Important Discrete Random Variables</a></li>
<li class="chapter" data-level="2.2.10" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#some-important-continuous-random-variables"><i class="fa fa-check"></i><b>2.2.10</b> Some Important Continuous Random Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-ch:SLR.html"><a href="3-ch:SLR.html"><i class="fa fa-check"></i><b>3</b> Review: Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html"><i class="fa fa-check"></i><b>3.1</b> The Simple Linear Regression Model</a>
<ul>
<li class="chapter" data-level="" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#the-data-generating-process"><i class="fa fa-check"></i>The Data-Generating Process</a></li>
<li class="chapter" data-level="3.1.1" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#assumptions-about-the-error-term"><i class="fa fa-check"></i><b>3.1.1</b> Assumptions About the Error Term</a></li>
<li class="chapter" data-level="3.1.2" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#the-population-regression-line"><i class="fa fa-check"></i><b>3.1.2</b> The Population Regression Line</a></li>
<li class="chapter" data-level="3.1.3" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#terminology-estimates-versus-estimators"><i class="fa fa-check"></i><b>3.1.3</b> Terminology: Estimates versus Estimators</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html"><i class="fa fa-check"></i><b>3.2</b> Ordinary Least Squares Estimation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html#terminology-sample-regression-line-prediction-and-residuals"><i class="fa fa-check"></i><b>3.2.1</b> Terminology: Sample Regression Line, Prediction and Residuals</a></li>
<li class="chapter" data-level="3.2.2" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html#sec:SLROLS"><i class="fa fa-check"></i><b>3.2.2</b> Deriving the Expression of the OLS Estimator</a></li>
<li class="chapter" data-level="3.2.3" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html#behavior-of-the-ols-estimates-for-resampled-data-conditionally-on-x_i"><i class="fa fa-check"></i><b>3.2.3</b> Behavior of the OLS Estimates for Resampled Data (conditionally on <span class="math inline">\(X_i\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html"><i class="fa fa-check"></i><b>3.3</b> Properties of the OLS Estimator</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html#mean-and-bias-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.1</b> Mean and Bias of the OLS Estimator</a></li>
<li class="chapter" data-level="3.3.2" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html#variance-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.2</b> Variance of the OLS Estimator</a></li>
<li class="chapter" data-level="3.3.3" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html#consistency-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.3</b> Consistency of the OLS Estimator</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-ch:MLR.html"><a href="4-ch:MLR.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-assumptions.html"><a href="4.1-assumptions.html"><i class="fa fa-check"></i><b>4.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="4.1-assumptions.html"><a href="4.1-assumptions.html#some-implications-of-the-exogeneity-assumption"><i class="fa fa-check"></i><b>4.1.1</b> Some Implications of the Exogeneity Assumption</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4.2-deriving-the-expression-of-the-ols-estimator.html"><a href="4.2-deriving-the-expression-of-the-ols-estimator.html"><i class="fa fa-check"></i><b>4.2</b> Deriving the Expression of the OLS Estimator</a></li>
<li class="chapter" data-level="4.3" data-path="4.3-some-quantities-of-interest.html"><a href="4.3-some-quantities-of-interest.html"><i class="fa fa-check"></i><b>4.3</b> Some Quantities of Interest</a></li>
<li class="chapter" data-level="4.4" data-path="4.4-method-of-moments-estimator.html"><a href="4.4-method-of-moments-estimator.html"><i class="fa fa-check"></i><b>4.4</b> Method of Moments Estimator</a></li>
<li class="chapter" data-level="4.5" data-path="4.5-unbiasedness-of-hatbetax.html"><a href="4.5-unbiasedness-of-hatbetax.html"><i class="fa fa-check"></i><b>4.5</b> Unbiasedness of <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="4.6" data-path="4.6-ch:VarEstBeta.html"><a href="4.6-ch:VarEstBeta.html"><i class="fa fa-check"></i><b>4.6</b> Variance of <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="4.7" data-path="4.7-the-gauss-markov-theorem.html"><a href="4.7-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>4.7</b> The Gauss-Markov Theorem</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-ch:SSINF.html"><a href="5-ch:SSINF.html"><i class="fa fa-check"></i><b>5</b> Small Sample Inference</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5.1-ch:testmultp.html"><a href="5.1-ch:testmultp.html"><i class="fa fa-check"></i><b>5.1</b> Hypothesis Tests about Multiple Parameters</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="5.1-ch:testmultp.html"><a href="5.1-ch:testmultp.html#the-test-statistic-and-its-null-distribution"><i class="fa fa-check"></i><b>5.1.1</b> The Test Statistic and its Null Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5.2-ch:testingsinglep.html"><a href="5.2-ch:testingsinglep.html"><i class="fa fa-check"></i><b>5.2</b> Tests about One Parameter</a></li>
<li class="chapter" data-level="5.3" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html"><i class="fa fa-check"></i><b>5.3</b> Testtheory</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html#significance-level"><i class="fa fa-check"></i><b>5.3.1</b> Significance Level</a></li>
<li class="chapter" data-level="5.3.2" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html#critical-value-for-the-f-test"><i class="fa fa-check"></i><b>5.3.2</b> Critical Value for the <span class="math inline">\(F\)</span>-Test</a></li>
<li class="chapter" data-level="5.3.3" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html#critical-values-for-the-t-test"><i class="fa fa-check"></i><b>5.3.3</b> Critical Value(s) for the <span class="math inline">\(t\)</span>-Test</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5.4-type-ii-error-and-power.html"><a href="5.4-type-ii-error-and-power.html"><i class="fa fa-check"></i><b>5.4</b> Type II Error and Power</a></li>
<li class="chapter" data-level="5.5" data-path="5.5-p-value.html"><a href="5.5-p-value.html"><i class="fa fa-check"></i><b>5.5</b> <span class="math inline">\(p\)</span>-Value</a></li>
<li class="chapter" data-level="5.6" data-path="5.6-CIsmallsample.html"><a href="5.6-CIsmallsample.html"><i class="fa fa-check"></i><b>5.6</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.7" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html"><i class="fa fa-check"></i><b>5.7</b> Practice: Small Sample Inference</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html#normally-distributed-hatbetax"><i class="fa fa-check"></i><b>5.7.1</b> Normally Distributed <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="5.7.2" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html#testing-multiple-parameters"><i class="fa fa-check"></i><b>5.7.2</b> Testing Multiple Parameters</a></li>
<li class="chapter" data-level="5.7.3" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html#dualty-of-confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>5.7.3</b> Dualty of Confidence Intervals and Hypothesis Tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-ch:LSINF.html"><a href="6-ch:LSINF.html"><i class="fa fa-check"></i><b>6</b> Large Sample Inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html"><i class="fa fa-check"></i><b>6.1</b> Tools for Asymptotic Statistics</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#modes-of-convergence"><i class="fa fa-check"></i><b>6.1.1</b> Modes of Convergence</a></li>
<li class="chapter" data-level="" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#four-important-modes-of-convergence"><i class="fa fa-check"></i>Four Important Modes of Convergence</a></li>
<li class="chapter" data-level="" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#relations-among-modes-of-convergence"><i class="fa fa-check"></i>Relations among Modes of Convergence</a></li>
<li class="chapter" data-level="6.1.2" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#continuous-mapping-theorem-cmt"><i class="fa fa-check"></i><b>6.1.2</b> Continuous Mapping Theorem (CMT)</a></li>
<li class="chapter" data-level="6.1.3" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#slutsky-theorem"><i class="fa fa-check"></i><b>6.1.3</b> Slutsky Theorem</a></li>
<li class="chapter" data-level="6.1.4" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#law-of-large-numbers-lln-and-central-limit-theorem-clt"><i class="fa fa-check"></i><b>6.1.4</b> Law of Large Numbers (LLN) and Central Limit Theorem (CLT)</a></li>
<li class="chapter" data-level="6.1.5" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#estimators-as-a-sequences-of-random-variables"><i class="fa fa-check"></i><b>6.1.5</b> Estimators as a Sequences of Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6.2-asymptotics-under-the-classic-regression-model.html"><a href="6.2-asymptotics-under-the-classic-regression-model.html"><i class="fa fa-check"></i><b>6.2</b> Asymptotics under the Classic Regression Model</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="6.2-asymptotics-under-the-classic-regression-model.html"><a href="6.2-asymptotics-under-the-classic-regression-model.html#the-case-of-heteroscedasticity"><i class="fa fa-check"></i><b>6.2.1</b> The Case of Heteroscedasticity</a></li>
<li class="chapter" data-level="6.2.2" data-path="6.2-asymptotics-under-the-classic-regression-model.html"><a href="6.2-asymptotics-under-the-classic-regression-model.html#hypothesis-testing-and-confidence-intervals"><i class="fa fa-check"></i><b>6.2.2</b> Hypothesis Testing and Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6.3-robust-confidence-intervals.html"><a href="6.3-robust-confidence-intervals.html"><i class="fa fa-check"></i><b>6.3</b> Robust Confidence Intervals</a></li>
<li class="chapter" data-level="6.4" data-path="6.4-practice-large-sample-inference.html"><a href="6.4-practice-large-sample-inference.html"><i class="fa fa-check"></i><b>6.4</b> Practice: Large Sample Inference</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="6.4-practice-large-sample-inference.html"><a href="6.4-practice-large-sample-inference.html#normally-distributed-hatbeta-for-ntoinfty"><i class="fa fa-check"></i><b>6.4.1</b> Normally Distributed <span class="math inline">\(\hat\beta\)</span> for <span class="math inline">\(n\to\infty\)</span></a></li>
<li class="chapter" data-level="6.4.2" data-path="6.4-practice-large-sample-inference.html"><a href="6.4-practice-large-sample-inference.html#testing-multiple-and-single-parameters"><i class="fa fa-check"></i><b>6.4.2</b> Testing Multiple and Single Parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-maximum-likelihood.html"><a href="7-maximum-likelihood.html"><i class="fa fa-check"></i><b>7</b> Maximum Likelihood</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7.1-likelihood-principle.html"><a href="7.1-likelihood-principle.html"><i class="fa fa-check"></i><b>7.1</b> Likelihood Principle</a></li>
<li class="chapter" data-level="7.2" data-path="7.2-properties-of-maximum-likelihood-estimators.html"><a href="7.2-properties-of-maximum-likelihood-estimators.html"><i class="fa fa-check"></i><b>7.2</b> Properties of Maximum Likelihood Estimators</a></li>
<li class="chapter" data-level="7.3" data-path="7.3-the-log-likelihood-function.html"><a href="7.3-the-log-likelihood-function.html"><i class="fa fa-check"></i><b>7.3</b> The (Log-)Likelihood Function</a></li>
<li class="chapter" data-level="7.4" data-path="7.4-optimization-non-analytical-solutions.html"><a href="7.4-optimization-non-analytical-solutions.html"><i class="fa fa-check"></i><b>7.4</b> Optimization: Non-Analytical Solutions</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="7.4-optimization-non-analytical-solutions.html"><a href="7.4-optimization-non-analytical-solutions.html#newton-raphson-optimization"><i class="fa fa-check"></i><b>7.4.1</b> Newton-Raphson Optimization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="7.5-ols-estimation-as-ml-estimation.html"><a href="7.5-ols-estimation-as-ml-estimation.html"><i class="fa fa-check"></i><b>7.5</b> OLS-Estimation as ML-Estimation</a></li>
<li class="chapter" data-level="7.6" data-path="7.6-variance-of-ml-estimators-hatbeta_ml-and-s2_ml.html"><a href="7.6-variance-of-ml-estimators-hatbeta_ml-and-s2_ml.html"><i class="fa fa-check"></i><b>7.6</b> Variance of ML-Estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}\)</span></a></li>
<li class="chapter" data-level="7.7" data-path="7.7-consistency-of-hatbeta_ml-and-s_ml2.html"><a href="7.7-consistency-of-hatbeta_ml-and-s_ml2.html"><i class="fa fa-check"></i><b>7.7</b> Consistency of <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s_{ML}^2\)</span></a></li>
<li class="chapter" data-level="7.8" data-path="7.8-asymptotic-theory-of-maximum-likelihood-estimators.html"><a href="7.8-asymptotic-theory-of-maximum-likelihood-estimators.html"><i class="fa fa-check"></i><b>7.8</b> Asymptotic Theory of Maximum-Likelihood Estimators</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-ivr.html"><a href="8-ivr.html"><i class="fa fa-check"></i><b>8</b> Instrumental Variables Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8.1-TIVEWASRAASI.html"><a href="8.1-TIVEWASRAASI.html"><i class="fa fa-check"></i><b>8.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="8.1-TIVEWASRAASI.html"><a href="8.1-TIVEWASRAASI.html#the-two-stage-least-squares-estimator"><i class="fa fa-check"></i><b>8.1.1</b> The Two-Stage Least Squares Estimator</a></li>
<li class="chapter" data-level="8.1.2" data-path="8.1-TIVEWASRAASI.html"><a href="8.1-TIVEWASRAASI.html#application-demand-for-cigarettes-12"><i class="fa fa-check"></i><b>8.1.2</b> Application: Demand For Cigarettes (1/2)</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8.2-TGIVRM.html"><a href="8.2-TGIVRM.html"><i class="fa fa-check"></i><b>8.2</b> The General IV Regression Model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8.2-TGIVRM.html"><a href="8.2-TGIVRM.html#application-demand-for-cigarettes-22"><i class="fa fa-check"></i><b>8.2.1</b> Application: Demand for Cigarettes (2/2)</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8.3-civ.html"><a href="8.3-civ.html"><i class="fa fa-check"></i><b>8.3</b> Checking Instrument Validity</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="8.3-civ.html"><a href="8.3-civ.html#instrument-relevance"><i class="fa fa-check"></i><b>8.3.1</b> Instrument Relevance</a></li>
<li class="chapter" data-level="8.3.2" data-path="8.3-civ.html"><a href="8.3-civ.html#instrument-validity"><i class="fa fa-check"></i><b>8.3.2</b> Instrument Validity</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8.4-attdfc.html"><a href="8.4-attdfc.html"><i class="fa fa-check"></i><b>8.4</b> Application to the Demand for Cigarettes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Econometrics (M.Sc.)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tools-for-asymptotic-statistics" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Tools for Asymptotic Statistics</h2>
<div id="modes-of-convergence" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Modes of Convergence</h3>
<p>In the following we will discuss the four most important convergence concepts for sequences of random variables <span class="math inline">\((z_1,z_2,\dots,z_n)\)</span> shortly denoted by <span class="math inline">\(\{z_n\}\)</span>. Non-random scalars (or vectors or matrices) will be denoted by Greek letters such as <span class="math inline">\(\alpha\)</span>.</p>
<!-- Sequences of random vectors (or matrices) will be denoted by $\{\mathbf{z}_n\}$.  -->
<!-- % Vector-Convergence if and only if element-wise converegence:  -->
<!-- %https://www.statlect.com/asymptotic-theory/mean-square-convergence#:~:text=The%20concept%20of%20mean%2Dsquare,difference%20is%20on%20average%20small. -->
</div>
<div id="four-important-modes-of-convergence" class="section level3 unnumbered">
<h3>Four Important Modes of Convergence</h3>
<p>A sequence of random scalars <span class="math inline">\(\{z_n\}\)</span>  to a constant (non-random) <span class="math inline">\(\alpha\)</span> if, for any (arbitrarily small) <span class="math inline">\(\eps&gt;0\)</span>,
<span class="math display">\[\begin{eqnarray*}
  \lim_{n\to\infty} P\left(|z_n-\alpha|&gt;\eps\right)=0.
\end{eqnarray*}\]</span>
We write: <span class="math inline">\(\plim_{n\to\infty}z_n=\alpha\)</span>, or <span class="math inline">\(z_n\toprob\alpha\)</span>. Convergence in probability of a sequence of random vectors (or matrices) <span class="math inline">\(\{z_n\}\)</span> to a constant vector (or matrix) <span class="math inline">\(\alpha\)</span> requires  convergence in probability.</p>
<p>A sequence of random scalars <span class="math inline">\(\{z_n\}\)</span>  to a constant (non-random) <span class="math inline">\(\alpha\)</span> if
<span class="math display">\[\begin{eqnarray*}
P\left(\lim_{n\to\infty}z_n=\alpha\right)=1.
\end{eqnarray*}\]</span>
We write: <span class="math inline">\(z_n\toas\alpha\)</span>. Almost sure convergence of a sequence of random vectors (or matrices) <span class="math inline">\(\{z_n\}\)</span> to a constant vector (or matrix) <span class="math inline">\(\alpha\)</span> requires  almost sure convergence.</p>
<p>Almost sure convergence is (usually) rather hard to derive, since the probability is about an event concerning an infinite sequence. Fortunately, however, there are established strong laws of large numbers that we can use for showing almost sure convergence.</p>
<p>A sequence of random scalars <span class="math inline">\(\{z_n\}\)</span>  (or ) to a constant (non-random) <span class="math inline">\(\alpha\)</span> if
<span class="math display">\[\begin{eqnarray*}
  \lim_{n\to\infty}E\left((z_n-\alpha)^2\right)=0
\end{eqnarray*}\]</span>
We write: <span class="math inline">\(z_n\toms\alpha\)</span>. If <span class="math inline">\(z_n\)</span> is an estimator (e.g., <span class="math inline">\(z_n=\hat\beta_{k,n}\)</span>) the expression <span class="math inline">\(E\left((z_n-\alpha)^2\right)\)</span> is termed the : <span class="math inline">\(\text{MSE}(z_n)=E\left((z_n-\alpha)^2\right)\)</span>. Mean square convergence of a sequence of random vectors (or matrices) <span class="math inline">\(\{z_n\}\)</span> to a deterministic vector (or matrix) <span class="math inline">\(\alpha\)</span> requires  mean square convergence.</p>
<!-- \paragraph*{Convergence to a Random Variable:} The above presented definitions of convergence can be also applied to limits that are random variables. We say that a sequence of random vectors $\{\mathbf{z}_n\}$ converges to a random vector $\mathbf{z}$ and write $\mathbf{z}_n\toprob\mathbf{z}$ if the sequence $\{\mathbf{z}_n-\mathbf{z}\}$ converges to $\mathbf{0}$. Similarly, for $\mathbf{z}_n\toas\mathbf{z}$ and $\mathbf{z}_n\toms\mathbf{z}$.  -->
<p>Let <span class="math inline">\(F_n\)</span> be the cumulative distribution function (cdf) of <span class="math inline">\(z_n\)</span> and <span class="math inline">\(F\)</span> the cdf of <span class="math inline">\(z\)</span>. A sequence of random scalars <span class="math inline">\(\{z_n\}\)</span>  to a random scalar <span class="math inline">\(z\)</span> if for all <span class="math inline">\(t\)</span> such that <span class="math inline">\(F(t)\)</span> is continuous at <span class="math inline">\(t\)</span>,
<span class="math display">\[\begin{eqnarray*}
  \lim_{n\to\infty}F_n(t)=F(t).
\end{eqnarray*}\]</span>
We write: <span class="math inline">\(z_n\todistr z\)</span> and call <span class="math inline">\(F\)</span> the  (or )  of <span class="math inline">\(z_n\)</span>. Sometimes you will see statements like <span class="math inline">\(z_n\todistr N(0,1)\)</span> or <span class="math inline">\(z_n\overset{a}{\sim}N(0,1)\)</span>, which should be read as <span class="math inline">\(z_n\todistr z\)</span>, where <span class="math inline">\(z\sim N(0,1)\)</span>.</p>
<p>A stochastic sequence <span class="math inline">\(\{z_n\}\)</span> can also convergence in distribution to a  <span class="math inline">\(\alpha\)</span>. In this case <span class="math inline">\(\alpha\)</span> is treated as a degenerated random variable with cdf
<span class="math display">\[
F_\alpha(t)=\left\{\begin{matrix}0&amp;\text{if}\;\;t&lt;\alpha\\ 1&amp;\text{if}\;\;t\geq\alpha\end{matrix}\right.
\]</span></p>
<p>Let <span class="math inline">\(z_n,z\in\mathbb{R}^K\)</span> be <span class="math inline">\(K\)</span>-dimensional random variables, then
<span class="math display">\[
z_n\todistr z\text{\quad if and only if \quad}\lambda&#39;z_n\todistr\lambda&#39;z
\]</span>
for any <span class="math inline">\(\lambda\in\mathbb{R}^K\)</span>. This statement is known as the . It is needed since element-wise convergence in distribution does generally not imply convergence of the  distribution of <span class="math inline">\(z_n\)</span> to the  distribution of <span class="math inline">\(z\)</span>; except, if all elements are independent from each other.</p>
<!-- \paragraph*{Remark:} Note that convergence in distribution, as the name suggests, only involves the distributions of the random variables. Thus, the random variables need not even be defined on the same probability space (that is, they need not be defined for the same random experiment), and indeed we don't even need the random variables at all. (But all this is just thought provoking \dots typically, we'll only consider cases with a common probability space.) -->
</div>
<div id="relations-among-modes-of-convergence" class="section level3 unnumbered">
<h3>Relations among Modes of Convergence</h3>
<p>Proofs can be found, e.g., here: </p>
</div>
<div id="continuous-mapping-theorem-cmt" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Continuous Mapping Theorem (CMT)</h3>
<p>Proof can be found, e.g., in , van der Vaart (1998), Theorem 2.3. Or here: </p>
<p>The CMT does  hold for m.s.-convergence except for the case where <span class="math inline">\(a(.)\)</span> is linear.<br />
<!-- %This is easily seen using the expression %$\E[(z_n-\alpha)^2]=\V(z_n)+(\E(z_n)-\alpha)^2$ and the  -->
<!-- %application of Jensen's inequality (see below). --></p>
As a consequence of the CMT (Lemma ) we have that the usual arithmetic operations preserve convergence in probability (equivalently for almost sure convergence and convergence in distribution):
<!-- The first statement above is immediately seen by setting $\mathbf{z}_n=\left(x_n, y_n\right)'$, $\boldsymbol\alpha=\left(\beta, \gamma\right)'$, and $\mathbf{a}(\boldsymbol\alpha)=(1,1)\boldsymbol\alpha$, similarly for all others.  -->
</div>
<div id="slutsky-theorem" class="section level3" number="6.1.3">
<h3><span class="header-section-number">6.1.3</span> Slutsky Theorem</h3>
The following results are concerned with combinations of convergence in probability and convergence in distribution. These are particularly important for the derivation of the asymptotic distribution of estimators.<br />

<p>Proofs can be found, e.g., in , van der Vaart, Theorem 2.8. Or here: </p>
<p>Sometimes, only parts  and  of Lemma  are called </p>
</div>
<div id="law-of-large-numbers-lln-and-central-limit-theorem-clt" class="section level3" number="6.1.4">
<h3><span class="header-section-number">6.1.4</span> Law of Large Numbers (LLN) and Central Limit Theorem (CLT)</h3>
<p>So far, we discussed the definitions of the four most important convergence modes, their relations among each other, and basic theorems (CMT and Slutsky) about functionals of stochastic sequences. Though, we still lack of tools that allow us to actually show that a stochastic sequence convergences (in some of the discussed modes) to some limit.</p>
<p>In the following we consider the stochastic sequences <span class="math inline">\(\{\bar{z}_n\}\)</span> of sample means <span class="math inline">\(\bar{z}_n=n^{-1}\sum_{i=1}^nz_i\)</span>, where <span class="math inline">\(z_i\)</span>, <span class="math inline">\(i=1,\dots,n\)</span>, are (scalar, vector, or matrix-valued) . Remember: the sample mean <span class="math inline">\(\bar{z}_n\)</span> is an estimator of the deterministic population mean <span class="math inline">\(\mu\)</span>.</p>
<p>Weak LLNs, strong LLNs, and CLTs tell us conditions under which arithmetic means <span class="math inline">\(\bar{z}_n=n^{-1}\sum_{i=1}^nz_i\)</span> converge:
<span class="math display">\[\begin{eqnarray*}
  \bar{z}_n&amp;\toprob&amp;\mu\quad\text{(weak LLN)}\\
  \bar{z}_n&amp;\toas&amp;\mu\quad\text{(strong LLN)}\\
  \sqrt{n}(\bar{z}_n-\mu)&amp;\todistr&amp;N(0,\sigma^2)\quad\text{(CLT)}
\end{eqnarray*}\]</span></p>
<p>In the following we introduce the most well-known versions of the weak, the strong LLN, and the CLT.</p>
<p>Proof can be found, for instance, here: </p>
<p>Proof can be found, e.g., in , Rao (1973), pp. 112-114.</p>
<p>The weak and the strong LLN for random vectors follow from requiring element-by-element convergence.</p>
<p>Proof can be found, e.g., in , van der Vaart (1998), Theorem 2.17.</p>
<p>The Lindeberg-Levy CLT for <span class="math inline">\(K\)</span>-dimensional random vectors follows from our above discussion on  From this we know that if <span class="math inline">\(\bar{z}_n\in\mathbb{R}^K\)</span> and <span class="math inline">\(\mu\in\mathbb{R}^K\)</span>, then
<span class="math display">\[\sqrt{n}(\bar{z}_n-\mu)\todistr \mathcal{N}(0,\Sigma)\quad\Leftrightarrow\quad \sqrt{n}(\lambda&#39;\bar{z}_n-\lambda&#39;\mu)\todistr \mathcal{N}(0,\lambda&#39;\Sigma\lambda),\]</span>
for any <span class="math inline">\(\lambda\in\mathbb{R}^K\)</span>.</p>
<p>That is, to apply the Lindeberg-Levy CLT (Theorem ) to multivariate (e.g., <span class="math inline">\(K\)</span>-dimensional) stochastic sequences, we need to check whether the univariate stochastic sequence <span class="math inline">\(\{\lambda&#39;z_i\}\)</span> is i.i.d. with <span class="math inline">\(E(\lambda&#39;z_i)=\lambda&#39;\mu\)</span> and <span class="math inline">\(\V(\lambda&#39;z_i)=\lambda&#39;\Sigma\lambda\)</span> for any <span class="math inline">\(\lambda\in\mathbb{R}^K\)</span>. This is the case if the multivariate (<span class="math inline">\(K\)</span>-dimensional) stochastic sequence <span class="math inline">\(\{z_i\}\)</span> is an i.i.d. sequence with <span class="math inline">\(E(z_i)=\mu\)</span> and <span class="math inline">\(\V(z_i)=\Sigma\)</span>.</p>
<p>The LLNs and the CLT are stated with respect to sequences of sample means <span class="math inline">\(\{\bar{z}_n\}\)</span>; i.e., the simplest estimators you probably can think of. We will see, however, that this is all we need in order to analyze also more complicated estimators such as the OLS estimator.</p>
</div>
<div id="estimators-as-a-sequences-of-random-variables" class="section level3" number="6.1.5">
<h3><span class="header-section-number">6.1.5</span> Estimators as a Sequences of Random Variables</h3>
<p>Our concepts above readily apply to general scalar-valued (univariate) or vector-valued (<span class="math inline">\(K\)</span>-dimensional) estimators, say <span class="math inline">\(\hat\theta_n\in\mathbb{R}^K\)</span>, that are computed from i.i.d. random samples.</p>
<!-- \paragraph*{Note.} Under the asymptotic perspective ($n\to\infty$) it's not necessary anymore to condition on $X$ since as $n\to\infty$ the stochastic influence of $X$ on  vanishes  -->
<p>We say that an estimator <span class="math inline">\(\hat\theta_n\)</span> is  if
<span class="math display">\[\hat\theta_n\toprob\theta\quad\text{as}\quad n\to\infty\]</span></p>
<p>The  of an estimator <span class="math inline">\(\hat\theta_n\)</span> of some true parameter <span class="math inline">\(\theta\)</span> is defined as:
<span class="math display">\[\text{ABias}(\hat\theta_n)=\lim_{n\to\infty}E(\hat\theta_n)-\theta\]</span>
If <span class="math inline">\(\text{ABias}(\hat\theta_n)=0\)</span>, then <span class="math inline">\(\hat\theta\)</span> is called an .</p>
<p>A consistent estimator <span class="math inline">\(\hat\theta_n\)</span> is  if
<span class="math display">\[\sqrt{n}(\hat\theta_n-\theta)\todistr \mathcal{N}(0,\Sigma)\quad\text{as}\quad n\to\infty\]</span>
where <span class="math inline">\(\lim_{n\to\infty}\V(\sqrt{n}(\hat\theta_n-\theta))=\lim_{n\to\infty}\V(\sqrt{n}\hat\theta_n)=\Sigma\)</span> as called the asymptotic variance of <span class="math inline">\(\sqrt{n}(\hat\theta_n-\theta)\)</span>.</p>
<p>Consistent estimators <span class="math inline">\(\hat{\theta}_n\toprob\theta\)</span> are called  if
<span class="math display">\[\sqrt{n}(\hat\theta_n-\theta)\todistr z \quad\text{as}\quad n\to\infty\]</span>
If additionally the random vector <span class="math inline">\(z\)</span> is normal distributed, then <span class="math inline">\(\hat\theta_n\)</span> is often called </p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="6-ch:LSINF.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="6.2-asymptotics-under-the-classic-regression-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Script_Econometrics_MSc.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
