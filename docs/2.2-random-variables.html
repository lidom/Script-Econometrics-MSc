<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.2 Random Variables | Econometrics (M.Sc.)</title>
  <meta name="description" content="2.2 Random Variables | Econometrics (M.Sc.)" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="2.2 Random Variables | Econometrics (M.Sc.)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/mylogo.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.2 Random Variables | Econometrics (M.Sc.)" />
  
  
  <meta name="twitter:image" content="/images/mylogo.png" />

<meta name="author" content="Prof. Dr. Dominik Liebl" />


<meta name="date" content="2021-10-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="2.1-probability-theory.html"/>
<link rel="next" href="3-ch:SLR.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="organization-of-the-course.html"><a href="organization-of-the-course.html"><i class="fa fa-check"></i>Organization of the Course</a></li>
<li class="chapter" data-level="" data-path="literature.html"><a href="literature.html"><i class="fa fa-check"></i>Literature</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-introduction-to-r.html"><a href="1-introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-short-glossary.html"><a href="1.1-short-glossary.html"><i class="fa fa-check"></i><b>1.1</b> Short Glossary</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-first-steps.html"><a href="1.2-first-steps.html"><i class="fa fa-check"></i><b>1.2</b> First Steps</a></li>
<li class="chapter" data-level="1.3" data-path="1.3-further-data-objects.html"><a href="1.3-further-data-objects.html"><i class="fa fa-check"></i><b>1.3</b> Further Data Objects</a></li>
<li class="chapter" data-level="1.4" data-path="1.4-simple-regression-analysis-using-r.html"><a href="1.4-simple-regression-analysis-using-r.html"><i class="fa fa-check"></i><b>1.4</b> Simple Regression Analysis using R</a></li>
<li class="chapter" data-level="1.5" data-path="1.5-programming-in-r.html"><a href="1.5-programming-in-r.html"><i class="fa fa-check"></i><b>1.5</b> Programming in R</a></li>
<li class="chapter" data-level="1.6" data-path="1.6-r-packages.html"><a href="1.6-r-packages.html"><i class="fa fa-check"></i><b>1.6</b> R-packages</a></li>
<li class="chapter" data-level="1.7" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html"><i class="fa fa-check"></i><b>1.7</b> Tidyverse</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#tidyverse-plotting-basics"><i class="fa fa-check"></i><b>1.7.1</b> Tidyverse: Plotting Basics</a></li>
<li class="chapter" data-level="1.7.2" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#tidyverse-data-wrangling-basics"><i class="fa fa-check"></i><b>1.7.2</b> Tidyverse: Data Wrangling Basics</a></li>
<li class="chapter" data-level="1.7.3" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#the-pipe-operator"><i class="fa fa-check"></i><b>1.7.3</b> The pipe operator <code>%&gt;%</code></a></li>
<li class="chapter" data-level="1.7.4" data-path="1.7-tidyverse.html"><a href="1.7-tidyverse.html#the-group_by-function"><i class="fa fa-check"></i><b>1.7.4</b> The <code>group_by()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="1.8-further-links.html"><a href="1.8-further-links.html"><i class="fa fa-check"></i><b>1.8</b> Further Links</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="1.8-further-links.html"><a href="1.8-further-links.html#further-r-intros"><i class="fa fa-check"></i><b>1.8.1</b> Further R-Intros</a></li>
<li class="chapter" data-level="1.8.2" data-path="1.8-further-links.html"><a href="1.8-further-links.html#version-control-gitgithub"><i class="fa fa-check"></i><b>1.8.2</b> Version Control (Git/GitHub)</a></li>
<li class="chapter" data-level="1.8.3" data-path="1.8-further-links.html"><a href="1.8-further-links.html#r-ladies"><i class="fa fa-check"></i><b>1.8.3</b> R-Ladies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-review-probability-and-statistics.html"><a href="2-review-probability-and-statistics.html"><i class="fa fa-check"></i><b>2</b> Review: Probability and Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html"><i class="fa fa-check"></i><b>2.1</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>2.1.1</b> Sample Spaces and Events</a></li>
<li class="chapter" data-level="2.1.2" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#probability"><i class="fa fa-check"></i><b>2.1.2</b> Probability</a></li>
<li class="chapter" data-level="2.1.3" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#independent-events"><i class="fa fa-check"></i><b>2.1.3</b> Independent Events</a></li>
<li class="chapter" data-level="2.1.4" data-path="2.1-probability-theory.html"><a href="2.1-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>2.1.4</b> Conditional Probability</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html"><i class="fa fa-check"></i><b>2.2</b> Random Variables</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#univariate-distribution-and-probability-functions"><i class="fa fa-check"></i><b>2.2.1</b> Univariate Distribution and Probability Functions</a></li>
<li class="chapter" data-level="2.2.2" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#multivariate-distribution-and-probability-functions"><i class="fa fa-check"></i><b>2.2.2</b> Multivariate Distribution and Probability Functions</a></li>
<li class="chapter" data-level="2.2.3" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#means-and-moments"><i class="fa fa-check"></i><b>2.2.3</b> Means and Moments</a></li>
<li class="chapter" data-level="2.2.4" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#unconditional-means"><i class="fa fa-check"></i><b>2.2.4</b> Unconditional Means</a></li>
<li class="chapter" data-level="2.2.5" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#conditional-means"><i class="fa fa-check"></i><b>2.2.5</b> Conditional Means</a></li>
<li class="chapter" data-level="2.2.6" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#means-of-transformed-random-variables-and-moments"><i class="fa fa-check"></i><b>2.2.6</b> Means of Transformed Random Variables and Moments</a></li>
<li class="chapter" data-level="2.2.7" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>2.2.7</b> Independent Random Variables</a></li>
<li class="chapter" data-level="2.2.8" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#i.i.d.-samples"><i class="fa fa-check"></i><b>2.2.8</b> I.I.D. Samples</a></li>
<li class="chapter" data-level="2.2.9" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#some-important-discrete-random-variables"><i class="fa fa-check"></i><b>2.2.9</b> Some Important Discrete Random Variables</a></li>
<li class="chapter" data-level="2.2.10" data-path="2.2-random-variables.html"><a href="2.2-random-variables.html#some-important-continuous-random-variables"><i class="fa fa-check"></i><b>2.2.10</b> Some Important Continuous Random Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-ch:SLR.html"><a href="3-ch:SLR.html"><i class="fa fa-check"></i><b>3</b> Review: Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html"><i class="fa fa-check"></i><b>3.1</b> The Simple Linear Regression Model</a>
<ul>
<li class="chapter" data-level="" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#the-data-generating-process"><i class="fa fa-check"></i>The Data-Generating Process</a></li>
<li class="chapter" data-level="3.1.1" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#assumptions-about-the-error-term"><i class="fa fa-check"></i><b>3.1.1</b> Assumptions About the Error Term</a></li>
<li class="chapter" data-level="3.1.2" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#the-population-regression-line"><i class="fa fa-check"></i><b>3.1.2</b> The Population Regression Line</a></li>
<li class="chapter" data-level="3.1.3" data-path="3.1-the-simple-linear-regression-model.html"><a href="3.1-the-simple-linear-regression-model.html#terminology-estimates-versus-estimators"><i class="fa fa-check"></i><b>3.1.3</b> Terminology: Estimates versus Estimators</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html"><i class="fa fa-check"></i><b>3.2</b> Ordinary Least Squares Estimation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html#terminology-sample-regression-line-prediction-and-residuals"><i class="fa fa-check"></i><b>3.2.1</b> Terminology: Sample Regression Line, Prediction and Residuals</a></li>
<li class="chapter" data-level="3.2.2" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html#sec:SLROLS"><i class="fa fa-check"></i><b>3.2.2</b> Deriving the Expression of the OLS Estimator</a></li>
<li class="chapter" data-level="3.2.3" data-path="3.2-ordinary-least-squares-estimation.html"><a href="3.2-ordinary-least-squares-estimation.html#behavior-of-the-ols-estimates-for-resampled-data-conditionally-on-x_i"><i class="fa fa-check"></i><b>3.2.3</b> Behavior of the OLS Estimates for Resampled Data (conditionally on <span class="math inline">\(X_i\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html"><i class="fa fa-check"></i><b>3.3</b> Properties of the OLS Estimator</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html#mean-and-bias-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.1</b> Mean and Bias of the OLS Estimator</a></li>
<li class="chapter" data-level="3.3.2" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html#variance-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.2</b> Variance of the OLS Estimator</a></li>
<li class="chapter" data-level="3.3.3" data-path="3.3-properties-of-the-ols-estimator.html"><a href="3.3-properties-of-the-ols-estimator.html#consistency-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.3</b> Consistency of the OLS Estimator</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-ch:MLR.html"><a href="4-ch:MLR.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-assumptions.html"><a href="4.1-assumptions.html"><i class="fa fa-check"></i><b>4.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="4.1-assumptions.html"><a href="4.1-assumptions.html#some-implications-of-the-exogeneity-assumption"><i class="fa fa-check"></i><b>4.1.1</b> Some Implications of the Exogeneity Assumption</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4.2-deriving-the-expression-of-the-ols-estimator.html"><a href="4.2-deriving-the-expression-of-the-ols-estimator.html"><i class="fa fa-check"></i><b>4.2</b> Deriving the Expression of the OLS Estimator</a></li>
<li class="chapter" data-level="4.3" data-path="4.3-some-quantities-of-interest.html"><a href="4.3-some-quantities-of-interest.html"><i class="fa fa-check"></i><b>4.3</b> Some Quantities of Interest</a></li>
<li class="chapter" data-level="4.4" data-path="4.4-method-of-moments-estimator.html"><a href="4.4-method-of-moments-estimator.html"><i class="fa fa-check"></i><b>4.4</b> Method of Moments Estimator</a></li>
<li class="chapter" data-level="4.5" data-path="4.5-unbiasedness-of-hatbetax.html"><a href="4.5-unbiasedness-of-hatbetax.html"><i class="fa fa-check"></i><b>4.5</b> Unbiasedness of <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="4.6" data-path="4.6-ch:VarEstBeta.html"><a href="4.6-ch:VarEstBeta.html"><i class="fa fa-check"></i><b>4.6</b> Variance of <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="4.7" data-path="4.7-the-gauss-markov-theorem.html"><a href="4.7-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>4.7</b> The Gauss-Markov Theorem</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-ch:SSINF.html"><a href="5-ch:SSINF.html"><i class="fa fa-check"></i><b>5</b> Small Sample Inference</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5.1-ch:testmultp.html"><a href="5.1-ch:testmultp.html"><i class="fa fa-check"></i><b>5.1</b> Hypothesis Tests about Multiple Parameters</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="5.1-ch:testmultp.html"><a href="5.1-ch:testmultp.html#the-test-statistic-and-its-null-distribution"><i class="fa fa-check"></i><b>5.1.1</b> The Test Statistic and its Null Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5.2-ch:testingsinglep.html"><a href="5.2-ch:testingsinglep.html"><i class="fa fa-check"></i><b>5.2</b> Tests about One Parameter</a></li>
<li class="chapter" data-level="5.3" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html"><i class="fa fa-check"></i><b>5.3</b> Testtheory</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html#significance-level"><i class="fa fa-check"></i><b>5.3.1</b> Significance Level</a></li>
<li class="chapter" data-level="5.3.2" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html#critical-value-for-the-f-test"><i class="fa fa-check"></i><b>5.3.2</b> Critical Value for the <span class="math inline">\(F\)</span>-Test</a></li>
<li class="chapter" data-level="5.3.3" data-path="5.3-testtheory.html"><a href="5.3-testtheory.html#critical-values-for-the-t-test"><i class="fa fa-check"></i><b>5.3.3</b> Critical Value(s) for the <span class="math inline">\(t\)</span>-Test</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5.4-type-ii-error-and-power.html"><a href="5.4-type-ii-error-and-power.html"><i class="fa fa-check"></i><b>5.4</b> Type II Error and Power</a></li>
<li class="chapter" data-level="5.5" data-path="5.5-p-value.html"><a href="5.5-p-value.html"><i class="fa fa-check"></i><b>5.5</b> <span class="math inline">\(p\)</span>-Value</a></li>
<li class="chapter" data-level="5.6" data-path="5.6-CIsmallsample.html"><a href="5.6-CIsmallsample.html"><i class="fa fa-check"></i><b>5.6</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.7" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html"><i class="fa fa-check"></i><b>5.7</b> Practice: Small Sample Inference</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html#normally-distributed-hatbetax"><i class="fa fa-check"></i><b>5.7.1</b> Normally Distributed <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="5.7.2" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html#testing-multiple-parameters"><i class="fa fa-check"></i><b>5.7.2</b> Testing Multiple Parameters</a></li>
<li class="chapter" data-level="5.7.3" data-path="5.7-PSSI.html"><a href="5.7-PSSI.html#dualty-of-confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>5.7.3</b> Dualty of Confidence Intervals and Hypothesis Tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-ch:LSINF.html"><a href="6-ch:LSINF.html"><i class="fa fa-check"></i><b>6</b> Large Sample Inference</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html"><i class="fa fa-check"></i><b>6.1</b> Tools for Asymptotic Statistics</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#modes-of-convergence"><i class="fa fa-check"></i><b>6.1.1</b> Modes of Convergence</a></li>
<li class="chapter" data-level="" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#four-important-modes-of-convergence"><i class="fa fa-check"></i>Four Important Modes of Convergence</a></li>
<li class="chapter" data-level="" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#relations-among-modes-of-convergence"><i class="fa fa-check"></i>Relations among Modes of Convergence</a></li>
<li class="chapter" data-level="6.1.2" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#continuous-mapping-theorem-cmt"><i class="fa fa-check"></i><b>6.1.2</b> Continuous Mapping Theorem (CMT)</a></li>
<li class="chapter" data-level="6.1.3" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#slutsky-theorem"><i class="fa fa-check"></i><b>6.1.3</b> Slutsky Theorem</a></li>
<li class="chapter" data-level="6.1.4" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#law-of-large-numbers-lln-and-central-limit-theorem-clt"><i class="fa fa-check"></i><b>6.1.4</b> Law of Large Numbers (LLN) and Central Limit Theorem (CLT)</a></li>
<li class="chapter" data-level="6.1.5" data-path="6.1-tools-for-asymptotic-statistics.html"><a href="6.1-tools-for-asymptotic-statistics.html#estimators-as-a-sequences-of-random-variables"><i class="fa fa-check"></i><b>6.1.5</b> Estimators as a Sequences of Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6.2-asymptotics-under-the-classic-regression-model.html"><a href="6.2-asymptotics-under-the-classic-regression-model.html"><i class="fa fa-check"></i><b>6.2</b> Asymptotics under the Classic Regression Model</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="6.2-asymptotics-under-the-classic-regression-model.html"><a href="6.2-asymptotics-under-the-classic-regression-model.html#the-case-of-heteroscedasticity"><i class="fa fa-check"></i><b>6.2.1</b> The Case of Heteroscedasticity</a></li>
<li class="chapter" data-level="6.2.2" data-path="6.2-asymptotics-under-the-classic-regression-model.html"><a href="6.2-asymptotics-under-the-classic-regression-model.html#hypothesis-testing-and-confidence-intervals"><i class="fa fa-check"></i><b>6.2.2</b> Hypothesis Testing and Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6.3-robust-confidence-intervals.html"><a href="6.3-robust-confidence-intervals.html"><i class="fa fa-check"></i><b>6.3</b> Robust Confidence Intervals</a></li>
<li class="chapter" data-level="6.4" data-path="6.4-practice-large-sample-inference.html"><a href="6.4-practice-large-sample-inference.html"><i class="fa fa-check"></i><b>6.4</b> Practice: Large Sample Inference</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="6.4-practice-large-sample-inference.html"><a href="6.4-practice-large-sample-inference.html#normally-distributed-hatbeta-for-ntoinfty"><i class="fa fa-check"></i><b>6.4.1</b> Normally Distributed <span class="math inline">\(\hat\beta\)</span> for <span class="math inline">\(n\to\infty\)</span></a></li>
<li class="chapter" data-level="6.4.2" data-path="6.4-practice-large-sample-inference.html"><a href="6.4-practice-large-sample-inference.html#testing-multiple-and-single-parameters"><i class="fa fa-check"></i><b>6.4.2</b> Testing Multiple and Single Parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-maximum-likelihood.html"><a href="7-maximum-likelihood.html"><i class="fa fa-check"></i><b>7</b> Maximum Likelihood</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7.1-likelihood-principle.html"><a href="7.1-likelihood-principle.html"><i class="fa fa-check"></i><b>7.1</b> Likelihood Principle</a></li>
<li class="chapter" data-level="7.2" data-path="7.2-properties-of-maximum-likelihood-estimators.html"><a href="7.2-properties-of-maximum-likelihood-estimators.html"><i class="fa fa-check"></i><b>7.2</b> Properties of Maximum Likelihood Estimators</a></li>
<li class="chapter" data-level="7.3" data-path="7.3-the-log-likelihood-function.html"><a href="7.3-the-log-likelihood-function.html"><i class="fa fa-check"></i><b>7.3</b> The (Log-)Likelihood Function</a></li>
<li class="chapter" data-level="7.4" data-path="7.4-optimization-non-analytical-solutions.html"><a href="7.4-optimization-non-analytical-solutions.html"><i class="fa fa-check"></i><b>7.4</b> Optimization: Non-Analytical Solutions</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="7.4-optimization-non-analytical-solutions.html"><a href="7.4-optimization-non-analytical-solutions.html#newton-raphson-optimization"><i class="fa fa-check"></i><b>7.4.1</b> Newton-Raphson Optimization</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="7.5-ols-estimation-as-ml-estimation.html"><a href="7.5-ols-estimation-as-ml-estimation.html"><i class="fa fa-check"></i><b>7.5</b> OLS-Estimation as ML-Estimation</a></li>
<li class="chapter" data-level="7.6" data-path="7.6-variance-of-ml-estimators-hatbeta_ml-and-s2_ml.html"><a href="7.6-variance-of-ml-estimators-hatbeta_ml-and-s2_ml.html"><i class="fa fa-check"></i><b>7.6</b> Variance of ML-Estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}\)</span></a></li>
<li class="chapter" data-level="7.7" data-path="7.7-consistency-of-hatbeta_ml-and-s_ml2.html"><a href="7.7-consistency-of-hatbeta_ml-and-s_ml2.html"><i class="fa fa-check"></i><b>7.7</b> Consistency of <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s_{ML}^2\)</span></a></li>
<li class="chapter" data-level="7.8" data-path="7.8-asymptotic-theory-of-maximum-likelihood-estimators.html"><a href="7.8-asymptotic-theory-of-maximum-likelihood-estimators.html"><i class="fa fa-check"></i><b>7.8</b> Asymptotic Theory of Maximum-Likelihood Estimators</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-ivr.html"><a href="8-ivr.html"><i class="fa fa-check"></i><b>8</b> Instrumental Variables Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8.1-TIVEWASRAASI.html"><a href="8.1-TIVEWASRAASI.html"><i class="fa fa-check"></i><b>8.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="8.1-TIVEWASRAASI.html"><a href="8.1-TIVEWASRAASI.html#the-two-stage-least-squares-estimator"><i class="fa fa-check"></i><b>8.1.1</b> The Two-Stage Least Squares Estimator</a></li>
<li class="chapter" data-level="8.1.2" data-path="8.1-TIVEWASRAASI.html"><a href="8.1-TIVEWASRAASI.html#application-demand-for-cigarettes-12"><i class="fa fa-check"></i><b>8.1.2</b> Application: Demand For Cigarettes (1/2)</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8.2-TGIVRM.html"><a href="8.2-TGIVRM.html"><i class="fa fa-check"></i><b>8.2</b> The General IV Regression Model</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8.2-TGIVRM.html"><a href="8.2-TGIVRM.html#application-demand-for-cigarettes-22"><i class="fa fa-check"></i><b>8.2.1</b> Application: Demand for Cigarettes (2/2)</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8.3-civ.html"><a href="8.3-civ.html"><i class="fa fa-check"></i><b>8.3</b> Checking Instrument Validity</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="8.3-civ.html"><a href="8.3-civ.html#instrument-relevance"><i class="fa fa-check"></i><b>8.3.1</b> Instrument Relevance</a></li>
<li class="chapter" data-level="8.3.2" data-path="8.3-civ.html"><a href="8.3-civ.html#instrument-validity"><i class="fa fa-check"></i><b>8.3.2</b> Instrument Validity</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8.4-attdfc.html"><a href="8.4-attdfc.html"><i class="fa fa-check"></i><b>8.4</b> Application to the Demand for Cigarettes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Econometrics (M.Sc.)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-variables" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Random Variables</h2>
<p>Statistics and econometrics are concerned with data. How do we link sample spaces, events and probabilities to data? The link is provided by the concept of a <strong>random variable</strong>. A real-valued  is a mapping <span class="math inline">\(X: \Omega \rightarrow \mathbb{R}\)</span> that assigns a real number <span class="math inline">\(X(\omega)\in\mathbb{R}\)</span> to each outcome <span class="math inline">\(\omega\)</span>.</p>
<p>At a certain point in most statistics/econometrics courses, the sample space, <span class="math inline">\(\Omega\)</span>, is rarely mentioned and we work directly with random variables. But you should keep in mind that the sample space is really there, lurking in the background.</p>
<p>Flip a coin ten times. Let <span class="math inline">\(X(\omega)\)</span> be the number of heads in the sequence <span class="math inline">\(\omega.\)</span> For example, if <span class="math inline">\(\omega=\text{HHTHHTHHTT}\)</span> then <span class="math inline">\(X(\omega)=6\)</span>.</p>
<p>Let <span class="math inline">\(\Omega=\left\{(x, y)|x^{2}+y^{2} \leq 1\right\}\)</span> be the unit disc. Consider drawing a point  from <span class="math inline">\(\Omega\)</span>. A typical outcome is then of the form <span class="math inline">\(\omega=(x, y) .\)</span> Some examples of random variables are <span class="math inline">\(X(\omega)=x, Y(\omega)=y, Z(\omega)=x+y, W(\omega)=\sqrt{x^{2}+y^{2}}\)</span>.</p>
<p>Given a real-valued random variable <span class="math inline">\(X\in\mathbb{R}\)</span> and a subset <span class="math inline">\(A\)</span> of the real line (<span class="math inline">\(A\subset\mathbb{R}\)</span>), define <span class="math inline">\(X^{-1}(A)=\{\omega \in \Omega|X(\omega) \in A\}\)</span>. This allows us to link the probabilities on the random variable <span class="math inline">\(X\)</span>, i.e. the probabilities we are usually working with, to the underlying probabilities on the events, i.e. the probabilities lurking in the background.</p>
Flip a coin twice and let <span class="math inline">\(X\)</span> be the number of heads. Then, <span class="math inline">\(P_X(X=0)=P(\{T T\})=1 / 4\)</span>, <span class="math inline">\(P_X(X=1)=P(\{H T, T H\})=1 / 2\)</span> and <span class="math inline">\(P_X(X=2)=P(\{H H\})=1 / 4\)</span>. Thus, the events and their associated probability distribution, <span class="math inline">\(P\)</span>, and the random variable <span class="math inline">\(X\)</span> and its distribution, <span class="math inline">\(P_X\)</span>, can be summarized as follows:
<!-- Try generalizing this to $n$ flips. -->
<p>Here, <span class="math inline">\(P_{X}\)</span> is not the same probability function as <span class="math inline">\(P\)</span> because <span class="math inline">\(P\)</span> maps from the sample space events, <span class="math inline">\(\omega\)</span>, to <span class="math inline">\([0,1]\)</span>, while <span class="math inline">\(P_X\)</span> maps from the random-variable events, <span class="math inline">\(X(\omega)\)</span>, to <span class="math inline">\([0,1]\)</span>. We will typically forget about the sample space <span class="math inline">\(\Omega\)</span> and just think of the random variable as an experiment with real-valued (possible multivariate) outcomes. We will therefore write <span class="math inline">\(P\left(X=x_{k}\right)\)</span> instead of <span class="math inline">\(P_{X}\left(X=x_{k}\right)\)</span> to simplify the notation.</p>
<div id="univariate-distribution-and-probability-functions" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Univariate Distribution and Probability Functions</h3>
<div id="cumulative-distribution-function" class="section level4" number="2.2.1.1">
<h4><span class="header-section-number">2.2.1.1</span> Cumulative Distribution Function</h4>
<p>The 
<span class="math display">\[F_{X}: \mathbb{R} \rightarrow [0,1]\]</span>
of a real-valued random variable <span class="math inline">\(X\in\mathbb{R}\)</span> is defined by
<span class="math display">\[
F_{X}(x)=\mathbb{P}(X \leq x).
\]</span></p>
<p>You might wonder why we bother to define the cdf. The reason is that it effectively contains all the information
about the random variable. Indeed, let <span class="math inline">\(X\in\mathbb{R}\)</span> have cdf <span class="math inline">\(F\)</span> and let <span class="math inline">\(Y\in\mathbb{R}\)</span> have cdf <span class="math inline">\(G\)</span>. If <span class="math inline">\(F(x)=G(x)\)</span> for all <span class="math inline">\(x\in\mathbb{R}\)</span> then <span class="math inline">\(P(X \in A)=P(Y \in A)\)</span> for all <span class="math inline">\(A\subset\mathbb{R}\)</span>. In order to denote that two random variables, here <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, have the same distribution, one can write shortly <span class="math inline">\(X\overset{d}{=}Y\)</span>.</p>
<p>Equality in distribution, <span class="math inline">\(X\overset{d}{=}Y\)</span>, does generally  mean equality in realizations, that is <span class="math inline">\(X\overset{d}{=}Y \not\Rightarrow X(\omega)=Y(\omega)\)</span> for all <span class="math inline">\(\omega\in\Omega\)</span>.</p>
<p>A function <span class="math inline">\(F\)</span> mapping the real line to <span class="math inline">\([0,1]\)</span>, short <span class="math inline">\(F:\mathbb{R}\to[0,1]\)</span>, is called a cdf for some probability measure <span class="math inline">\(P\)</span> if and only if it satisfies the following three properties:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(F\)</span> is non-decreasing i.e. <span class="math inline">\(x_{1}&lt;x_{2}\)</span> implies that <span class="math inline">\(F\left(x_{1}\right) \leq F\left(x_{2}\right)\)</span>.</p></li>
<li><p><span class="math inline">\(F\)</span> is normalized: <span class="math inline">\(\lim_{x\rightarrow-\infty} F(x)=0\)</span> and <span class="math inline">\(\lim_{x \rightarrow \infty} F(x)=1\)</span></p></li>
<li><p><span class="math inline">\(F\)</span> is right-continuous, i. e. <span class="math inline">\(F(x)=F\left(x^{+}\right)\)</span> for all <span class="math inline">\(x\)</span>, where
<span class="math display">\[
  F\left(x^{+}\right)=\lim_{y\to x, y&gt;x} F(y).
  \]</span></p></li>
</ol>
<p>Alternatively to cumulative distribution functions one can use  in order to describe the probability law of  random variables and  in order to describe the probability law of  random variables.</p>
</div>
<div id="probability-functions-for-discrete-random-variables." class="section level4" number="2.2.1.2">
<h4><span class="header-section-number">2.2.1.2</span> Probability Functions for Discrete Random Variables.</h4>
<p>A random variable <span class="math inline">\(X\)</span> is  if it takes only countably many values
<span class="math display">\[
X\in\{x_{1}, x_{2}, \ldots\}.
\]</span>
For instance, <span class="math inline">\(X\in\{1,2,3\}\)</span> or <span class="math inline">\(X\in\{2,4,6,\dots\}\)</span> or <span class="math inline">\(X\in\mathbb{Z}\)</span> or <span class="math inline">\(X\in\mathbb{Q}\)</span>.</p>
<p>We define the  or  for <span class="math inline">\(X\)</span> by
<span class="math display">\[
f_{X}(x)=\mathbb{P}(X=x)\quad\text{for all}\quad x\in\{x_1,x_2,\dots\}
\]</span></p>
</div>
<div id="density-functions-for-continuous-random-variables." class="section level4" number="2.2.1.3">
<h4><span class="header-section-number">2.2.1.3</span> Density Functions for Continuous Random Variables.</h4>
A random variable <span class="math inline">\(X\)</span> is  if there exists a function <span class="math inline">\(f_{X}\)</span> such that
<p>The function <span class="math inline">\(f_{X}\)</span> is called the  or short . We have that
<span class="math display">\[
F_{X}(x)=\int_{-\infty}^{x} f_{X}(t) dt\quad\text{and}\quad f_{X}(x)=F_{X}^{\prime}(x)
\]</span>
at all points <span class="math inline">\(x\)</span> at which <span class="math inline">\(F_{X}\)</span> is differentiable.</p>
</div>
</div>
<div id="multivariate-distribution-and-probability-functions" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Multivariate Distribution and Probability Functions</h3>
<p>A <span class="math inline">\(d\)</span>-dimensional random vector is a column-vector <span class="math inline">\(X=(X_1,\dots,X_d)^\prime\)</span>, where each element is a univariate random variable.</p>
<div id="multidimensional-distribution-function" class="section level4" number="2.2.2.1">
<h4><span class="header-section-number">2.2.2.1</span> Multidimensional Distribution Function</h4>
<p>The  <span class="math inline">\(F\)</span> is given by
<span class="math display">\[F(a_1,\dots,a_d)=P(X_1\le a_1,\dots,X_d\le a_d).\]</span></p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="2.2-random-variables.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Install the package if not installed yet</span></span>
<span id="cb61-2"><a href="2.2-random-variables.html#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;mnormt&quot;)</span></span>
<span id="cb61-3"><a href="2.2-random-variables.html#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="2.2-random-variables.html#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mnormt)</span>
<span id="cb61-5"><a href="2.2-random-variables.html#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="2.2-random-variables.html#cb61-6" aria-hidden="true" tabindex="-1"></a>x     <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="fl">0.25</span>) </span>
<span id="cb61-7"><a href="2.2-random-variables.html#cb61-7" aria-hidden="true" tabindex="-1"></a>y     <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="fl">0.25</span>)</span>
<span id="cb61-8"><a href="2.2-random-variables.html#cb61-8" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb61-9"><a href="2.2-random-variables.html#cb61-9" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb61-10"><a href="2.2-random-variables.html#cb61-10" aria-hidden="true" tabindex="-1"></a>f     <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y) <span class="fu">pmnorm</span>(<span class="fu">cbind</span>(x, y), mu, sigma)</span>
<span id="cb61-11"><a href="2.2-random-variables.html#cb61-11" aria-hidden="true" tabindex="-1"></a>z     <span class="ot">&lt;-</span> <span class="fu">outer</span>(x, y, f)</span>
<span id="cb61-12"><a href="2.2-random-variables.html#cb61-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-13"><a href="2.2-random-variables.html#cb61-13" aria-hidden="true" tabindex="-1"></a><span class="fu">persp</span>(x, y, z, <span class="at">theta =</span> <span class="sc">-</span><span class="dv">30</span>, <span class="at">phi =</span> <span class="dv">25</span>, </span>
<span id="cb61-14"><a href="2.2-random-variables.html#cb61-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">shade =</span> <span class="fl">0.75</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">expand =</span> <span class="fl">0.5</span>, <span class="at">r =</span> <span class="dv">2</span>, </span>
<span id="cb61-15"><a href="2.2-random-variables.html#cb61-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">ltheta =</span> <span class="dv">25</span>, <span class="at">ticktype =</span> <span class="st">&quot;detailed&quot;</span>)</span></code></pre></div>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-36-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="multidimensional-probability-function" class="section level4" number="2.2.2.2">
<h4><span class="header-section-number">2.2.2.2</span> Multidimensional Probability Function</h4>
<p><span class="math inline">\(X\)</span> takes only countably many (i.e. discrete) values <span class="math inline">\(\mathbf{x}_1,\mathbf{x}_2,\dots\in\mathbb{R}^d\)</span> and has a  <span class="math inline">\(p(\mathbf{x}_i)=P(X=\mathbf{x}_i)\)</span> for <span class="math inline">\(i=1,2,\dots\)</span>. That is,
<span class="math display">\[\begin{align*}
P(X\in [a_1,b_1]\times\dots\times [a_d,b_d])=
\sum_{\mathbf{x}_i\in [a_1,b_1]\times\dots\times [a_d,b_d]}p(\mathbf{x}_i).
\end{align*}\]</span></p>
</div>
<div id="multidimensional-density-function" class="section level4" number="2.2.2.3">
<h4><span class="header-section-number">2.2.2.3</span> Multidimensional Density Function</h4>
<span class="math inline">\(X\)</span> takes values in <span class="math inline">\(\mathbb{R}^d\)</span> and has a  <span class="math inline">\(f(x_1,\dots,x_d)\)</span>. That is,
<span class="math display">\[\begin{align*}
P(X\in [a_1,b_1]\times\dots\times [a_d,b_d])=\int\limits_{a_d}^{b_d}\dots \int\limits _{a_1}^{b_1}f(x_1,\dots,x_d)dx_1\dots dx_d.
\end{align*}\]</span>
In the following we focus only on continuous random vectors – the discrete cases are treated analogously. Properties of  functions:
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="2.2-random-variables.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Load the package</span></span>
<span id="cb62-2"><a href="2.2-random-variables.html#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mnormt)</span>
<span id="cb62-3"><a href="2.2-random-variables.html#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="2.2-random-variables.html#cb62-4" aria-hidden="true" tabindex="-1"></a>x     <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="fl">0.25</span>) </span>
<span id="cb62-5"><a href="2.2-random-variables.html#cb62-5" aria-hidden="true" tabindex="-1"></a>y     <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="fl">0.25</span>)</span>
<span id="cb62-6"><a href="2.2-random-variables.html#cb62-6" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb62-7"><a href="2.2-random-variables.html#cb62-7" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb62-8"><a href="2.2-random-variables.html#cb62-8" aria-hidden="true" tabindex="-1"></a>f     <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y) <span class="fu">dmnorm</span>(<span class="fu">cbind</span>(x, y), mu, sigma)</span>
<span id="cb62-9"><a href="2.2-random-variables.html#cb62-9" aria-hidden="true" tabindex="-1"></a>z     <span class="ot">&lt;-</span> <span class="fu">outer</span>(x, y, f)</span>
<span id="cb62-10"><a href="2.2-random-variables.html#cb62-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-11"><a href="2.2-random-variables.html#cb62-11" aria-hidden="true" tabindex="-1"></a><span class="fu">persp</span>(x, y, z, <span class="at">theta =</span> <span class="sc">-</span><span class="dv">30</span>, <span class="at">phi =</span> <span class="dv">25</span>, </span>
<span id="cb62-12"><a href="2.2-random-variables.html#cb62-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">shade =</span> <span class="fl">0.75</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">expand =</span> <span class="fl">0.5</span>, <span class="at">r =</span> <span class="dv">2</span>, </span>
<span id="cb62-13"><a href="2.2-random-variables.html#cb62-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">ltheta =</span> <span class="dv">25</span>, <span class="at">ticktype =</span> <span class="st">&quot;detailed&quot;</span>)</span></code></pre></div>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-37-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="marginal-distribution-and-density-functions" class="section level4" number="2.2.2.4">
<h4><span class="header-section-number">2.2.2.4</span> Marginal Distribution and Density Functions</h4>
Each random element, <span class="math inline">\(X_j\)</span>, with <span class="math inline">\(j=1,\dots,d\)</span>, of the random vector <span class="math inline">\(X\)</span> has its own  <span class="math inline">\(F_j\)</span>. This is just the univariate distribution of <span class="math inline">\(X_j\)</span> when ignoring all other random variables in <span class="math inline">\(X\)</span>. Formally we have:
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-38-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="conditional-distributions" class="section level4" number="2.2.2.5">
<h4><span class="header-section-number">2.2.2.5</span> Conditional Distributions</h4>
<p>Often, we are interested in the  of <span class="math inline">\(X_j\)</span> given certain values of all other random variables<br />
<span class="math display">\[X_1=x_1,\ldots, X_{j-1}=x_{j-1}, X_{j+1}=x_{j+1},\ldots,X_d=x_d.\]</span>
That is, the distribution of <span class="math inline">\(X_j\)</span> when fixing the values of<br />
<span class="math inline">\(X_1=x_1,\ldots,\)</span> <span class="math inline">\(X_{j-1}=x_{j-1},\)</span> <span class="math inline">\(X_{j+1}=x_{j+1},\ldots, X_d=x_d\)</span>. An important tool is here the  of, for instance, <span class="math inline">\(X_1\)</span> given <span class="math inline">\(X_2=x_2,\ldots,X_d=x_d\)</span>:
<span class="math display">\[
f(x_1\mid x_2,\ldots,x_d)=\frac{f(x_1,x_2,\ldots,x_d)}{f_{X_{2},\ldots,X_{d}}(x_2,\ldots,x_d)},
\]</span>
where <span class="math inline">\(f_{X_{2},\ldots,X_{d}}\)</span> denotes the joint density of <span class="math inline">\(X_2,\ldots,X_d\)</span>.</p>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-39-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="means-and-moments" class="section level3" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Means and Moments</h3>
</div>
<div id="unconditional-means" class="section level3" number="2.2.4">
<h3><span class="header-section-number">2.2.4</span> Unconditional Means</h3>
<p>The  of <span class="math inline">\(X_1\)</span> is given by
<span class="math display">\[
E(X_1)= \int x f_{X_1}(x)dx.
\]</span>
The unconditional mean of a random vector <span class="math inline">\(X=(X_1,\dots,X_d)&#39;\)</span> is given by the vector of element-wise means
<span class="math display">\[
E(X)=(E(X_1),\dots,E(X_d))&#39;.
\]</span></p>
</div>
<div id="conditional-means" class="section level3" number="2.2.5">
<h3><span class="header-section-number">2.2.5</span> Conditional Means</h3>
<p>Of central importance in  is the . The conditional mean of <span class="math inline">\(X_1\)</span> for given values <span class="math inline">\(X_2=x_2,\ldots,X_d=x_d\)</span>:
<span class="math display">\[\begin{align*}
  m(x_2,\dots,x_d):&amp;=E(X_1|X_2=x_2,\ldots,X_d=x_d)\\
                   &amp;= \int x_1 f(x_1\mid x_2,\ldots,x_d)dx_1,
\end{align*}\]</span><br />
where <span class="math inline">\(m(x_2,\dots,x_d)\)</span> denotes the .</p>
</div>
<div id="means-of-transformed-random-variables-and-moments" class="section level3" number="2.2.6">
<h3><span class="header-section-number">2.2.6</span> Means of Transformed Random Variables and Moments</h3>
The  <span class="math inline">\(r(X)\)</span> is given by
<span class="math display">\[
E(r(X))=\int r(x) f_{X}(x)dx.
\]</span>
Typical transformations are, for instance
<p>where the latter transformation leads to the , i.e. the variance of <span class="math inline">\(X\)</span>, <span class="math inline">\(Var(X)=\int (x - E(X))^2 f_{X}(x)dx\)</span>.</p>
<ul>
<li><p>The k<span class="math inline">\(th\)</span>, <span class="math inline">\(k&gt;0\)</span>, moment is given by
<span class="math display">\[
\mu_{k}=\mathrm{E}\left[X^{k}\right]=\int_{-\infty}^{+\infty}x^{k} f_X(x)d x.
\]</span></p></li>
<li><p>The k<span class="math inline">\(th\)</span>, <span class="math inline">\(k&gt;1\)</span>, central moment is given by
<span class="math display">\[
\mu^c_{k}=\mathrm{E}\left[(X-\mathrm{E}[X])^{k}\right]=\int_{-\infty}^{+\infty}(x-\mu)^{k} f_X(x)d x,
\]</span>
where <span class="math inline">\(\mu=E(X)\)</span>.</p></li>
</ul>
<p>Moments determine the tail of a distribution (but not much else); see . Roughly: The more moments a distribution has the faster converge its tails to zero. Distributions with compact supports (e.g. the uniform distribution <span class="math inline">\(U[a,b]\)</span>) have infinitely many moments. The Normal distribution has also infinitely many moments – even though this distribution has not a compact support since <span class="math inline">\(\phi(x)&gt;0\)</span> for all <span class="math inline">\(x\in\mathbb{R}\)</span>. .</p>
<div id="law-of-total-expectation" class="section level4" number="2.2.6.1">
<h4><span class="header-section-number">2.2.6.1</span> Law of Total Expectation</h4>
<p>As long as we do not fix the values of the conditioning variables, <span class="math inline">\(X_2,\dots,X_d\)</span>, they are random variables. Consequently, the conditional mean is generally itself a random variable
<span class="math display">\[
E(X_1|X_2,\ldots,X_d)=\int x_1 f(x_1\mid X_2,\ldots,X_d)dx_1. 
\]</span>
Note that <span class="math inline">\(f(x_1\mid X_2,\ldots,X_d)\)</span> is just a transformation of the random variables <span class="math inline">\(X_2,\dots,X_d\)</span>. So we can easily compute the unconditional mean <span class="math inline">\(E(X_1)\)</span> by taking the mean of <span class="math inline">\(E(X_1|X_2,\ldots,X_d)\)</span> as following,
<span class="math display">\[\begin{align*}
&amp;E\big({\color{RedViolet}E(X_1|X_2,\ldots,X_d)}\big)=\\
&amp;=\int\dots\int\;{\color{RedViolet}\int x_1 f(x_1\mid x_2,\ldots,x_d)dx_1}\;f_{X_2,\dots,X_d}(x_2,\ldots,x_d)dx_2\dots dx_d\\
&amp;=\int x_1 \left(\int\dots\int f(x_1,{\color{blue}x_2,\ldots,x_d}){\color{blue}dx_2\dots dx_d}\right)dx_1\\
&amp;=\int x_1 f_{X_1}(x_1)dx_1\\
&amp;=E(X_1).
\end{align*}\]</span></p>
<p>The result that <span class="math inline">\(E\big(E(X_1|X_2,\ldots,X_d)\big)=E(X_1)\)</span> is called  or .</p>
</div>
</div>
<div id="independent-random-variables" class="section level3" number="2.2.7">
<h3><span class="header-section-number">2.2.7</span> Independent Random Variables</h3>
<p>Random variables <span class="math inline">\(X_1,\dots,X_d\)</span> are mutually  if for all <span class="math inline">\(x=(x_1,\dots,x_d)^\prime\)</span> it is true that
<span class="math display">\[\begin{align*}
  F(x_1,\dots,x_d)&amp;=F_1(x_1)\cdot F_2(x_2)\cdot\ldots\cdot F_d(x_d)\\
  f(x_1,\dots,x_d)&amp;=f_1(x_1)\cdot f_2(x_2)\cdot\ldots\cdot f_d(x_d)
\end{align*}\]</span></p>
The following holds true:
</div>
<div id="i.i.d.-samples" class="section level3" number="2.2.8">
<h3><span class="header-section-number">2.2.8</span> I.I.D. Samples</h3>
<p>Tradition dictates that the sample size is denoted by the natural number <span class="math inline">\(n\in\{1,2,\dots\}\)</span>. A random sample is a collection <span class="math inline">\(X=(X_{1}, \ldots, X_{n})\)</span> of random variables <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span>. If <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> are all  from each other and if each random variable has the same marginal distribution, we say that the random sample
<span class="math display">\[
X=(X_{1}, \ldots, X_{n})\text{ is \textbf{i.i.d. (independent and identically distributed)}}. 
\]</span></p>
</div>
<div id="some-important-discrete-random-variables" class="section level3" number="2.2.9">
<h3><span class="header-section-number">2.2.9</span> Some Important Discrete Random Variables</h3>
<!-- ### The point mass distribution {-}  -->
<!-- $X$ has a point mass distribution at $a$, written $X \sim \delta_{a},$ if $P(X=a)=1$ in which case -->
<!-- $$ -->
<!-- F(x)=\left\{\begin{array}{ll} -->
<!-- 0 & x<a \\ -->
<!-- 1 & x \geq a -->
<!-- \end{array}\right. -->
<!-- $$ -->
<!-- The probability function is $f(x)=1$ for $x=a$ and $0$ otherwise. -->
<div id="the-discrete-uniform-distribution" class="section level4" number="2.2.9.1">
<h4><span class="header-section-number">2.2.9.1</span> The Discrete Uniform Distribution</h4>
<p>Let <span class="math inline">\(k&gt;1\)</span> be a given integer. Suppose that <span class="math inline">\(X\)</span> has probability mass function given by
<span class="math display">\[
f(x)=\left\{\begin{array}{ll}
1 / k &amp; \text { for } x=1, \ldots, k \\
0 &amp; \text { otherwise. }
\end{array}\right.
\]</span>
We say that <span class="math inline">\(X\)</span> has a uniform distribution on <span class="math inline">\(\{1, \ldots, k\}\)</span>.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="2.2-random-variables.html#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">51</span>)</span>
<span id="cb63-2"><a href="2.2-random-variables.html#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Set the parameter k</span></span>
<span id="cb63-3"><a href="2.2-random-variables.html#cb63-3" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb63-4"><a href="2.2-random-variables.html#cb63-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Draw one realization from the discrete uniform distribution</span></span>
<span id="cb63-5"><a href="2.2-random-variables.html#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>k, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb63-6"><a href="2.2-random-variables.html#cb63-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 7</span></span></code></pre></div>
</div>
<div id="the-bernoulli-distribution" class="section level4" number="2.2.9.2">
<h4><span class="header-section-number">2.2.9.2</span> The Bernoulli Distribution</h4>
<p>Let <span class="math inline">\(X\)</span> represent a possibly unfair coin flip. Then <span class="math inline">\(P(X=1)=p\)</span> and <span class="math inline">\(P(X=0)=1-p\)</span> for some <span class="math inline">\(p \in[0,1]\)</span>. We say that <span class="math inline">\(X\)</span> has a Bernoulli distribution written <span class="math inline">\(X\sim\operatorname{Bernoulli }(p)\)</span>. The probability function is <span class="math inline">\(f(x)=p^{x}(1-p)^{1-x}\)</span> for <span class="math inline">\(x \in\{0,1\}\)</span></p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="2.2-random-variables.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">51</span>)</span>
<span id="cb64-2"><a href="2.2-random-variables.html#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Set the parameter p</span></span>
<span id="cb64-3"><a href="2.2-random-variables.html#cb64-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.25</span></span>
<span id="cb64-4"><a href="2.2-random-variables.html#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Draw n realization from the discrete uniform distribution</span></span>
<span id="cb64-5"><a href="2.2-random-variables.html#cb64-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb64-6"><a href="2.2-random-variables.html#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">size =</span> n, <span class="at">prob =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">-</span>p, p), <span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb64-7"><a href="2.2-random-variables.html#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1 0 0 1 0</span></span>
<span id="cb64-8"><a href="2.2-random-variables.html#cb64-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-9"><a href="2.2-random-variables.html#cb64-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Alternatively:</span></span>
<span id="cb64-10"><a href="2.2-random-variables.html#cb64-10" aria-hidden="true" tabindex="-1"></a><span class="do">## (Bernoulli(p) equals Binomial(1,p))</span></span>
<span id="cb64-11"><a href="2.2-random-variables.html#cb64-11" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="at">n =</span> n, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">prob =</span> p)</span>
<span id="cb64-12"><a href="2.2-random-variables.html#cb64-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1 1 0 1 0</span></span></code></pre></div>
</div>
<div id="the-binomial-distribution" class="section level4" number="2.2.9.3">
<h4><span class="header-section-number">2.2.9.3</span> The Binomial Distribution</h4>
<p>Suppose we have a coin which falls heads with probability <span class="math inline">\(p\)</span> for some <span class="math inline">\(p\in[0,1]\)</span>. Flip the coin <span class="math inline">\(n\)</span> times and let <span class="math inline">\(X\)</span> be the number of heads (or successes). Assume that the tosses are independent. Let <span class="math inline">\(f(x)=P(X=x)\)</span> be the mass function. It can be shown that
<span class="math display">\[
f(x)=\left\{
\begin{array}{ll}
\left(\begin{array}{l}
n \\
x
\end{array}\right) p^{x}(1-p)^{n-x} &amp; \text { for } x=0, \ldots, n \\
0 &amp; \text { otherwise. }
\end{array}\right.
\]</span>
A random variable with this mas function is called a <strong>binomial random variable</strong> and we write <span class="math inline">\(X \sim \operatorname{Binomial}(n, p)\)</span>. If <span class="math inline">\(X_{1} \sim\)</span> Binomial <span class="math inline">\(\left(n_1, p1\right)\)</span> and <span class="math inline">\(X_{2} \sim\)</span> Binomial<span class="math inline">\(\left(n_2, p\right)\)</span> and if <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent, then <span class="math inline">\(X_{1}+X_{2} \sim \operatorname{Binomial}\left(n_1+n_2, p\right)\)</span></p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="2.2-random-variables.html#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">51</span>)</span>
<span id="cb65-2"><a href="2.2-random-variables.html#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Set the parameters n and p</span></span>
<span id="cb65-3"><a href="2.2-random-variables.html#cb65-3" aria-hidden="true" tabindex="-1"></a>size <span class="ot">&lt;-</span>   <span class="dv">10</span> <span class="co"># number of trials</span></span>
<span id="cb65-4"><a href="2.2-random-variables.html#cb65-4" aria-hidden="true" tabindex="-1"></a>p    <span class="ot">&lt;-</span> <span class="fl">0.25</span> <span class="co"># prob of success</span></span>
<span id="cb65-5"><a href="2.2-random-variables.html#cb65-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-6"><a href="2.2-random-variables.html#cb65-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Draw n realization from the binomial distribution:</span></span>
<span id="cb65-7"><a href="2.2-random-variables.html#cb65-7" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb65-8"><a href="2.2-random-variables.html#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="at">n =</span> n, <span class="at">size =</span> size, <span class="at">prob =</span> p)</span>
<span id="cb65-9"><a href="2.2-random-variables.html#cb65-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 4 1 2 6 1</span></span></code></pre></div>
</div>
</div>
<div id="some-important-continuous-random-variables" class="section level3" number="2.2.10">
<h3><span class="header-section-number">2.2.10</span> Some Important Continuous Random Variables</h3>
<div id="the-uniform-distribution" class="section level4" number="2.2.10.1">
<h4><span class="header-section-number">2.2.10.1</span> The Uniform Distribution</h4>
<p><span class="math inline">\(X\)</span> has a <span class="math inline">\(\operatorname{Uniform}(a, b)\)</span> distribution, written <span class="math inline">\(X\sim \operatorname{Uniform}(a, b),\)</span> if
<span class="math display">\[
f(x)=\left\{\begin{array}{ll}
\frac{1}{b-a} &amp; \text { for } x \in[a, b] \\
0 &amp; \text { otherwise }
\end{array}\right.
\]</span>
where <span class="math inline">\(a&lt;b\)</span>. The distribution function is
<span class="math display">\[
F(x)=\left\{\begin{array}{ll}
0 &amp; x&lt;a \\
\frac{x-a}{b-a} &amp; x \in[a, b] \\
1 &amp; x&gt;b
\end{array}\right.
\]</span></p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="2.2-random-variables.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Drawing from the uniform distribution:</span></span>
<span id="cb66-2"><a href="2.2-random-variables.html#cb66-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb66-3"><a href="2.2-random-variables.html#cb66-3" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb66-4"><a href="2.2-random-variables.html#cb66-4" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb66-5"><a href="2.2-random-variables.html#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="fu">runif</span>(<span class="at">n =</span> n, <span class="at">min =</span> a, <span class="at">max =</span> b)</span>
<span id="cb66-6"><a href="2.2-random-variables.html#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.83442365 0.75138318 0.40601047 0.97101998 0.11233151 0.50750617 0.69714201</span></span>
<span id="cb66-7"><a href="2.2-random-variables.html#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [8] 0.17104008 0.25448233 0.01813812</span></span></code></pre></div>
</div>
<div id="the-normal-or-gaussian-distribution" class="section level4" number="2.2.10.2">
<h4><span class="header-section-number">2.2.10.2</span> The Normal (or Gaussian) Distribution</h4>
<p><span class="math inline">\(X\)</span> has a Normal (or Gaussian) distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma,\)</span> denoted by <span class="math inline">\(X \sim N\left(\mu, \sigma^{2}\right),\)</span> if
<span class="math display">\[
f(x)=\frac{1}{\sigma \sqrt{2 \pi}} \exp \left\{-\frac{1}{2 \sigma^{2}}(x-\mu)^{2}\right\}, \quad x \in \mathbb{R}
\]</span>
where <span class="math inline">\(\mu \in \mathbb{R}\)</span> and <span class="math inline">\(\sigma&gt;0.\)</span> Later we shall see that <span class="math inline">\(\mu\)</span> is the  (or mean of the distribution and <span class="math inline">\(\sigma\)</span> is the  (or standard deviation) of the distribution. The Normal plays an important role in probability and statistics. Many phenomena in nature have approximately Normal distributions. The <strong>Central Limit Theorem</strong> gives a special role to the Normal distribution by stating that the distribution of averages of random variables can be approximated by a Normal distribution.</p>
<p>We say that <span class="math inline">\(X\)</span> has a standard Normal distribution if <span class="math inline">\(\mu=0\)</span> and <span class="math inline">\(\sigma=1\)</span>. Tradition dictates that a standard Normal random variable is denoted by <span class="math inline">\(Z\)</span>. The PDF and CDF of a standard Normal are denoted by <span class="math inline">\(\phi(z)\)</span> and <span class="math inline">\(\Phi(z)\)</span>. There is no closed-form expression for <span class="math inline">\(\Phi\)</span>. Here are some useful facts:</p>
<ol style="list-style-type: lower-roman">
<li><p>If <span class="math inline">\(X \sim N\left(\mu, \sigma^{2}\right)\)</span> then <span class="math inline">\(Z=(X-\mu) / \sigma \sim N(0,1)\)</span></p></li>
<li><p>If <span class="math inline">\(Z \sim N(0,1)\)</span> then <span class="math inline">\(X=\mu+\sigma Z \sim N\left(\mu, \sigma^{2}\right)\)</span></p></li>
<li><p>If <span class="math inline">\(X_{i} \sim N\left(\mu_{i}, \sigma_{i}^{2}\right), i=1, \ldots, n\)</span> are independent then
<span class="math display">\[
\sum_{i=1}^{n} X_{i} \sim N\left(\sum_{i=1}^{n} \mu_{i}, \sum_{i=1}^{n} \sigma_{i}^{2}\right).
\]</span></p></li>
</ol>
<p>The following -codes plots the standard Normal density function:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="2.2-random-variables.html#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># draw a plot of the N(0,1) PDF</span></span>
<span id="cb67-2"><a href="2.2-random-variables.html#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x),</span>
<span id="cb67-3"><a href="2.2-random-variables.html#cb67-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>),</span>
<span id="cb67-4"><a href="2.2-random-variables.html#cb67-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>, </span>
<span id="cb67-5"><a href="2.2-random-variables.html#cb67-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;Standard Normal Density Function&quot;</span>) </span></code></pre></div>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-44-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>This is how you can draw realizations from pseudo random Normal variables:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="2.2-random-variables.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Drawing from the uniform distribution:</span></span>
<span id="cb68-2"><a href="2.2-random-variables.html#cb68-2" aria-hidden="true" tabindex="-1"></a>n     <span class="ot">&lt;-</span> <span class="dv">12</span></span>
<span id="cb68-3"><a href="2.2-random-variables.html#cb68-3" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb68-4"><a href="2.2-random-variables.html#cb68-4" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb68-5"><a href="2.2-random-variables.html#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma) </span>
<span id="cb68-6"><a href="2.2-random-variables.html#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1]  0.085602504 -0.695791615 -1.364410561 -0.183503290 -1.675347076  0.007303551</span></span>
<span id="cb68-7"><a href="2.2-random-variables.html#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7]  0.346965187  0.037914318  0.881345676 -0.882815597 -0.883560071 -0.795629557</span></span></code></pre></div>
<p>An extension of the normal distribution in a univariate setting is the multivariate normal distribution. Let <span class="math inline">\(X=(X_1,\dots,X_k)&#39;\)</span> be a <span class="math inline">\(k\)</span>-dimensional normal variable, short <span class="math inline">\(X\sim N_k(\mu,\Sigma)\)</span> with mean vector <span class="math inline">\(E(X)=\mu\in\mathbb{R}^k\)</span> and covariance matrix <span class="math inline">\(\operatorname{Cov}(X)=\Sigma\)</span>. The joint density function or <strong>probability density function (pdf)</strong> of the <span class="math inline">\(k\)</span>-dimensional multivariate normal distribution is
<span class="math display">\[
f_{X}\left(x_{1}, \ldots, x_{k}\right)=\frac{\exp \left(-\frac{1}{2}(x-\mu)&#39; \Sigma^{-1}(x-\mu)\right)}{\sqrt{(2 \pi)^{k}|\Sigma|}},
\]</span>
where <span class="math inline">\(|\Sigma|\)</span> denotes the determinant of <span class="math inline">\(\Sigma\)</span>. For <span class="math inline">\(k=2\)</span> we have the bivariate pdf of two random normal variables, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> say
<span class="math display">\[\begin{align*}
g_{X,Y}(x,y) =&amp; \, \frac{1}{2\pi\sigma_X\sigma_Y\sqrt{1-\rho_{XY}^2}} \\ 
\cdot &amp; \, \exp \left\{ \frac{1}{-2(1-\rho_{XY}^2)} \left[ \left( \frac{x-\mu_x}{\sigma_X} \right)^2 - 2\rho_{XY}\left( \frac{x-\mu_X}{\sigma_X} \right)\left( \frac{y-\mu_Y}{\sigma_Y} \right) + \left( \frac{y-\mu_Y}{\sigma_Y} \right)^2 \right]  \right\}.
\end{align*}\]</span>
Lets consider the special case where <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent standard normal random variables with densities <span class="math inline">\(f_X(x)\)</span> and <span class="math inline">\(f_Y(y)\)</span>. We then have the parameters <span class="math inline">\(\sigma_X = \sigma_Y = 1\)</span>, <span class="math inline">\(\mu_X=\mu_Y=0\)</span> (due to marginal standard normality) and correlation <span class="math inline">\(\rho_{XY}=0\)</span> (due to independence). The joint density of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> then becomes
<span class="math display">\[
g_{X,Y}(x,y) = f_X(x) f_Y(y) = \frac{1}{2\pi} \cdot \exp \left\{ -\frac{1}{2}\left[x^2 + y^2\right]\right\}.
\]</span></p>
</div>
<div id="chisqdist" class="section level4" number="2.2.10.3">
<h4><span class="header-section-number">2.2.10.3</span> The Chi-Squared Distribution</h4>
<p>The chi-squared distribution is another distribution relevant in econometrics. It is often needed when testing special types of hypotheses frequently encountered when dealing with regression models.</p>
<p>The sum of <span class="math inline">\(M\)</span> squared <em>independent standard normal</em> distributed random variables, <span class="math inline">\(Z_1,\dots,Z_M\)</span> follows a chi-squared distribution with <span class="math inline">\(M\)</span> degrees of freedom:
<span class="math display">\[\begin{align*}
Z_1^2 + \dots + Z_M^2 = \sum_{m=1}^M Z_m^2 \sim \chi^2_M. 
\end{align*}\]</span>
A <span class="math inline">\(\chi^2\)</span> distributed random variable with <span class="math inline">\(M\)</span> degrees of freedom has expectation <span class="math inline">\(M\)</span>, mode at <span class="math inline">\(M-2\)</span> for <span class="math inline">\(M \geq 2\)</span> and variance <span class="math inline">\(2 \cdot M\)</span>.</p>
<p>Using the code below, we can display the pdf and the distribution function or <strong>cumulated density function (cdf)</strong> of a <span class="math inline">\(\chi^2_3\)</span> random variable in a single plot. This is achieved by setting the argument <code>add = TRUE"</code> in the second call of <code>"curve()"</code>. Further we adjust limits of both axes using <code>"xlim"</code> and <code>"ylim"</code> and choose different colors to make both functions better distinguishable. The plot is completed by adding a legend with help of <code>"legend()"</code>.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="2.2-random-variables.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the PDF</span></span>
<span id="cb69-2"><a href="2.2-random-variables.html#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dchisq</span>(x, <span class="at">df =</span> <span class="dv">3</span>), </span>
<span id="cb69-3"><a href="2.2-random-variables.html#cb69-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), </span>
<span id="cb69-4"><a href="2.2-random-variables.html#cb69-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), </span>
<span id="cb69-5"><a href="2.2-random-variables.html#cb69-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb69-6"><a href="2.2-random-variables.html#cb69-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb69-7"><a href="2.2-random-variables.html#cb69-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;pdf and cdf of Chi-Squared Distribution, M = 3&quot;</span>)</span>
<span id="cb69-8"><a href="2.2-random-variables.html#cb69-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-9"><a href="2.2-random-variables.html#cb69-9" aria-hidden="true" tabindex="-1"></a><span class="co"># add the CDF to the plot</span></span>
<span id="cb69-10"><a href="2.2-random-variables.html#cb69-10" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">pchisq</span>(x, <span class="at">df =</span> <span class="dv">3</span>), </span>
<span id="cb69-11"><a href="2.2-random-variables.html#cb69-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), </span>
<span id="cb69-12"><a href="2.2-random-variables.html#cb69-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">add =</span> <span class="cn">TRUE</span>, </span>
<span id="cb69-13"><a href="2.2-random-variables.html#cb69-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb69-14"><a href="2.2-random-variables.html#cb69-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-15"><a href="2.2-random-variables.html#cb69-15" aria-hidden="true" tabindex="-1"></a><span class="co"># add a legend to the plot</span></span>
<span id="cb69-16"><a href="2.2-random-variables.html#cb69-16" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, </span>
<span id="cb69-17"><a href="2.2-random-variables.html#cb69-17" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&quot;PDF&quot;</span>, <span class="st">&quot;CDF&quot;</span>), </span>
<span id="cb69-18"><a href="2.2-random-variables.html#cb69-18" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), </span>
<span id="cb69-19"><a href="2.2-random-variables.html#cb69-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span></code></pre></div>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-46-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Since the outcomes of a <span class="math inline">\(\chi^2_M\)</span> distributed random variable are always positive, the support of the related PDF and CDF is <span class="math inline">\(\mathbb{R}_{\geq0}\)</span>.</p>
<p>As expectation and variance depend (solely!) on the degrees of freedom, the distribution’s shape changes drastically if we vary the number of squared standard normals that are summed up. This relation is often depicted by overlaying densities for different <span class="math inline">\(M\)</span>, see the <a href="https://en.wikipedia.org/wiki/Chi-squared_distribution">Wikipedia Article</a>.</p>
<p>We reproduce this here by plotting the density of the <span class="math inline">\(\chi_1^2\)</span> distribution on the interval <span class="math inline">\([0,15]\)</span> with <code>"curve()"</code>. In the next step, we loop over degrees of freedom <span class="math inline">\(M=2,...,7\)</span> and add a density curve for each <span class="math inline">\(M\)</span> to the plot. We also adjust the line color for each iteration of the loop by setting <code>"col = M"</code>. At last, we add a legend that displays degrees of freedom and the associated colors.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="2.2-random-variables.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the density for M=1</span></span>
<span id="cb70-2"><a href="2.2-random-variables.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dchisq</span>(x, <span class="at">df =</span> <span class="dv">1</span>), </span>
<span id="cb70-3"><a href="2.2-random-variables.html#cb70-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">15</span>), </span>
<span id="cb70-4"><a href="2.2-random-variables.html#cb70-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;x&quot;</span>, </span>
<span id="cb70-5"><a href="2.2-random-variables.html#cb70-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>, </span>
<span id="cb70-6"><a href="2.2-random-variables.html#cb70-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;Chi-Square Distributed Random Variables&quot;</span>)</span>
<span id="cb70-7"><a href="2.2-random-variables.html#cb70-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-8"><a href="2.2-random-variables.html#cb70-8" aria-hidden="true" tabindex="-1"></a><span class="co"># add densities for M=2,...,7 to the plot using a &#39;for()&#39; loop </span></span>
<span id="cb70-9"><a href="2.2-random-variables.html#cb70-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (M <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">7</span>) {</span>
<span id="cb70-10"><a href="2.2-random-variables.html#cb70-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">curve</span>(<span class="fu">dchisq</span>(x, <span class="at">df =</span> M),</span>
<span id="cb70-11"><a href="2.2-random-variables.html#cb70-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">15</span>), </span>
<span id="cb70-12"><a href="2.2-random-variables.html#cb70-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">add =</span> T, </span>
<span id="cb70-13"><a href="2.2-random-variables.html#cb70-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> M)</span>
<span id="cb70-14"><a href="2.2-random-variables.html#cb70-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb70-15"><a href="2.2-random-variables.html#cb70-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-16"><a href="2.2-random-variables.html#cb70-16" aria-hidden="true" tabindex="-1"></a><span class="co"># add a legend</span></span>
<span id="cb70-17"><a href="2.2-random-variables.html#cb70-17" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, </span>
<span id="cb70-18"><a href="2.2-random-variables.html#cb70-18" aria-hidden="true" tabindex="-1"></a>       <span class="fu">as.character</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>), </span>
<span id="cb70-19"><a href="2.2-random-variables.html#cb70-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span> , </span>
<span id="cb70-20"><a href="2.2-random-variables.html#cb70-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="dv">1</span>, </span>
<span id="cb70-21"><a href="2.2-random-variables.html#cb70-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;D.F.&quot;</span>)</span></code></pre></div>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-47-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Increasing the degrees of freedom shifts the distribution to the right (the mode becomes larger) and increases the dispersion (the distribution’s variance grows).</p>
</div>
<div id="the-student-t-distribution" class="section level4" number="2.2.10.4">
<h4><span class="header-section-number">2.2.10.4</span> The Student t Distribution</h4>
<p>Let <span class="math inline">\(Z\)</span> be a standard normal random variable, <span class="math inline">\(W\)</span> a <span class="math inline">\(\chi^2_\nu\)</span> random variable and further assume that <span class="math inline">\(Z\)</span> and <span class="math inline">\(W\)</span> are independent. Then it holds that
<span class="math display">\[
\frac{Z}{\sqrt{W/\nu}} =:X \sim t_\nu
\]</span>
and <span class="math inline">\(X\)</span> follows a <em>Student <span class="math inline">\(t\)</span> distribution</em> (or simply <span class="math inline">\(t\)</span> distribution) with <span class="math inline">\(\nu\)</span> degrees of freedom.</p>
<p>The shape of a <span class="math inline">\(t_\nu\)</span> distribution depends on <span class="math inline">\(\nu\)</span>. <span class="math inline">\(t\)</span> distributions are symmetric, bell-shaped and look similar to a normal distribution, especially when <span class="math inline">\(\nu\)</span> is large. This is not a coincidence: for a sufficiently large <span class="math inline">\(\nu\)</span>, the <span class="math inline">\(t_\nu\)</span> distribution can be approximated by the standard normal distribution. This approximation works reasonably well for <span class="math inline">\(\nu\geq 30\)</span>.</p>
<p>A <span class="math inline">\(t_\nu\)</span> distributed random variable <span class="math inline">\(X\)</span> has an expectation if <span class="math inline">\(\nu&gt;1\)</span> and it has a variance if <span class="math inline">\(\nu&gt;2\)</span>.
<span class="math display">\[\begin{align*}
  E(X) =&amp; 0, \ M&gt;1 \\
  \text{Var}(X) =&amp; \frac{M}{M-2}, \ M&gt;2
\end{align*}\]</span></p>
<p>Let us plot some <span class="math inline">\(t\)</span> distributions with different degrees of freedoms <span class="math inline">\(\nu\)</span> and compare them to the standard normal distribution.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="2.2-random-variables.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the standard normal density</span></span>
<span id="cb71-2"><a href="2.2-random-variables.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x), </span>
<span id="cb71-3"><a href="2.2-random-variables.html#cb71-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), </span>
<span id="cb71-4"><a href="2.2-random-variables.html#cb71-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span> <span class="st">&quot;x&quot;</span>, </span>
<span id="cb71-5"><a href="2.2-random-variables.html#cb71-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">lty =</span> <span class="dv">2</span>, </span>
<span id="cb71-6"><a href="2.2-random-variables.html#cb71-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>, </span>
<span id="cb71-7"><a href="2.2-random-variables.html#cb71-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;Densities of t Distributions&quot;</span>)</span>
<span id="cb71-8"><a href="2.2-random-variables.html#cb71-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-9"><a href="2.2-random-variables.html#cb71-9" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the t density for M=2</span></span>
<span id="cb71-10"><a href="2.2-random-variables.html#cb71-10" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">2</span>), </span>
<span id="cb71-11"><a href="2.2-random-variables.html#cb71-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), </span>
<span id="cb71-12"><a href="2.2-random-variables.html#cb71-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="dv">2</span>, </span>
<span id="cb71-13"><a href="2.2-random-variables.html#cb71-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">add =</span> T)</span>
<span id="cb71-14"><a href="2.2-random-variables.html#cb71-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-15"><a href="2.2-random-variables.html#cb71-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the t density for M=4</span></span>
<span id="cb71-16"><a href="2.2-random-variables.html#cb71-16" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">4</span>), </span>
<span id="cb71-17"><a href="2.2-random-variables.html#cb71-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), </span>
<span id="cb71-18"><a href="2.2-random-variables.html#cb71-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="dv">3</span>, </span>
<span id="cb71-19"><a href="2.2-random-variables.html#cb71-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">add =</span> T)</span>
<span id="cb71-20"><a href="2.2-random-variables.html#cb71-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-21"><a href="2.2-random-variables.html#cb71-21" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the t density for M=25</span></span>
<span id="cb71-22"><a href="2.2-random-variables.html#cb71-22" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">25</span>), </span>
<span id="cb71-23"><a href="2.2-random-variables.html#cb71-23" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>), </span>
<span id="cb71-24"><a href="2.2-random-variables.html#cb71-24" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="dv">4</span>, </span>
<span id="cb71-25"><a href="2.2-random-variables.html#cb71-25" aria-hidden="true" tabindex="-1"></a>      <span class="at">add =</span> T)</span>
<span id="cb71-26"><a href="2.2-random-variables.html#cb71-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-27"><a href="2.2-random-variables.html#cb71-27" aria-hidden="true" tabindex="-1"></a><span class="co"># add a legend</span></span>
<span id="cb71-28"><a href="2.2-random-variables.html#cb71-28" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, </span>
<span id="cb71-29"><a href="2.2-random-variables.html#cb71-29" aria-hidden="true" tabindex="-1"></a>       <span class="fu">c</span>(<span class="st">&quot;N(0, 1)&quot;</span>, <span class="st">&quot;M=2&quot;</span>, <span class="st">&quot;M=4&quot;</span>, <span class="st">&quot;M=25&quot;</span>), </span>
<span id="cb71-30"><a href="2.2-random-variables.html#cb71-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, </span>
<span id="cb71-31"><a href="2.2-random-variables.html#cb71-31" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>))</span></code></pre></div>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-48-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The plot illustrates that as the degrees of freedom increase, the shape of the <span class="math inline">\(t\)</span> distribution comes closer to that of a standard normal bell curve. Already for <span class="math inline">\(\nu=25\)</span> we find little difference to the standard normal density. If <span class="math inline">\(\nu\)</span> is small, we find the distribution to have heavier tails than a standard normal.</p>
</div>
<div id="cauchy-distribution" class="section level4" number="2.2.10.5">
<h4><span class="header-section-number">2.2.10.5</span> Cauchy Distribution</h4>
<p>The Cauchy distribution is a special
case of the <span class="math inline">\(t\)</span> distribution corresponding to <span class="math inline">\(\nu=1\)</span>. The density is
<span class="math display">\[
f(x)=\frac{1}{\pi\left(1+x^{2}\right)}.
\]</span>
<!-- To see that this is indeed a density, let's do the integral: -->
<!-- $$ -->
<!-- \begin{aligned} -->
<!-- \int_{-\infty}^{\infty} f(x) d x &=\frac{1}{\pi} \int_{-\infty}^{\infty} \frac{d x}{1+x^{2}}=\frac{1}{\pi} \int_{-\infty}^{\infty} \frac{d \tan ^{-1}}{d x} \\ -->
<!-- &=\frac{1}{\pi}\left[\tan ^{-1}(\infty)-\tan ^{-1}(-\infty)\right]=\frac{1}{\pi}\left[\frac{\pi}{2}-\left(-\frac{\pi}{2}\right)\right]=1 -->
<!-- \end{aligned} -->
<!-- $$ --></p>
<p>For the Cauchy distribution, the <strong>expectation does not exist</strong> – that is, it has no mean. Let’s try to compute the mean of a Cauchy distribution and see what goes wrong. Its mean should be
<span class="math display">\[
\mu=E(X)=\int_{-\infty}^{\infty} \frac{x d x}{\pi\left(1+x^{2}\right)}.
\]</span>
In order for this improper integral to exist, we need both integrals <span class="math inline">\(\int_{-\infty}^{0}\)</span> and <span class="math inline">\(\int_{0}^{\infty}\)</span> to be finite. Let’s look at the second integral.
<span class="math display">\[
\int_{0}^{\infty} \frac{x d x}{\pi\left(1+x^{2}\right)}=\left.\frac{1}{2 \pi} \log \left(1+x^{2}\right)\right|_{0} ^{\infty}=\infty
\]</span>
Similarly, the other integral, <span class="math inline">\(\int_{-\infty}^{0},\)</span> is <span class="math inline">\(-\infty\)</span>. Since they’re not both finite, the integral <span class="math inline">\(\int_{-\infty}^{\infty}\)</span> doesn’t exist. In other words <span class="math inline">\(\infty-\infty\)</span> is not a number. Thus, the Cauchy distribution has no mean.</p>
<p>What this means in practice is that if you take a sample <span class="math inline">\(x_{1}, x_{2}, \ldots, x_{n}\)</span> from the Cauchy distribution, then the average <span class="math inline">\(\bar{x}\)</span> does not tend to a particular number. Instead, every so often you will get such a huge number, either positive or negative, that the average is overwhelmed by it.</p>
</div>
<div id="sec:Fdist" class="section level4" number="2.2.10.6">
<h4><span class="header-section-number">2.2.10.6</span> The F Distribution</h4>
<p>Another ratio of random variables important to econometricians is the ratio of two independent <span class="math inline">\(\chi^2\)</span> distributed random variables that are divided by their degrees of freedom <span class="math inline">\(M\)</span> and <span class="math inline">\(n\)</span>. The quantity</p>
<p><span class="math display">\[ \frac{W/M}{V/n} \sim F_{M,n} \ \ \text{with} \ \ W \sim \chi^2_M \ \ , \ \ V \sim \chi^2_n \]</span>
follows an <span class="math inline">\(F\)</span> distribution with numerator degrees of freedom <span class="math inline">\(M\)</span> and denominator degrees of freedom <span class="math inline">\(n\)</span>, denoted <span class="math inline">\(F_{M,n}\)</span>. The distribution was first derived by George Snedecor but was named in honor of <a href="https://en.wikipedia.org/wiki/Ronald_Fisher">Sir Ronald Fisher</a>.</p>
<p>By definition, the support of both PDF and CDF of an <span class="math inline">\(F_{M,n}\)</span> distributed random variable is <span class="math inline">\(\mathbb{R}_{\geq0}\)</span>.</p>
<p>Say we have an <span class="math inline">\(F\)</span> distributed random variable <span class="math inline">\(Y\)</span> with numerator degrees of freedom <span class="math inline">\(3\)</span> and denominator degrees of freedom <span class="math inline">\(14\)</span> and are interested in <span class="math inline">\(P(Y \geq 2)\)</span>. This can be computed with help of the function <code>"pf()"</code>. By setting the argument <code>"lower.tail"</code> to <code>"FALSE"</code> we ensure that  computes <span class="math inline">\(1- P(Y \leq 2)\)</span>, i.e,the probability mass in the tail right of <span class="math inline">\(2\)</span>.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="2.2-random-variables.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pf</span>(<span class="dv">2</span>, <span class="at">df1 =</span> <span class="dv">3</span>, <span class="at">df2 =</span> <span class="dv">14</span>, <span class="at">lower.tail =</span> F)</span>
<span id="cb72-2"><a href="2.2-random-variables.html#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.1603538</span></span></code></pre></div>
<p>We can visualize this probability by drawing a line plot of the related density and adding a color shading with <code>"polygon()"</code>.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="2.2-random-variables.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define coordinate vectors for vertices of the polygon</span></span>
<span id="cb73-2"><a href="2.2-random-variables.html#cb73-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="fu">seq</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.01</span>), <span class="dv">10</span>)</span>
<span id="cb73-3"><a href="2.2-random-variables.html#cb73-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">df</span>(<span class="fu">seq</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.01</span>), <span class="dv">3</span>, <span class="dv">14</span>), <span class="dv">0</span>)</span>
<span id="cb73-4"><a href="2.2-random-variables.html#cb73-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-5"><a href="2.2-random-variables.html#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="co"># draw density of F_{3, 14}</span></span>
<span id="cb73-6"><a href="2.2-random-variables.html#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">df</span>(x ,<span class="dv">3</span> ,<span class="dv">14</span>), </span>
<span id="cb73-7"><a href="2.2-random-variables.html#cb73-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.8</span>), </span>
<span id="cb73-8"><a href="2.2-random-variables.html#cb73-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), </span>
<span id="cb73-9"><a href="2.2-random-variables.html#cb73-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&quot;Density&quot;</span>,</span>
<span id="cb73-10"><a href="2.2-random-variables.html#cb73-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;Density Function&quot;</span>)</span>
<span id="cb73-11"><a href="2.2-random-variables.html#cb73-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-12"><a href="2.2-random-variables.html#cb73-12" aria-hidden="true" tabindex="-1"></a><span class="co"># draw the polygon</span></span>
<span id="cb73-13"><a href="2.2-random-variables.html#cb73-13" aria-hidden="true" tabindex="-1"></a><span class="fu">polygon</span>(x, y, <span class="at">col =</span> <span class="st">&quot;orange&quot;</span>)</span></code></pre></div>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-50-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The <span class="math inline">\(F\)</span> distribution is related to many other distributions. An important special case encountered in econometrics arises if the denominator degrees of freedom are large such that the <span class="math inline">\(F_{M,n}\)</span> distribution can be approximated by the <span class="math inline">\(F_{M,\infty}\)</span> distribution which turns out to be simply the distribution of a <span class="math inline">\(\chi^2_M\)</span> random variable divided by its degrees of freedom <span class="math inline">\(M\)</span>, i.e. 
<span class="math display">\[ 
W/M \sim F_{M,\infty} \quad\text{with}\quad W \sim \chi^2_M.
\]</span></p>

</div>
</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="2.1-probability-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="3-ch:SLR.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Script_Econometrics_MSc.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
