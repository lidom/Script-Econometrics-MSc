<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.2 Ordinary Least Squares Estimation | Econometrics (M.Sc.)</title>
  <meta name="description" content="3.2 Ordinary Least Squares Estimation | Econometrics (M.Sc.)" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="3.2 Ordinary Least Squares Estimation | Econometrics (M.Sc.)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/mylogo.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.2 Ordinary Least Squares Estimation | Econometrics (M.Sc.)" />
  
  
  <meta name="twitter:image" content="/images/mylogo.png" />

<meta name="author" content="Prof. Dr. Dominik Liebl" />


<meta name="date" content="2021-11-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="the-simple-linear-regression-model.html"/>
<link rel="next" href="properties-of-the-ols-estimator.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#organization-of-the-course"><i class="fa fa-check"></i>Organization of the Course</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#literature"><i class="fa fa-check"></i>Literature</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="short-glossary.html"><a href="short-glossary.html"><i class="fa fa-check"></i><b>1.1</b> Short Glossary</a></li>
<li class="chapter" data-level="1.2" data-path="first-steps.html"><a href="first-steps.html"><i class="fa fa-check"></i><b>1.2</b> First Steps</a></li>
<li class="chapter" data-level="1.3" data-path="further-data-objects.html"><a href="further-data-objects.html"><i class="fa fa-check"></i><b>1.3</b> Further Data Objects</a></li>
<li class="chapter" data-level="1.4" data-path="simple-regression-analysis-using-r.html"><a href="simple-regression-analysis-using-r.html"><i class="fa fa-check"></i><b>1.4</b> Simple Regression Analysis using R</a></li>
<li class="chapter" data-level="1.5" data-path="programming-in-r.html"><a href="programming-in-r.html"><i class="fa fa-check"></i><b>1.5</b> Programming in R</a></li>
<li class="chapter" data-level="1.6" data-path="r-packages.html"><a href="r-packages.html"><i class="fa fa-check"></i><b>1.6</b> R-packages</a></li>
<li class="chapter" data-level="1.7" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>1.7</b> Tidyverse</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="tidyverse.html"><a href="tidyverse.html#tidyverse-plotting-basics"><i class="fa fa-check"></i><b>1.7.1</b> Tidyverse: Plotting Basics</a></li>
<li class="chapter" data-level="1.7.2" data-path="tidyverse.html"><a href="tidyverse.html#tidyverse-data-wrangling-basics"><i class="fa fa-check"></i><b>1.7.2</b> Tidyverse: Data Wrangling Basics</a></li>
<li class="chapter" data-level="1.7.3" data-path="tidyverse.html"><a href="tidyverse.html#the-pipe-operator"><i class="fa fa-check"></i><b>1.7.3</b> The pipe operator <code>%&gt;%</code></a></li>
<li class="chapter" data-level="1.7.4" data-path="tidyverse.html"><a href="tidyverse.html#the-group_by-function"><i class="fa fa-check"></i><b>1.7.4</b> The <code>group_by()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="further-links.html"><a href="further-links.html"><i class="fa fa-check"></i><b>1.8</b> Further Links</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="further-links.html"><a href="further-links.html#further-r-intros"><i class="fa fa-check"></i><b>1.8.1</b> Further R-Intros</a></li>
<li class="chapter" data-level="1.8.2" data-path="further-links.html"><a href="further-links.html#version-control-gitgithub"><i class="fa fa-check"></i><b>1.8.2</b> Version Control (Git/GitHub)</a></li>
<li class="chapter" data-level="1.8.3" data-path="further-links.html"><a href="further-links.html#r-ladies"><i class="fa fa-check"></i><b>1.8.3</b> R-Ladies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="review-probability-and-statistics.html"><a href="review-probability-and-statistics.html"><i class="fa fa-check"></i><b>2</b> Review: Probability and Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2.1</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="probability-theory.html"><a href="probability-theory.html#sample-spaces-and-elementary-events"><i class="fa fa-check"></i><b>2.1.1</b> Sample Spaces and (Elementary) Events</a></li>
<li class="chapter" data-level="2.1.2" data-path="probability-theory.html"><a href="probability-theory.html#probability"><i class="fa fa-check"></i><b>2.1.2</b> Probability</a></li>
<li class="chapter" data-level="2.1.3" data-path="probability-theory.html"><a href="probability-theory.html#independent-events"><i class="fa fa-check"></i><b>2.1.3</b> Independent Events</a></li>
<li class="chapter" data-level="2.1.4" data-path="probability-theory.html"><a href="probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>2.1.4</b> Conditional Probability</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>2.2</b> Random Variables</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="random-variables.html"><a href="random-variables.html#univariate-distribution-and-probability-functions"><i class="fa fa-check"></i><b>2.2.1</b> Univariate Distribution and Probability Functions</a></li>
<li class="chapter" data-level="2.2.2" data-path="random-variables.html"><a href="random-variables.html#multivariate-distribution-and-probability-functions"><i class="fa fa-check"></i><b>2.2.2</b> Multivariate Distribution and Probability Functions</a></li>
<li class="chapter" data-level="2.2.3" data-path="random-variables.html"><a href="random-variables.html#means-and-moments"><i class="fa fa-check"></i><b>2.2.3</b> Means and Moments</a></li>
<li class="chapter" data-level="2.2.4" data-path="random-variables.html"><a href="random-variables.html#unconditional-means"><i class="fa fa-check"></i><b>2.2.4</b> Unconditional Means</a></li>
<li class="chapter" data-level="2.2.5" data-path="random-variables.html"><a href="random-variables.html#conditional-means"><i class="fa fa-check"></i><b>2.2.5</b> Conditional Means</a></li>
<li class="chapter" data-level="2.2.6" data-path="random-variables.html"><a href="random-variables.html#means-of-transformed-random-variables-and-moments"><i class="fa fa-check"></i><b>2.2.6</b> Means of Transformed Random Variables and Moments</a></li>
<li class="chapter" data-level="2.2.7" data-path="random-variables.html"><a href="random-variables.html#independent-random-variables"><i class="fa fa-check"></i><b>2.2.7</b> Independent Random Variables</a></li>
<li class="chapter" data-level="2.2.8" data-path="random-variables.html"><a href="random-variables.html#i.i.d.-samples"><i class="fa fa-check"></i><b>2.2.8</b> I.I.D. Samples</a></li>
<li class="chapter" data-level="2.2.9" data-path="random-variables.html"><a href="random-variables.html#some-important-discrete-random-variables"><i class="fa fa-check"></i><b>2.2.9</b> Some Important Discrete Random Variables</a></li>
<li class="chapter" data-level="2.2.10" data-path="random-variables.html"><a href="random-variables.html#some-important-continuous-random-variables"><i class="fa fa-check"></i><b>2.2.10</b> Some Important Continuous Random Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch:SLR.html"><a href="ch:SLR.html"><i class="fa fa-check"></i><b>3</b> Review: Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-simple-linear-regression-model.html"><a href="the-simple-linear-regression-model.html"><i class="fa fa-check"></i><b>3.1</b> The Simple Linear Regression Model</a>
<ul>
<li class="chapter" data-level="" data-path="the-simple-linear-regression-model.html"><a href="the-simple-linear-regression-model.html#the-data-generating-process"><i class="fa fa-check"></i>The Data-Generating Process</a></li>
<li class="chapter" data-level="3.1.1" data-path="the-simple-linear-regression-model.html"><a href="the-simple-linear-regression-model.html#assumptions-about-the-error-term"><i class="fa fa-check"></i><b>3.1.1</b> Assumptions About the Error Term</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-simple-linear-regression-model.html"><a href="the-simple-linear-regression-model.html#the-population-regression-line"><i class="fa fa-check"></i><b>3.1.2</b> The Population Regression Line</a></li>
<li class="chapter" data-level="3.1.3" data-path="the-simple-linear-regression-model.html"><a href="the-simple-linear-regression-model.html#terminology-estimates-versus-estimators"><i class="fa fa-check"></i><b>3.1.3</b> Terminology: Estimates versus Estimators</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ordinary-least-squares-estimation.html"><a href="ordinary-least-squares-estimation.html"><i class="fa fa-check"></i><b>3.2</b> Ordinary Least Squares Estimation</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ordinary-least-squares-estimation.html"><a href="ordinary-least-squares-estimation.html#terminology-sample-regression-line-prediction-and-residuals"><i class="fa fa-check"></i><b>3.2.1</b> Terminology: Sample Regression Line, Prediction and Residuals</a></li>
<li class="chapter" data-level="3.2.2" data-path="ordinary-least-squares-estimation.html"><a href="ordinary-least-squares-estimation.html#sec:SLROLS"><i class="fa fa-check"></i><b>3.2.2</b> Deriving the Expression of the OLS Estimator</a></li>
<li class="chapter" data-level="3.2.3" data-path="ordinary-least-squares-estimation.html"><a href="ordinary-least-squares-estimation.html#behavior-of-the-ols-estimates-for-resampled-data-conditionally-on-x_i"><i class="fa fa-check"></i><b>3.2.3</b> Behavior of the OLS Estimates for Resampled Data (conditionally on <span class="math inline">\(X_i\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="properties-of-the-ols-estimator.html"><a href="properties-of-the-ols-estimator.html"><i class="fa fa-check"></i><b>3.3</b> Properties of the OLS Estimator</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="properties-of-the-ols-estimator.html"><a href="properties-of-the-ols-estimator.html#mean-and-bias-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.1</b> Mean and Bias of the OLS Estimator</a></li>
<li class="chapter" data-level="3.3.2" data-path="properties-of-the-ols-estimator.html"><a href="properties-of-the-ols-estimator.html#variance-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.2</b> Variance of the OLS Estimator</a></li>
<li class="chapter" data-level="3.3.3" data-path="properties-of-the-ols-estimator.html"><a href="properties-of-the-ols-estimator.html#consistency-of-the-ols-estimator"><i class="fa fa-check"></i><b>3.3.3</b> Consistency of the OLS Estimator</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch:MLR.html"><a href="ch:MLR.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>4.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="assumptions.html"><a href="assumptions.html#some-implications-of-the-exogeneity-assumption"><i class="fa fa-check"></i><b>4.1.1</b> Some Implications of the Exogeneity Assumption</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="deriving-the-expression-of-the-ols-estimator.html"><a href="deriving-the-expression-of-the-ols-estimator.html"><i class="fa fa-check"></i><b>4.2</b> Deriving the Expression of the OLS Estimator</a></li>
<li class="chapter" data-level="4.3" data-path="some-quantities-of-interest.html"><a href="some-quantities-of-interest.html"><i class="fa fa-check"></i><b>4.3</b> Some Quantities of Interest</a></li>
<li class="chapter" data-level="4.4" data-path="method-of-moments-estimator.html"><a href="method-of-moments-estimator.html"><i class="fa fa-check"></i><b>4.4</b> Method of Moments Estimator</a></li>
<li class="chapter" data-level="4.5" data-path="unbiasedness-of-hatbetax-and-hatbeta.html"><a href="unbiasedness-of-hatbetax-and-hatbeta.html"><i class="fa fa-check"></i><b>4.5</b> Unbiasedness of <span class="math inline">\(\hat\beta|X\)</span> and <span class="math inline">\(\hat\beta\)</span></a></li>
<li class="chapter" data-level="4.6" data-path="ch:VarEstBeta.html"><a href="ch:VarEstBeta.html"><i class="fa fa-check"></i><b>4.6</b> Variance of <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="4.7" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>4.7</b> The Gauss-Markov Theorem</a></li>
<li class="chapter" data-level="4.8" data-path="practice.html"><a href="practice.html"><i class="fa fa-check"></i><b>4.8</b> Practice</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="practice.html"><a href="practice.html#dummy-variables-and-contrast-codings"><i class="fa fa-check"></i><b>4.8.1</b> Dummy variables and contrast codings</a></li>
<li class="chapter" data-level="4.8.2" data-path="practice.html"><a href="practice.html#the-function"><i class="fa fa-check"></i><b>4.8.2</b> The function </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch:SSINF.html"><a href="ch:SSINF.html"><i class="fa fa-check"></i><b>5</b> Small Sample Inference</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ch:testmultp.html"><a href="ch:testmultp.html"><i class="fa fa-check"></i><b>5.1</b> Hypothesis Tests about Multiple Parameters</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ch:testmultp.html"><a href="ch:testmultp.html#the-test-statistic-and-its-null-distribution"><i class="fa fa-check"></i><b>5.1.1</b> The Test Statistic and its Null Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ch:testingsinglep.html"><a href="ch:testingsinglep.html"><i class="fa fa-check"></i><b>5.2</b> Tests about One Parameter</a></li>
<li class="chapter" data-level="5.3" data-path="testtheory.html"><a href="testtheory.html"><i class="fa fa-check"></i><b>5.3</b> Testtheory</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="testtheory.html"><a href="testtheory.html#significance-level"><i class="fa fa-check"></i><b>5.3.1</b> Significance Level</a></li>
<li class="chapter" data-level="5.3.2" data-path="testtheory.html"><a href="testtheory.html#critical-value-for-the-f-test"><i class="fa fa-check"></i><b>5.3.2</b> Critical Value for the <span class="math inline">\(F\)</span>-Test</a></li>
<li class="chapter" data-level="5.3.3" data-path="testtheory.html"><a href="testtheory.html#critical-values-for-the-t-test"><i class="fa fa-check"></i><b>5.3.3</b> Critical Value(s) for the <span class="math inline">\(t\)</span>-Test</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="type-ii-error-and-power.html"><a href="type-ii-error-and-power.html"><i class="fa fa-check"></i><b>5.4</b> Type II Error and Power</a></li>
<li class="chapter" data-level="5.5" data-path="p-value.html"><a href="p-value.html"><i class="fa fa-check"></i><b>5.5</b> <span class="math inline">\(p\)</span>-Value</a></li>
<li class="chapter" data-level="5.6" data-path="CIsmallsample.html"><a href="CIsmallsample.html"><i class="fa fa-check"></i><b>5.6</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.7" data-path="PSSI.html"><a href="PSSI.html"><i class="fa fa-check"></i><b>5.7</b> Practice: Small Sample Inference</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="PSSI.html"><a href="PSSI.html#normally-distributed-hatbetax"><i class="fa fa-check"></i><b>5.7.1</b> Normally Distributed <span class="math inline">\(\hat\beta|X\)</span></a></li>
<li class="chapter" data-level="5.7.2" data-path="PSSI.html"><a href="PSSI.html#testing-multiple-parameters"><i class="fa fa-check"></i><b>5.7.2</b> Testing Multiple Parameters</a></li>
<li class="chapter" data-level="5.7.3" data-path="PSSI.html"><a href="PSSI.html#dualty-of-confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>5.7.3</b> Dualty of Confidence Intervals and Hypothesis Tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Econometrics (M.Sc.)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ordinary-least-squares-estimation" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Ordinary Least Squares Estimation</h2>
<p>There are many ways to estimate the parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> of the simple linear regression model in . In the following, we will derive the Ordinary Least Squares (OLS) estimator using a ``mechanical’’ approach. In the next chapter, we will use an alternative approach () which provides a perspective that is particularly interesting/useful in econometrics. You will see that the properties of the estimators for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> crucially depend on our assumption regarding the error terms <span class="math inline">\(\varepsilon_i\)</span> and the explanatory variables <span class="math inline">\(X_i\)</span>.</p>
<div id="terminology-sample-regression-line-prediction-and-residuals" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Terminology: Sample Regression Line, Prediction and Residuals</h3>
<p>Let us define some necessary terms. Call <span class="math inline">\(\hat\beta_0\)</span> our estimate of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span> our estimate of <span class="math inline">\(\beta_1\)</span>. Now, define the <strong>predicted value</strong>, <span class="math inline">\(\hat Y_i\)</span>, of the dependent variable, <span class="math inline">\(Y_i\)</span>, to be<br />
<span class="math display">\[\begin{align}
\hat Y_i&amp;= \hat\beta_0 + \hat\beta_1 X_i\label{eq:fitted_y}
\end{align}\]</span>
This is just the prediction of the dependent variable, <span class="math inline">\(Y_i\)</span>, given the value of <span class="math inline">\(X_i\)</span> and the estimates <span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span>. Equation  defines the <strong>sample regression line</strong>.</p>
<p>Define the , <span class="math inline">\(\hat\eps_i\)</span>, as the difference between the observed value, <span class="math inline">\(Y_i\)</span>, and the predicted value, <span class="math inline">\(\hat Y_i\)</span>:
<span class="math display">\[\begin{align*}
\hat\eps_i&amp;= Y_i - \hat Y_i \\
          &amp;= Y_i - \hat\beta_0 - \hat\beta_1 X_i
\end{align*}\]</span>
The residual, <span class="math inline">\(\hat\eps_i\)</span>, is the vertical distance between the observed value, <span class="math inline">\(Y_i\)</span>, and the sample regression line, i.e., the prediction, <span class="math inline">\(\hat{Y}_i\)</span>, of <span class="math inline">\(Y_i\)</span>.</p>
<p>We must make an important distinction between the residuals, <span class="math inline">\(\hat\eps_i\)</span>, and the errors <span class="math inline">\(\varepsilon_i\)</span>.
<span class="math display">\[\begin{align*}
\hat\eps_i        &amp;= Y_i - \hat\beta_0 - \hat\beta_1 X_i \quad\text{(computable)}\\ 
\varepsilon_i     &amp;= Y_i -     \beta_0 -     \beta_1 X_i \quad\text{(unobservable)}
\end{align*}\]</span>
Because <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are unknown, we can never know the value of the error terms <span class="math inline">\(\varepsilon_i\)</span>. However, because we actually come up with the estimates <span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span>, and because we observe <span class="math inline">\(X_i\)</span>, we can calculate the residual <span class="math inline">\(\hat\eps_i\)</span> for each observation. This distinction is important to keep in mind.</p>
<!-- \smallskip -->
<!-- \noindent Overview:   -->
<!-- \begin{equation*} -->
<!-- \begin{array}{lrcl} -->
<!-- \text{Sample Regression Line:  }&  \hat y &=& \hat\beta_0 + \hat\beta_1 x \\ -->
<!-- \text{Population Regression Line:  }&  E[Y_i|X_i] &=& \beta_0 + \beta_1 X_i \\ -->
<!-- \text{Observed Value for $i=1$:  }&  y_1 &=& \beta_0 + \beta_1 x_1 + \varepsilon_1 \\ -->
<!-- \text{Observed Value for $i=1$:  }&  y_1 &=& \hat\beta_0 + \hat\beta_1 x_1 + e_1 -->
<!-- \end{array} -->
<!-- \end{equation*}   -->
<p>Note that we can write
<span class="math display">\[\begin{align*}
\varepsilon_i &amp;= Y_i - \beta_0 - \beta_1 X_i\\
           &amp;= Y_i - E[Y_i | X_i].
\end{align*}\]</span>
But for this to make sense, we needed to impose the <strong>exogeneity assumption</strong> that <span class="math inline">\(E[\varepsilon_i | X_i]=0\)</span>, since only then we can identify the population regression line <span class="math inline">\(\beta_0 + \beta_1 X_i\)</span> using the conditional mean of <span class="math inline">\(Y_i\)</span> given <span class="math inline">\(X_i\)</span>.</p>
</div>
<div id="sec:SLROLS" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Deriving the Expression of the OLS Estimator</h3>
<p>The method of  () estimation has a long history and was first described by Legendre in 1805 – although Karl Friedrich Gauss claimed to use OLS since 1795. In 1809 Gauss published his work on OLS which extended the work of Legendre.</p>
<p>The idea of OLS is to choose parameter values that 
for a given data set. These minimizing parameters are then the estimates of the unknown population parameters. It turns out that the OLS estimator is equipped with several desirable properties. In a sense, OLS is a purely  method. We will see that it is equivalent to an alternative estimation method called <em>methods of moments</em> which have a more profound econometric motivation, given a certain set of (moment-)assumptions.</p>
<p>Our objective is to find the parameter values <span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span> that minimize the sum of squared residuals, <span class="math inline">\(S_n(b_0,b_1)\)</span>, for a given sample (i.e., for given data) <span class="math inline">\(((Y_1,X_1),\dots,(Y_n,X_n))\)</span> of the random sample <span class="math inline">\(((Y_1,X_1),\dots,(Y_n,X_n))\)</span>, where
<span class="math display">\[\begin{align*}
S_n(b_0, b_1)&amp;=\sum_{i=1}^n \hat{\eps}_i^2 \\
             &amp;=\sum_{i=1}^n (Y_i - \hat Y_i)^2 \\
             &amp;= \sum_{i=1}^n (Y_i - b_0 - b_1 X_i)^2 \\
             &amp;= \sum_{i=1}^n (Y_i^2 - 2 b_0 Y_i -  2b_1 Y_i X_i  + b_0^2 + 
                                                                    2b_0 b_1 X_i + b_1^2 X_i^2).
\end{align*}\]</span><br />
Now partially differentiate the last line with respect to <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, respectively.
<span class="math display">\[\begin{align*}
\dfrac{\partial S_n(b_0,b_1)}{\partial b_0}&amp;= \sum_{i=1}^n \left(-2Y_i + 2b_0 +2 b_1 X_i\right)\\
\dfrac{\partial S_n(b_0,b_1)}{\partial b_1}&amp;= \sum_{i=1}^n\left(-2Y_i X_i +  2 b_0 X_i +
                                                              2 b_1 X_i^2\right)
\end{align*}\]</span>
Next, we want to find the minimizing arguments
<span class="math display">\[(\hat\beta_0,\hat\beta_1)&#39;=\min\arg_{(b_0,b_1)\in\mathbb{R}^2}S_n(b_0,b_1).\]</span>
For this we set the two partial derivatives equal to zero which gives us two equations that fully determine the values <span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span>:
<span class="math display">\[\begin{align*}
n\hat\beta_0 - \sum_{i=1}^n Y_i+ \hat\beta_1 \sum_{i=1}^n X_i  &amp;=0\\      
\sum_{i=1}^n\left(-Y_i X_i + \hat\beta_0 X_i +\hat\beta_1 X_i^2\right)&amp;=0 
% -\left(\sum_{i=1}^n Y_i X_i\right) + \hat\beta_1 \left( \sum_{i=1}^n X_i^2\right)&amp;=0
\end{align*}\]</span>
The two latter equations are known as the . It is easy to see from the first normal equation that the OLS estimator of <span class="math inline">\(\beta_0\)</span> is
<span class="math display">\[\begin{equation}
\hat\beta_0 = \bar{Y} - \hat\beta_1 \bar{X}
\end{equation}\]</span>
Substituting <span class="math inline">\(\hat\beta_0\)</span> into the second normal equation gives
<span class="math display">\[\begin{align*} 0&amp;=\sum_{i=1}^n\left(-Y_i X_i +  ( \bar{Y} - \hat\beta_1 \bar{X}) X_i +
                                                               \hat\beta_1 X_i^2\right) \\
                                &amp;= \sum_{i=1}^n\left(-X_i (Y_i - \bar{Y})+    \hat\beta_1 X_i(X_i - \bar{X})\right)\\
                                &amp;=-\left(\sum_{i=1}^n X_i (Y_i - \bar{Y})\right) + \hat\beta_1 \left(\sum_{i=1}^n X_i (X_i - \bar{X})\right)\\
\end{align*}\]</span>
Solving for <span class="math inline">\(\hat\beta_1\)</span> gives
<span class="math display">\[\begin{align*}
\hat\beta_1&amp;=\dfrac{\sum_{i=1}^n (Y_i - \bar{Y})X_i}{\sum_{i=1}^n (X_i-\bar {X})X_i}\\\notag
                    &amp;=\dfrac{\sum_{i=1}^n (Y_i - \bar{Y}) (X_i- \bar{X})}{\sum_{i=1}^n (X_i-\bar {X})(X_i - \bar{X})}\\\notag
                    &amp;=\dfrac{\sum_{i=1}^n (X_i- \bar{X})Y_i}{\sum_{i=1}^n (X_i-\bar{X})^2}
\end{align*}\]</span>
The last two lines follow from the  that will be discussed in the exercises of this chapter.</p>
<p>Here is some -code for computing <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> for a given realization of the random sample <span class="math inline">\(((Y_1,X_1),\dots,(Y_n,X_n))\)</span>, i.e. for a given (well, here simulated) data set <span class="math inline">\(((Y_1,X_1),\dots,(Y_n,X_n))\)</span>.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="ordinary-least-squares-estimation.html#cb74-1" aria-hidden="true" tabindex="-1"></a>n     <span class="ot">&lt;-</span> <span class="dv">25</span> <span class="co"># sample size</span></span>
<span id="cb74-2"><a href="ordinary-least-squares-estimation.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="do">## simulate data</span></span>
<span id="cb74-3"><a href="ordinary-least-squares-estimation.html#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb74-4"><a href="ordinary-least-squares-estimation.html#cb74-4" aria-hidden="true" tabindex="-1"></a>X     <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">1</span>, <span class="at">max =</span> <span class="dv">10</span>)</span>
<span id="cb74-5"><a href="ordinary-least-squares-estimation.html#cb74-5" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb74-6"><a href="ordinary-least-squares-estimation.html#cb74-6" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb74-7"><a href="ordinary-least-squares-estimation.html#cb74-7" aria-hidden="true" tabindex="-1"></a>beta1 <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb74-8"><a href="ordinary-least-squares-estimation.html#cb74-8" aria-hidden="true" tabindex="-1"></a>Y     <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> beta1 <span class="sc">*</span> X <span class="sc">+</span> error</span>
<span id="cb74-9"><a href="ordinary-least-squares-estimation.html#cb74-9" aria-hidden="true" tabindex="-1"></a><span class="do">## save simulated data as data frame</span></span>
<span id="cb74-10"><a href="ordinary-least-squares-estimation.html#cb74-10" aria-hidden="true" tabindex="-1"></a>data_sim <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="st">&quot;Y&quot;</span> <span class="ot">=</span> Y, <span class="st">&quot;X&quot;</span> <span class="ot">=</span> X)</span>
<span id="cb74-11"><a href="ordinary-least-squares-estimation.html#cb74-11" aria-hidden="true" tabindex="-1"></a><span class="do">## OLS fit</span></span>
<span id="cb74-12"><a href="ordinary-least-squares-estimation.html#cb74-12" aria-hidden="true" tabindex="-1"></a>lm_obj   <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y<span class="sc">~</span>X, <span class="at">data =</span> data_sim)</span>
<span id="cb74-13"><a href="ordinary-least-squares-estimation.html#cb74-13" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb74-14"><a href="ordinary-least-squares-estimation.html#cb74-14" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot</span></span>
<span id="cb74-15"><a href="ordinary-least-squares-estimation.html#cb74-15" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">family =</span> <span class="st">&quot;serif&quot;</span>)</span>
<span id="cb74-16"><a href="ordinary-least-squares-estimation.html#cb74-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> data_sim<span class="sc">$</span>X, <span class="at">y =</span> data_sim<span class="sc">$</span>Y, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">axes=</span><span class="cn">FALSE</span>, </span>
<span id="cb74-17"><a href="ordinary-least-squares-estimation.html#cb74-17" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="fl">0.8</span>, <span class="at">xlab =</span> <span class="st">&quot;X&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Y&quot;</span>)</span>
<span id="cb74-18"><a href="ordinary-least-squares-estimation.html#cb74-18" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">tick =</span> <span class="cn">FALSE</span>)</span>
<span id="cb74-19"><a href="ordinary-least-squares-estimation.html#cb74-19" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">tick =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb74-20"><a href="ordinary-least-squares-estimation.html#cb74-20" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(lm_obj, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd =</span> <span class="fl">1.3</span>, <span class="at">col=</span><span class="st">&quot;darkorange&quot;</span>)</span>
<span id="cb74-21"><a href="ordinary-least-squares-estimation.html#cb74-21" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> beta0, <span class="at">b =</span> beta1, <span class="at">lwd=</span><span class="fl">1.3</span>, <span class="at">col=</span><span class="st">&quot;darkblue&quot;</span>)</span>
<span id="cb74-22"><a href="ordinary-least-squares-estimation.html#cb74-22" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>,</span>
<span id="cb74-23"><a href="ordinary-least-squares-estimation.html#cb74-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;darkorange&quot;</span>, <span class="st">&quot;darkblue&quot;</span>), </span>
<span id="cb74-24"><a href="ordinary-least-squares-estimation.html#cb74-24" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Sample Regression Line&quot;</span>, </span>
<span id="cb74-25"><a href="ordinary-least-squares-estimation.html#cb74-25" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Population Regression Line&quot;</span>), </span>
<span id="cb74-26"><a href="ordinary-least-squares-estimation.html#cb74-26" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="fl">1.3</span>, <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="at">bty=</span><span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-52-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="ordinary-least-squares-estimation.html#cb75-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-2"><a href="ordinary-least-squares-estimation.html#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimates </span></span>
<span id="cb75-3"><a href="ordinary-least-squares-estimation.html#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(lm_obj)</span>
<span id="cb75-4"><a href="ordinary-least-squares-estimation.html#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)           X </span></span>
<span id="cb75-5"><a href="ordinary-least-squares-estimation.html#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   -1.561339    2.512011</span></span></code></pre></div>
<p>The coefficients have the usual intercept and slope interpretation. That is, for the unknown parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> we have that
<span class="math display">\[\begin{align*}
\dfrac{\partial E[Y | X]}{\partial X} = \beta_1\qquad\text{with}\qquad
E[Y | X] &amp;= \beta_0 + \beta_1 X.
\end{align*}\]</span>
That is, <span class="math inline">\(\beta_1\)</span> is the true (unknown)  of a one unit change in <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>. Therefore, <span class="math inline">\(\hat\beta_1\)</span> is the  of a one unit change in <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>:
<span class="math display">\[\begin{align*}
\widehat{\dfrac{\partial E[Y | X]}{\partial X}} = \hat\beta_1\qquad\text{with}\qquad
\widehat{E[Y | X]} &amp;= \hat\beta_0 + \hat\beta_1 X.
\end{align*}\]</span></p>
</div>
<div id="behavior-of-the-ols-estimates-for-resampled-data-conditionally-on-x_i" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Behavior of the OLS Estimates for Resampled Data (conditionally on <span class="math inline">\(X_i\)</span>)</h3>
Usually, we only observe the  <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> computed for a given data set. However, in order to understand the statistical properties of the  <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> we need to view them as random variables which yield different realizations in repeated samples generated from  conditionally on <span class="math inline">\(X_1,\dots,X_n\)</span>. This allows us then to think about questions like:
<p>A first idea about the statistical properties of the estimators <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> can be gained using Monte Carlo simulations as following.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="ordinary-least-squares-estimation.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Sample sizes</span></span>
<span id="cb76-2"><a href="ordinary-least-squares-estimation.html#cb76-2" aria-hidden="true" tabindex="-1"></a>n_small      <span class="ot">&lt;-</span>  <span class="dv">10</span> <span class="co"># small sample size</span></span>
<span id="cb76-3"><a href="ordinary-least-squares-estimation.html#cb76-3" aria-hidden="true" tabindex="-1"></a>n_large      <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="co"># large sample size</span></span>
<span id="cb76-4"><a href="ordinary-least-squares-estimation.html#cb76-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-5"><a href="ordinary-least-squares-estimation.html#cb76-5" aria-hidden="true" tabindex="-1"></a><span class="do">## True parameter values</span></span>
<span id="cb76-6"><a href="ordinary-least-squares-estimation.html#cb76-6" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb76-7"><a href="ordinary-least-squares-estimation.html#cb76-7" aria-hidden="true" tabindex="-1"></a>beta1 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb76-8"><a href="ordinary-least-squares-estimation.html#cb76-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-9"><a href="ordinary-least-squares-estimation.html#cb76-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate explanatory variables (random design)</span></span>
<span id="cb76-10"><a href="ordinary-least-squares-estimation.html#cb76-10" aria-hidden="true" tabindex="-1"></a>X_n_small  <span class="ot">&lt;-</span> <span class="fu">runif</span>(n_small, <span class="at">min =</span> <span class="dv">1</span>, <span class="at">max =</span> <span class="dv">10</span>)</span>
<span id="cb76-11"><a href="ordinary-least-squares-estimation.html#cb76-11" aria-hidden="true" tabindex="-1"></a>X_n_large  <span class="ot">&lt;-</span> <span class="fu">runif</span>(n_large, <span class="at">min =</span> <span class="dv">1</span>, <span class="at">max =</span> <span class="dv">10</span>)</span>
<span id="cb76-12"><a href="ordinary-least-squares-estimation.html#cb76-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-13"><a href="ordinary-least-squares-estimation.html#cb76-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Monte-Carlo (MC) Simulation </span></span>
<span id="cb76-14"><a href="ordinary-least-squares-estimation.html#cb76-14" aria-hidden="true" tabindex="-1"></a><span class="do">## 1. Generate data</span></span>
<span id="cb76-15"><a href="ordinary-least-squares-estimation.html#cb76-15" aria-hidden="true" tabindex="-1"></a><span class="do">## 2. Compute and store estimates</span></span>
<span id="cb76-16"><a href="ordinary-least-squares-estimation.html#cb76-16" aria-hidden="true" tabindex="-1"></a><span class="do">## Repeat steps 1. and 2. many times</span></span>
<span id="cb76-17"><a href="ordinary-least-squares-estimation.html#cb76-17" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb76-18"><a href="ordinary-least-squares-estimation.html#cb76-18" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Monte Carlo repetitions</span></span>
<span id="cb76-19"><a href="ordinary-least-squares-estimation.html#cb76-19" aria-hidden="true" tabindex="-1"></a><span class="do">## How many samples to draw from the models</span></span>
<span id="cb76-20"><a href="ordinary-least-squares-estimation.html#cb76-20" aria-hidden="true" tabindex="-1"></a>rep          <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb76-21"><a href="ordinary-least-squares-estimation.html#cb76-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-22"><a href="ordinary-least-squares-estimation.html#cb76-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Containers to store the lm-results</span></span>
<span id="cb76-23"><a href="ordinary-least-squares-estimation.html#cb76-23" aria-hidden="true" tabindex="-1"></a>n_small_list <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="at">mode =</span> <span class="st">&quot;list&quot;</span>, <span class="at">length =</span> rep)</span>
<span id="cb76-24"><a href="ordinary-least-squares-estimation.html#cb76-24" aria-hidden="true" tabindex="-1"></a>n_large_list <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="at">mode =</span> <span class="st">&quot;list&quot;</span>, <span class="at">length =</span> rep)</span>
<span id="cb76-25"><a href="ordinary-least-squares-estimation.html#cb76-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-26"><a href="ordinary-least-squares-estimation.html#cb76-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>rep){</span>
<span id="cb76-27"><a href="ordinary-least-squares-estimation.html#cb76-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Sampling from the model conditionally on X_n_small</span></span>
<span id="cb76-28"><a href="ordinary-least-squares-estimation.html#cb76-28" aria-hidden="true" tabindex="-1"></a>error_n_small     <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_small, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb76-29"><a href="ordinary-least-squares-estimation.html#cb76-29" aria-hidden="true" tabindex="-1"></a>Y_n_small         <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> beta1 <span class="sc">*</span> X_n_small <span class="sc">+</span> error_n_small</span>
<span id="cb76-30"><a href="ordinary-least-squares-estimation.html#cb76-30" aria-hidden="true" tabindex="-1"></a>n_small_list[[r]] <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y_n_small <span class="sc">~</span> X_n_small)  </span>
<span id="cb76-31"><a href="ordinary-least-squares-estimation.html#cb76-31" aria-hidden="true" tabindex="-1"></a><span class="do">## Sampling from the model conditionally on X_n_large</span></span>
<span id="cb76-32"><a href="ordinary-least-squares-estimation.html#cb76-32" aria-hidden="true" tabindex="-1"></a>error_n_large     <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_large, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb76-33"><a href="ordinary-least-squares-estimation.html#cb76-33" aria-hidden="true" tabindex="-1"></a>Y_n_large         <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> beta1 <span class="sc">*</span> X_n_large <span class="sc">+</span> error_n_large</span>
<span id="cb76-34"><a href="ordinary-least-squares-estimation.html#cb76-34" aria-hidden="true" tabindex="-1"></a>n_large_list[[r]] <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y_n_large <span class="sc">~</span> X_n_large)  </span>
<span id="cb76-35"><a href="ordinary-least-squares-estimation.html#cb76-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb76-36"><a href="ordinary-least-squares-estimation.html#cb76-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-37"><a href="ordinary-least-squares-estimation.html#cb76-37" aria-hidden="true" tabindex="-1"></a><span class="do">## Reading out the parameter estimates</span></span>
<span id="cb76-38"><a href="ordinary-least-squares-estimation.html#cb76-38" aria-hidden="true" tabindex="-1"></a>beta0_estimates_n_small <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, rep)</span>
<span id="cb76-39"><a href="ordinary-least-squares-estimation.html#cb76-39" aria-hidden="true" tabindex="-1"></a>beta1_estimates_n_small <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, rep)</span>
<span id="cb76-40"><a href="ordinary-least-squares-estimation.html#cb76-40" aria-hidden="true" tabindex="-1"></a>beta0_estimates_n_large <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, rep)</span>
<span id="cb76-41"><a href="ordinary-least-squares-estimation.html#cb76-41" aria-hidden="true" tabindex="-1"></a>beta1_estimates_n_large <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, rep)</span>
<span id="cb76-42"><a href="ordinary-least-squares-estimation.html#cb76-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>rep){</span>
<span id="cb76-43"><a href="ordinary-least-squares-estimation.html#cb76-43" aria-hidden="true" tabindex="-1"></a>beta0_estimates_n_small[r] <span class="ot">&lt;-</span> n_small_list[[r]]<span class="sc">$</span>coefficients[<span class="dv">1</span>]</span>
<span id="cb76-44"><a href="ordinary-least-squares-estimation.html#cb76-44" aria-hidden="true" tabindex="-1"></a>beta1_estimates_n_small[r] <span class="ot">&lt;-</span> n_small_list[[r]]<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb76-45"><a href="ordinary-least-squares-estimation.html#cb76-45" aria-hidden="true" tabindex="-1"></a>beta0_estimates_n_large[r] <span class="ot">&lt;-</span> n_large_list[[r]]<span class="sc">$</span>coefficients[<span class="dv">1</span>]</span>
<span id="cb76-46"><a href="ordinary-least-squares-estimation.html#cb76-46" aria-hidden="true" tabindex="-1"></a>beta1_estimates_n_large[r] <span class="ot">&lt;-</span> n_large_list[[r]]<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb76-47"><a href="ordinary-least-squares-estimation.html#cb76-47" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Now, we have produced realizations of the estimators <span class="math inline">\(\hat\beta_0|X\)</span> and <span class="math inline">\(\hat\beta_1|X\)</span> conditionally on <span class="math display">\[X=\begin{pmatrix}1&amp;X_1\\\vdots&amp;\vdots\\1&amp;X_n\end{pmatrix}\]</span>
and we have saved these realizations in <code>beta0_estimates_n_small</code>, <code>beta1_estimates_n_small</code>, <code>beta0_estimates_n_large</code>, and 
<code>beta1_estimates_n_large</code>. This allows us to visualize the behavior of the OLS estimates for the repeatedly sampled data (conditionally on <span class="math inline">\(X_i\)</span>).</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="ordinary-least-squares-estimation.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plotting the results</span></span>
<span id="cb77-2"><a href="ordinary-least-squares-estimation.html#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;scales&quot;</span>) <span class="co"># alpha() produces transparent colors</span></span>
<span id="cb77-3"><a href="ordinary-least-squares-estimation.html#cb77-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-4"><a href="ordinary-least-squares-estimation.html#cb77-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Define a common y-axis range</span></span>
<span id="cb77-5"><a href="ordinary-least-squares-estimation.html#cb77-5" aria-hidden="true" tabindex="-1"></a>y_range <span class="ot">&lt;-</span> <span class="fu">range</span>(beta0_estimates_n_small,</span>
<span id="cb77-6"><a href="ordinary-least-squares-estimation.html#cb77-6" aria-hidden="true" tabindex="-1"></a>                 beta1_estimates_n_small)<span class="sc">*</span><span class="fl">1.1</span></span>
<span id="cb77-7"><a href="ordinary-least-squares-estimation.html#cb77-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-8"><a href="ordinary-least-squares-estimation.html#cb77-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate the plot</span></span>
<span id="cb77-9"><a href="ordinary-least-squares-estimation.html#cb77-9" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">family =</span> <span class="st">&quot;serif&quot;</span>) <span class="co"># Serif fonts</span></span>
<span id="cb77-10"><a href="ordinary-least-squares-estimation.html#cb77-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Layout of plotting area</span></span>
<span id="cb77-11"><a href="ordinary-least-squares-estimation.html#cb77-11" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>), <span class="dv">2</span>, <span class="dv">3</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>), <span class="at">widths =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb77-12"><a href="ordinary-least-squares-estimation.html#cb77-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot 1</span></span>
<span id="cb77-13"><a href="ordinary-least-squares-estimation.html#cb77-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span><span class="dv">0</span>, <span class="at">axes=</span><span class="cn">FALSE</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Y&quot;</span>, <span class="at">type=</span><span class="st">&quot;n&quot;</span>,</span>
<span id="cb77-14"><a href="ordinary-least-squares-estimation.html#cb77-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">10</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">35</span>), <span class="at">main=</span><span class="st">&quot;Small Sample (n=10)&quot;</span>)</span>
<span id="cb77-15"><a href="ordinary-least-squares-estimation.html#cb77-15" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">tick =</span> <span class="cn">FALSE</span>); <span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">tick =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb77-16"><a href="ordinary-least-squares-estimation.html#cb77-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>rep){</span>
<span id="cb77-17"><a href="ordinary-least-squares-estimation.html#cb77-17" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(n_small_list[[r]], <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd =</span> <span class="fl">1.3</span>, <span class="at">col=</span><span class="st">&quot;darkorange&quot;</span>)</span>
<span id="cb77-18"><a href="ordinary-least-squares-estimation.html#cb77-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb77-19"><a href="ordinary-least-squares-estimation.html#cb77-19" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> beta0, <span class="at">b =</span> beta1, <span class="at">lwd=</span><span class="fl">1.3</span>, <span class="at">col=</span><span class="st">&quot;darkblue&quot;</span>)</span>
<span id="cb77-20"><a href="ordinary-least-squares-estimation.html#cb77-20" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;darkorange&quot;</span>, <span class="st">&quot;darkblue&quot;</span>), <span class="at">legend=</span><span class="fu">c</span>(</span>
<span id="cb77-21"><a href="ordinary-least-squares-estimation.html#cb77-21" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;Sample regression lines from</span><span class="sc">\n</span><span class="st">repeated samples (cond. on X)&quot;</span>, </span>
<span id="cb77-22"><a href="ordinary-least-squares-estimation.html#cb77-22" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&quot;Population regression line&quot;</span>), </span>
<span id="cb77-23"><a href="ordinary-least-squares-estimation.html#cb77-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="fl">1.3</span>, <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="at">bty=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb77-24"><a href="ordinary-least-squares-estimation.html#cb77-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot 2</span></span>
<span id="cb77-25"><a href="ordinary-least-squares-estimation.html#cb77-25" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">rep</span>(<span class="dv">0</span>,rep), <span class="at">y=</span>beta0_estimates_n_small, <span class="at">axes=</span><span class="cn">FALSE</span>, </span>
<span id="cb77-26"><a href="ordinary-least-squares-estimation.html#cb77-26" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">pch=</span><span class="dv">19</span>, <span class="at">cex=</span><span class="fl">1.2</span>, <span class="at">ylim=</span>y_range,</span>
<span id="cb77-27"><a href="ordinary-least-squares-estimation.html#cb77-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">main=</span><span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">0</span>]<span class="sc">~</span><span class="st">&#39;|&#39;</span><span class="sc">~</span>X), <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">&quot;red&quot;</span>,<span class="fl">0.2</span>))</span>
<span id="cb77-28"><a href="ordinary-least-squares-estimation.html#cb77-28" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> <span class="dv">0</span>, <span class="at">y=</span>beta0, <span class="at">pch=</span><span class="st">&quot;-&quot;</span>, <span class="at">cex =</span> <span class="fl">1.2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span>
<span id="cb77-29"><a href="ordinary-least-squares-estimation.html#cb77-29" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span>beta0, <span class="at">labels =</span> <span class="fu">expression</span>(beta[<span class="dv">0</span>]), <span class="at">pos =</span> <span class="dv">4</span>)</span>
<span id="cb77-30"><a href="ordinary-least-squares-estimation.html#cb77-30" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot 3</span></span>
<span id="cb77-31"><a href="ordinary-least-squares-estimation.html#cb77-31" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">rep</span>(<span class="dv">0</span>,rep), <span class="at">y=</span>beta1_estimates_n_small, <span class="at">axes=</span><span class="cn">FALSE</span>, </span>
<span id="cb77-32"><a href="ordinary-least-squares-estimation.html#cb77-32" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">pch=</span><span class="dv">19</span>, <span class="at">cex=</span><span class="fl">1.2</span>, <span class="at">ylim=</span>y_range,</span>
<span id="cb77-33"><a href="ordinary-least-squares-estimation.html#cb77-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">main=</span><span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">1</span>]<span class="sc">~</span><span class="st">&#39;|&#39;</span><span class="sc">~</span>X), <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">&quot;red&quot;</span>,<span class="fl">0.2</span>))</span>
<span id="cb77-34"><a href="ordinary-least-squares-estimation.html#cb77-34" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> <span class="dv">0</span>, <span class="at">y=</span>beta1, <span class="at">pch=</span><span class="st">&quot;-&quot;</span>, <span class="at">cex =</span> <span class="fl">1.2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span>
<span id="cb77-35"><a href="ordinary-least-squares-estimation.html#cb77-35" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span>beta1, <span class="at">labels =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">pos =</span> <span class="dv">4</span>)</span>
<span id="cb77-36"><a href="ordinary-least-squares-estimation.html#cb77-36" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot 4</span></span>
<span id="cb77-37"><a href="ordinary-least-squares-estimation.html#cb77-37" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span><span class="dv">0</span>, <span class="at">axes=</span><span class="cn">FALSE</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Y&quot;</span>, <span class="at">type=</span><span class="st">&quot;n&quot;</span>,</span>
<span id="cb77-38"><a href="ordinary-least-squares-estimation.html#cb77-38" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">10</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">35</span>), <span class="at">main=</span><span class="st">&quot;Large Sample (n=100)&quot;</span>)</span>
<span id="cb77-39"><a href="ordinary-least-squares-estimation.html#cb77-39" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>, <span class="at">tick =</span> <span class="cn">FALSE</span>); <span class="fu">axis</span>(<span class="dv">2</span>, <span class="at">tick =</span> <span class="cn">FALSE</span>, <span class="at">las =</span> <span class="dv">2</span>)</span>
<span id="cb77-40"><a href="ordinary-least-squares-estimation.html#cb77-40" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>rep){</span>
<span id="cb77-41"><a href="ordinary-least-squares-estimation.html#cb77-41" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(n_large_list[[r]], <span class="at">lty=</span><span class="dv">2</span>, <span class="at">lwd =</span> <span class="fl">1.3</span>, <span class="at">col=</span><span class="st">&quot;darkorange&quot;</span>)</span>
<span id="cb77-42"><a href="ordinary-least-squares-estimation.html#cb77-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb77-43"><a href="ordinary-least-squares-estimation.html#cb77-43" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> beta0, <span class="at">b =</span> beta1, <span class="at">lwd=</span><span class="fl">1.3</span>, <span class="at">col=</span><span class="st">&quot;darkblue&quot;</span>)</span>
<span id="cb77-44"><a href="ordinary-least-squares-estimation.html#cb77-44" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot 5</span></span>
<span id="cb77-45"><a href="ordinary-least-squares-estimation.html#cb77-45" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">rep</span>(<span class="dv">0</span>,rep), <span class="at">y=</span>beta0_estimates_n_large, <span class="at">axes=</span><span class="cn">FALSE</span>, </span>
<span id="cb77-46"><a href="ordinary-least-squares-estimation.html#cb77-46" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">pch=</span><span class="dv">19</span>, <span class="at">cex=</span><span class="fl">1.2</span>, <span class="at">ylim=</span>y_range,</span>
<span id="cb77-47"><a href="ordinary-least-squares-estimation.html#cb77-47" aria-hidden="true" tabindex="-1"></a>  <span class="at">main=</span><span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">0</span>]<span class="sc">~</span><span class="st">&#39;|&#39;</span><span class="sc">~</span>X), <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">&quot;red&quot;</span>,<span class="fl">0.2</span>))</span>
<span id="cb77-48"><a href="ordinary-least-squares-estimation.html#cb77-48" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> <span class="dv">0</span>, <span class="at">y=</span>beta0, <span class="at">pch=</span><span class="st">&quot;-&quot;</span>, <span class="at">cex =</span> <span class="fl">1.2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span>
<span id="cb77-49"><a href="ordinary-least-squares-estimation.html#cb77-49" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span>beta0, <span class="at">labels =</span> <span class="fu">expression</span>(beta[<span class="dv">0</span>]), <span class="at">pos =</span> <span class="dv">4</span>)</span>
<span id="cb77-50"><a href="ordinary-least-squares-estimation.html#cb77-50" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot 6</span></span>
<span id="cb77-51"><a href="ordinary-least-squares-estimation.html#cb77-51" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">rep</span>(<span class="dv">0</span>,rep), <span class="at">y=</span>beta1_estimates_n_large, <span class="at">axes=</span><span class="cn">FALSE</span>, </span>
<span id="cb77-52"><a href="ordinary-least-squares-estimation.html#cb77-52" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">pch=</span><span class="dv">19</span>, <span class="at">cex=</span><span class="fl">1.2</span>, <span class="at">ylim=</span>y_range,</span>
<span id="cb77-53"><a href="ordinary-least-squares-estimation.html#cb77-53" aria-hidden="true" tabindex="-1"></a>  <span class="at">main=</span><span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">1</span>]<span class="sc">~</span><span class="st">&#39;|&#39;</span><span class="sc">~</span>X), <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">&quot;red&quot;</span>,<span class="fl">0.2</span>))</span>
<span id="cb77-54"><a href="ordinary-least-squares-estimation.html#cb77-54" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span>beta1, <span class="at">pch=</span><span class="st">&quot;-&quot;</span>, <span class="at">cex =</span> <span class="fl">1.2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span>
<span id="cb77-55"><a href="ordinary-least-squares-estimation.html#cb77-55" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span>beta1, <span class="at">labels =</span> <span class="fu">expression</span>(beta[<span class="dv">1</span>]), <span class="at">pos =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="Script_Econometrics_MSc_files/figure-html/unnamed-chunk-54-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
This are promising plots:
<p>However, this was only a simulation for one specific data generating process. Such a Monte Carlo simulation does not allow us to generalize these properties. Next we use theoretical arguments to show that these properties also hold in general.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-simple-linear-regression-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="properties-of-the-ols-estimator.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Script_Econometrics_MSc.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed",
"download": "https://uni-bonn.sciebo.de/s/IZ2yeLeA4dRTFUY",
"search": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
