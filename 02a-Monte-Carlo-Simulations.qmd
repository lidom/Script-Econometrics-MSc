# Monte Carlo Simulations



In the following parts of the lecture, we will use Monte Carlo simulations in oder to check whether a certain estimator is able to estimate its (usually unknown) target parameter. In this chapter, we will learn what Monte Carlo simulations are and how they can be implemented. 

Let's assume that we have an iid random sample $X_1,\dots,X_n$ with $X_i\sim f_X$ for all $i=1,\dots,n$, and let $\theta\in\mathbb{R}$ denote some parameter (e.g. the mean or the variance) of the density $f_X$. An estimator $\hat\theta_n$ of $\theta$, can (and should be) thought of as a function of the random sample $X_1,\dots,X_n$,
$$
\hat\theta_n:=\hat\theta(X_1,\dots,X_n).
$$

Any reasonable estimator $\hat\theta_n$ should be able to approximate the (usually unknown) parameter value $\theta$
$$
\hat\theta_n\approx\theta,
$$
and the approximation should become better as the sample size increases (i.e. as $n\to\infty$). 

Statisticians and econometricians use different metrics to assess the approximation quality of an estimator $\hat\theta_n$. 

::: {#def-bias}

## Bias

The bias of an estimator $\hat\theta_n$ is defined as

$$
\operatorname{Bias}\left(\hat\theta_n\right) = \hat\theta_n
$$

:::


like, for instance, the arithmetic mean  
$$
\bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i
$$
as an estimator of the population mean value $\mu$. 


Let $X_1,\dots,X_n\overset{iid}{\sim}$