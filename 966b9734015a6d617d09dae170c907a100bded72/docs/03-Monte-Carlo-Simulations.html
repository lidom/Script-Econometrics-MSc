<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Econometrics M.Sc. - 3&nbsp; Estimation Theory and Monte Carlo Simulations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./04-Multiple-Linear-Regression.html" rel="next">
<link href="./02-Probability.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Estimation Theory and Monte Carlo Simulations</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./" class="sidebar-logo-link">
      <img src="./images/Uni_Bonn_Logo.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Econometrics M.Sc.</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Organization of the Course</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-Introduction-to-R.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-Probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-Monte-Carlo-Simulations.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Estimation Theory and Monte Carlo Simulations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-Multiple-Linear-Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-Small-Sample-Inference.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Small Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-Asymptotics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Large Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-Instrumental-Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Instrumental Variables</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#estimator-vs.-estimate" id="toc-estimator-vs.-estimate" class="nav-link active" data-scroll-target="#estimator-vs.-estimate"><span class="toc-section-number">3.1</span>  Estimator vs.&nbsp;Estimate</a></li>
  <li><a href="#deriving-the-distribution-of-estimators" id="toc-deriving-the-distribution-of-estimators" class="nav-link" data-scroll-target="#deriving-the-distribution-of-estimators"><span class="toc-section-number">3.2</span>  Deriving the Distribution of Estimators</a>
  <ul class="collapse">
  <li><a href="#sec-ExampleSampleMean" id="toc-sec-ExampleSampleMean" class="nav-link" data-scroll-target="#sec-ExampleSampleMean"><span class="toc-section-number">3.2.1</span>  Example: Sample Mean <span class="math inline">\(\bar{X}_n\)</span></a></li>
  </ul></li>
  <li><a href="#assessing-the-quality-of-estimators" id="toc-assessing-the-quality-of-estimators" class="nav-link" data-scroll-target="#assessing-the-quality-of-estimators"><span class="toc-section-number">3.3</span>  Assessing the Quality of Estimators</a>
  <ul class="collapse">
  <li><a href="#approximating-bias-variance-and-mse-using-mc-simulations" id="toc-approximating-bias-variance-and-mse-using-mc-simulations" class="nav-link" data-scroll-target="#approximating-bias-variance-and-mse-using-mc-simulations"><span class="toc-section-number">3.3.1</span>  Approximating Bias, Variance, and MSE using MC Simulations</a></li>
  <li><a href="#example-revisited-sample-mean" id="toc-example-revisited-sample-mean" class="nav-link" data-scroll-target="#example-revisited-sample-mean">Example (revisited): Sample Mean</a></li>
  <li><a href="#comparing-the-mc-results-with-the-theoretical-bias-variance-and-mse-of-the-sample-mean" id="toc-comparing-the-mc-results-with-the-theoretical-bias-variance-and-mse-of-the-sample-mean" class="nav-link" data-scroll-target="#comparing-the-mc-results-with-the-theoretical-bias-variance-and-mse-of-the-sample-mean">Comparing the MC-Results with the theoretical bias, variance, and mse of the sample mean</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="toc-section-number">3.4</span>  Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Estimation Theory and Monte Carlo Simulations</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>Learning outcomes of this chapter:</p>
<ul>
<li>You know the basic concepts of estimation theory and you can apply them to specific estimators.
<ul>
<li>Estimate vs estimator</li>
<li>Estimator’s distribution, bias, variance, and standard error</li>
</ul></li>
<li>You know how to use a Monte Carlo simulation to check the accuracy (bias, variance, and standard error) of a given (simple) estimator</li>
</ul>
<section id="estimator-vs.-estimate" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="estimator-vs.-estimate"><span class="header-section-number">3.1</span> Estimator vs.&nbsp;Estimate</h2>
<p>Let’s assume that we have an iid random sample <span class="math inline">\(\{X_1,\dots,X_n\}\)</span> with <span class="math display">\[
X_i\overset{iid}{\sim} F_X
\]</span> for all <span class="math inline">\(i=1,\dots,n\)</span>, and let <span class="math inline">\(\theta\in\mathbb{R}\)</span> denote some parameter (e.g.&nbsp;the mean or the variance) of the distribution <span class="math inline">\(F_X\)</span>.</p>
<p>An <strong>estimator</strong> <span class="math inline">\(\hat\theta_n\)</span> of <span class="math inline">\(\theta\)</span> is a function of the random sample <span class="math inline">\(X_1,\dots,X_n\)</span>, <span class="math display">\[
\hat\theta_n:=\hat\theta(X_1,\dots,X_n).
\]</span></p>
<p>Since <span class="math inline">\(\hat\theta_n\)</span> is a function of the random variables <span class="math inline">\(X_1,\dots,X_n\)</span>, the estimator <span class="math inline">\(\hat\theta_n\)</span> is itself a <strong>random variable</strong>.</p>
<p>The observed data <span class="math inline">\(X_{1,obs},\dots,X_{n,obs}\)</span> is assumed to be a certain realization of the random sample <span class="math inline">\(X_1,\dots,X_n\)</span>. The corresponding <strong>realization</strong> of the estimator is called an <strong>estimate</strong> of <span class="math inline">\(\theta\)</span> <span class="math display">\[
\hat\theta_{n,obs}=\hat\theta(X_{1,obs},\dots,X_{n,obs}).
\]</span></p>
<p><strong>Examples:</strong></p>
<ul>
<li><p>The sample mean as an estimator of the population mean <span class="math inline">\(E(X_i) =\theta\)</span>: <span class="math display">\[
\hat\theta_n=\bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i
\]</span></p></li>
<li><p>The sample variance as an estimator of the population variance <span class="math inline">\(Var(X_i) =\theta\)</span>: <span class="math display">\[
\hat\theta_n=s_{UB}^2=\frac{1}{n-1}\sum_{i=1}^n\left(X_i - \bar{X}_n\right)^2
\]</span></p></li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Often we do not use a distinguishing notation, but denote both the estimator and its realization as <span class="math inline">\(\hat\theta_{n}\)</span>. This ambiguity is often convenient since both points of views can make sense in a given context.</p>
</div>
</div>
</section>
<section id="deriving-the-distribution-of-estimators" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="deriving-the-distribution-of-estimators"><span class="header-section-number">3.2</span> Deriving the Distribution of Estimators</h2>
<p>Usually, we do not know the distribution <span class="math inline">\(F_X\)</span> of the random sample <span class="math inline">\(X_1,\dots,X_n\)</span> and thus we neither know the value of <span class="math inline">\(\theta\)</span> nor the distribution of the estimator <span class="math display">\[
\hat\theta_n=\hat\theta(X_1,\dots,X_n).
\]</span> This is the fundamental statistical problem that we need to overcome in statistical inference (estimating <span class="math inline">\(\theta\)</span>, hypothesis testing about <span class="math inline">\(\theta\)</span>, etc.).</p>
<p>There are (roughly) three different possibilities to derive/approximate the distribution of an estimator <span class="math inline">\(\hat\theta_n:\)</span></p>
<ul>
<li><strong>Option 1: Mathematical derivation using a <em>complete</em> distributional assumption on <span class="math inline">\(F_X\)</span>.</strong> Assuming a certain distribution <span class="math inline">\(F_X\)</span> for the random sample <span class="math inline">\(X_1,\dots,X_n\)</span> may allow us to derive mathematically the <em>exact</em> distribution of <span class="math inline">\(\hat\theta_n\)</span> for given sample sizes <span class="math inline">\(n.\)</span><br> ➡️ We consider this option in <a href="05-Small-Sample-Inference.html"><span>Chapter&nbsp;5</span></a>.
<ul>
<li>Pro: If the distributional assumption is correct, one has <em>exact</em> inference for each sample size <span class="math inline">\(n\)</span>.</li>
<li>Con: This option can fail miserably if the distributional assumption on <span class="math inline">\(F_X\)</span> is wrong.</li>
<li>Con: This option is often only possible for rather simple distributions <span class="math inline">\(F_X\)</span> like the normal distribution.</li>
</ul></li>
<li><strong>Option 2: Mathematical derivation using only an <em>incomplete</em> distributional assumption on <span class="math inline">\(F_X\)</span> and asymptotic statistics.</strong> Large sample <span class="math inline">\((n\to\infty)\)</span> approximations (i.e.&nbsp;laws of large numbers and central limit theorems) often allows us to derive the <em>approximate</em> distribution of <span class="math inline">\(\hat\theta_n\)</span> for large sample sizes <span class="math inline">\(n.\)</span><br> ➡️ We consider this option in <a href="06-Asymptotics.html"><span>Chapter&nbsp;6</span></a>.
<ul>
<li>Pro: Only a few qualitative distributional assumptions are needed. (Typically: A random sample with finite variances.)<br>
</li>
<li>Con: The derived asymptotic (<span class="math inline">\(n\to\infty\)</span>) distribution is only exact for the practically impossible case where <span class="math inline">\(n=\infty\)</span> and thus can fail to approximate the exact distribution of <span class="math inline">\(\hat\theta_n\)</span> for given (finite) sample sizes <span class="math inline">\(n\)</span>; particularly if <span class="math inline">\(n\)</span> is small.</li>
</ul></li>
<li><strong>Option 3: Monte Carlo (MC) Simulations using a <em>complete</em> distributional assumption on <span class="math inline">\(F_X\)</span>.</strong> Assuming a certain distribution <span class="math inline">\(F_X\)</span> for the random sample <span class="math inline">\(X_1,\dots,X_n\)</span> we can approximate (with arbitrary precision) the <em>exact</em> distribution of <span class="math inline">\(\hat\theta_n\)</span> for given sample sizes <span class="math inline">\(n;\)</span> see the Algorithm “MC-Simulation”. <br> ➡️ We use this option to check the behavior of estimators under different scenarios for <span class="math inline">\(F_X\)</span> and <span class="math inline">\(n\)</span> throughout the rest of this script.<br>
<ul>
<li>Pro: Works for a basically every distribution <span class="math inline">\(F_X\)</span> and sample size <span class="math inline">\(n.\)</span><br>
</li>
<li>Con: This option can fail miserably if the distributional assumption on <span class="math inline">\(F_X\)</span> is wrong.</li>
</ul></li>
</ul>
<p><strong>Algorithm “MC-Simulation”:</strong><br> <strong>1. Step: Generate realizations of <span class="math inline">\(\hat{\theta}_n\)</span>.</strong> Use a (pseudo-)random number generator to draw a large number of <span class="math inline">\(B\)</span> (e.g.&nbsp;<span class="math inline">\(B=10,000\)</span>) many realizations of the random sample <span class="math inline">\(\{X_1,\dots,X_n\}\)</span> for a given distribution <span class="math inline">\(F_X\)</span> and a given sample size <span class="math inline">\(n:\)</span> <span class="math display">\[\begin{align*}
&amp;(X_{1,1,obs},\dots,X_{n,1,obs})\\
&amp;(X_{1,2,obs},\dots,X_{n,2,obs})\\
&amp; \hspace{2cm}\vdots \\
&amp;(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}\]</span> Compute for each realization of the random sample a realization of <span class="math inline">\(\hat{\theta}_n:\)</span> <span class="math display">\[\begin{align*}
\hat\theta_{n,1,obs} &amp;= \hat\theta(X_{1,1,obs},\dots,X_{n,1,obs})\\
\hat\theta_{n,2,obs} &amp;= \hat\theta(X_{1,2,obs},\dots,X_{n,2,obs})\\
&amp;\vdots\\
\hat\theta_{n,B,obs} &amp;= \hat\theta(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}\]</span> <strong>2. Step: Approximate the distribution of <span class="math inline">\(\hat{\theta}_n\)</span> (or a features of it).</strong> Use the realizations <span class="math inline">\(\hat\theta_{n,1,obs},\dots,\hat\theta_{n,B,obs}\)</span> to approximate the exact distribution of <span class="math inline">\(\hat\theta_n\)</span> for a given <span class="math inline">\(F_X\)</span> and a give sample size <span class="math inline">\(n.\)</span><br></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Step 2 of the above algorithm works, since the empirical distribution function <span class="math display">\[
\hat{F}_{\hat{\theta}_n,B}(x)=\frac{1}{B}\sum_{j=1}^BI_{(\hat\theta_{n,1,obs} \leq x)}
\]</span> approximates the true (unknown) distribution function of <span class="math inline">\(\hat{\theta}_n\)</span> <span class="math display">\[
F_{\hat{\theta}_n}(x)=P(\hat\theta_{n} \leq x)
\]</span> arbitrarily well as <span class="math inline">\(B\to\infty.\)</span></p>
<p>This hold true, since by the famous <a href="https://en.wikipedia.org/wiki/Glivenko%E2%80%93Cantelli_theorem">Glivenko–Cantelli theorem</a><br>
<span class="math display">\[
\sup_x\left| \hat{F}_{\hat{\theta}_n,B}(x) - F_{\hat{\theta}_n}(x)\right|\to 0\quad\text{as}\quad B\to\infty.
\]</span> almost surely as <span class="math inline">\(B\to\infty.\)</span></p>
<p>Instead of approximating the whole distribution of <span class="math inline">\(\hat{\theta}_n,\)</span> we may only be interested in approximating specific features of the this distribution, such as:</p>
<ul>
<li>the bias of <span class="math inline">\(\hat{\theta}_n\)</span></li>
<li>the variance of <span class="math inline">\(\hat{\theta}_n\)</span></li>
<li>the standard error of <span class="math inline">\(\hat{\theta}_n\)</span></li>
<li>the mean squared error of <span class="math inline">\(\hat{\theta}_n\)</span></li>
<li>etc.</li>
</ul>
<p><strong>Note:</strong> These features are simple functionals of <span class="math inline">\(\hat{F}_{\hat{\theta}_n,B},\)</span> and thus can also be approximated arbitrarily well as <span class="math inline">\(B\to\infty.\)</span></p>
</div>
</div>
<section id="sec-ExampleSampleMean" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="sec-ExampleSampleMean"><span class="header-section-number">3.2.1</span> Example: Sample Mean <span class="math inline">\(\bar{X}_n\)</span></h3>
<p>Let <span class="math inline">\(\{X_1,\dots,X_n\}\)</span> be an iid random sample with <span class="math display">\[
X_i\overset{iid}{\sim} F_X,
\]</span> where</p>
<ul>
<li><span class="math inline">\(F_X\)</span> is a normal distribution <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span> with
<ul>
<li>mean <span class="math inline">\((\theta=)\mu=10\)</span> and</li>
<li>variance <span class="math inline">\(\sigma^2=5\)</span>.</li>
</ul></li>
</ul>
<p>To estimate the (usually unknown) mean value <span class="math inline">\(\mu=10,\)</span> we use the sample mean estimator <span class="math display">\[
\bar{X}_n =  \frac{1}{n}\sum_{i=1}^n X_i
\]</span></p>
<p>We consider two sample sizes <span class="math inline">\(n=5\)</span> and <span class="math inline">\(n=50.\)</span></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Mathematical Derivation using the Distributional Assumptions
</div>
</div>
<div class="callout-body-container callout-body">
<p>Here we have specified the distribution <span class="math inline">\(F_X\)</span> completely by setting <span class="math inline">\(F_X=\mathcal{N}(\mu=10,\sigma^2=5).\)</span> This is such a simple case, that we can actually use mathematical derivations to derive the distribution of <span class="math inline">\(\bar{X}_n.\)</span> (Often, this is not possible.)</p>
<p>Observe that since <span class="math inline">\(X_i\overset{\text{iid}}{\sim}\mathcal{N}(\mu,\sigma^2),\)</span> <span class="math display">\[
\sum_{i=1}^nX_i\sim\mathcal{N}(n \mu, n \sigma^2).
\]</span> Multiplying by <span class="math inline">\(\frac{1}{n}\)</span> yields <span class="math display">\[\begin{align*}
\frac{1}{n}\sum_{i=1}^nX_i = \bar{X}_n
&amp;\sim\mathcal{N}\left(\frac{1}{n}n \mu, \frac{1}{n^2}n \sigma^2\right)\\[2ex]
\bar{X}_n &amp;\sim\mathcal{N}\left( \mu, \frac{1}{n} \sigma^2\right).
\end{align*}\]</span></p>
<p><strong>Summing up:</strong> If <span class="math inline">\(X_i\overset{iid}{\sim}\mathcal{N}(\mu,\sigma^2),\)</span> then the exact (exact for each <span class="math inline">\(n\)</span>) distribution of <span class="math inline">\(\bar{X}_n\)</span> is given by <span class="math display">\[
\bar{X}_n\sim\mathcal{N}\left( \mu, \frac{1}{n} \sigma^2\right).
\]</span></p>
<ul>
<li>For <span class="math inline">\(\mu=10,\)</span> <span class="math inline">\(\sigma=5,\)</span> <span class="math inline">\(n=5\)</span>: <span class="math display">\[
\bar{X}_n\sim\mathcal{N}\left(10, 1\right).
\]</span></li>
<li>For <span class="math inline">\(\mu=10,\)</span> <span class="math inline">\(\sigma=5,\)</span> <span class="math inline">\(n=50\)</span>: <span class="math display">\[
\bar{X}_n\sim\mathcal{N}\left(10, 0.1\right).
\]</span></li>
</ul>
<p>⚠️ Unfortunately, such a mathematical derivation works only for very simple estimators and only for simple (and completely specified) distributions <span class="math inline">\(F_X.\)</span></p>
<p>🤓 But for this special case, we can now check, whether a Monte Carlo simulation is able to approximate the distribution of <span class="math inline">\(\bar{X}_n\sim\mathcal{N}\left( \mu, \frac{1}{n} \sigma^2\right).\)</span></p>
</div>
</div>
<p>Next, we use a Monte Carlo simulation to approximate the distribution of the estimator <span class="math display">\[
\bar{X}_n =  \frac{1}{n}\sum_{i=1}^n X_i.
\]</span></p>
<p>The following <code>R</code> code generates <span class="math inline">\(B=10,000\)</span> many realizations of the random sample <span class="math inline">\(X_i\overset{iid}{\sim}\mathcal{N}(\mu,\sigma^2)\)</span> with <span class="math inline">\(\mu=10\)</span> and <span class="math inline">\(\sigma^2=5.\)</span></p>
<p><span class="math display">\[\begin{align*}
&amp;(X_{1,1,obs},\dots,X_{n,1,obs})\\
&amp;(X_{1,2,obs},\dots,X_{n,2,obs})\\
&amp; \hspace{2cm}\vdots \\
&amp;(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}\]</span> leading to <span class="math inline">\(B\)</span> many realizations of the estimator <span class="math inline">\(\bar{X}_n\)</span> <span class="math display">\[\begin{align*}
\bar{X}_{n,1,obs} &amp;= \hat\theta(X_{1,1,obs},\dots,X_{n,1,obs})\\
\bar{X}_{n,2,obs} &amp;= \hat\theta(X_{1,2,obs},\dots,X_{n,2,obs})\\
&amp;\vdots\\
\bar{X}_{n,B,obs} &amp;= \hat\theta(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}\]</span> These realizations are then used to approximate the true distribution of <span class="math inline">\(\bar{X}_n.\)</span></p>
<div class="cell" data-hash="03-Monte-Carlo-Simulations_cache/html/unnamed-chunk-1_8b784b13b640587562ce7d5192e2ad51">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="do">## True parameter value </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>mu            <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Monte Carlo repetitions:</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>B             <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Sequence of different sample sizes:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>n_seq         <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">50</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="do">## #############################################</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 1st Coding-Possibility: Using a for() loop ##</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="do">## #############################################</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Set seed for the random number generator to get reproducible results</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Container for the generated estimates:</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>estimates_mat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> B, <span class="at">ncol =</span> <span class="fu">length</span>(n_seq))</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(n_seq)){</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="do">## select the sample size</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> n_seq[j]</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="do">## generate realization of the random sample </span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    X_sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">5</span>))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="do">## compute the sample mean and safe it</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    estimates_mat[b,j] <span class="ot">&lt;-</span> <span class="fu">mean</span>(X_sample)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="do">## ############################################</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="do">## 2nd Coding-Possibility: Using replicate() ##</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="do">## ############################################</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="do">## Set seed for the random number generator to get reproducible results</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="do">## Function that generates estimator realizations </span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>my_estimates_generator <span class="ot">&lt;-</span> <span class="cf">function</span>(n){</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>  X_sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">5</span>))</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute the sample mean realization</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">mean</span>(X_sample))</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>estimates_mat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">1</span>])),</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">2</span>]))</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Based on the <span class="math inline">\(B=10,000\)</span> realizations of the estimator <span class="math inline">\(\bar{X}_n\)</span>, we can compute the empirical density functions <span class="math inline">\(\hat{F}_{X_n,B}\)</span> (see <a href="#fig-ecdf">Figure&nbsp;<span>3.1</span></a>) and histograms (see <a href="#fig-histdensplots">Figure&nbsp;<span>3.2</span></a>) to get an idea about the true distribution of <span class="math inline">\(\bar{X}_n.\)</span></p>
<p>In this simple case, we also know the theoretical distribution function <span class="math inline">\(F_{X_n}\)</span> and density function which allows us to check the simulation results (see <a href="#fig-ecdf">Figure&nbsp;<span>3.1</span></a> and <a href="#fig-histdensplots">Figure&nbsp;<span>3.2</span></a>).</p>
<div class="cell" data-layout-align="center" data-hash="03-Monte-Carlo-Simulations_cache/html/fig-ecdf_0b60b2625ad02dfabc21ffad26b23404">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scales)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">ecdf</span>(estimates_mat[,<span class="dv">1</span>]), <span class="at">main=</span><span class="st">"n=5"</span>, <span class="at">ylab=</span><span class="st">""</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">col =</span> <span class="st">"black"</span>, <span class="at">xlim =</span> <span class="fu">range</span>(estimates_mat[,<span class="dv">1</span>]), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">1.25</span>))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">expression</span>(mu<span class="sc">==</span><span class="dv">10</span>), <span class="at">side =</span> <span class="dv">1</span>, <span class="at">at =</span> <span class="dv">10</span>, <span class="at">line =</span> <span class="fl">2.5</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">pnorm</span>(x, <span class="at">mean=</span><span class="dv">10</span>, <span class="at">sd=</span><span class="fu">sqrt</span>(<span class="dv">5</span><span class="sc">/</span><span class="dv">5</span>)), <span class="at">add=</span>T, <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">"blue"</span>, <span class="fl">0.25</span>), <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd=</span><span class="dv">4</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"True Distr.-Function"</span>, <span class="st">"Empir. Distr.-Function"</span>), </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="fu">alpha</span>(<span class="st">"blue"</span>, <span class="fl">0.5</span>)), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="fl">1.3</span>, <span class="dv">2</span>), <span class="at">bty =</span> <span class="st">"n"</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="do">##      </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">ecdf</span>(estimates_mat[,<span class="dv">2</span>]), <span class="at">main=</span><span class="st">"n=50"</span>, <span class="at">ylab=</span><span class="st">""</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">col =</span> <span class="st">"black"</span>,  <span class="at">xlim =</span> <span class="fu">range</span>(estimates_mat[,<span class="dv">1</span>]), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">1.25</span>))</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">expression</span>(mu<span class="sc">==</span><span class="dv">10</span>), <span class="at">side =</span> <span class="dv">1</span>, <span class="at">at =</span> <span class="dv">10</span>, <span class="at">line =</span> <span class="fl">2.5</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">pnorm</span>(x, <span class="at">mean=</span><span class="dv">10</span>, <span class="at">sd=</span><span class="fu">sqrt</span>(<span class="dv">5</span><span class="sc">/</span><span class="dv">50</span>)), <span class="at">add=</span>T, <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">"blue"</span>, <span class="fl">0.25</span>), <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd=</span><span class="dv">4</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"True Distr.-Function"</span>, <span class="st">"Empir. Distr.-Function"</span>), </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="fu">alpha</span>(<span class="st">"blue"</span>, <span class="fl">0.5</span>)), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="fl">1.3</span>, <span class="dv">2</span>), <span class="at">bty =</span> <span class="st">"n"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-ecdf" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-Monte-Carlo-Simulations_files/figure-html/fig-ecdf-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.1: Empirical distribution functions <span class="math inline">\(\hat{F}_{X_{n},B}\)</span> computed from the <span class="math inline">\((B=10000)\)</span> simulated realizations <span class="math inline">\(\bar{X}_{n,1,obs},\dots,\bar{X}_{n,B,obs}\)</span> and the theoretical distribution functions for <span class="math inline">\(n=5,50.\)</span> The empirical and the theoretical distribution functions match perfectly.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center" data-hash="03-Monte-Carlo-Simulations_cache/html/fig-histdensplots_9dfc69c382ff423f544a658ff07eb662">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scales)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(estimates_mat[,<span class="dv">1</span>], <span class="at">main=</span><span class="st">"n=5"</span>, <span class="at">xlab=</span><span class="st">""</span>,  <span class="at">xlim =</span> <span class="fu">range</span>(estimates_mat[,<span class="dv">1</span>]), <span class="at">prob =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1.5</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">expression</span>(mu<span class="sc">==</span><span class="dv">10</span>), <span class="at">side =</span> <span class="dv">1</span>, <span class="at">at =</span> <span class="dv">10</span>, <span class="at">line =</span> <span class="fl">2.5</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x, <span class="at">mean=</span><span class="dv">10</span>, <span class="at">sd=</span><span class="fu">sqrt</span>(<span class="dv">5</span><span class="sc">/</span><span class="dv">5</span>)), <span class="at">add=</span>T, <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">"blue"</span>, <span class="fl">0.25</span>), <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd=</span><span class="dv">4</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"True Density"</span>, <span class="st">"Histogram"</span>), </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="fu">alpha</span>(<span class="st">"blue"</span>, <span class="fl">0.5</span>)), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="fl">1.3</span>, <span class="dv">2</span>), <span class="at">bty =</span> <span class="st">"n"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(estimates_mat[,<span class="dv">2</span>], <span class="at">main=</span><span class="st">"n=50"</span>, <span class="at">xlab=</span><span class="st">""</span>, <span class="at">xlim =</span> <span class="fu">range</span>(estimates_mat[,<span class="dv">1</span>]), <span class="at">prob =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1.5</span>))</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">expression</span>(mu<span class="sc">==</span><span class="dv">10</span>), <span class="at">side =</span> <span class="dv">1</span>, <span class="at">at =</span> <span class="dv">10</span>, <span class="at">line =</span> <span class="fl">2.5</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x, <span class="at">mean=</span><span class="dv">10</span>, <span class="at">sd=</span><span class="fu">sqrt</span>(<span class="dv">5</span><span class="sc">/</span><span class="dv">50</span>)), <span class="at">add=</span>T, <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">"blue"</span>, <span class="fl">0.25</span>), <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd=</span><span class="dv">4</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"True Density"</span>, <span class="st">"Histogram"</span>), </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"black"</span>, <span class="fu">alpha</span>(<span class="st">"blue"</span>, <span class="fl">0.5</span>)), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="fl">1.3</span>, <span class="dv">2</span>), <span class="at">bty =</span> <span class="st">"n"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-histdensplots" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="03-Monte-Carlo-Simulations_files/figure-html/fig-histdensplots-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.2: Histrograms of <span class="math inline">\((B=10000)\)</span> simulated realizations <span class="math inline">\(\bar{X}_{n,1,obs},\dots,\bar{X}_{n,B,obs}\)</span> and true density functions for <span class="math inline">\(n=5,50.\)</span> The empirical (simulation based) histrograms and the theoretical density functions match perfectly.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Observations in <a href="#fig-ecdf">Figure&nbsp;<span>3.1</span></a> and <a href="#fig-histdensplots">Figure&nbsp;<span>3.2</span></a>: The empirical distribution functions and the histograms based on the simulated realizations <span class="math display">\[
\bar{X}_{n,1,obs},\dots,\bar{X}_{n,B,obs}
\]</span> mach their theoretical counterparts almost perfectly since we chose a sufficient large number of <span class="math inline">\(B=10000\)</span> simulations.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Take away message
</div>
</div>
<div class="callout-body-container callout-body">
<p>We can use Monte Carlo simulations to approximate the <em>exact</em> distribution of an estimator <span class="math inline">\(\hat{\theta}_n\)</span> for given distributions <span class="math inline">\(F_X\)</span> of the underlying random sample. These approximations become arbitrarily precise as <span class="math inline">\(B\to\infty\)</span>.</p>
</div>
</div>
<!-- * At least on average, the estimates $\bar{X}_n$ are close to the target parameter $\mu=10$ for each sample size $n\in\{5,15,50\}$. This feature of the estimator's distribution is summarized by the **bias** (see next section) of an estimator.

* As the sample size increases, the distributions of the estimators $\bar{X}_n$ concentrate around the target parameter $\mu=10$. This feature of the estimator's distribution is summarized by the **mean squared error** (see next section) of an estimator.

Thus here the quality of the estimator $\bar{X}_n$ gets better as $n$ gets large. To describe the quality of estimators more compactly, statisticians/econometricians use specific metrics like bias, variance and the mean squared error of the distribution of a estimator $\hat\theta$. -->
</section>
</section>
<section id="assessing-the-quality-of-estimators" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="assessing-the-quality-of-estimators"><span class="header-section-number">3.3</span> Assessing the Quality of Estimators</h2>
<!-- But how good is a given estimator $\hat\theta_n$ for a given sample size?  -->
<p>Any reasonable estimator <span class="math inline">\(\hat\theta_n\)</span> should be able to approximate the (usually unknown) parameter value <span class="math inline">\(\theta\)</span>, <span class="math display">\[
\left(\text{random quantity}\right)\quad\hat\theta_n\approx\theta\quad\left(\text{deterministic parameter}\right),
\]</span> and the approximation should get better as the sample size increases, i.e.&nbsp;as <span class="math inline">\(n\to\infty\)</span>.</p>
<p>The simulation results shown in <a href="#fig-ecdf">Figure&nbsp;<span>3.1</span></a> and <a href="#fig-histdensplots">Figure&nbsp;<span>3.2</span></a> show this desired behavior for the case of <span class="math inline">\(\hat{\theta}_n=\bar{X}_n.\)</span></p>
<p>To check (via MC-Simulations) the quality of an estimator, one can look at the total distribution or density function of <span class="math inline">\(\hat{\theta}_n\)</span>; as done in <a href="#fig-ecdf">Figure&nbsp;<span>3.1</span></a> and <a href="#fig-histdensplots">Figure&nbsp;<span>3.2</span></a>. However, it is often more convenient to consider only the most relevant features of the distribution of an estimator.</p>
<p>Statisticians/econometricians use different metrics to assess the quality of an estimator <span class="math inline">\(\hat\theta_n\)</span>. The most prominent metrics are:</p>
<ul>
<li>bias of an estimator <span class="math inline">\(\hat{\theta}_n\)</span></li>
<li>variance and standard error of an estimator <span class="math inline">\(\hat{\theta}_n\)</span></li>
<li>mean squared error (mse) of an estimator <span class="math inline">\(\hat{\theta}_n\)</span></li>
</ul>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-bias" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.1 (Bias of <span class="math inline">\(\theta\)</span>) </strong></span>The <strong>bias</strong> of an estimator <span class="math inline">\(\hat\theta_n\)</span> is defined as</p>
<p><span class="math display">\[
\operatorname{Bias}\left(\hat\theta_n\right) = E\left(\hat\theta_n\right) - \theta.
\]</span></p>
</div>
</div>
</div>
<p>If an estimator <span class="math inline">\(\hat\theta_n\)</span> has no bias <span class="math display">\[
\operatorname{Bias}\left(\hat\theta_n\right)=0
\]</span> for all <span class="math inline">\(\theta\)</span> and all sample sizes <span class="math inline">\(n,\)</span> we call it an <strong>unbiased estimator</strong>.</p>
<p>Many modern estimators are <em>not</em> unbiased. However, every estimator should be at least <strong>asymptotically unbiased</strong>, i.e. <span class="math display">\[
\lim_{n\to\infty}\operatorname{Bias}\left(\hat\theta_n\right)=0
\]</span> for all <span class="math inline">\(\theta.\)</span></p>
<p>We would like to have estimators with a small (or zero) bias.</p>
<p>If the bias of an estimator is small (or zero), we know that the distribution of the estimator is roughly (or exactly) centered around the true (usually unknown) parameter <span class="math inline">\(\theta.\)</span></p>
<p>However, also unbiased estimators <span class="math inline">\(\hat{\theta}_n\)</span> may still vary a lot around the parameter <span class="math inline">\(\theta\)</span> to be estimated. Therefore, is is also important to assess the variance of the estimator.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-var" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.2 (Variance and Standard Error of <span class="math inline">\(\theta\)</span>) </strong></span>The <strong>variance</strong> of an estimator <span class="math inline">\(\hat\theta_n\)</span> is defined equivalently to the variance of any other random variable</p>
<p><span class="math display">\[
Var\left(\hat\theta_n\right) = E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right].
\]</span> The square root of the variance of an estimator is called <strong>standard error</strong> (not standard deviation) of <span class="math inline">\(\hat\theta_n\)</span>, <span class="math display">\[
\operatorname{SE}\left(\hat\theta_n\right) = \sqrt{Var\left(\hat\theta_n\right)}.
\]</span></p>
</div>
</div>
</div>
<p>We would like to have estimators with a small as possible variance, and the variance should decline as the sample size increases, such that <span class="math inline">\(\lim_{n\to\infty}Var\left(\hat\theta_n\right)=0\)</span>.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="def-mse" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.3 (Mean Squared Error of <span class="math inline">\(\theta\)</span>) </strong></span>The <strong>mean squared error</strong> of an estimator <span class="math inline">\(\hat\theta_n\)</span> is defined as</p>
<p><span class="math display">\[
\operatorname{MSE}\left(\hat\theta_n\right) =  E\left[\left(\hat\theta_n - \theta\right)^2\right].
\]</span></p>
</div>
</div>
</div>
<p>We would like to have estimators with a small as possible mean squared error, and the mean squared error should decline as the sample size increases, such that <span class="math inline">\(\lim_{n\to\infty}\operatorname{MSE}\left(\hat\theta_n\right)=0\)</span>.</p>
<p>The following holds true:</p>
<ul>
<li>The mean squared error equals the sum of the squared bias and the variance:</li>
</ul>
<p><span class="math display">\[
\operatorname{MSE}\left(\hat\theta_n\right) = \left(\operatorname{Bias}\left(\hat\theta_n\right)\right)^2 +  Var\left(\hat\theta_n\right)
\]</span></p>
<ul>
<li>For unbiased estimators (i.e.&nbsp;<span class="math inline">\(E(\hat\theta_n)=\theta\)</span>) the mean squared error equals the variance, i.e.</li>
</ul>
<p><span class="math display">\[
\underbrace{E\left[\left(\hat\theta_n - \theta\right)^2\right]}_{\operatorname{MSE}\left(\hat\theta_n\right)} = \underbrace{E\left[\left(\hat\theta_n - E\left(\hat\theta_n\right)\right)^2\right]}_{ Var\left(\hat\theta_n\right)}
\]</span></p>
<p>Unfortunately, it is often difficult to derive the above assessment metrics for given sample sizes <span class="math inline">\(n\)</span> and given data distributions <span class="math inline">\(F_X\)</span>. Monte Carlo simulations allow us to solve this issue.</p>
<section id="approximating-bias-variance-and-mse-using-mc-simulations" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="approximating-bias-variance-and-mse-using-mc-simulations"><span class="header-section-number">3.3.1</span> Approximating Bias, Variance, and MSE using MC Simulations</h3>
<p>We can use Monte Carlo simulations to approximate the assessment metrics <span class="math inline">\(\operatorname{Bias}\left(\hat\theta_n\right),\)</span> <span class="math inline">\(Var\left(\hat\theta_n\right),\)</span> and <span class="math inline">\(\operatorname{MSE}\left(\hat\theta_n\right)\)</span> for given sample sizes <span class="math inline">\(n\)</span> and given data distributions <span class="math inline">\(F_X\)</span> with arbitrary precision.</p>
<p>Any of the the above assessment metrics require us to compute means of random variables:</p>
<ul>
<li><p>For the <span class="math inline">\(\operatorname{Bias}\left(\hat\theta_n\right)\)</span> we need to compute <span class="math inline">\(E\left(\hat\theta_n\right)-\theta\)</span></p></li>
<li><p>For the <span class="math inline">\(Var\left(\hat\theta_n\right)\)</span> we need to compute <span class="math inline">\(E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right]\)</span>.</p></li>
<li><p>For the <span class="math inline">\(\operatorname{MSE}\left(\hat\theta_n\right)\)</span> we need to compute <span class="math inline">\(E\left[\left(\hat\theta_n - \theta\right)^2\right]\)</span>.</p></li>
</ul>
<p>A Monte Carlo simulation can approximate these means by using the <strong>law of large numbers</strong> which states that a sample mean over iid random variables is able to approximate the population mean of these random variables as the number of random variables to average over get large.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>Thus, to compute a very precise approximation to <span class="math inline">\(E\left(\hat\theta_n\right)-\theta\)</span>, we can use a computer to execute the following algorithm:</p>
<p><strong>Step 1.</strong> Generate <span class="math inline">\(B\)</span> many (e.g.&nbsp;<span class="math inline">\(B=10,000\)</span>) realizations of the iid random sample <span class="math inline">\((X_1,\dots,X_n)\)</span> <span class="math display">\[\begin{align*}
&amp;(X_{1,1,obs},\dots,X_{n,1,obs})\\
&amp;(X_{1,2,obs},\dots,X_{n,2,obs})\\
&amp; \hspace{2cm}\vdots \\
&amp;(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}\]</span> leading to <span class="math inline">\(B\)</span> many realizations of the estimator <span class="math inline">\(\hat{\theta}_n\)</span> <span class="math display">\[\begin{align*}
\hat{\theta}_{n,1,obs} &amp;= \hat\theta(X_{1,1,obs},\dots,X_{n,1,obs})\\
\hat{\theta}_{n,2,obs} &amp;= \hat\theta(X_{1,2,obs},\dots,X_{n,2,obs})\\
&amp;\;\vdots\\
\hat{\theta}_{n,B,obs} &amp;= \hat\theta(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}\]</span></p>
<p><strong>Step 2.</strong> Use the simulated realizations <span class="math inline">\(\hat{\theta}_{n,1,obs},\dots,\hat{\theta}_{n,B,obs}\)</span> to approximate the bias, variance, and the mean squared error of the estimator <span class="math inline">\(\hat{\theta}_n\)</span>:</p>
<ul>
<li>The bias of <span class="math inline">\(\operatorname{Bias}\left(\hat\theta_n\right)=E\left(\hat\theta_n\right)-\theta\)</span> can be approximated by</li>
</ul>
<p><span class="math display">\[
\widehat{\operatorname{Bias}}_{MC}\left(\hat\theta_n\right) = \left(\frac{1}{B}\sum_{b=1}^B \hat\theta_{n,b,obs}\right) - \theta
\]</span></p>
<ul>
<li><p>The variance <span class="math inline">\(Var\left(\hat\theta_n\right)=E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right]\)</span> can be approximated by <span class="math display">\[
\widehat{Var}_{MC}\left(\hat\theta_n\right) = \frac{1}{B}\sum_{b=1}^B \left(\hat\theta_{n,b,obs} - \left(\frac{1}{B}\sum_{b=1}^B \hat\theta_{n,b,obs}\right)\right)^2
\]</span></p></li>
<li><p>The mean squared error <span class="math inline">\(\operatorname{MSE}\left(\hat\theta_n\right)=E\left[\left(\hat\theta_n - \theta\right)^2\right]\)</span> can be approximated by <span class="math display">\[
\widehat{\operatorname{MSE}}_{MC}\left(\hat\theta_n\right) = \frac{1}{B}\sum_{b=1}^B \left(\hat\theta_{n,b,obs} - \theta\right)^2
\]</span></p></li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>By the law of large numbers these approximations get arbitrarily precise as <span class="math inline">\(B \to \infty,\)</span> i.e. <span class="math display">\[\begin{align*}
\widehat{\operatorname{Bias}}_{MC}\left(\hat\theta_n\right)&amp;\to
\operatorname{Bias}\left(\hat\theta_n\right)\quad\text{as}\quad B\to\infty\\[2ex]
\widehat{Var}_{MC}\left(\hat\theta_n\right)&amp;\to
Var\left(\hat\theta_n\right)\quad\text{as}\quad B\to\infty\\[2ex]
\widehat{\operatorname{MSE}}_{MC}\left(\hat\theta_n\right)&amp;\to
\operatorname{MSE}\left(\hat\theta_n\right)\quad\text{as}\quad B\to\infty
\end{align*}\]</span></p>
<p>So for large <span class="math inline">\(B\)</span> (e.g.&nbsp;<span class="math inline">\(B=10,000\)</span>) we can consider <span class="math display">\[
\widehat{\operatorname{Bias}}_{MC}(\hat\theta_n),
\widehat{Var}_{MC}(\hat\theta_n),\text{ and }\;\;  
\widehat{\operatorname{MSE}}_{MC}(\hat\theta_n)
\]</span> as roughly equal to <span class="math display">\[
\operatorname{Bias}(\hat\theta_n),
Var(\hat\theta_n),\text{ and }
\operatorname{MSE}(\hat\theta_n).
\]</span></p>
</div>
</div>
</section>
<section id="example-revisited-sample-mean" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="example-revisited-sample-mean">Example (revisited): Sample Mean</h3>
<p>The following <code>R</code> code contains a Monte Carlo simulation with <span class="math inline">\(B = 10000\)</span> replications to approximate the bias, the variance, and the mean squared error for the sample mean <span class="math display">\[
(\hat\theta_n=)\bar{X}_n=\sum_{i=1}^nX_i
\]</span> Setup:</p>
<ul>
<li><span class="math inline">\(X_i\overset{iid}{\sim}F_X\)</span>, <span class="math inline">\(i=1,\dots,n\)</span>, with <span class="math inline">\(F_X=\mathcal{N}(\mu,\sigma^2)\)</span></li>
<li>Mean <span class="math inline">\(\mu=10\)</span> and variance <span class="math inline">\(\sigma^2=5\)</span></li>
<li>Sample sizes <span class="math inline">\(n\in\{5,15,50\}\)</span> <!-- The following `R` codes generated `B = 10000` realizations of the estimator $\bar{X}_n$ for each sample size $n\in\{5,15,50\}$ and stores all these realizations in a $10000\times 3$ matrix `estimates_mat`: --></li>
</ul>
<div class="cell" data-hash="03-Monte-Carlo-Simulations_cache/html/unnamed-chunk-4_429c1e5dca7901e578f93b31d61e87b7">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Set seed for the random number generator to get reproducible results</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="do">## True parameter value ('theta' here 'mu')</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>mu            <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Monte Carlo repetitions:</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>B             <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Sequence of different sample sizes:</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>n_seq         <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">50</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Function that generates estimator realizations </span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>my_estimates_generator <span class="ot">&lt;-</span> <span class="cf">function</span>(n){</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  X_sample <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="at">n =</span> n, <span class="at">mean =</span> mu, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">5</span>))</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute the sample mean realization</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">mean</span>(X_sample))</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>estimates_mat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">1</span>])),</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">2</span>])),</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(B, <span class="fu">my_estimates_generator</span>(<span class="at">n =</span> n_seq[<span class="dv">3</span>]))</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Bias of the sample mean for different sample sizes n</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>MC_Bias_n_seq <span class="ot">&lt;-</span> <span class="fu">apply</span>(estimates_mat, <span class="dv">2</span>, mean) <span class="sc">-</span> mu</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Variance of the sample mean for different sample sizes n</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>MC_Var_n_seq  <span class="ot">&lt;-</span> <span class="fu">apply</span>(estimates_mat, <span class="dv">2</span>, var)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Mean squared error of the sample mean for different sample sizes n</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>MC_MSE_n_seq  <span class="ot">&lt;-</span> <span class="fu">apply</span>(estimates_mat, <span class="dv">2</span>, <span class="cf">function</span>(x){<span class="fu">mean</span>((x <span class="sc">-</span> mu)<span class="sc">^</span><span class="dv">2</span>)})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#tbl-mcbvmse">Table&nbsp;<span>3.1</span></a> shows the Monte Carlo approximations for the bias, the variance, and the mean squared error of <span class="math inline">\(\bar{X}_n.\)</span></p>
<div class="cell" data-hash="03-Monte-Carlo-Simulations_cache/html/tbl-mcbvmse_22700ec548e36fd18a5735b5dcf99e1f">
<div class="cell-output-display">
<div id="tbl-mcbvmse" class="anchored">

<table class="table" style="margin-left: auto; margin-right: auto;"><caption>Table&nbsp;3.1:  Monte Carlo approximations for the true bias, true variance, and true mean squared error of sample mean. </caption>
 <thead>
  <tr>
   <th style="text-align:right;"> n </th>
   <th style="text-align:right;"> Bias (MC-Sim)  </th>
   <th style="text-align:right;"> Variance (MC-Sim) </th>
   <th style="text-align:right;"> MSE (MC-Sim)  </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> -0.001 </td>
   <td style="text-align:right;"> 1.02 </td>
   <td style="text-align:right;"> 1.02 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 0.000 </td>
   <td style="text-align:right;"> 0.33 </td>
   <td style="text-align:right;"> 0.33 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 50 </td>
   <td style="text-align:right;"> 0.001 </td>
   <td style="text-align:right;"> 0.10 </td>
   <td style="text-align:right;"> 0.10 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p>These Monte Carlo approximations (<a href="#tbl-mcbvmse">Table&nbsp;<span>3.1</span></a>) indicate that:</p>
<ul>
<li>The true bias <span class="math inline">\(\operatorname{Bias}(\bar{X}_n)\)</span> is very likely zero for all sample sizes <span class="math inline">\(n\in\{5,15,50\}\)</span></li>
</ul>
<!-- , and thus $Var(\bar{X}_n)\approx \operatorname{MSE}(\bar{X}_n)$ for all sample sizes $n\in\{5,15,50\}$. -->
<ul>
<li>The true mean squared error <span class="math inline">\(\operatorname{MSE}(\bar{X}_n)\)</span> is very likely decreasing as the sample size <span class="math inline">\(n\)</span> get larger.</li>
</ul>
<!-- The sample mean $\bar{X}_n$ is known to be a very good estimator of the population mean $\mu$ and the above simulation results conform this.  -->
</section>
<section id="comparing-the-mc-results-with-the-theoretical-bias-variance-and-mse-of-the-sample-mean" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="comparing-the-mc-results-with-the-theoretical-bias-variance-and-mse-of-the-sample-mean">Comparing the MC-Results with the theoretical bias, variance, and mse of the sample mean</h3>
<p>Since this example is so simple, we actually know the true bias, the true variance, and the true mean squared error of <span class="math inline">\(\bar{X}_n.\)</span> In <a href="#sec-ExampleSampleMean"><span>Section&nbsp;3.2.1</span></a>, we have already derived the exact theoretical distribution of <span class="math inline">\(\bar{X}_n\)</span> under the assumed random sample with sampling distribution <span class="math inline">\(F_X=\mathcal{N}(\mu,\sigma^2):\)</span> <span class="math display">\[
\bar{X}_n\sim\mathcal{N}\left(\mu,\frac{1}{n}\sigma^2\right).
\]</span></p>
<p>Using this, we can simply compute the <em>true</em> bias, variance and mean squared error of <span class="math inline">\(\bar{X}_n\)</span> for <span class="math inline">\(n\in\{5,15,50\}\)</span> and compare them with their Monte Carlo approximations:</p>
<ul>
<li><p>True bias of <span class="math inline">\(\bar{X}_n\)</span>: <span class="math display">\[\begin{align*}
\operatorname{Bias}\left(\bar{X}_n\right)
&amp;=E\left(\bar{X}_n\right) - \mu \\[2ex]
&amp;=E\left(\frac{1}{n}\sum_{i=1}^n X_i\right) - \mu \\[2ex]
&amp;= \left(\frac{1}{n}\sum_{i=1}^nE(X_i)\right) -\mu\\[2ex]
&amp;= \frac{n}{n}\mu-\mu \\[2ex]
&amp;=0,
\end{align*}\]</span> thus <span class="math inline">\(\bar{X}_n\)</span> is unbiased for all <span class="math inline">\(\mu.\)</span></p></li>
<li><p>True variance of <span class="math inline">\(\bar{X}_n\)</span>: <span class="math display">\[\begin{align*}
Var\left(\bar{X}_n\right)
&amp;=Var\left(\frac{1}{n}\sum_{i=1}^n X_i\right)\\[2ex]
&amp;= \frac{1}{n^2} \sum_{i=1}^nVar\left(X_i\right)\\[2ex]
&amp;= \frac{n}{n^2}\sigma^2 \\[2ex]
&amp;= \frac{1}{n}\sigma^2
\end{align*}\]</span></p></li>
<li><p>True MSE of <span class="math inline">\(\bar{X}_n\)</span>: <span class="math display">\[\begin{align*}
\operatorname{MSE}\left(\bar{X}_n\right)
&amp;=\left(\operatorname{Bias}\left(\bar{X}_n\right)\right)^2 +
Var\left(\frac{1}{n}\sum_{i=1}^nX_i\right)\\[2ex]
&amp;= 0+\frac{1}{n}\sigma^2
\end{align*}\]</span></p></li>
</ul>
<p>The following table shows the true bias, true variance and true mean squared error values for <span class="math inline">\(\sigma^2=5\)</span> and <span class="math inline">\(n\in\{5,15,50\}\)</span>:</p>
<div class="cell" data-hash="03-Monte-Carlo-Simulations_cache/html/tbl-truebvmse_02ac36d2d66f7c9f45ed11334711e570">
<div class="cell-output-display">
<div id="tbl-truebvmse" class="anchored">

<table class="table" style="margin-left: auto; margin-right: auto;"><caption>Table&nbsp;3.2:  True bias, true variance, and true mean squared error of sample mean. (Only computable in simple special cases.) </caption>
 <thead>
  <tr>
   <th style="text-align:right;"> n </th>
   <th style="text-align:right;"> Bias (true)  </th>
   <th style="text-align:right;"> Variance (true) </th>
   <th style="text-align:right;"> MSE (true)  </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:right;"> 5 </td>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 1.00 </td>
   <td style="text-align:right;"> 1.00 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 15 </td>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 0.33 </td>
   <td style="text-align:right;"> 0.33 </td>
  </tr>
  <tr>
   <td style="text-align:right;"> 50 </td>
   <td style="text-align:right;"> 0 </td>
   <td style="text-align:right;"> 0.10 </td>
   <td style="text-align:right;"> 0.10 </td>
  </tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Obviously, the Monte Carlo approximations (<a href="#tbl-mcbvmse">Table&nbsp;<span>3.1</span></a>) for these true values (<a href="#tbl-truebvmse">Table&nbsp;<span>3.2</span></a>) are very good.</p>
<p>If we would further increase the number of Monte Carlo repetitions <span class="math inline">\(B,\)</span> the Monte Carlo approximations in <a href="#tbl-mcbvmse">Table&nbsp;<span>3.1</span></a> would get even more precise since we can make them arbitrarily precise by letting <span class="math inline">\(B\to\infty\)</span> using the law of large numbers.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Take away message (continued)
</div>
</div>
<div class="callout-body-container callout-body">
<p>We can use Monte Carlo simulations to approximate the <em>exact</em> distribution and its features (e.g.&nbsp;bias, variance, mse) of an estimator <span class="math inline">\(\hat{\theta}_n\)</span> for given distributions <span class="math inline">\(F_X\)</span> of the underlying random sample. These approximations become arbitrarily precise as <span class="math inline">\(B\to\infty\)</span>.</p>
<p>Therefore, Monte Carlo simulations can be used to check estimation procedures when applied to specific data generating processes and sample sizes.</p>
<!-- MC simulations are an important tool, since modern estimation procedures are usually only justified based on asymptotic statistics $(n\to\infty)$ and sometimes only under relative restrictive assumptions. 

In such cases, MC simulations can be used to investigate the behavior of the estimation procedure in practical, finite sample sizes $n$ and under different data generating processes. 

MC simulations can also help to get an idea about how restrictive theoretical assumptions are in practice and how sensitive the an estimation procedure is with respect to violations of the theoretical assumptions.   -->
</div>
</div>
</section>
</section>
<section id="exercises" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="exercises"><span class="header-section-number">3.4</span> Exercises</h2>
<ul>
<li><a href="https://www.dropbox.com/scl/fi/xuqqzulvje2f07kq8da1f/Ch3_Exercises1.pdf?rlkey=i7b0c5x259eyd483na0esrtel&amp;dl=0">Exercises for Chapter 3</a></li>
</ul>
<!-- * [Exercises for Chapter 3 with Solutions](https://www.dropbox.com/scl/fi/lpek08w3v713b3fkfcqce/Ch3_Exercises_with_Solutions1.pdf?rlkey=covd2axn4sd56kassw6jhx6po&dl=0) -->
<!-- ```{r, fig.align="center"} -->
<!-- par(mfrow=c(1,3)) -->
<!-- plot(x = n_seq, y = Bias_n_seq, type = "b", ylim = c(-0.2, 0.2),  -->
<!--      main="Bias", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- plot(x = n_seq, y = Var_n_seq, type = "b", ylim = c(0, 1.5), -->
<!--      main="Variance", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- plot(x = n_seq, y = MSE_n_seq, type = "b", ylim = c(0, 1.5), -->
<!--      main="MSE", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- ``` -->
<!-- like, for instance, the arithmetic mean   -->
<!-- $$ -->
<!-- \bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i -->
<!-- $$ -->
<!-- as an estimator of the population mean value $\mu$.  -->


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>See <a href="06-Asymptotics.html#thm-SLLN1">Theorem&nbsp;<span>6.5</span></a> in <a href="06-Asymptotics.html"><span>Chapter&nbsp;6</span></a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02-Probability.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./04-Multiple-Linear-Regression.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>