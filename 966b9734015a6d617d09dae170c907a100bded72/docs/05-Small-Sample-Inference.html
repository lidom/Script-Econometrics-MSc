<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Econometrics M.Sc. - 5&nbsp; Small Sample Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./06-Asymptotics.html" rel="next">
<link href="./04-Multiple-Linear-Regression.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Small Sample Inference</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./" class="sidebar-logo-link">
      <img src="./images/Uni_Bonn_Logo.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Econometrics M.Sc.</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Organization of the Course</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-Introduction-to-R.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-Probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-Monte-Carlo-Simulations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Estimation Theory and Monte Carlo Simulations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-Multiple-Linear-Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-Small-Sample-Inference.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Small Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-Asymptotics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Large Sample Inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-Instrumental-Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Instrumental Variables</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-testmultp" id="toc-sec-testmultp" class="nav-link active" data-scroll-target="#sec-testmultp"><span class="toc-section-number">5.1</span>  Hypothesis Tests about Multiple Parameters (F-Tests)</a>
  <ul class="collapse">
  <li><a href="#the-test-statistic-and-its-null-distribution" id="toc-the-test-statistic-and-its-null-distribution" class="nav-link" data-scroll-target="#the-test-statistic-and-its-null-distribution"><span class="toc-section-number">5.1.1</span>  The Test Statistic and its Null Distribution</a></li>
  </ul></li>
  <li><a href="#ch:testingsinglep" id="toc-ch:testingsinglep" class="nav-link" data-scroll-target="#ch\:testingsinglep"><span class="toc-section-number">5.2</span>  Tests about One Parameter (t-Tests)</a></li>
  <li><a href="#testtheory" id="toc-testtheory" class="nav-link" data-scroll-target="#testtheory"><span class="toc-section-number">5.3</span>  Testtheory</a>
  <ul class="collapse">
  <li><a href="#size-and-significance-level-alpha" id="toc-size-and-significance-level-alpha" class="nav-link" data-scroll-target="#size-and-significance-level-alpha"><span class="toc-section-number">5.3.1</span>  Size and Significance Level <span class="math inline">\(\alpha\)</span></a></li>
  <li><a href="#critical-values" id="toc-critical-values" class="nav-link" data-scroll-target="#critical-values"><span class="toc-section-number">5.3.2</span>  Critical Values</a></li>
  <li><a href="#power" id="toc-power" class="nav-link" data-scroll-target="#power"><span class="toc-section-number">5.3.3</span>  Power</a></li>
  <li><a href="#p-value" id="toc-p-value" class="nav-link" data-scroll-target="#p-value"><span class="toc-section-number">5.3.4</span>  <span class="math inline">\(p\)</span>-Value</a></li>
  </ul></li>
  <li><a href="#sec-CIsmallsample" id="toc-sec-CIsmallsample" class="nav-link" data-scroll-target="#sec-CIsmallsample"><span class="toc-section-number">5.4</span>  Confidence Intervals</a></li>
  <li><a href="#sec-PSSI" id="toc-sec-PSSI" class="nav-link" data-scroll-target="#sec-PSSI"><span class="toc-section-number">5.5</span>  Monte Carlo Simulations</a>
  <ul class="collapse">
  <li><a href="#check-distribution-of-hatbetax-vs-distribution-of-hatbeta" id="toc-check-distribution-of-hatbetax-vs-distribution-of-hatbeta" class="nav-link" data-scroll-target="#check-distribution-of-hatbetax-vs-distribution-of-hatbeta"><span class="toc-section-number">5.5.1</span>  Check: Distribution of <span class="math inline">\(\hat\beta|X\)</span> vs Distribution of <span class="math inline">\(\hat\beta\)</span></a></li>
  <li><a href="#check-testing-multiple-parameters" id="toc-check-testing-multiple-parameters" class="nav-link" data-scroll-target="#check-testing-multiple-parameters"><span class="toc-section-number">5.5.2</span>  Check: Testing Multiple Parameters</a></li>
  <li><a href="#check-dualty-of-confidence-intervals-and-hypothesis-tests" id="toc-check-dualty-of-confidence-intervals-and-hypothesis-tests" class="nav-link" data-scroll-target="#check-dualty-of-confidence-intervals-and-hypothesis-tests"><span class="toc-section-number">5.5.3</span>  Check: Dualty of Confidence Intervals and Hypothesis Tests</a></li>
  </ul></li>
  <li><a href="#sec-RDSSInf" id="toc-sec-RDSSInf" class="nav-link" data-scroll-target="#sec-RDSSInf"><span class="toc-section-number">5.6</span>  Real Data Example</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-ssinf" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Small Sample Inference</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>The content of this chapter is very much inspired by Chapter 1 of <span class="citation" data-cites="Hayashi2000">Hayashi (<a href="#ref-Hayashi2000" role="doc-biblioref">2000</a>)</span>.</p>
<p>It’s is very hard to say when a sample size <span class="math inline">\(n\)</span> is small. Often people say something like:</p>
<ul>
<li><span class="math inline">\(n&lt;30\)</span> means small samples and <span class="math inline">\(n\geq 30\)</span> large samples, or</li>
<li><span class="math inline">\(n/K&lt;10\)</span> means small samples and <span class="math inline">\(n/K\geq 10\)</span> large samples,</li>
</ul>
<p>but these are only a very rough rules of thumb and may not apply in practice.</p>
<p>The core issue with small sample sizes is that we cannot do inference using the law of large numbers and the central limit theorem. Thus we need rather strict assumptions on the distribution of the error term, in order to do inference in finite samples. If these assumption are fulfilled, however, then we do <strong>exact</strong> inference.</p>
<p><strong>Exact inference:</strong> By “exact inference” we mean correct inference for each sample size <span class="math inline">\(n\)</span>. That is, no asymptotic <span class="math inline">\((n\to\infty)\)</span> arguments will be used.</p>
<p><strong>Assumptions:</strong> Recall that we, in general, did not impose a complete distributional assumption on <span class="math inline">\(\varepsilon\)</span> in Assumption 4 (<a href="04-Multiple-Linear-Regression.html"><span>Chapter&nbsp;4</span></a>). For instance, the i.i.d. normal case in Assumption 4 was only one possible <em>option</em>. However, to do exact inference, the normality Assumption on the error terms is not a mere option, but a <em>necessity</em>.</p>
<p>For this chapter we assume that Assumptions 1-3 from <a href="04-Multiple-Linear-Regression.html"><span>Chapter&nbsp;4</span></a> hold and that additionally the following assumption holds:</p>
<p><strong>Assumption 4<span class="math inline">\(^\boldsymbol{\ast}\)</span>: Conditional Gaussian error distribution:</strong> The error terms are Gaussian and homoskedastik, i.e., <span class="math display">\[
\varepsilon_i|X_i\sim\mathcal{N}(0,\sigma^2)
\]</span> for all <span class="math inline">\(i=1,\dots,n.\)</span></p>
<p>Assumption 4<span class="math inline">\(^\boldsymbol{\ast}\)</span> together with the random sample assumption of Assumption 1, part (b), leads to Gaussian spherical errors conditionally on <span class="math inline">\(X\)</span>, <span class="math display">\[
\varepsilon|X\sim\mathcal{N}\left(0,\sigma^2I_n\right),
\]</span> where <span class="math inline">\(\varepsilon=(\varepsilon_1,\dots,\varepsilon_n)'\)</span>.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">

</div>
</div>
<div class="callout-body-container callout-body">
<div id="thm-normalbeta" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.1 (Normality of <span class="math inline">\(\hat\beta\)</span>) </strong></span>Under Assumptions 1-4<span class="math inline">\(^\ast\)</span> we have that <span id="eq-ssnorm"><span class="math display">\[
\hat\beta_n|X \sim \mathcal{N}\left(\beta,Var(\hat\beta_n|X)\right),
\tag{5.1}\]</span></span> where <span class="math inline">\(Var(\hat\beta_n|X)=\sigma^2(X'X)^{-1}\)</span>.</p>
</div>
</div>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>This result follows from noting that <span class="math display">\[\begin{align*}
\hat\beta_n
&amp;=(X'X)^{-1}X'Y\\[2ex]
&amp;=\beta+(X'X)^{-1}X'\varepsilon
\end{align*}\]</span> and because <span class="math inline">\((X'X)^{-1}X'\varepsilon\)</span> is just a linear combination of the normally distributed error terms <span class="math inline">\(\varepsilon\)</span> which, therefore, is again normally distributed, conditionally on <span class="math inline">\(X\)</span>. Note that the specific normal distribution depends on the observed realization of <span class="math inline">\(X\)</span>.</p>
</div>
<p><strong>Remark:</strong> The subscript <span class="math inline">\(n\)</span> in <span class="math inline">\(\hat\beta_n\)</span> is here only to emphasize that the distribution of <span class="math inline">\(\hat\beta_n\)</span> depends on <span class="math inline">\(n\)</span>; we will, however, often simply write <span class="math inline">\(\hat\beta\)</span>.</p>
<section id="sec-testmultp" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-testmultp"><span class="header-section-number">5.1</span> Hypothesis Tests about Multiple Parameters (F-Tests)</h2>
<p>Let us consider the following system of <span class="math inline">\(q\)</span>-many null hypotheses: <span class="math display">\[\begin{align*}
H_0: \underset{(q\times K)}{R}\underset{(K\times 1)}{\beta} - \underset{(q\times 1)}{r} = \underset{(q\times 1)}{0},
\end{align*}\]</span> where the <span class="math inline">\((q \times K)\)</span> matrix <span class="math inline">\(R\)</span> and the <span class="math inline">\(q\)</span>-vector <span class="math inline">\(r=(r_{1},\dots,r_{q})'\)</span> are chosen by the statistician to specify her/his null hypothesis about the unknown true parameter vector <span class="math inline">\(\beta\)</span>. To make sure that there are no redundant equations, it is required that <span class="math inline">\(\operatorname{rank}(R)=q\)</span>.</p>
<p>We must also specify the alternative against which we are testing the null hypothesis, for instance <span class="math display">\[\begin{equation*}
H_1: R\beta -r \neq 0
\end{equation*}\]</span></p>
<p>The above multiple parameter hypotheses cover also the special case of single parameter hypothesis; for instance, by setting <span class="math inline">\(R=(0,1,0\dots,0)\)</span> and <span class="math inline">\(r=0\)</span> one get’s <span class="math display">\[\begin{equation*}
\begin{array}{ll}
H_0:  &amp; \beta_{k}=0 \\
H_1:  &amp; \beta_{k} \ne 0 \\
\end{array}
\end{equation*}\]</span></p>
<p>Under our assumptions (Assumptions 1 to 4<span class="math inline">\(^\ast\)</span>), we have that <span class="math display">\[
\begin{align*}
(R\hat\beta_n-r)|X&amp;\sim\mathcal{N}\left(R\beta -r,RVar(\hat\beta_n|X)R'\right)\\
(R\hat\beta_n-r)|X&amp;\overset{H_0}{\sim}\mathcal{N}\left(0,RVar(\hat\beta_n|X)R'\right)
\end{align*}
\]</span></p>
<p>That is,</p>
<ul>
<li>the realizations of <span class="math inline">\((R\hat\beta_n -r)|X\)</span> will scatter around the <em>unknown</em> <span class="math inline">\((R\beta -r)\)</span> in a Gaussian fashion.</li>
<li>if the null hypothesis is correct (i.e., <span class="math inline">\((R\beta-r)=0\)</span>), the realizations of <span class="math inline">\((R\hat\beta_n-r)|X\)</span> scatter around the <span class="math inline">\((q\times 1)\)</span> vector <span class="math inline">\(0\)</span>.</li>
</ul>
<p>We use a test statistic to detect a systematic location shift away from the zero vector. <!-- * if the alternative hypothesis is correct (i.e., $(R\beta-r)=a\neq 0$), there will be a systematic location-shift in $(R\hat\beta_n-r)|X$ which we try to detect using statistical hypothesis testing.  --></p>
<!-- the realizations of $R\hat\beta_n-r|X$ scatter around the $q$-vector $a\neq 0$.  So, under the alternative hypothesis,  -->
<section id="the-test-statistic-and-its-null-distribution" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="the-test-statistic-and-its-null-distribution"><span class="header-section-number">5.1.1</span> The Test Statistic and its Null Distribution</h3>
<p>The fact that <span class="math inline">\((R\hat\beta_n-r)\in\mathbb{R}^q\)</span> is a <span class="math inline">\(q\)</span>-dimensional random variable makes it a little bothersome to use as a test-statistic. Fortunately, we can turn <span class="math inline">\((R\hat\beta_n-r)\)</span> into a scalar-valued test statistic using the following quadratic form: <span class="math display">\[
W=\underbrace{(R\hat\beta_n -r)'}_{(1\times q)}\underbrace{[RVar(\hat\beta_n|X)R']^{-1}}_{(q\times q)}\underbrace{(R\hat\beta_n -r)}_{(q\times 1)}
\]</span> Note that the test statistic <span class="math inline">\(W\)</span> is simply measuring the distance (it’s a weighted L2-distance) between the <span class="math inline">\((q\times 1)\)</span> vectors <span class="math inline">\(R\hat\beta_n\)</span> and <span class="math inline">\(r\)</span>.</p>
<p>Under the null hypothesis (i.e., if <span class="math inline">\(H_0\)</span> is true), <span class="math inline">\(W|X\)</span> is a sum of <span class="math inline">\(q\)</span>-many independent squared standard normal random variables. Therefore, under the null hypothesis, <span class="math inline">\(W|X\)</span> is chi-square distributed with <span class="math inline">\(q\)</span> degrees of freedom (see <a href="02-Probability.html#sec-chisqdist"><span>Section&nbsp;2.2.10.3</span></a>), <span class="math display">\[
\begin{align*}
W|X&amp;\overset{H_0}{\sim} \chi^2_{(q)}\\
\Rightarrow \quad\quad W&amp;\overset{H_0}{\sim} \chi^2_{(q)}
\end{align*}
\]</span> Note that the distribution of <span class="math inline">\(W|X\)</span> does not depend on <span class="math inline">\(X,\)</span> (i.e.&nbsp;it’s a <span class="math inline">\(\chi^2_{(q)}\)</span>-distribution no matter the realization of <span class="math inline">\(X\)</span>) and thus our test decisions do not depend on the values of <span class="math inline">\(X.\)</span> (Good news!)</p>
<p>Usually, we do not know <span class="math inline">\(Var(\hat\beta_n|X),\)</span> and thus we need to estimate this quantity from the data. Unfortunately, in the small sample case, we can only deal with homoskedastic error terms. For truly exact finite sample inference, we need a variance estimator for which we can derive the exact small sample distribution. Therefore, we require Assumption 4<span class="math inline">\(^*\)</span> of spherical errors (i.e., <span class="math inline">\(Var(\varepsilon|X)=I_n\sigma^2\)</span>) which yields that <span class="math inline">\(Var(\hat\beta_n|X)=\sigma^2(X'X)^{-1}\)</span>, and where <span class="math inline">\(\sigma^2\)</span> can be estimated by the unbiased (<span class="math inline">\(UB\)</span>) variance estimator<br>
<span class="math display">\[
s_{UB}^2=(n-K)^{-1}\sum_{i=1}^n\hat\varepsilon_i^2.
\]</span><br>
From the normality assumption in Assumption 4<span class="math inline">\(^*\)</span>, it follows then that <span id="eq-distsquared"><span class="math display">\[
\frac{(n-K)}{\sigma^{2}}s_{UB}^2\sim\chi^2_{(n-K)}.
\tag{5.2}\]</span></span></p>
<p>The <span class="math inline">\(F\)</span> test statistic uses then <span class="math inline">\(s_{UB}^2\)</span> as an estimator of <span class="math inline">\(\sigma^2\)</span> <span class="math display">\[
F=(R\hat\beta_n -r)'[R(s_{UB}^2(X'X)^{-1})R']^{-1}(R\hat\beta_n -r)/q
\]</span> and takes into account the additional randomness (estimation errors) due to <span class="math inline">\(s_{UB}^2\)</span>, which leads to the following exact null distribution of the <span class="math inline">\(F\)</span> test <span id="eq-Ftest"><span class="math display">\[
F\overset{H_0}{\sim} F_{(q,n-K)},
\tag{5.3}\]</span></span> where <span class="math inline">\(F_{(q,n-K)}\)</span> denotes the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(q\)</span> numerator and <span class="math inline">\(n-K\)</span> denominator degrees of freedom.</p>
<p>As in the case of <span class="math inline">\(W\)</span>, the distribution of <span class="math inline">\(F\)</span> conditional on <span class="math inline">\(X\)</span> does not depend on <span class="math inline">\(X\)</span>; i.e.&nbsp;<span class="math inline">\(F|X\overset{H_0}{\sim}F_{(q,n-K)},\)</span> but <span class="math inline">\(F_{(q,n-K)}\)</span> does not depend on <span class="math inline">\(X,\)</span> thus we can write <span class="math inline">\(F\overset{H_0}{\sim}F_{(q,n-K)}.\)</span></p>
<p>The distributional statements in <a href="#eq-distsquared">Equation&nbsp;<span>5.2</span></a> and <a href="#eq-Ftest">Equation&nbsp;<span>5.3</span></a> are a little cumbersome to derive and we do not go into details here, but in case you’re interested you can find some more details, for instance, in Chapter 1 of <span class="citation" data-cites="Hayashi2000">Hayashi (<a href="#ref-Hayashi2000" role="doc-biblioref">2000</a>)</span>.</p>
<p>By contrast to <span class="math inline">\(W,\)</span> <span class="math inline">\(F\)</span> is now a practically useful test statistic, and we can use the observed value <span class="math inline">\(F_{\text{obs}}\)</span> to measure the distance of our estimate <span class="math inline">\(R\hat\beta_n\)</span> from its hypothetical value <span class="math inline">\(r.\)</span></p>
<p>Observed values, <span class="math inline">\(F_{\text{obs}}\)</span>, that are “unusually large” under the null hypothesis, lead to a rejection of the null hypothesis. The null distribution <span class="math inline">\(F_{(q,n-K)}\)</span> of <span class="math inline">\(F\)</span> is used to judge what’s “unusually large” under the null hypothesis.</p>
<p><strong>The F distribution.</strong> The F distribution is a ratio of two <span class="math inline">\(\chi^2\)</span> distributions. It has two parameters: the numerator degrees of freedom, and the denominator degrees of freedom. Each combination of the parameters yields a different F distribution. See <a href="02-Probability.html#sec-Fdist"><span>Section&nbsp;2.2.10.6</span></a> for more information on the <span class="math inline">\(F\)</span> distribution.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-1_c0e52edffc08555ebf8880c3905e5752">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="ch:testingsinglep" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="ch:testingsinglep"><span class="header-section-number">5.2</span> Tests about One Parameter (t-Tests)</h2>
<p>A hypothesis about only <strong>one parameter</strong> <span class="math display">\[\begin{equation*}
\begin{array}{ll}
H_0: &amp; \beta_k=\beta_k^{(0)}\\
\text{versus}\quad H_1: &amp; \beta_k\ne \beta_k^{(0)}\\
\end{array}
\end{equation*}\]</span> is simply a special case of the general null hypothesis <span class="math inline">\(H_0:R\beta -r =0,\)</span> where <span class="math inline">\(R\)</span> is a <span class="math inline">\((1\times K)\)</span> row-vector of zeros, but with a one as the <span class="math inline">\(k\)</span>th element, and where the null hypothetical value is set by the statistician <span class="math inline">\(r=\beta_k^{(0)}\)</span> (e.g.&nbsp;<span class="math inline">\(\beta_k^{(0)}=0\)</span>).</p>
<p>Thus the <span class="math inline">\(F\)</span>-test statistic simplifies to <span class="math display">\[
F=\frac{\left(\hat{\beta}_k-\beta_k^{(0)}\right)^2}{\widehat{Var}(\hat{\beta}_k|X)}\overset{H_0}{\sim}F_{(1,n-K)},
\]</span> where <span class="math display">\[\widehat{Var}(\hat{\beta}_k|X)=s^2_{UB}[(X'X)^{-1}]_{kk}.
\]</span> Taking square roots yields the <span class="math inline">\(t\)</span> test statistic <span class="math display">\[
T=\frac{\hat{\beta}_k-\beta_k^{(0)}}{\widehat{\operatorname{SE}}(\hat{\beta}_k|X)}\overset{H_0}{\sim}t_{(n-K)},
\]</span> where <span class="math display">\[
\widehat{\operatorname{SE}}(\hat{\beta}_k|X)=s_{UB}[(X'X)^{-1/2}]_{kk},
\]</span> and where <span class="math inline">\(t_{(n-K)}\)</span> denotes the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K\)</span> degrees of freedom.</p>
<p>Thus the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K\)</span> degrees of freedom is the appropriate distribution to judge whether or not an observed value <span class="math inline">\(T_{\text{obs}}\)</span> of the test statistic is “unusually large” under the null hypothesis.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>All commonly used statistical software packages report <span class="math inline">\(t\)</span>-tests testing the null hypothesis <span class="math display">\[
H_0:\beta_k=0
\]</span> for each <span class="math inline">\(k=1,\dots,K.\)</span> This means to test the null hypothesis that <span class="math inline">\(X_k\)</span> has “no (linear) effect” on the conditional mean of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X.\)</span></p>
</div>
</div>
<p><strong>The <span class="math inline">\(t\)</span> distribution.</strong> The following plot illustrates that as the degrees of freedom increase, the shape of the <span class="math inline">\(t\)</span> distribution comes closer to that of a standard normal bell curve. Already for <span class="math inline">\(25\)</span> degrees of freedom we find little difference to the standard normal density. In case of small degrees of freedom values, we find the distribution to have heavier tails than a standard normal. See <a href="02-Probability.html#sec-tdist"><span>Section&nbsp;2.2.10.4</span></a> for more information about the <span class="math inline">\(t\)</span>-distribution.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-2_8568957aa6352f1933b895f9e1ea5a71">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="testtheory" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="testtheory"><span class="header-section-number">5.3</span> Testtheory</h2>
<p>Every statistical test statistic is a function of the random sample, i.e. <span class="math display">\[
T\equiv T((X_1,Y_1),\dots,(X_n,Y_n))
\]</span> and is thus a random variable.</p>
<p>The observed value <span class="math display">\[
T_{\text{obs}}\equiv T((X_{1,obs},Y_{1,obs}),\dots,(X_{n,obs},Y_{n,obs}))
\]</span> is used to decide whether we can reject the null hypothesis <span class="math inline">\(H_0\)</span> or not.</p>
<p>If <span class="math display">\[
T_{\text{obs}}\in \{\text{rejection region}\}
\]</span> we reject <span class="math inline">\(H_0.\)</span></p>
<p>If <span class="math display">\[
T_{\text{obs}}\not\in \{\text{rejection region}\}
\]</span> we do not reject <span class="math inline">\(H_0.\)</span></p>
<p>Hereby differentiate two decision errors:</p>
<ul>
<li><strong>type-I-error</strong></li>
<li><strong>type-II-error</strong></li>
</ul>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
type-I-error and Size
</div>
</div>
<div class="callout-body-container callout-body">
<p>We conduct a type-I-error if we reject <span class="math inline">\(H_0\)</span> even though <span class="math inline">\(H_0\)</span> is true, i.e.&nbsp;if <span class="math display">\[
T_{\text{obs}}\in \{\text{rejection region}\}
\]</span> even though <span class="math inline">\(H_0\)</span> is true.</p>
<p>The probability of a type-I-error is also called <strong>size</strong> of the test statistic <span class="math inline">\(T,\)</span> <span class="math display">\[\begin{align*}
\text{Size}=&amp;P(\text{type-I-error})\\[2ex]
=&amp;P(\text{reject } H_0| H_0\text{ is true})\\[2ex]
=&amp;P(T \in \{\text{rejection region}\} | H_0\text{ is true})
\end{align*}\]</span> and we want this probability to be small.</p>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
type-II-error and Power
</div>
</div>
<div class="callout-body-container callout-body">
<p>We conduct a type-II-error if we do not reject <span class="math inline">\(H_0\)</span> even though <span class="math inline">\(H_1\)</span> is true, i.e.&nbsp;if <span class="math display">\[
T_{\text{obs}}\not \in \{\text{rejection region}\}
\]</span> even though <span class="math inline">\(H_1\)</span> is true.</p>
<p>The probability of a type-II-error is <span class="math display">\[\begin{align*}
&amp;P(\text{type-II-error})\\[2ex]
=&amp;P(\text{not reject } H_0| H_1\text{ is true})\\[2ex]
=&amp;P(T \not\in \{\text{rejection region}\} | H_1\text{ is true})
\end{align*}\]</span></p>
<p>One minus the probability of a type-II-error is called <strong>power</strong>: <span class="math display">\[\begin{align*}
\text{Power}=&amp;1-P(\text{type-II-error})\\[2ex]
=&amp;1-P(\text{not reject } H_0| H_1\text{ is true})\\[2ex]
=&amp;P(\text{reject } H_0| H_1\text{ is true})\\[2ex]
=&amp;P(T\in \{\text{rejection region}\} | H_1\text{ is true})
\end{align*}\]</span> Since we want to detect violations of <span class="math inline">\(H_0,\)</span> we want test statistics with a large power.</p>
</div>
</div>
<section id="size-and-significance-level-alpha" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="size-and-significance-level-alpha"><span class="header-section-number">5.3.1</span> Size and Significance Level <span class="math inline">\(\alpha\)</span></h3>
<p>A statistical hypothesis test is considered a <strong>valid test</strong> if the probability of a type-I-error is bounded from above by the <strong>significance level (nominal size)</strong> <span class="math inline">\(\alpha\)</span>, i.e.&nbsp;if<br>
<span class="math display">\[\begin{align*}
\underbrace{P(\text{reject } H_0| H_0\text{ is true})}_{\text{Size of $T$}}\quad \leq \underbrace{\alpha}_{\text{Nominal Size}}
\end{align*}\]</span></p>
<p>Since we want to keep the probability of falsely rejecting <span class="math inline">\(H_0\)</span> small, we choose small singificance levels such as</p>
<ul>
<li><span class="math inline">\(\alpha=0.05\)</span> or</li>
<li><span class="math inline">\(\alpha=0.001\)</span></li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Exact (non-conservative) vs conservative tests vs invalid
</div>
</div>
<div class="callout-body-container callout-body">
<p>A test statistic <span class="math inline">\(T\)</span> is called <strong>exact (or non-conservative)</strong> if <span class="math display">\[
P(\text{type-I-error})=\alpha.
\]</span> A test statistic <span class="math inline">\(T\)</span> is called <strong>conservative</strong> if <span class="math display">\[
P(\text{type-I-error})&lt;\alpha.
\]</span> A test statistic <span class="math inline">\(T\)</span> is called <strong>invalid</strong> if <span class="math display">\[
P(\text{type-I-error})&gt;\alpha.
\]</span></p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Under Assumption 1-4<span class="math inline">\(^\ast,\)</span> the <span class="math inline">\(F\)</span>-test and the <span class="math inline">\(t\)</span>-test are <strong>exact</strong> statistical tests.</p>
</div>
</div>
</div>
</div>
<!-- and a given alternative hypothesis, we can divide the range of all possible values of the test statistic (i.e., $\mathbb{R}$ since both $t\in\mathbb{R}$ and $F\in\mathbb{R}$) into a **rejection region** and a **non-rejection region** by using **critical values** derived from the distribution of the test statistic under the null hypothesis.  We can do this because the test statistics $t$ and $F$ have known distributions under the null hypothesis ($t\overset{H_0}{\sim}t_{n-K}$ and $F\overset{H_0}{\sim}F_{(q,n-K)}$).  -->
</section>
<section id="critical-values" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="critical-values"><span class="header-section-number">5.3.2</span> Critical Values</h3>
<p>The <strong>rejection region</strong> for a statistical test statistic <span class="math inline">\(T\)</span> is defined using <strong>critical values</strong> which are certain quantiles of the distribution of the test statistic <span class="math inline">\(T\)</span> under the assumption that <span class="math inline">\(H_0\)</span> is true.</p>
<section id="the-f-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-f-test">The <span class="math inline">\(F\)</span>-Test</h4>
<p>The <span class="math inline">\(F\)</span>-test allows us to test <span class="math display">\[\begin{align*}
&amp;H_0: R\beta = r\\[2ex]
\text{versus}\quad
&amp;H_1: R\beta\neq r,
\end{align*}\]</span> where <span class="math inline">\(\beta\)</span> denotes the true (unknown) parameter vector and <span class="math inline">\(r\)</span> the null-hypothetical value specified by the statistician (e.g.&nbsp;<span class="math inline">\(r=0\)</span>).</p>
<p>We know that <span class="math display">\[
F\overset{H_0}{\sim}F_{q,n-K}.
\]</span></p>
<p>Let <span class="math inline">\(c_{1-\alpha}\)</span> denote the <span class="math inline">\((1-\alpha)\)</span> quantile of the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\((q,n-K)\)</span> degrees of freedom.</p>
<p>This quantile <span class="math inline">\(c_{1-\alpha}\)</span> is the <strong>critical value</strong> that defines the <strong>rejection region</strong>: <span class="math display">\[
\{\text{rejection region}\}=\; ]c_{1-\alpha},\infty[
\]</span> <!-- , and 
- non-rejection region, $]0,c_{1-\alpha}]$  --></p>
<p>Thus <span class="math display">\[\begin{align*}
&amp;P(\text{reject } H_0 | H_0\text{ is true})\\[2ex]
=&amp;P(T \in \{\text{rejection region}\} | H_0\text{ is true})\\[2ex]
=&amp;P\Big(F &gt; c_{1-\alpha}| H_0\text{ is true}\Big)=\alpha,
\end{align*}\]</span></p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-3_aa0ae8567f7fc54717ecac869fbae9b5">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><strong>The rejection region:</strong> The rejection region describes a range of values of the test statistic <span class="math inline">\(F\)</span> which we rarely see if the null hypothesis is true (only in at most <span class="math inline">\(\alpha \cdot 100\%\)</span> cases). If the observed value of the test statistic, <span class="math inline">\(F_{\text{obs}}\)</span>, falls in this region, we will reject the null hypothesis and accept type-I-error rate of <span class="math inline">\(\alpha\)</span>.</p>
<p><strong>The non-rejection region:</strong> The non-rejection region describes a range of values of the test statistic <span class="math inline">\(F\)</span> which we expect to see (in <span class="math inline">\((1-\alpha) \cdot 100\%\)</span> cases) if the null hypothesis is true. If the observed value of the test statistic, <span class="math inline">\(F_{\text{obs}}\)</span> falls in this region, we will not reject the null hypothesis.</p>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Danger
</div>
</div>
<div class="callout-body-container callout-body">
<p>Not rejecting the null hypothesis does not mean that we can conclude that the null hypothesis is true.</p>
<p>A possible violation of the null hypothesis may only be too small to stand out from the estimation errors (a type-II-error even). But we do not control the probability of such type II errors—we only control the probability of type I errors.</p>
<p>Therefore, <strong>never ever</strong> state something like: “I conclude <span class="math inline">\(H_0\)</span> is true.”</p>
</div>
</div>
<p>To find the critical value <span class="math inline">\(c_{1-\alpha}\)</span> we can use <code>R</code> as following:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-4_1729164745e2beaa5cd2709144d45275">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>df1   <span class="ot">&lt;-</span> <span class="dv">9</span>    <span class="co"># numerator df</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>df2   <span class="ot">&lt;-</span> <span class="dv">120</span>  <span class="co"># denominator df</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># significance level</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Critical value:</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>crit_value <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df1 =</span> df1, <span class="at">df2 =</span> df2)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>crit_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.958763</code></pre>
</div>
</div>
<p>Changing the significance level from <span class="math inline">\(\alpha=0.05\)</span> to <span class="math inline">\(\alpha=0.01\)</span> makes the critical value <span class="math inline">\(c_{1-\alpha}\)</span> larger and, therefore, the rejection region smaller (fewer Type I errors)</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-5_31485ccc071b6fa5b7bb0fb81a287217">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.01</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Critical value:</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>crit_value <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df1 =</span> df1, <span class="at">df2 =</span> df2)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>crit_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.558574</code></pre>
</div>
</div>
</section>
<section id="the-two-sided-t-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-two-sided-t-test">The Two-Sided <span class="math inline">\(t\)</span>-Test</h4>
<p>The two-sided <span class="math inline">\(t\)</span>-test allows us to test <span class="math display">\[\begin{align*}
&amp; H_0: \beta_k=\beta_k^{(0)}\\
\text{versus}\quad
&amp; H_1: \beta_k\ne \beta_k^{(0)}
\end{align*}\]</span> where <span class="math inline">\(\beta_k\)</span> denotes the true (unknown) parameter value and <span class="math inline">\(\beta_k^{(0)}\)</span> the null hypothetical value specified by the statisticaian (e.g.&nbsp;<span class="math inline">\(\beta_k^{(0)}=0\)</span>).</p>
<p>We know that <span class="math display">\[
T\overset{H_0}{\sim}t_{n-K}.
\]</span></p>
<p>Let <span class="math inline">\(c_{\alpha/2}\)</span> and <span class="math inline">\(c_{1-\alpha/2}\)</span> denote the <span class="math inline">\(\alpha/2\)</span> and the <span class="math inline">\((1-\alpha/2)\)</span> quantiles of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom.</p>
<p>These quantiles are the <strong>critical values</strong> that define the <strong>rejection region</strong> of the two-sided <span class="math inline">\(t\)</span>-test: <span class="math display">\[
\{\text{rejection region}\}=\;]-\infty,c_{\alpha/2}[\;\;\cup\;\;]c_{1-\alpha/2}, \infty[
\]</span></p>
<p>Thus <span class="math display">\[\begin{align*}
&amp;P(\text{reject } H_0 | H_0\text{ is true})\\[2ex]
=&amp;P(T \in \{\text{rejection region}\} | H_0\text{ is true})\\[2ex]
=&amp;P\Big(T &lt; c_{\alpha/2}\quad\text{or}\quad T&gt;c_{1-\alpha/2}| H_0\text{ is true}\Big)\\[2ex]
=&amp;P\Big(T &lt; c_{\alpha/2} \; | H_0\text{ is true}\Big) +
  P\Big(T&gt;c_{1-\alpha/2}| H_0\text{ is true}\Big)\\[2ex]
&amp;=\frac{\alpha}{2}+\frac{\alpha}{2}=\alpha.
\end{align*}\]</span></p>
<p>Fig <a href="#fig-twoSided">Figure&nbsp;<span>5.1</span></a> shows an example of the rejection region for the case of a significance level <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(n-K=12\)</span> degrees of freedom.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/fig-twoSided_bc9c5ed37b794f6dffba37f4f5133c77">
<div class="cell-output-display">
<div id="fig-twoSided" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/fig-twoSided-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.1: <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K=12\)</span> degrees of freedom and critical values <span class="math inline">\(c_{\alpha/2}=-2.18\)</span> and <span class="math inline">\(c_{1-\alpha/2}=2.18\)</span> for the significance level <span class="math inline">\(\alpha=0.05\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>To find the critical values we can use <code>R</code> as following:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-7_126903710c902c38b9357af8fe316119">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df    <span class="ot">&lt;-</span> <span class="dv">12</span>   <span class="co"># degrees of freedom </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># significance level</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Two-sided critical value (= (1-alpha/2) quantile):</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>c_twoSided <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>, <span class="at">df =</span> df)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="do">## lower critical value</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span>c_twoSided</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -2.178813</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="do">## upper critical value</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>c_twoSided</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.178813</code></pre>
</div>
</div>
</section>
<section id="the-one-sided-t-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-one-sided-t-test">The One-Sided <span class="math inline">\(t\)</span>-Test</h4>
<p>Possible one-sided hypotheses:</p>
<p><span class="math display">\[\begin{align*}
&amp;H_0: \beta_k \leq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1: \beta_k &gt;    \beta_k^{(0)}\\
\end{align*}\]</span></p>
<p>or</p>
<p><span class="math display">\[\begin{align*}
&amp;H_0: \beta_k \geq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1: \beta_k &lt;  \beta_k^{(0)}\\
\end{align*}\]</span></p>
<!-- In case of a one-sided $t$-test, we will reject the null if $T_{\text{obs}}$ is sufficiently "far away" from zero in the relevant direction of $H_1$.  -->
<p>We know that <span class="math display">\[
T\overset{H_0}{\sim}t_{n-K}.
\]</span></p>
<p>Let <span class="math inline">\(c_{\alpha}\)</span> and <span class="math inline">\(c_{1-\alpha}\)</span> denote the <span class="math inline">\(\alpha\)</span> and the <span class="math inline">\((1-\alpha)\)</span> quantiles of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom.</p>
<p>These quantiles are the <strong>critical values</strong> that define the <strong>rejection region</strong> of the one-sided <span class="math inline">\(t\)</span>-tests:</p>
<p>For testing <span class="math display">\[\begin{align*}
&amp;H_0: \beta_k \leq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1: \beta_k &gt;    \beta_k^{(0)}\\
\end{align*}\]</span> the rejection region is <span class="math display">\[
\{\text{rejection region}\}=\;]c_{1-\alpha}, \infty[
\]</span></p>
<p>Fig <a href="#fig-oneSidedRight">Figure&nbsp;<span>5.2</span></a> shows an example of the rejection region for the case of a significance level <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(n-K=12\)</span> degrees of freedom.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/fig-oneSidedRight_df2d5244f8f826aeb0c1386e91012c5e">
<div class="cell-output-display">
<div id="fig-oneSidedRight" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/fig-oneSidedRight-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.2: <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K=12\)</span> degrees of freedom and critical value <span class="math inline">\(c_{1-\alpha}=1.78\)</span> for the significance level <span class="math inline">\(\alpha=0.05\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>For testing <span class="math display">\[\begin{align*}
&amp;H_0:  \beta_k \geq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1:  \beta_k &lt;  \beta_k^{(0)}\\
\end{align*}\]</span> the rejection region is <span class="math display">\[
\{\text{rejection region}\}=\;]-\infty,c_{\alpha/2}[
\]</span></p>
<p>Fig <a href="#fig-oneSidedLeft">Figure&nbsp;<span>5.3</span></a> shows an example of the rejection region for the case of a significance level <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(n-K=12\)</span> degrees of freedom.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/fig-oneSidedLeft_4b03a9767e2e6068e858cd43e4ebedb9">
<div class="cell-output-display">
<div id="fig-oneSidedLeft" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/fig-oneSidedLeft-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.3: <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K=12\)</span> degrees of freedom and critical value <span class="math inline">\(c_{\alpha}=-1.78\)</span> for the significance level <span class="math inline">\(\alpha=0.05\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>To find the critical values we can use <code>R</code> as following:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-10_ccbd9541109ded1492cf630ddb76a1ce">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df    <span class="ot">&lt;-</span> <span class="dv">12</span>   <span class="co"># degrees of freedom </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># significance level</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="do">## One-sided critical value (alpha) quantile:</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>c_oneSided <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> alpha, <span class="at">df =</span> df)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>c_oneSided</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -1.782288</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="do">## One-sided critical value (1-alpha) quantile:</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>c_oneSided <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df =</span> df)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>c_oneSided</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.782288</code></pre>
</div>
</div>
</section>
</section>
<section id="power" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="power"><span class="header-section-number">5.3.3</span> Power</h3>
<!-- A type-II-error is the mistake of not rejecting the null hypothesis when in fact it should have been rejected. The probability of making a type-II-error equals one minus the probability of correctly rejecting the null hypothesis ("Power").  -->
<!-- For instance, in the case of using the $t$-test to test the null hypothesis $H_0: \beta_k=0$ versus the one-sided alternative hypothesis $H_1:\beta_k>0$) we have that 
\begin{align*}
P(\text{type-II-error})
&=P_{H_1}\Big(t\;\in\;\overbrace{]-\infty,c_{1-\alpha}]}^{\text{non-rejection region}}\Big)\\
&=1-\underbrace{P_{H_1}\Big(t\;\in\;\overbrace{]c_{1-\alpha},\infty[}^{\text{rejection region}}\Big)}_{\text{"Power"}},
\end{align*}
where $P_{H_1}$ means that we compute the probability under the assumption that $H_1$ is true.  -->
<!-- 
::: {.callout-note}
There is a trade off between the probability of making a type-I-error and the probability of making a type-II-error: a lower significance level $\alpha$ decreases $P(\text{type-I-error})$, but necessarily increases $P(\text{type-II-error})$ and vice versa.  
Ideally, we would have some sense of the costs of making each of these errors, and would choose our significance level to minimize these total costs. However, the costs are often difficult to know.  
:::  
-->
<p>Since we want to detect violations of the null-hypothesis, we want that our test has a large power <span class="math display">\[\begin{align*}
\text{Power}
&amp; = 1 - P(\text{type-II-error})\\[2ex]
&amp; = 1 - P(\text{Not reject $H_0$ given $H_1$ is true})\\[2ex]
&amp; = P(\text{Reject $H_0$ given $H_1$ is true})\\[2ex]
&amp; = P(\text{Detect a violation of the null})
\end{align*}\]</span></p>
<p>Unfortunately, computing the power of a statistical test is usually impossible, since this requires knowing the distribution of the test statistic under the alternative hypothesis <span class="math inline">\(H_1.\)</span> The distribution of a test statistic under <span class="math inline">\(H_1\)</span> can only be derived under quite restrictive setups.</p>
<p>In the following, we consider such a restrictive setup for the <span class="math inline">\(t\)</span>-test statistic.</p>
<p>Let’s consider the one-sided hypothesis <span class="math display">\[\begin{align*}
&amp;H_0: \beta_k\leq \beta_{k}^{(0)}\\
&amp;H_1: \beta_k&gt;\beta_{k}^{(0)},
\end{align*}\]</span> where</p>
<ul>
<li><span class="math inline">\(\beta_k\)</span> denotes the true (unknown) parameter value and</li>
<li><span class="math inline">\(\beta_{k}^{(0)}\)</span> denotes the hypothetical parameter value,</li>
</ul>
<p>and where the true standard error of <span class="math inline">\(\hat\beta_k\)</span> given <span class="math inline">\(X\)</span> is known to be<br>
<span class="math display">\[
\operatorname{SE}(\hat\beta_k|X)=\frac{1}{\sqrt{n}}4.5.
\]</span></p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Standard error of <span class="math inline">\(\hat\beta_k\)</span> is proportional to <span class="math inline">\(1/\sqrt{n}\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Of course, usually we do not know the standard error of the estimator, but have to estimate it. But it is true that the standard error of the OLS estimator <span class="math inline">\(\hat{\beta}_k\)</span> is <strong>proportional to</strong> <span class="math inline">\(1/\sqrt{n},\)</span> <span class="math display">\[
\operatorname{SE}(\hat\beta_k|X) = \frac{1}{\sqrt{n}}\cdot \texttt{constant},
\]</span> where the <span class="math inline">\(\texttt{constant}\)</span> may depend on <span class="math inline">\(X,\)</span> but not on <span class="math inline">\(n.\)</span></p>
</div>
</div>
<p>Under this setup, the <span class="math inline">\(t\)</span>-test statistic is normally distributed, since we do not need to estimate the standard error <span class="math inline">\(\operatorname{SE}(\hat\beta_k|X)=(1/\sqrt{n})4.5.\)</span></p>
<p>If <span class="math inline">\(H_0\)</span> is true with <span class="math inline">\(\beta_k=\beta_k^{(0)},\)</span> then <span class="math display">\[\begin{align*}
T
&amp;=\frac{\hat\beta_k-\beta_k^{(0)}}{\frac{1}{\sqrt{n}}4.5}\\[2ex]
&amp;=\frac{\sqrt{n}(\hat\beta_k-\beta_k)}{4.5} \sim \mathcal{N}(0,1).
\end{align*}\]</span></p>
<p>If <span class="math inline">\(H_1\)</span> is true with <span class="math inline">\(\beta_k-\beta_k^{(0)}&gt;0,\)</span> then <span class="math display">\[\begin{align*}
T&amp;=\frac{\hat\beta_k-\beta_k^{(0)}}{\frac{1}{\sqrt{n}}4.5}
=\frac{\hat\beta_k\overbrace{-\beta_k+\beta_k}^{=0}-\beta_k^{(0)}}{\frac{1}{\sqrt{n}}4.5}\\[2ex]
&amp;=\underbrace{\frac{\sqrt{n}(\hat\beta_k-\beta_k)}{4.5}}_{\sim \mathcal{N}(0,1)}+\underbrace{\frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}}_{=\text{mean-shift}}\\[2ex]
&amp;\sim \mathcal{N}\left(\frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5},1\right)
\end{align*}\]</span></p>
<p>Power: <span class="math display">\[\begin{align*}
\text{Power}
&amp; = P(\text{Reject $H_0$ given $H_1$ is true})\\[2ex]
%&amp; = P(T \in \left]z_{1-\alpha},\infty\right[ \;\;|\; H_1\text{ is true})\\[2ex]
&amp; = P(T &gt; z_{1-\alpha}\;|\; H_1\text{ is true}),
\end{align*}\]</span> where <span class="math inline">\(z_{1-\alpha}\)</span> denotes the <span class="math inline">\((1-\alpha)\)</span> quantile of the standard normal distribution <span class="math inline">\(\mathcal{N}(0,1),\)</span> and where <span class="math display">\[
T\sim \mathcal{N}\left(\frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5},1\right).
\]</span></p>
<p>This allows us to compute the power as following: <span class="math display">\[\begin{align*}
\text{Power}
&amp; = P(T &gt; z_{1-\alpha}\;|\; H_1\text{ is true}),
\\[2ex]
&amp; = P\Bigg(\overbrace{T - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}}^{=Z\sim\mathcal{N}(0,1)} &gt; z_{1-\alpha} - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}\Bigg)\\[2ex]
&amp; = P\left(Z &gt; z_{1-\alpha} - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}\right)\\[2ex]%,\quad\text{where}\quad Z\sim\mathcal{N}(0,1)\\[2ex]
&amp;=1-P\left(Z \leq z_{1-\alpha} - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}\right)\\[2ex]
&amp;=1-\Phi\left(z_{1-\alpha} - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}\right),
\end{align*}\]</span> where <span class="math inline">\(\Phi\)</span> denotes the cumulative distribution function of the standard normal distribution <span class="math inline">\(\mathcal{N}(0,1).\)</span></p>
<!-- So, the distribution of the test statistic under $H_1$ depends on:

* The value of $\sqrt{\sigma^2[(X'X)^{-1}]_{kk}}$ (here $1.5$).  
* The difference between the actual parameter value $(\beta_k=3)$ and the hypothetical parameter $(r=0)$ value under the null-hypothesis.  -->
<p><a href="#fig-Power">Figure&nbsp;<span>5.4</span></a> illustrates the probability of a type-II-error and the power for the case where</p>
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(n=9\)</span></li>
<li><span class="math inline">\(\beta_k - \beta_k^{(0)}=3\)</span></li>
</ul>
<p>such that <span class="math display">\[\begin{align*}
\text{Power}
&amp;=1-\Phi\Bigg(z_{1-\alpha} - \overbrace{\frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}}^{=\frac{3\cdot 3}{4.5} = 2}\Bigg)\\[2ex]
&amp;=1-\Phi\left(1.64  - 2 \right)\\[2ex]
&amp;=1-0.36=0.64
\end{align*}\]</span> That is, we detect the violation of the null hypothesis <span class="math inline">\((\beta_k - \beta_k^{(0)}=3)\)</span> with probability <span class="math inline">\(0.64;\)</span> i.e., we expect to detect the violation of the null hypothesis in <span class="math inline">\(64\%\)</span> of resamplings from the random sample.</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/fig-Power_688e4f7f4d7b30030eae9e3369dc009e">
<div class="cell-output-display">
<div id="fig-Power" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/fig-Power-1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5.4: Probability of a type-II-error and the power for a one-sided <span class="math inline">\(t\)</span>-test at significance level <span class="math inline">\(\alpha = 0.05,\)</span> sample size <span class="math inline">\(n=9,\)</span> and violation of the null hypothesis <span class="math inline">\(\beta_k - \beta_k^{(0)}=3.\)</span></figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Power is a function of <span class="math inline">\(\alpha,\)</span> <span class="math inline">\((\beta_k-\beta_k^{(0)}),\)</span> and <span class="math inline">\(n\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<!-- Thus, the power of the $t$-test statistic is a function of 

* the significance level $\alpha$
* the violation of $H_0$, $(\beta_k-\beta_k^{(0)})>0$
* the sample size $n$ -->
<!-- \begin{align*}
\text{Power}(\alpha, (\beta_k-\beta_k^{(0)}), \sqrt{n})
&=1-\Phi\left(z_{1-\alpha} - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}\right),
\end{align*} -->
<p>Indeed, for all reasonable test statistics we have that: <span class="math display">\[\begin{align*}
%&amp;\text{One-Sided $H_1:\beta_k&gt;\beta_k^{(0)}$:}\\
%&amp;\text{Power}\left(\alpha, (\beta_k-\beta_k^{(0)}), \sqrt{n}\right)
%\to 1 \quad \text{as}\quad (\beta_k-\beta_k^{(0)})\to\infty\\[2ex]
%&amp;\text{One-Sided $H_1:\beta_k&lt;\beta_k^{(0)}$:}\\
%&amp;\text{Power}\left(\alpha, (\beta_k-\beta_k^{(0)}), \sqrt{n}\right)
%\to 1 \quad \text{as}\quad (\beta_k-\beta_k^{(0)})\to-\infty\\[2ex]
&amp;\text{Two-Sided $H_1:\beta_k\neq\beta_k^{(0)}$:}\\
&amp;\text{Power}\left(\alpha, (\beta_k-\beta_k^{(0)}), \sqrt{n}\right)
\to 1 \quad \text{as}\quad |\beta_k-\beta_k^{(0)}|\to\infty\\[2ex]
&amp;\text{Power}\left(\alpha, (\beta_k-\beta_k^{(0)}), \sqrt{n}\right)
\to 1 \quad \text{as}\quad n\to\infty\\[2ex]
&amp;\text{Power}\left(\alpha, (\beta_k-\beta_k^{(0)}), \sqrt{n}\right)
\to 0 \quad \text{as}\quad \alpha\to 0
\end{align*}\]</span> <!-- when keeping each of the other arguments fixed.  --></p>
</div>
</div>
</section>
<section id="p-value" class="level3" data-number="5.3.4">
<h3 data-number="5.3.4" class="anchored" data-anchor-id="p-value"><span class="header-section-number">5.3.4</span> <span class="math inline">\(p\)</span>-Value</h3>
<section id="f-test" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="f-test"><span class="math inline">\(F\)</span>-Test</h4>
<p>The <span class="math inline">\(F\)</span>-test allows us to test <span class="math display">\[\begin{align*}
&amp;H_0: R\beta = r\\[2ex]
\text{versus}\quad
&amp;H_1: R\beta\neq r,
\end{align*}\]</span> where <span class="math inline">\(\beta\)</span> denotes the true (unknown) parameter vector and <span class="math inline">\(r\)</span> the null-hypothetical value specified by the statistician (e.g.&nbsp;<span class="math inline">\(r=0\)</span>).</p>
<p>We know that <span class="math display">\[
F\overset{H_0}{\sim}F_{q,n-K}.
\]</span></p>
<p>The <span class="math inline">\(p\)</span>-value of the <span class="math inline">\(F\)</span>-test is the probability of seeing realizations of <span class="math inline">\(F\)</span> that are equal to or larger than the observed value <span class="math inline">\(F_{\text{obs}}\)</span> given that the null hypothesis is true <span class="math display">\[
p_{\text{obs}}=P(F\geq F_{\text{obs}}\;|\;H_0 \text{ is true})
\]</span></p>
<ul>
<li><p>We reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} &lt; \alpha
\]</span></p></li>
<li><p>We cannot reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} \geq \alpha
\]</span></p></li>
</ul>
</section>
<section id="the-one-sided-t-test-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-one-sided-t-test-1">The One-Sided <span class="math inline">\(t\)</span>-Test</h4>
<p>Possible one-sided hypotheses:</p>
<p><span class="math display">\[\begin{align*}
&amp;H_0: \beta_k \leq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1:\beta_k &gt;    \beta_k^{(0)}\\
\end{align*}\]</span></p>
<p>or</p>
<p><span class="math display">\[\begin{align*}
&amp;H_0: \beta_k \geq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1: \beta_k &lt;  \beta_k^{(0)}\\
\end{align*}\]</span></p>
<!-- In case of a one-sided $t$-test, we will reject the null if $T_{\text{obs}}$ is sufficiently "far away" from zero in the relevant direction of $H_1$.  -->
<p>We know that <span class="math display">\[
T\overset{H_0}{\sim}t_{n-K}.
\]</span></p>
<p>The <span class="math inline">\(p\)</span>-value of the one-sided <span class="math inline">\(t\)</span>-test for testing <span class="math display">\[\begin{align*}
&amp;H_0: \beta_k \leq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1: \beta_k &gt;    \beta_k^{(0)}\\
\end{align*}\]</span> is the probability of seeing realizations of <span class="math inline">\(T\)</span> that are equal to or larger than the observed value <span class="math inline">\(T_{\text{obs}}\)</span> given that the null hypothesis is true <span class="math display">\[
p_{\text{obs}}=P(T\geq T_{\text{obs}}\;|\;H_0 \text{ is true}).
\]</span> * We reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} &lt; \alpha
\]</span></p>
<ul>
<li>We cannot reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} \geq \alpha
\]</span></li>
</ul>
<p>The <span class="math inline">\(p\)</span>-value of the one-sided <span class="math inline">\(t\)</span>-test for testing <span class="math display">\[\begin{align*}
&amp;H_0: \beta_k \geq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1: \beta_k &lt;    \beta_k^{(0)}\\
\end{align*}\]</span> is the probability of seeing realizations of <span class="math inline">\(T\)</span> that are equal to or smaller than the observed value <span class="math inline">\(T_{\text{obs}}\)</span> given that the null hypothesis is true <span class="math display">\[
p_{\text{obs}}=P(T\leq T_{\text{obs}}\;|\;H_0 \text{ is true}).
\]</span></p>
<ul>
<li><p>We reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} &lt; \alpha
\]</span></p></li>
<li><p>We cannot reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} \geq \alpha
\]</span></p></li>
</ul>
</section>
<section id="the-two-sided-t-test-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-two-sided-t-test-1">The Two-Sided <span class="math inline">\(t\)</span>-Test</h4>
<p>The two-sided <span class="math inline">\(t\)</span>-test allows us to test <span class="math display">\[\begin{align*}
&amp; H_0: \beta_k=\beta_k^{(0)}\\
\text{versus}\quad
&amp; H_1: \beta_k\ne \beta_k^{(0)}
\end{align*}\]</span> where <span class="math inline">\(\beta_k\)</span> denotes the true (unknown) parameter value and <span class="math inline">\(\beta_k^{(0)}\)</span> the null hypothetical value specified by the statisticaian (e.g.&nbsp;<span class="math inline">\(\beta_k^{(0)}=0\)</span>).</p>
<p>We know that <span class="math display">\[
T\overset{H_0}{\sim}t_{n-K}.
\]</span></p>
<p>The <span class="math inline">\(p\)</span>-value of the two-sided <span class="math inline">\(t\)</span>-test is the probability of seeing realizations of <span class="math inline">\(T\)</span> that are equal to or more extreme than the observed value <span class="math inline">\(T_{\text{obs}}\)</span> given that the null hypothesis is true <span class="math display">\[\begin{align*}
p_{\text{obs}}
&amp;=P(|T|\geq |T_{\text{obs}}|\;|\;H_0 \text{ is true})\\[2ex]
&amp;=2\cdot\min\{P(T\leq T_{\text{obs}}\;|\;H_0 \text{ is true}),
            P(T\geq T_{\text{obs}}\;|\;H_0 \text{ is true})\}
\end{align*}\]</span></p>
<ul>
<li><p>We reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} &lt; \alpha
\]</span></p></li>
<li><p>We cannot reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} \geq \alpha
\]</span></p></li>
</ul>
<!-- The $p$-value of a test statistic is the significance level we would obtain if we took the sample value of the observed test statistic, $F_{\text{obs}}$ or $t_{\text{obs}},$ as the border between the rejection and non-rejection regions. 

* **$F$-test:** 
* **$t$-test:** 
   * Two sided, i.e.,  $H_0:\beta_k = r$ vs. $H_1:\beta_k\neq r$: <br> 
    $p=2\cdot\min\{P_{H_0}(t\leq t_{\text{obs}}),P_{H_0}(t\geq t_{\text{obs}})\}=P_{H_0}(|t|\geq|t_{\text{obs}}|)$ <br>
    The latter equality holds since the $t$ distrbution is symmetric. 
   * One sided, i.e., $H_0:\beta_k \leq r$ vs. $H_1:\beta_k> r$: <br> 
     $p=P_{H_0}(t\geq t_{\text{obs}})$
   * One sided, i.e., $H_0:\beta_k \geq r$ vs. $H_1:\beta_k< r$: <br> 
     $p=P_{H_0}(t\leq t_{\text{obs}})$

Put another way, the $p$-value is the greatest significance level for which we just fail to reject the null. Therefore, the $p$-value is sometimes also called "marginal significance value". 

If the $p$-value is strictly smaller than the chosen significance level $\alpha$, we reject the null hypothesis.  -->
</section>
</section>
</section>
<section id="sec-CIsmallsample" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="sec-CIsmallsample"><span class="header-section-number">5.4</span> Confidence Intervals</h2>
<p>We define a two-sided <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> percent confidence interval for the <em>deterministic</em> (unknown) true <span class="math inline">\(\beta_k\)</span> as the <strong>random interval</strong> <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span> for which <span class="math display">\[
P\Big(\beta_k\in\operatorname{CI}_{k,1-\alpha}\Big)\geq 1-\alpha.
\]</span> Derivation of the random interval <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span>:</p>
<p>Observe that (under Ass 1-4<span class="math inline">\(^\ast\)</span>) <span id="eq-CIDistr"><span class="math display">\[
\frac{\hat\beta_k-\beta_k}{\widehat{\operatorname{SE}}(\hat\beta_k|X)}\sim t_{(n-K)}
\tag{5.4}\]</span></span> Therefore, <span class="math display">\[\begin{align*}
P\left(-c_{1-\alpha/2}\leq\frac{\hat\beta_k-\beta_k}{\widehat{\operatorname{SE}}(\hat\beta_k|X)}\leq c_{1-\alpha/2}\right)=1-\alpha,
\end{align*}\]</span> where <span class="math inline">\(c_{1-\alpha/2}\)</span> denotes the <span class="math inline">\((1-\alpha)\)</span> quantile of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom. Next, we can do the following equivalent transformations <span class="math display">\[\begin{align*}
P\left(-c_{1-\alpha/2}\leq\frac{\hat\beta_k-\beta_k}{\widehat{\operatorname{SE}}(\hat\beta_k|X)}\leq c_{1-\alpha/2}\right)&amp;=1-\alpha\\
\Leftrightarrow P\left(\hat\beta_k-c_{1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_k|X)\leq \beta_k\leq\hat\beta_k +c_{1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_k|X)\right)&amp;=1-\alpha\\
\Leftrightarrow P\left(\beta_k\in\underbrace{\left[\hat\beta_k-c_{1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_k|X),\;\hat\beta_k +c_{1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_k|X)\right]}_{=:\operatorname{CI}_{k,1-\alpha}}\right)&amp;=1-\alpha
\end{align*}\]</span> That is, the random interval <span class="math display">\[
\operatorname{CI}_{k,1-\alpha}=\left[\hat\beta_k-c_{1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_k|X),\;\hat\beta_k + c_{1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_k|X)\right]
\]</span> is our <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> confidence interval for <span class="math inline">\(\beta_k\)</span>.</p>
<p>Since the confidence interval is based on the exact distribution (under Assumptions 1-4<span class="math inline">\(^\ast\)</span>) in <a href="#eq-CIDistr">Equation&nbsp;<span>5.4</span></a>, the confidence interval has an <strong>exact</strong> coverage probability <span class="math display">\[\begin{align*}
P\left(\beta_k\in\operatorname{CI}_{k,1-\alpha}\right)&amp;=1-\alpha
\end{align*}\]</span> provided the Assumptions 1-4<span class="math inline">\(^\ast\)</span> are true.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Interpretation of Confidence Intervals
</div>
</div>
<div class="callout-body-container callout-body">
<p>The random interval <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span> for <span class="math inline">\(\beta_k\)</span> contains the true parameter value <span class="math inline">\(\beta_k\)</span> with probability <span class="math inline">\(1-\alpha;\)</span> i.e.&nbsp;we expect that <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span> covers <span class="math inline">\(\beta_k\)</span> in <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> of resamplings from the random sample.</p>
<p>It’s best to take a look at dynamic visualizations like this one:</p>
<center>
<a href="https://rpsychologist.com/d3/ci/">https://rpsychologist.com/d3/ci/</a>
</center>
<p>Unfortunately, this “frequentist” interpretation is not a statement about a single given <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span> realization computed for a given data set. A given, realized <span class="math inline">\(\operatorname{CI}_{k,1-\alpha}\)</span> will either contain the true parameter <span class="math inline">\(\beta_k\)</span> or not, and usually we do not know the answer. So, confidence intervals are quite hard to interpret. However, they are very well suited as a tool to visualize estimation uncertainties in different parameter estimators, for instance, across <span class="math inline">\(\hat\beta_k\)</span>, <span class="math inline">\(k=1,\dots,K\)</span>.</p>
<center>
<img src="images/Meme_CI_2.jpg" class="img-fluid">
</center>
</div>
</div>
</section>
<section id="sec-PSSI" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="sec-PSSI"><span class="header-section-number">5.5</span> Monte Carlo Simulations</h2>
<p>Let’s check the above exact inference results using <code>R</code> and Monte Carlo simulations. First, we program a function <code>myDataGenerator()</code> which allows us to generate data from the following model, i.e., from the following fully specified data generating process: <span class="math display">\[\begin{align*}
Y_i   &amp;=\beta_1+\beta_2X_{i2}+\beta_3X_{i3}+\varepsilon_i,\qquad i=1,\dots,n\\
\beta &amp;=(\beta_1,\beta_2,\beta_3)'=(2,3,4)'\\
X_{i2}&amp;\sim U[2,10]\\
X_{i3}&amp;\sim U[12,22]\\
\varepsilon_i|X&amp;\sim\mathcal{N}(0,3^2),
\end{align*}\]</span> where <span class="math inline">\((Y_i,X_i)\)</span> is i.i.d. across <span class="math inline">\(i=1,\dots,n\)</span>. Let us consider a small sample size of <span class="math inline">\(n=7\)</span>.</p>
<p>The below function <code>myDataGenerator()</code> allows to sample new realizations of <span class="math inline">\(Y_1,\dots,Y_n\)</span> conditionally on a given data matrix <span class="math inline">\(X\)</span>. Moreover, you can provide your own values for the sample size <span class="math inline">\(n\)</span> and for the parameter vector <span class="math inline">\(\beta=(\beta_1,\beta_2,\beta_3)'\)</span>.</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-12_87033c8c2aceebb086c8b70905d0affa">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Function to generate artificial data</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="do">## If the user provides 'X_cond' data, </span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="do">## the sampling of new Y variables is </span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="do">## conditionally on the given X_cond variables.</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="do">## If X_cond = NULL, sampling is done unconditionally. </span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>myDataGenerator <span class="ot">&lt;-</span> <span class="cf">function</span>(n, beta, <span class="at">X_cond =</span> <span class="cn">NULL</span>){</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">is.null</span>(X_cond)){</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>      X   <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n), </span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">runif</span>(n, <span class="dv">2</span>, <span class="dv">10</span>), </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">runif</span>(n,<span class="dv">12</span>, <span class="dv">22</span>))</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>      X   <span class="ot">&lt;-</span> X_cond</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>  eps  <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="dv">3</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>  Y    <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta <span class="sc">+</span> eps</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="st">"Y"</span>   <span class="ot">=</span> Y, </span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"X_1"</span> <span class="ot">=</span> X[,<span class="dv">1</span>], </span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"X_2"</span> <span class="ot">=</span> X[,<span class="dv">2</span>], </span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"X_3"</span> <span class="ot">=</span> X[,<span class="dv">3</span>])</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>  <span class="do">##</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Small sample size</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>n             <span class="ot">&lt;-</span> <span class="dv">7</span>        </span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Define a true beta vector</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>beta_true     <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate Y and X data </span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>test_data     <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta=</span>beta_true)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="do">## Store the X data as 'X_cond'  </span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>X_cond        <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(test_data[,<span class="sc">-</span><span class="dv">1</span>]) <span class="co"># as matrix allows matrix multiplications</span></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate new Y data conditionally on X            </span></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>test_data_X_cond <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n    =</span> n, </span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">beta =</span> beta_true, </span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">X    =</span> X_cond)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="do">## compare</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(test_data,     <span class="dv">3</span>), <span class="dv">2</span>)    <span class="co"># New Y, new X</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       Y X_1  X_2   X_3
1 100.00   1 8.98 17.00
2  94.84   1 5.78 19.37
3  71.94   1 2.64 15.39</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(test_data_X_cond, <span class="dv">3</span>), <span class="dv">2</span>) <span class="co"># New Y, old X (conditionally on X)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      Y X_1  X_2   X_3
1 98.71   1 8.98 17.00
2 92.65   1 5.78 19.37
3 68.27   1 2.64 15.39</code></pre>
</div>
</div>
<section id="check-distribution-of-hatbetax-vs-distribution-of-hatbeta" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="check-distribution-of-hatbetax-vs-distribution-of-hatbeta"><span class="header-section-number">5.5.1</span> Check: Distribution of <span class="math inline">\(\hat\beta|X\)</span> vs Distribution of <span class="math inline">\(\hat\beta\)</span></h3>
<p>The above data generating process fulfills Assumptions 1-4<span class="math inline">\(^*\)</span>. So, by theory, the estimators <span class="math inline">\(\hat\beta|X\)</span> should be normal distributed conditionally on <span class="math inline">\(X\)</span>, <span class="math display">\[
\hat\beta_k|X\sim\mathcal{N}(\beta_k,\sigma^2[(X'X)^{-1}]_{kk}),\quad k=1,\dots,K=3,
\]</span> where <span class="math inline">\([(X'X)^{-1}]_{kk}\)</span> denotes the element in the <span class="math inline">\(k\)</span>th row and <span class="math inline">\(k\)</span>th column of the <span class="math inline">\(K\times K\)</span> matrix <span class="math inline">\((X'X)^{-1}\)</span>.</p>
<p>In order to check the effect of “conditioning on <span class="math inline">\(X\)</span>”, let us focus on <span class="math inline">\(\hat\beta_2\)</span> and use two different Monte Carlo simulations:</p>
<ol type="1">
<li>Generate <code>B</code><span class="math inline">\(=10000\)</span> realizations of <span class="math inline">\(\hat\beta_2\)</span> conditionally on <span class="math inline">\(X\)</span>.</li>
<li>Generate <code>B</code><span class="math inline">\(=10000\)</span> realizations of <span class="math inline">\(\hat\beta_2\)</span> <strong>un</strong>conditionally on <span class="math inline">\(X\)</span>.</li>
</ol>
<p>Then estimate the distributons from both Monte Carlo samples and compare them with the theoretical distribution <span class="math display">\[
\hat\beta_2|X\sim\mathcal{N}(\beta_k,\sigma^2[(X'X)^{-1}]_{22})
\]</span></p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-13_dddc4e5a7b4421217ed0ab9b33be347b">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11100</span>) <span class="co"># seed of the random number generator</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="do">## A function to generate realizations of the estimator </span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="do">## \hat{beta}_2 conditionally or unconditionally on X:</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>hatbeta2_sim_fun <span class="ot">&lt;-</span> <span class="cf">function</span>(conditional, <span class="at">X_cond =</span> <span class="cn">NULL</span>){</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(conditional <span class="sc">==</span> <span class="cn">TRUE</span>){</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>            data     <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true, <span class="at">X_cond =</span> X_cond)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>            lm_obj   <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> data)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>            hatbeta2 <span class="ot">&lt;-</span> <span class="fu">coef</span>(lm_obj)[<span class="dv">2</span>]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(conditional <span class="sc">==</span> <span class="cn">FALSE</span>){</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>            data     <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>            lm_obj   <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> data)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>            hatbeta2 <span class="ot">&lt;-</span> <span class="fu">coef</span>(lm_obj)[<span class="dv">2</span>]</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(hatbeta2)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of Monte Carlo replications</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Draw realizations of \hat{beta}_2</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="do">## 1. Generate \hat{beta}_2 realizations conditionally on X</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>hatbeta2_sim_cond   <span class="ot">&lt;-</span> <span class="fu">replicate</span>(B, <span class="fu">hatbeta2_sim_fun</span>(<span class="at">conditional =</span> <span class="cn">TRUE</span>,  <span class="at">X_cond =</span> X_cond))</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="do">## 2. Generate \hat{beta}_2 realizations unconditionally on X</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>hatbeta2_sim_uncond <span class="ot">&lt;-</span> <span class="fu">replicate</span>(B, <span class="fu">hatbeta2_sim_fun</span>(<span class="at">conditional =</span> <span class="cn">FALSE</span>))</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"scales"</span>) <span class="co"># transparent colors with the alpha() function </span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="do">## Theoretical normal distribution of beta_hat_2 versus the</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="do">## estimated densities based on the two Monte Carlo samples</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="do">## true beta_2</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>beta_true_2     <span class="ot">&lt;-</span> beta_true[<span class="dv">2</span>] </span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="do">## true standard deviation of the error term</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>sigma           <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a><span class="do">## true variance of \hat\beta_2 conditionally on X_cond</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>var_true_beta_2 <span class="ot">&lt;-</span> sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">solve</span>(<span class="fu">t</span>(X_cond) <span class="sc">%*%</span> X_cond)[<span class="dv">2</span>,<span class="dv">2</span>]</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a><span class="do">## Theoretical Gaussian density of \hat\beta_2 conditionally on X_cond</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="at">expr =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> beta_true_2, <span class="at">sd=</span><span class="fu">sqrt</span>(var_true_beta_2)), </span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a><span class="at">xlab=</span><span class="st">""</span>, <span class="at">ylab=</span><span class="st">""</span>, <span class="at">col=</span><span class="fu">gray</span>(.<span class="dv">2</span>), <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">lty=</span><span class="dv">1</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">1.5</span>))</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimated density based on the MC-sample of \hat\beta_2 conditionally on X_cond</span></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(hatbeta2_sim_cond, <span class="at">bw =</span> <span class="fu">bw.SJ</span>(hatbeta2_sim_cond)), <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">"blue"</span>,.<span class="dv">5</span>), <span class="at">lwd=</span><span class="dv">3</span>)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimated density based on the MC-sample of \hat\beta_2 *un*conditionally on X_cond</span></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(hatbeta2_sim_uncond, <span class="at">bw=</span><span class="fu">bw.SJ</span>(hatbeta2_sim_uncond)), <span class="at">col=</span><span class="fu">alpha</span>(<span class="st">"red"</span>,.<span class="dv">5</span>), <span class="at">lwd=</span><span class="dv">3</span>)</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">lwd=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">3</span>),</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span><span class="fu">c</span>(<span class="fu">gray</span>(.<span class="dv">2</span>), <span class="fu">alpha</span>(<span class="st">"blue"</span>,.<span class="dv">45</span>), <span class="fu">alpha</span>(<span class="st">"red"</span>,.<span class="dv">5</span>)), <span class="at">bty=</span><span class="st">"n"</span>, <span class="at">legend=</span> </span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="fu">expression</span>(<span class="st">"Theoretical Gaussian Density of"</span><span class="sc">~</span><span class="fu">hat</span>(beta)[<span class="dv">2</span>]<span class="sc">~</span><span class="st">'|'</span><span class="sc">~</span>X), </span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expression</span>(<span class="st">"Empirical Density based on the 10000 MC realizations of"</span><span class="sc">~</span><span class="fu">hat</span>(beta)[<span class="dv">2</span>]<span class="sc">~</span><span class="st">'|'</span><span class="sc">~</span>X),</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expression</span>(<span class="st">"Empirical Density based on the 10000 MC realizations of"</span><span class="sc">~</span><span class="fu">hat</span>(beta)[<span class="dv">2</span>])))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Observations:</p>
<ul>
<li>The empirical conditional distribution of <span class="math inline">\(\hat{\beta}_2|X\)</span> matches with the theoretical conditional distribution of <span class="math inline">\(\hat{\beta}_2|X\)</span>.</li>
<li>The empirical <strong>un</strong>conditional distribution of <span class="math inline">\(\hat{\beta}_2\)</span> does <strong>not</strong> match with the theoretical conditional distribution of <span class="math inline">\(\hat{\beta}_2|X\)</span>.</li>
</ul>
<p>Thus, in small sample, the distribution of <span class="math inline">\(\hat{\beta}_2\)</span> is strongly influenced by the <span class="math inline">\(X\)</span> we condition on. This affects also important features of the distribution of <span class="math inline">\(\hat{\beta}_2\)</span> like the variance.</p>
<section id="variance-of-hatbetax-vs.-variance-of-hatbeta" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="variance-of-hatbetax-vs.-variance-of-hatbeta">Variance of <span class="math inline">\(\hat\beta|X\)</span> vs.&nbsp;Variance of <span class="math inline">\(\hat\beta\)</span></h4>
<p>The theoretical variance of <span class="math inline">\(\hat{\beta}_2|X\)</span> is:<br></p>
<center>
<span class="math inline">\(Var(\hat{\beta}_2|X)=\sigma^2[(X'X)^{-1}]_{22}=\)</span> <code>var_true_beta_2</code>.
</center>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-14_5535eaf70aeb30981ec9d796dc9d0cfc">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>var_true_beta_2 <span class="ot">&lt;-</span> sigma<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">solve</span>(<span class="fu">t</span>(X_cond) <span class="sc">%*%</span> X_cond)[<span class="dv">2</span>,<span class="dv">2</span>]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(var_true_beta_2, <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.285</code></pre>
</div>
</div>
<p>The Monte Carlo realizations of <span class="math inline">\(\hat{\beta}_2|X\)</span>, i.e.&nbsp;conditionally on <span class="math inline">\(X\)</span>, have an empirical variance of</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-15_e19d1eff4c580152faedbd3ba8eed0c9">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">var</span>(hatbeta2_sim_cond), <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.284</code></pre>
</div>
</div>
<p>which basically matches the theoretical counterpart.</p>
<p>The Monte Carlo realizations of <span class="math inline">\(\hat{\beta}_2\)</span>, i.e.&nbsp;<strong>un</strong>conditionally on <span class="math inline">\(X\)</span>, have an empirical variance of</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-16_33d8f6e8560791f83305ad5eda94244b">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">var</span>(hatbeta2_sim_uncond), <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.477</code></pre>
</div>
</div>
<p>which is clearly different from the theoretical counterpart.</p>
<!-- While the unconditional distribution has a larger variance.  -->
<!-- ```{r} -->
<!-- ## True mean and variance of the true normal distribution  -->
<!-- ## of beta_hat_2|X=X_cond: -->
<!-- # true mean -->
<!-- # true variance -->
<!-- var_true_beta_2 <- sigma^2 * diag(solve(t(X_cond) %*% X_cond))[2] -->
<!-- ## Let's generate 5000 realizations from beta_hat_2  -->
<!-- ## conditionally on X=X_cond and check whether the empirical   -->
<!-- ## distribution of these 5000 realizations is close  -->
<!-- ## to the true normal distribution of beta_hat_2: -->
<!-- B          <- 5000 # MC replications -->
<!-- beta_hat_2 <- rep(NA, times=rep) -->
<!-- ## -->
<!-- for(r in 1:B){ -->
<!--     MC_data <- myDataGenerator(n    = n,  -->
<!--                                beta = beta_true,  -->
<!--                                X    = X_cond) -->
<!--     lm_obj        <- lm(Y ~ X_2 + X_3, data = MC_data) -->
<!--     beta_hat_2[r] <- coef(lm_obj)[2] -->
<!-- } -->
<!-- ## Compare -->
<!-- ## True beta_2 versus average of beta_hat_2 estimates -->
<!-- c(beta_true_2, round(mean(beta_hat_2), 4)) -->
<!-- ``` -->
<!-- The values are very close to each other, thus, on average the estimation results are basically equal to the true parameter value.  -->
<!-- ```{r} -->
<!-- ## Compare -->
<!-- ## True variance of beta_hat_2 versus  -->
<!-- ## empirical variance of beta_hat_2 estimates -->
<!-- c(round(var_true_beta_2, 4), round(var(beta_hat_2), 4)) -->
<!-- ``` -->
<!-- The values are very close to each other, thus the theoretical variance describes very well the actual variance of $\hat\beta_2|X$.  -->
<!-- ```{r, fig.align="center", echo=TRUE, fig.width = 8, fig.height = 5, out.width = "1\\textwidth"} -->
<!-- ## True normal distribution of beta_hat_2 versus  -->
<!-- ## empirical density of beta_hat_2 estimates -->
<!-- library("scales") -->
<!-- curve(expr = dnorm(x, mean = beta_true_2,  -->
<!--                    sd=sqrt(var_true_beta_2)),  -->
<!--       xlab="",ylab="", col=gray(.2), lwd=3, lty=1,  -->
<!--       xlim=range(beta_hat_2), ylim=c(0,1.1)) -->
<!-- hist(beta_hat_2, freq=FALSE, col=alpha("blue",.35), add=TRUE) -->
<!-- lines(density(beta_hat_2, bw = bw.SJ(beta_hat_2)),  -->
<!--       col=alpha("blue",.5), lwd=3) -->
<!-- legend("topleft", lty=c(1,NA,1), lwd=c(3,NA,3), pch=c(NA,15,NA), pt.cex=c(NA,2,NA), -->
<!--      col=c(gray(.2), alpha("blue",.45), alpha("blue",.5)), bty="n", legend=  -->
<!-- c(expression( -->
<!--   "Theoretical Gaussian Density of"~hat(beta)[2]~'|'~X),  -->
<!--   expression( -->
<!--   "Histogram based on the 5000 MC realizations of"~ -->
<!--   hat(beta)[2]~'|'~X),  -->
<!--   expression( -->
<!--   "Nonparametric Density Estimation based on the 5000 MC realizations of"~ -->
<!--   hat(beta)[2]~'|'~X))) -->
<!-- ``` -->
<!-- Great! The nonparametric density estimation (estimated via `density()`) and the histogram computed based on the 5000 simulated realizations of $\hat\beta_2|X$ are indicating that $\hat\beta_2|X$ is really normally distributed as described by our theoretical result in Equation @eq-ssnorm.  -->
<!-- However, what would happen if we would sample *unconditionally* on $X$? How does the distribution of $\hat\beta_2$ would then look like?  -->
<!-- ```{r} -->
<!-- set.seed(1110) -->
<!-- ## Let's generate 5000 realizations from beta_hat_2  -->
<!-- ## WITHOUT conditioning on X -->
<!-- beta_hat_2_uncond <- rep(NA, times=rep) -->
<!-- ## -->
<!-- for(r in 1:rep){ -->
<!--     MC_data <- myDataGenerator(n    = n,  -->
<!--                                beta = beta_true) -->
<!--     lm_obj               <- lm(Y ~ X_2 + X_3, data = MC_data) -->
<!--     beta_hat_2_uncond[r] <- coef(lm_obj)[2] -->
<!-- } -->
<!-- ## Compare: -->
<!-- ## True beta_2 versus average of beta_hat_2 estimates -->
<!-- c(beta_true_2, round(mean(beta_hat_2_uncond), 4)) -->
<!-- ``` -->
<!-- OK, at least on average the point point estimates are basically equal to the true parameter value.  -->
<!-- ```{r} -->
<!-- ## Compare:  -->
<!-- ## True variance of beta_hat_2 versus  -->
<!-- ## empirical variance of beta_hat_2 estimates -->
<!-- c(round(var_true_beta_2, 4), round(var(beta_hat_2_uncond), 4)) -->
<!-- ``` -->
<!-- Ouch! The theoretical variance of $\hat\beta_2|X$ is quite different from the actual variance of $\hat\beta_2$ (i.e. simulated without conditioning in $X$). That is, we cannot simply neglect that the variance of $\hat\beta_2$ depends on the observed realization of $X$ in small samples.  -->
<!-- ```{r, fig.align="center", echo=TRUE, fig.width = 8, fig.height = 5, out.width = "1\\textwidth"} -->
<!-- ## Plotting the theoretical distribution of beta_hat_2|X  -->
<!-- ## versus the simulated distribution -->
<!-- curve(expr = dnorm(x, mean = beta_true_2, sd=sqrt(var_true_beta_2)),  -->
<!--       xlab="",ylab="", col=gray(.2), lwd=3, lty=1,  -->
<!--       xlim=range(beta_hat_2_uncond), ylim=c(0,1.5)) -->
<!-- hist(beta_hat_2_uncond, freq=FALSE, col=alpha("blue",.35), add=TRUE) -->
<!-- lines(density(beta_hat_2_uncond, bw=bw.SJ(beta_hat_2_uncond)),  -->
<!--       col=alpha("blue",.5), lwd=3) -->
<!-- legend("topleft", lty=c(1,NA,1), lwd=c(3,NA,3), pch=c(NA,15,NA), pt.cex=c(NA,2,NA), -->
<!--      col=c(gray(.2), alpha("blue",.45), alpha("blue",.5)), bty="n", legend=  -->
<!-- c(expression( -->
<!--   "Theoretical Gaussian Density of"~hat(beta)[2]~'|'~X),  -->
<!-- expression( -->
<!--   "Histogram based on the 5000 MC realizations of"~ -->
<!--   hat(beta)[2]),  -->
<!-- expression("Nonparam. Density Estimation based on the 5000 MC realizations of"~ -->
<!--   hat(beta)[2]))) -->
<!-- ``` -->
<!-- Not so good. The theoretical distribution of $\hat\beta_2|X$ has much fatter tails than the simulated distribution of $\hat\beta_2$  (i.e. simulated without conditioning in $X$). That is, we cannot simply neglect that the distribution of $\hat\beta_2$ depends on the observed realization of $X$ in small samples. In large sample, however, the effect of a given realization $X$ is (fortunately) negligible, as we will see in @sec-lsinf.  -->
</section>
</section>
<section id="check-testing-multiple-parameters" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="check-testing-multiple-parameters"><span class="header-section-number">5.5.2</span> Check: Testing Multiple Parameters</h3>
<p>In the following, we do inference about multiple parameters. We test <span class="math display">\[\begin{align*}
H_0:\;&amp;\beta_2=3\quad\text{and}\quad\beta_3=4\\
\text{versus}\quad H_1:\;&amp;\beta_2\neq 3\quad\text{and/or}\quad\beta_3\neq 4.
\end{align*}\]</span> Or equivalently <span class="math display">\[\begin{align*}
H_0:\;&amp;R\beta -r = 0 \\
H_1:\;&amp;R\beta -r \neq 0,
\end{align*}\]</span> where <span class="math display">\[
R=\left(
\begin{matrix}
0&amp;1&amp;0\\
0&amp;0&amp;1\\
\end{matrix}\right)\quad\text{ and }\quad
r=\left(\begin{matrix}3\\4\\\end{matrix}\right).
\]</span> The following <code>R</code> code can be used to test this hypothesis:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-17_6f8c48ad10ae60b2c30b302909f3f919">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Library containing the function 'linearHyothesis()' </span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="do">## for testing multiple parameters </span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressMessages</span>(<span class="fu">library</span>(<span class="st">"car"</span>)) </span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="do">## See ?linearHypothesis</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate one Monte Carlo sample (under H0)</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>data   <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimate the linear regression model parameters</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>lm_obj <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> data)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Option 1:</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>test_result <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">linearHypothesis</span>(</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">model =</span> lm_obj, </span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">hypothesis.matrix =</span> <span class="fu">c</span>(<span class="st">"X_2=3"</span>, <span class="st">"X_3=4"</span>))   </span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>test_result        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear hypothesis test

Hypothesis:
X_2 = 3
X_3 = 4

Model 1: restricted model
Model 2: Y ~ X_2 + X_3

  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
1      6 113.751                           
2      4  67.656  2    46.095 1.3626 0.3538</code></pre>
</div>
</div>
<p>The <span class="math inline">\(p\)</span>-value <span class="math inline">\(p=\)</span> 0.3538 is larger than the chosen significance level <span class="math inline">\(\alpha=0.05\)</span> thus we cannot reject the null hypothesis “<span class="math inline">\(H_0:\;\beta_2=3\)</span> and <span class="math inline">\(\beta_3=4.\)</span>”</p>
<p>The following codes gives an alternative, equivalent way to compute the test result:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-18_b00f8c561117e0b2890aba45b328d039">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Option 2:</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>),</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>           <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(<span class="at">model =</span> lm_obj, </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">hypothesis.matrix =</span> R, </span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">rhs =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we simulated data “under the null hypothesis” and thus it is not surpising that we cannot reject the null hypothesis at a significance level of, for instance, <span class="math inline">\(\alpha=0.05\)</span>. However, in repeated samples we should nevertheless observe <span class="math inline">\(\alpha\cdot 100\%\)</span> type I errors (false rejections of <span class="math inline">\(H_0\)</span>) under the null hypothesis. Let’s check the type-I-error rate using the following Monte Carlo simulation:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-19_3ed41823d5fb326830a0c9c59e15dd1c">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Let's generate 5000 F-test decisions and check </span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="do">## whether the empirical rate of type I errors is </span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="do">## close to the theoretical significance level. </span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>B               <span class="ot">&lt;-</span> <span class="dv">5000</span> <span class="co"># MC replications</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>F_test_pvalues  <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="at">times=</span>B)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>  <span class="do">## generate new data (under H0)</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>  MC_data <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>  <span class="do">## estimate </span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>  lm_obj  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> MC_data)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute test and p-value</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>  p       <span class="ot">&lt;-</span> <span class="fu">linearHypothesis</span>(lm_obj, <span class="fu">c</span>(<span class="st">"X_2=3"</span>, <span class="st">"X_3=4"</span>))<span class="sc">$</span><span class="st">`</span><span class="at">Pr(&gt;F)</span><span class="st">`</span>[<span class="dv">2</span>]</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>  <span class="do">## save the p-value</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>  F_test_pvalues[r] <span class="ot">&lt;-</span> p</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="do">## Is the significance level ("nominal type-I-error rate") </span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="do">## smaller or equal to the actual type-I-error rate?</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>alpha        <span class="ot">&lt;-</span>  <span class="fl">0.05</span>          <span class="co"># signif level</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>rejections   <span class="ot">&lt;-</span> F_test_pvalues[F_test_pvalues <span class="sc">&lt;</span> alpha]</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">length</span>(rejections)<span class="sc">/</span>B, <span class="dv">4</span>) <span class="co"># actual type-I-error rate </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0504</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>alpha        <span class="ot">&lt;-</span>  <span class="fl">0.01</span>  <span class="co"># signif level</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>rejections   <span class="ot">&lt;-</span> F_test_pvalues[F_test_pvalues <span class="sc">&lt;</span> alpha]</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">length</span>(rejections)<span class="sc">/</span>B, <span class="dv">4</span>) <span class="co"># actual type-I-error rate </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0074</code></pre>
</div>
</div>
<p>Observations:</p>
<ol type="1">
<li>We correctly control for the type-I-error rate since the empirical type-I-error rate is not larger than the chosen significance level <span class="math inline">\(\alpha\)</span> (i.e.&nbsp;the nominal type-I-error rate).</li>
<li>Second, the <span class="math inline">\(F\)</span> test is not conservative since the empirical type-I-error rates essentially matche the chosen significance levels <span class="math inline">\(\alpha\)</span> (i.e.&nbsp;the nominal type-I-error rate). 2.1 In fact, if we would increase the number of Monte Carlo repetitions, the empirical type-I-error rate would converge to the nominal type-I-error rate <span class="math inline">\(\alpha\)</span> due to the law of large numbers.</li>
<li>Last but not least: All this works <strong>unconditionally</strong> on <span class="math inline">\(X\)</span> since the distribution of the <span class="math inline">\(F\)</span> statistic does not depend on <span class="math inline">\(X\)</span>. <!-- (Thus is also works conditionally on $X$ and you may check this at home.) --></li>
</ol>
<p>Next, we check how well the <span class="math inline">\(F\)</span> test detects certain <strong>violations of the null hypothesis</strong>. We do this by using the same data generating process, but by testing the following <span style="color:#FF0000">incorrect</span> null hypothesis: <span class="math display">\[\begin{align*}
H_0:\;&amp;{\color{red}\beta_2=4}\quad\text{and}\quad\beta_3=4\\
H_1:\;&amp;\beta_2\neq 4\quad\text{and/or}\quad\beta_3\neq 4
\end{align*}\]</span></p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-20_ee792751d8fc6cc97c9a3f20846b871d">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>B               <span class="ot">&lt;-</span> <span class="dv">5000</span> <span class="co"># MC replications</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>F_test_pvalues  <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="at">times=</span>B)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="do">## generate new data </span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  MC_data <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n    =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="do">## estimate </span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>  lm_obj  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> MC_data)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute test and p-value (for a false H0)</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  p       <span class="ot">&lt;-</span> <span class="fu">linearHypothesis</span>(lm_obj, <span class="fu">c</span>(<span class="st">"X_2=4"</span>, <span class="st">"X_3=4"</span>))<span class="sc">$</span><span class="st">`</span><span class="at">Pr(&gt;F)</span><span class="st">`</span>[<span class="dv">2</span>]</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>  <span class="do">## save the p-value</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>  F_test_pvalues[r] <span class="ot">&lt;-</span> p</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Checking the power of the F test </span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>alpha       <span class="ot">&lt;-</span>  <span class="fl">0.05</span>  <span class="co"># signif_level</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>rejections  <span class="ot">&lt;-</span> F_test_pvalues[F_test_pvalues <span class="sc">&lt;</span> alpha]</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(rejections)<span class="sc">/</span>B  <span class="co"># power </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.207</code></pre>
</div>
</div>
<p>We can now correctly reject the false null hypothesis in approximately 20.7 % of all Monte Carlo replications.</p>
<p><strong>Caution:</strong> This means that we are not able to detect the violation of the null hypothesis in 79.3 % of cases. Therefore, we can never use an insignificant test result (<span class="math inline">\(p\)</span>-value <span class="math inline">\(\geq\alpha\)</span>) as a confirmation of the null hypothesis. Obviously, there are type-II-error events (not rejecting a false <span class="math inline">\(H_0\)</span>), but since we typically do not know the distribution of the test statistic under the alternative hypothesis, we cannot control the type-II-error rate. We can only control the type-I-error rate by using a small significance level <span class="math inline">\(\alpha\)</span>.</p>
<p>Moreover, note that the <span class="math inline">\(F\)</span> test is not informative about which part of the null hypothesis (<span class="math inline">\(\beta_2=4\)</span> and/or <span class="math inline">\(\beta_3=4\)</span>) is violated. We only get the information that at least one of the multiple parameter hypotheses is violated.</p>
</section>
<section id="check-dualty-of-confidence-intervals-and-hypothesis-tests" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="check-dualty-of-confidence-intervals-and-hypothesis-tests"><span class="header-section-number">5.5.3</span> Check: Dualty of Confidence Intervals and Hypothesis Tests</h3>
<p>Confidence intervals can be computed using <code>R</code> as following:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-21_d72dbe92cb1a42c70156201f9564b669">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Significance level</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>alpha        <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Confidence level</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>conf_level   <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> alpha</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 95% CI for beta_2</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(lm_obj, <span class="at">parm =</span> <span class="st">"X_2"</span>, <span class="at">level =</span> conf_level)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      2.5 %   97.5 %
X_2 1.39882 2.710745</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 95% CI for beta_3 </span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(lm_obj, <span class="at">parm =</span> <span class="st">"X_3"</span>, <span class="at">level =</span> conf_level)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       2.5 %   97.5 %
X_3 3.573364 4.564121</code></pre>
</div>
</div>
<p>We can use these two-sided confidence intervals to conduct hypotheses tests. This property of confidence intervals is called the <strong>duality of confidence intervals and hypothesis tests</strong>.</p>
<p>For instance, when testing the null hypothesis <span class="math display">\[\begin{align*}
H_0:&amp;\beta_2=3\\
\text{versus}\quad H_1: &amp;\beta_2\neq 3
\end{align*}\]</span> we can either use a <span class="math inline">\(t\)</span>-test or equivalently check whether the confidence interval <span class="math inline">\(\operatorname{CI}_{2,1-\alpha}\)</span> for <span class="math inline">\(\beta_2\)</span> contains the hypothetical value <span class="math inline">\(4\)</span> or not.</p>
<ul>
<li>In case of <span class="math inline">\(3 \in\operatorname{CI}_{2,1-\alpha}\)</span>, we cannot reject the null hypothesis <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_2=3.\)</span></li>
<li>In case of <span class="math inline">\(3\not\in\operatorname{CI}_{2,1-\alpha}\)</span>, we can reject the null hypothesis <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_2=3.\)</span></li>
</ul>
<p>If the Assumptions 1-4<span class="math inline">\(^\ast\)</span> hold true, then <span class="math inline">\(\operatorname{CI}_{2,1-\alpha}\)</span> is an exact confidence interval. That is, under the null hypothesis, it falsely rejects the null hypothesis in only <span class="math inline">\(\alpha\cdot 100\%\)</span> of resamplings. Let’s check this in the following Monte Carlo simulation:</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-22_13b4c980b58636a803ce3eed4b45f47c">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Significance level</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>alpha      <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Container to save all CI realizations</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>confint_m  <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow=</span><span class="dv">2</span>, <span class="at">ncol=</span>B)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  <span class="do">## generate new data </span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  MC_data <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>  <span class="do">## estimate</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>  lm_obj  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> MC_data)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute confidence interval </span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>  CI <span class="ot">&lt;-</span> <span class="fu">confint</span>(lm_obj, <span class="at">parm=</span><span class="st">"X_2"</span>, <span class="at">level =</span> <span class="dv">1</span> <span class="sc">-</span> alpha)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>  <span class="do">## save confidence interval</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>  confint_m[,r] <span class="ot">&lt;-</span> CI</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="do">## check whether true parameter is inside the CI</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>inside_CI  <span class="ot">&lt;-</span> confint_m[<span class="dv">1</span>,] <span class="sc">&lt;=</span> beta_true_2 <span class="sc">&amp;</span> </span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>                beta_true_2 <span class="sc">&lt;=</span> confint_m[<span class="dv">2</span>,]</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a><span class="do">## CI-lower, CI-upper, beta_true_2 inside?</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">cbind</span>(<span class="fu">t</span>(confint_m), inside_CI))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                        inside_CI
[1,] 0.4820827 4.207598         1
[2,] 0.8180854 6.728337         1
[3,] 2.1488006 3.681674         1
[4,] 2.3729741 4.180756         1
[5,] 1.6603943 5.181375         1
[6,] 1.0120300 4.102050         1</code></pre>
</div>
</div>
<p>The following code computes the relative frequency of confidence intervals <strong>not containing</strong> the true parameter value <span class="math inline">\((\beta_2=3)\)</span>:</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-23_f8602873dbaf94dc7944c2b907460958">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">length</span>(inside_CI[inside_CI <span class="sc">==</span> <span class="cn">FALSE</span>])<span class="sc">/</span>B, <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.048</code></pre>
</div>
</div>
<p>That’s good! The relative frequency is basically equal to the chosen <span class="math inline">\(\alpha=0.05\)</span> value.</p>
<p>Next, we visualize a subsample of <code>100</code> confidence intervals from the total sample of <code>5000</code> generated confidence interval realizations:</p>
<div class="cell" data-layout-align="center" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-24_a0caf75ca8b44c9c598e9ec023726298">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>nCIs <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span><span class="dv">0</span>,<span class="at">type=</span><span class="st">"n"</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,nCIs), <span class="at">ylim=</span><span class="fu">range</span>(confint_m[,<span class="dv">1</span><span class="sc">:</span>nCIs]),</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">""</span>, <span class="at">xlab=</span><span class="st">"Resamplings"</span>, <span class="at">main=</span><span class="st">"Confidence Intervals"</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nCIs){</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(inside_CI[r]<span class="sc">==</span><span class="cn">TRUE</span>){</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">lines</span>(<span class="at">x=</span><span class="fu">c</span>(r,r), <span class="at">y=</span><span class="fu">c</span>(confint_m[<span class="dv">1</span>,r], confint_m[<span class="dv">2</span>,r]), <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="fu">gray</span>(.<span class="dv">5</span>,.<span class="dv">5</span>))</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">lines</span>(<span class="at">x=</span><span class="fu">c</span>(r,r), <span class="at">y=</span><span class="fu">c</span>(confint_m[<span class="dv">1</span>,r], confint_m[<span class="dv">2</span>,r]), <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">"darkred"</span>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">4</span>, <span class="at">at=</span>beta_true_2, <span class="at">labels =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]))</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span>beta_true_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>As expected, only about <span class="math inline">\(\alpha\cdot 100\%=5\%\)</span> of all confidence intervals do not contain the true parameter value <span class="math inline">\(\beta_2=3\)</span>, but about <span class="math inline">\((1-\alpha)\cdot 100\%=95\%\)</span> of all confidence intervals contain the true parameter value <span class="math inline">\(\beta_2=3\)</span>.</p>
</section>
</section>
<section id="sec-RDSSInf" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="sec-RDSSInf"><span class="header-section-number">5.6</span> Real Data Example</h2>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-25_6723f005b673bfdb1c96c217a2e3111e">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="do">## The AER package contains a lot of datasets </span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(AER))</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Attach the DoctorVisits data to make it usable</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"DoctorVisits"</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>lm_obj <span class="ot">&lt;-</span> <span class="fu">lm</span>(visits <span class="sc">~</span> gender <span class="sc">+</span> age <span class="sc">+</span> income, <span class="at">data =</span> DoctorVisits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The above <code>R</code> codes estimate the following regression model <span class="math display">\[
Y_i = \beta_1 + \beta_{gender} X_{gender,i}
              + \beta_{age} X_{age,i}
              + \beta_{income} X_{income,i} + \varepsilon_i,
\]</span> where <span class="math inline">\(i=1,\dots,n\)</span> and</p>
<ul>
<li><span class="math inline">\(X_{gender,i}=1\)</span> if the <span class="math inline">\(i\)</span>th subject is a woman and <span class="math inline">\(X_{gender,i}=0\)</span> if the <span class="math inline">\(i\)</span>th subject is a man</li>
<li><span class="math inline">\(X_{age,i}\)</span> is the age of subject <span class="math inline">\(i\)</span> measured in years divided by <span class="math inline">\(100\)</span></li>
<li><span class="math inline">\(X_{income,i}\)</span> is the annual income of subject <span class="math inline">\(i\)</span> in tens of thousands of dollars</li>
</ul>
<p>The following <code>R</code> codes produces the classic regression output table (simular tables are produced by all statistical/econometric software packages):</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-26_4cd639305e6b1e94689e029dd292f3bd">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>lm_obj_summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(lm_obj)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>lm_obj_summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = visits ~ gender + age + income, data = DoctorVisits)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.5009 -0.3435 -0.2306 -0.1682  8.6174 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   0.15371    0.03607   4.262 2.07e-05 ***
genderfemale  0.06245    0.02345   2.662  0.00778 ** 
age           0.40235    0.05713   7.043 2.13e-12 ***
income       -0.08231    0.03167  -2.599  0.00938 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.7908 on 5186 degrees of freedom
Multiple R-squared:  0.01885,   Adjusted R-squared:  0.01829 
F-statistic: 33.22 on 3 and 5186 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The above regression output table contains the following information:</p>
<ul>
<li><p><strong>Estimate:</strong> The column “Estimate” containes the estimates <span class="math display">\[
\hat\beta_{j},\quad j\in\{1,gender, age, income\}
\]</span> You can extract them using <code>coef(lm_obj)</code>.</p></li>
<li><p><strong>Std. Error:</strong> The column “Std. Error” containes the estimates <span class="math display">\[
\widehat{\operatorname{SE}}(\hat\beta_{j}|X),\quad j\in\{1,gender, age, income\}
\]</span></p>
<ul>
<li>You can extract the total <span class="math inline">\((K\times K)=(4\times 4)\)</span> variance-covariance matrix estimate <span class="math inline">\(\widehat{Var}(\hat\beta|X)\)</span> using <code>vcov(lm_obj)</code>.</li>
<li>The diagonal <code>diag(vcov(lm_obj))</code> contains the variance estimates <span class="math inline">\(\widehat{Var}(\hat\beta_j|X)\)</span>, <span class="math inline">\(j\in\{1,gender, age, income\}\)</span>.</li>
<li>The square root of the diagonal <code>sqrt(diag(vcov(lm_obj)))</code> allows you to compute the estimated standard errors shown in the regression table.</li>
</ul></li>
<li><p><strong>t value:</strong> The column “t value” contains the observed <span class="math inline">\(t\)</span> test statistics <span class="math display">\[
t_{obs,j}=\frac{\hat\beta_{j}}{\widehat{\operatorname{SE}}(\hat\beta_{j}|X)},\quad j\in\{1,gender, age, income\}
\]</span> You can extract the values using <code>lm_obj_summary$coefficients[,3]</code>.</p></li>
<li><p><strong>Pr(&gt;|t|):</strong> The column “Pr(&gt;|t|)” contains the <span class="math inline">\(p\)</span> values <span class="math display">\[
P_{H_0}(|t|&gt;t_{obs,j}),\quad j\in\{1,gender, age, income\}
\]</span> You can extract the values using <code>lm_obj_summary$coefficients[,4]</code>.</p></li>
<li><p><strong>Residual standard error</strong> <span class="math inline">\(\sqrt{\frac{1}{n-K}\sum_{i=1}^n\hat\varepsilon^2_i}=\)</span> <code>sqrt(sum(resid(lm_obj)^2)/(n-4))</code> <span class="math inline">\(=\)</span> 0.7908</p></li>
<li><p><strong>Multiple R-squared:</strong> <span class="math inline">\(R^2=\)</span> <code>lm_obj_summary$r.squared</code> <span class="math inline">\(=\)</span> 0.01885</p></li>
<li><p><strong>Adjusted R-squared:</strong> <span class="math inline">\(\bar{R}^2=\)</span> <code>lm_obj_summary$adj.r.squared</code> <span class="math inline">\(=\)</span> 0.01829</p></li>
<li><p><strong>F-statistic:</strong> This is a standard <span class="math inline">\(F\)</span> test that tests the null hypothesis that all parameters except the intercept are zero; i.e.<br> <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_{gender}=\beta_{age}=\beta_{income}=0\)</span><br> versus<br> <span class="math inline">\(H_1\)</span>: At least one parameter is not zero. <code>R</code>’s <code>summary()</code> functions reports an observed <span class="math inline">\(F\)</span> statistic value of <span class="math inline">\(33.22\)</span> which needs to be evaluated for an <span class="math inline">\(F\)</span> distribution with <span class="math inline">\(3\)</span> and <span class="math inline">\(5186\)</span> degrees of freedom leading to a <span class="math inline">\(p\)</span>-value <span class="math inline">\(p&lt; 0.00001.\)</span> <br><br> You can replicate this <span class="math inline">\(F\)</span>-test result using the following <code>R</code> code:</p></li>
</ul>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-27_b87ceb55f926be65cbaae6010fe2d460">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">model =</span> lm_obj, </span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">hypothesis.matrix =</span> <span class="fu">c</span>(<span class="st">"genderfemale=0"</span>, <span class="st">"age=0"</span>, <span class="st">"income=0"</span>))  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear hypothesis test

Hypothesis:
genderfemale = 0
age = 0
income = 0

Model 1: restricted model
Model 2: visits ~ gender + age + income

  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
1   5189 3305.5                                  
2   5186 3243.2  3     62.32 33.218 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<!-- #### Interpretation of $\hat\beta_{gender}$ {-} -->
<!-- Since $X_{gender,i}$ is a dummy variable,  -->
<section id="r-package-stargazer" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="r-package-stargazer"><code>R</code> Package Stargazer</h4>
<p>Beautiful and “publication ready” regression outputs can be produced using the <code>R</code> package <code>stargazer</code> and its function <code>stargazer()</code>:</p>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-28_645da944ec53e22711632520b084905e">

</div>
<center>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-29_ceb2c6d174a45c8314561ad0c06f8be6">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Hint: use type = "latex" </span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="do">## to produce a latex table</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">stargazer</span>(lm_obj, <span class="at">type=</span><span class="st">"html"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<table style="text-align:center">
<tbody><tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
visits
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
genderfemale
</td>
<td>
0.062<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.023)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
age
</td>
<td>
0.402<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.057)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
income
</td>
<td>
-0.082<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.032)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
0.154<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.036)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
5,190
</td>
</tr>
<tr>
<td style="text-align:left">
R<sup>2</sup>
</td>
<td>
0.019
</td>
</tr>
<tr>
<td style="text-align:left">
Adjusted R<sup>2</sup>
</td>
<td>
0.018
</td>
</tr>
<tr>
<td style="text-align:left">
Residual Std. Error
</td>
<td>
0.791 (df = 5186)
</td>
</tr>
<tr>
<td style="text-align:left">
F Statistic
</td>
<td>
33.218<sup>***</sup> (df = 3; 5186)
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
<em>Note:</em>
</td>
<td style="text-align:right">
<sup><em></em></sup><em>p&lt;0.1; <sup><strong></strong></sup><strong>p&lt;0.05; <sup></sup></strong></em>p&lt;0.01
</td>
</tr>

</tbody></table>
</div>
</center>
</section>
<section id="critical-discussion-of-the-regression-above-results" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="critical-discussion-of-the-regression-above-results">Critical Discussion of the Regression above Results</h4>
<p>The above real data analysis does <strong>not</strong> fit into the small sample inference framework we introduced in this chapter.</p>
<ol type="1">
<li>The dependent variable <span class="math inline">\(Y_i\)</span> <code>visits</code> is a <em>categorial</em> variable taking finitely many discrete values, indeed
<center>
<code>unique(DoctorVisits$visits)</code> = 1, 2, 3, 4, 8, 5, 7, 6, 9, 0.
</center>
Consequently, the error term <span class="math inline">\(\varepsilon_i\)</span> <strong>cannot be normal distributed</strong>.</li>
<li>The diagnostic plot (“Residuals versus Fitted”) indicates a possible issue <strong>violation of the homoskedasticity assumption</strong>. In case of homokedastic variances, the data points <span class="math inline">\((\hat\varepsilon_i,\hat{Y}_i)\)</span>, <span class="math inline">\(i=1,\dots,n\)</span> should roughly show a homogenous scattering across the fitted values <span class="math inline">\(\hat{Y}_i=X\hat\beta\)</span>. This seems not to be the case here.</li>
</ol>
<div class="cell" data-hash="05-Small-Sample-Inference_cache/html/unnamed-chunk-30_537c50a55394db028d1144140a24c3f0">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Diagonstic Plot </span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Residuals versus fitted values</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_obj, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="05-Small-Sample-Inference_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Lukily, the data set <code>DoctorVisits</code> actually has a <strong>large sample size</strong> of <span class="math inline">\(n=\)</span> 5190 and thus there is a way out of this problem: The large sample inference framework introduced in the next chapter.</p>
<!-- ## Exercises -->
<!-- * [Exercises for Chapter 5](Exercises/Ch5_Exercises.pdf) -->
<!-- * [Exercises of Chapter 5 with Solutions](Exercises/Ch5_Exercises_with_Solutions.pdf) -->
</section>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Hayashi2000" class="csl-entry" role="doc-biblioentry">
Hayashi, Fumio. 2000. <em>Econometrics</em>. Princeton University Press.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./04-Multiple-Linear-Regression.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Multiple Linear Regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./06-Asymptotics.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Large Sample Inference</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>