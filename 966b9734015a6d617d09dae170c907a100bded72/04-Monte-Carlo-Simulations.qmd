# Monte Carlo Simulations



In the following parts of the lecture, we will use Monte Carlo simulations in oder to check whether a certain estimator is able to estimate its (usually unknown) target parameter. In this chapter, we will learn what Monte Carlo simulations are and how they can be implemented. 


## Estimator vs. Estimate 

Let's assume that we have an iid random sample $X_1,\dots,X_n$ with 
$$
X_i\overset{iid}{\sim} F_X
$$ 
for all $i=1,\dots,n$, and let $\theta\in\mathbb{R}$ denote some parameter (e.g. the mean or the variance) of the distribution $F_X$. 

An **estimator** $\hat\theta_n$ of $\theta$ is a function of the random sample $X_1,\dots,X_n$,
$$
\hat\theta_n:=\hat\theta(X_1,\dots,X_n).
$$

Since $\hat\theta_n$ is a function of the random variables $X_1,\dots,X_n$, the estimator $\hat\theta_n$ is itself a **random variable**. 

The observed data $X_{1,obs},\dots,X_{n,obs}$ is assumed to be a certain realization of the random sample $X_1,\dots,X_n$. The corresponding **realization** of the estimator is called an **estimate** of $\theta$
$$
\hat\theta_{n,obs}=\hat\theta(X_{1,obs},\dots,X_{n,obs}).
$$

::: {.callout-note}
Often we do not use a distinguishing notation, but denote both the estimator and its realization as $\hat\theta_{n}$. This ambiguity is often convenient since both points of views can make sense in a given context. 
:::

**Examples:**

* The sample mean as an estimator of the population mean $E(X_i) =\theta$:
$$
\hat\theta_n=\bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i
$$ 

* The sample variance as an estimator of the population variance $Var(X_i) =\theta$:
$$
\hat\theta_n=s_{UB}^2=\frac{1}{n-1}\sum_{i=1}^n\left(X_i - \bar{X}_n\right)^2
$$ 


## Deriving the Distribution of Estimators

Usually, we do not know the distribution $F_X$ of the random sample $X_1,\dots,X_n$ and thus do not know the distribution of the estimator 
$$
\hat\theta_n=\hat\theta(X_1,\dots,X_n).
$$ 
This is a fundamental statistical problem and we need to overcome this problem in order to do statistical inference (hypothesis testing, etc.).  


There are different possibilities to derive/approximate the distribution of an estimator $\hat\theta_n$.  In times when when computers were expensive, statisticians mainly used mathematical derivations:  

* **Mathematical Derivation using Distributional Assumptions.** Assuming a certain distribution $F_X$ for the random sample $X_1,\dots,X_n$ allows us to derive the *exact* distribution of $\hat\theta_n$ mathematically. (We consider this option in @sec-ssinf.)
  * Pro: If the distributional assumption is correct, one has *exact* inference for each sample size $n$. 
  * Con: This option can fail miserably if the distributional assumption on $F_X$ is wrong. 
  * Con: Such mathematical derivations are often only possible for particular distributions $F_X$ like the normal distribution. 

* **Mathematical Derivation using Asymptotic Statistics.** Large sample $(n\to\infty)$ approximations (i.e. laws of large numbers and central limit theorems) allow us to derive the *approximate* distribution of $\hat\theta_n$. This option uses mathematical limit considerations by letting the sample size $n$ diverge to infinity. (We consider this option in @sec-lsinf.) 
  * Pro: Only a few qualitative distributional assumptions are needed. 
  * Con: The derived asymptotic ($n\to\infty$) distribution is only exact for the practically impossible case where $n=\infty$ and thus can fail to approximate the exact distribution of $\hat\theta_n$ for given (finite) sample sizes $n$; particularly if $n$ is small. 

With computers, we have further options to approximate the exact distribution of estimators using (pseudo-)random number generators. One example are Monte Carlo simulations:

* **Monte Carlo Simulations.** Let's say the distribution $F_X$ of the random sample were known. Then, using (pseudo-)random number generators, we can draw `B` many realizations 
\begin{align*}
&(X_{1,1,obs},\dots,X_{n,1,obs})\\
&(X_{1,2,obs},\dots,X_{n,2,obs})\\
& \hspace{2cm}\vdots \\
&(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}
of the random sample $X_{1},\dots,X_{n}$ from $F_X$ and thus can compute `B` many realizations 
\begin{align*}
\hat\theta_{n,1,obs} &= \hat\theta(X_{1,1,obs},\dots,X_{n,1,obs})\\
\hat\theta_{n,2,obs} &= \hat\theta(X_{1,2,obs},\dots,X_{n,2,obs})\\
&\vdots\\
\hat\theta_{n,B,obs} &= \hat\theta(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*} 
of the estimator $\hat\theta_n$. <br>
This set of realizations $\hat\theta_{n,1,obs},\dots,\hat\theta_{n,B,obs}$ allows us then to approximate the exact distribution of $\hat\theta_n$ for given sample sizes $n$ and given distributions $F_X$, since the empirical distribution function 
$$
\hat{F}_{\hat{\theta}_n}(x)=\frac{1}{B}\sum_{j=1}^BI_{(\hat\theta_{n,1,obs} \leq x)}
$$
approximates the true (unknown) distribution function of $\hat{\theta}_n$
$$
F_{\hat{\theta}_n}(x)=P(\hat\theta_{n} \leq x)
$$
arbitrarily well as $B\to\infty,$ i.e.
$$
\sup_x\left| \hat{F}_{\hat{\theta}_n}(x) - F_{\hat{\theta}_n}(x)\right|\to 0\quad\text{as}\quad B\to\infty.
$$
almost surely as $B\to\infty$; see the famous [Glivenkoâ€“Cantelli theorem](https://en.wikipedia.org/wiki/Glivenko%E2%80%93Cantelli_theorem). (We use this option to *validate* theoretical statements in @sec-ssinf and @sec-lsinf.)

  * Pro: Works for basically every distributional assumption. 
  * Con: This option can fail miserably if the distributional assumption on $F_X$ is wrong. 


<!-- Monte Carlo Simulations rely on distributional assumptions and thus may fail just as the first option (Mathematical Derivation using Distributional Assumptions). However, Monte Carlo Simulations are much wider applicable than since we can use computers to sample data from basically every distribution.   -->

### Conducting a Monte Carlo Simulation 

The following `R` code generates `B` many realizations of the sample mean estimator $\hat\theta_n=\bar{X}_n$ using a random sample $X_1,\dots,X_n$, where $F_X$ is a normal distribution with mean $(\theta=)\mu=10$ and variance $\sigma^2=5$:  
```{r}
## True parameter value 
mu            <- 10
## Number of Monte Carlo repetitions:
B             <- 10000
## Sequence of different sample sizes:
n_seq         <- c(5, 15, 50)


## ######################################
## 1st Possibility: Using a for() loop ##
## ######################################

## Set seed for the random number generator to get reproducible results
set.seed(3)

# Container for the generated estimates:
estimates_mat <- matrix(NA, nrow = B, ncol = length(n_seq))

for(j in 1:length(n_seq)){
  ## select the sample size
  n <- n_seq[j]
  for(b in 1:B){
    ## generate realization of the random sample 
    X_sample <- rnorm(n = n, mean = mu, sd = sqrt(5))
    ## compute the sample mean and safe it
    estimates_mat[b,j] <- mean(X_sample)
  }
}

## #####################################
## 2nd Possibility: Using replicate() ##
## #####################################

## Set seed for the random number generator to get reproducible results
set.seed(3)

## Function that generates estimator realizations 
my_estimates_generator <- function(n){
  X_sample <- rnorm(n = n, mean = mu, sd = sqrt(5))
  ## compute the sample mean realization
  return(mean(X_sample))
}

estimates_mat <- cbind(
  replicate(B, my_estimates_generator(n = n_seq[1])),
  replicate(B, my_estimates_generator(n = n_seq[2])),
  replicate(B, my_estimates_generator(n = n_seq[3]))
)
```

Based on the `B`$=10,000$ realizations of the estimator $\bar{X}_n$, we can compute histograms and non-parametric density estimates to get an idea about the true distribution of $\bar{X}_n$ for the case of random samples $X_1,\dots,X_n$ from a normal distribution with mean $\mu=10$ and variance $\sigma^2=5$:
```{r, fig.align="center", fig.cap=""}
#| label: fig-histdensplots
#| fig-cap: "Histrograms and non-parametric density estimates of the distributions of the sample mean estimator for different sample sizes." 
par(mfrow=c(1,3))
hist(estimates_mat[,1], main="n=5", xlab="",  xlim = range(estimates_mat[,1]), prob = TRUE, ylim = c(0, 1.2))
lines(density(estimates_mat[,1], bw = bw.SJ(estimates_mat[,1])), col="blue", lwd=1.5)
hist(estimates_mat[,2], main="n=15", xlab="", xlim = range(estimates_mat[,1]), prob = TRUE, ylim = c(0, 1.2))
lines(density(estimates_mat[,2], bw = bw.SJ(estimates_mat[,3])), col="blue", lwd=1.5)
hist(estimates_mat[,3], main="n=50", xlab="", xlim = range(estimates_mat[,1]), prob = TRUE, ylim = c(0, 1.2))
lines(density(estimates_mat[,2], bw = bw.SJ(estimates_mat[,3])), col="blue", lwd=1.5)
```

Observations (@fig-histdensplots): 

* At least on average, the estimates $\bar{X}_n$ are close to the target parameter $\mu=10$ for each sample size $n\in\{5,15,50\}$. This feature of the estimator's distribution is summarized by the **bias** (see next section) of an estimator.

* As the sample size increases, the distributions of the estimators $\bar{X}_n$ concentrate around the target parameter $\mu=10$. This feature of the estimator's distribution is summarized by the **mean squared error** (see next section) of an estimator.

Thus here the quality of the estimator $\bar{X}_n$ gets better as $n$ gets large. To describe the quality of estimators more compactly, statisticians/econometricians use specific metrics like bias, variance and the mean squared error of the distribution of a estimator $\hat\theta$.

## Assessing the Quality of Estimators 

<!-- But how good is a given estimator $\hat\theta_n$ for a given sample size?  -->

Any reasonable estimator $\hat\theta_n$ should be able to approximate the (usually unknown) parameter value $\theta$,
$$
\hat\theta_n\approx\theta,
$$
and the approximation should get better as the sample size increases (i.e. as $n\to\infty$).

Statisticians and econometricians use different metrics to assess the approximation quality of an estimator $\hat\theta_n$. The most prominent metrics are bias, variance, and mean squared error.

::: {.callout-note icon=false}
##
::: {#def-bias}
## Bias of $\theta$

The **bias** of an estimator $\hat\theta_n$ is defined as

$$
\operatorname{Bias}\left(\hat\theta_n\right) = E\left(\hat\theta_n\right) - \theta.
$$
:::
:::

If an estimator $\hat\theta_n$ has no bias 
$$
\operatorname{Bias}\left(\hat\theta_n\right)=0
$$ 
for all $n,$ we call it an **unbiased estimator**. Many modern estimators are *not* unbiased. However, every estimator should **asymptotically unbiased**, i.e.
$$
\lim_{n\to\infty}\operatorname{Bias}\left(\hat\theta_n\right)=0.
$$ 


We would like to have estimators with a small (or zero) bias. 

If the bias of an estimator is small (or zero), we know that the estimator will have a distribution that roughly (or exactly) centered around the true (usually unknown) parameter $\theta.$ However, such an estimator may still vary a lot around $\theta$. Therefore, is is also important to assess the variance of the estimator. 


::: {.callout-note icon=false}
##
::: {#def-var}

## Variance and Standard Error of $\theta$

The **variance** of an estimator $\hat\theta_n$ is defined equivalently to the variance of any other random variable

$$
Var\left(\hat\theta_n\right) = E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right].
$$
The square root of the variance of an estimator is called **standard error** (not standard deviation) of $\hat\theta_n$, 
$$
\operatorname{SE}\left(\hat\theta_n\right) = \sqrt{Var\left(\hat\theta_n\right)}.
$$
:::
:::

We would like to have estimators with a small as possible variance, and the variance should decline as the sample size increases, such that $\lim_{n\to\infty}Var\left(\hat\theta_n\right)=0$.


::: {.callout-note icon=false}
##
::: {#def-mse}

## Mean Squared Error of $\theta$

The **mean squared error** of an estimator $\hat\theta_n$ is defined as

$$
\operatorname{MSE}\left(\hat\theta_n\right) =  E\left[\left(\hat\theta_n - \theta\right)^2\right].
$$
:::
:::

We would like to have estimators with a small as possible mean squared error, and the mean squared error should decline as the sample size increases, such that $\lim_{n\to\infty}\operatorname{MSE}\left(\hat\theta_n\right)=0$.

The following holds true:

* The mean squared error equals the sum of the squared bias and the variance: 

$$
\operatorname{MSE}\left(\hat\theta_n\right) = \left(\operatorname{Bias}\left(\hat\theta_n\right)\right)^2 +  Var\left(\hat\theta_n\right) 
$$

* For unbiased estimators (i.e. $E(\hat\theta_n)=\theta$) the mean squared error equals the variance, i.e.

$$
\underbrace{E\left[\left(\hat\theta_n - \theta\right)^2\right]}_{\operatorname{MSE}\left(\hat\theta_n\right)} = \underbrace{E\left[\left(\hat\theta_n - E\left(\hat\theta_n\right)\right)^2\right]}_{ Var\left(\hat\theta_n\right)} 
$$


Unfortunately, it is often difficult to derive the above assessment metrics for given sample sizes $n$ and given data distributions $F_X$. Monte Carlo simulations allow us to solve this issue.

## Approximating Bias, Variance, and Mean Squared Error using Monte Carlo Simulations 

We can use Monte Carlo simulations to approximate the assessment metrics $\operatorname{Bias}\left(\hat\theta_n\right),$ $Var\left(\hat\theta_n\right),$ and  $\operatorname{MSE}\left(\hat\theta_n\right)$ for given sample sizes $n$ and given data distributions $F_X$ with arbitrary precision. 


Any of the the above assessment metrics require us to compute means of random variables: 

* For the $\operatorname{Bias}\left(\hat\theta_n\right)$ we need to compute $E\left(\hat\theta_n\right)-\theta$

* For the $Var\left(\hat\theta_n\right)$ we need to compute $E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right]$.

* For the $\operatorname{MSE}\left(\hat\theta_n\right)$ we need to compute $E\left[\left(\hat\theta_n - \theta\right)^2\right]$.


A Monte Carlo simulation can approximate these means by using the **law of large numbers** which states that a sample mean over iid random variables is able to approximate the population mean of these random variables as the number of random variables to average over get large.[^1]

[^1]: See @thm-SLLN1 in @sec-lsinf.


Thus, to compute a very precise approximation to $E\left(\hat\theta_n\right)-\theta$, we can use a computer to execute the following algorithm:

**Step 1.** Generate $B$ many (e.g. $B=10,000$) realizations of the iid random sample 

$$
(X_{1,1},\dots,X_{n,1}),\; (X_{1,2},\dots,X_{n,2}),\dots, (X_{1,B},\dots,X_{n,B})
$$

**Step 2.** Compute the corresponding $B$ many realizations of the estimator 

$$
\underbrace{\hat\theta(X_{1,1},\dots,X_{n,1})}_{=\hat\theta_{n,1}},\;\underbrace{\hat\theta(X_{1,2},\dots,X_{n,2})}_{=\hat\theta_{n,2}},\dots,\underbrace{\hat\theta(X_{1,B},\dots,X_{n,B})}_{=\hat\theta_{n,B}}
$$ 
**Step 3.** Use the simulated realizations $\hat{\theta}_{n,1},\dots,\hat{\theta}_{n,B}$ to approximate the bias, variance, and the mean squared error of the estimator $\hat{\theta}_n$:

* The bias of $\operatorname{Bias}\left(\hat\theta_n\right)=E\left(\hat\theta_n\right)-\theta$ can be approximated by 

$$
\widehat{\operatorname{Bias}}_{MC}\left(\hat\theta_n\right) = \left(\frac{1}{B}\sum_{b=1}^B \hat\theta_{n,b}\right) - \theta 
$$

* The variance $Var\left(\hat\theta_n\right)=E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right]$ can be approximated by
$$
\widehat{Var}_{MC}\left(\hat\theta_n\right) = \frac{1}{B}\sum_{b=1}^B \left(\hat\theta_{n,b} - \left(\frac{1}{B}\sum_{b=1}^B \hat\theta_{n,b}\right)\right)^2 
$$

* The mean squared error $\operatorname{MSE}\left(\hat\theta_n\right)=E\left[\left(\hat\theta_n - \theta\right)^2\right]$ can be approximated by 
$$
\widehat{\operatorname{MSE}}_{MC}\left(\hat\theta_n\right) = \frac{1}{B}\sum_{b=1}^B \left(\hat\theta_{n,b} - \theta\right)^2 
$$


By law of large numbers these approximations get arbitrarily precise as $B \to \infty$. 


### Example: Sample Mean {-}

The following `R` code contains a Monte Carlo simulation ( `B = 10000` replications) computing the bias, variance, and means squared error for the sample mean $(\hat\theta_n=)\bar{X}_n=\sum_{i=1}^nX_i$ as the estimator of the population mean $(\theta=)\mu$. The random sample $X_i\overset{iid}{\sim}F_X$, $i=1,\dots,n$, is drawn from a normal distribution $F_X=\mathcal{N}(\mu,\sigma^2)$ with mean $\mu=10$ and variance $\sigma^2=5$. We investigate the accuracy of the estimator for different sample sizes $n\in\{5,15,50\}$. 
<!-- The following `R` codes generated `B = 10000` realizations of the estimator $\bar{X}_n$ for each sample size $n\in\{5,15,50\}$ and stores all these realizations in a $10000\times 3$ matrix `estimates_mat`: -->
```{r}
## Set seed for the random number generator to get reproducible results
set.seed(3)
## True parameter value ('theta' here 'mu')
mu            <- 10
## Number of Monte Carlo repetitions:
B             <- 10000
## Sequence of different sample sizes:
n_seq         <- c(5, 15, 50)

## Function that generates estimator realizations 
my_estimates_generator <- function(n){
  X_sample <- rnorm(n = n, mean = mu, sd = sqrt(5))
  ## compute the sample mean realization
  return(mean(X_sample))
}

estimates_mat <- cbind(
  replicate(B, my_estimates_generator(n = n_seq[1])),
  replicate(B, my_estimates_generator(n = n_seq[2])),
  replicate(B, my_estimates_generator(n = n_seq[3]))
)
```



The following `R` code computes the Monte Carlo (MC) approximations for the bias, variance, and mean squared error of $\bar{X}_n$. The results should capture our observations. 
```{r}
## Bias of the sample mean for different sample sizes n
MC_Bias_n_seq <- apply(estimates_mat, 2, mean) - mu

## Variance of the sample mean for different sample sizes n
MC_Var_n_seq  <- apply(estimates_mat, 2, var)

## Mean squared error of the sample mean for different sample sizes n
MC_MSE_n_seq  <- apply(estimates_mat, 2, function(x){mean((x - mu)^2)})
```



The table shows the numerical values of the Monte Carlo *approximations* for the true bias, true variance, and true mean squared error of $\bar{X}_n$:
```{r, echo=FALSE}
#| label: tbl-mcbvmse
#| tbl-cap: Monte Carlo approximations for the true bias, true variance, and true mean squared error of sample mean.
suppressPackageStartupMessages(library("kableExtra"))
suppressPackageStartupMessages(library("tidyverse"))

MCResults <- tibble(
  "n"        = n_seq,
  "Bias (MC-Sim) "     = round(MC_Bias_n_seq, 3),
  "Variance (MC-Sim)"  = round(MC_Var_n_seq,  2),
  "MSE (MC-Sim) "      = round(MC_MSE_n_seq,  2))
           
MCResults %>% kbl() %>%  kable_styling()
```


These Monte Carlo approximations (@tbl-mcbvmse) indicate that:  

- The true bias $\operatorname{Bias}(\bar{X}_n)$ is very likely zero for all sample sizes $n\in\{5,15,50\}$

<!-- , and thus $Var(\bar{X}_n)\approx \operatorname{MSE}(\bar{X}_n)$ for all sample sizes $n\in\{5,15,50\}$. -->

- The true mean squared error $\operatorname{MSE}(\bar{X}_n)$ is very likely decreasing as the sample size $n$ get larger. 


<!-- The sample mean $\bar{X}_n$ is known to be a very good estimator of the population mean $\mu$ and the above simulation results conform this.  -->


Since this example is chosen to be an extremely simple one, we can easily derive the *true* bias, variance and mean squared error values and compare them with their Monte Carlo approximations: 

* True bias of $\bar{X}_n$:
\begin{align*}
\operatorname{Bias}\left(\bar{X}_n\right)
&=E\left(\frac{1}{n}\sum_{i=1}^nX_i\right) - \mu \\[2ex]
&= \left(\frac{1}{n}\sum_{i=1}^nE(X_i)\right) -\mu\\[2ex] 
&= \frac{n}{n}\mu-\mu \\[2ex]
&=0,
\end{align*}
thus the mean squared error of $\bar{X}_n$ equals the variance of $\bar{X}_n$. 

* True variance of $\bar{X}_n$:
\begin{align*}
Var\left(\bar{X}_n\right)
&=Var\left(\frac{1}{n}\sum_{i=1}^nX_i\right)\\[2ex] 
&= \frac{1}{n^2} \sum_{i=1}^nVar\left(X_i\right)\\[2ex]
&= \frac{n}{n^2}\sigma^2 \\[2ex]
&= \frac{1}{n}\sigma^2 
\end{align*}
The following table shows the true bias, true variance and true mean squared error values:

```{r, echo=FALSE}
#| label: tbl-truebvmse
#| tbl-cap: True bias, true variance, and true mean squared error of sample mean. (Only computable in simple special cases.)
suppressPackageStartupMessages(library("kableExtra"))
suppressPackageStartupMessages(library("tidyverse"))

MCResults <- tibble(
  "n"        = n_seq,
  "Bias (true) "     = rep(0, 3),
  "Variance (true)"  = round(5/n_seq, 2),
  "MSE (true) "      = round(5/n_seq, 2))
           
MCResults %>% kbl() %>%  kable_styling()
```

Obviously, the Monte Carlo approximations (@tbl-mcbvmse) for these true values (@tbl-truebvmse) are very good. If we would further increase the number of Monte Carlo repetitions `B`, the Monte Carlo approximations would get even more precise since we can make them arbitrarily precise by letting `B`$\to\infty$ using the law of large numbers. 



<!-- ## Exercises -->

<!-- * [Exercises for Chapter 4](Exercises/Ch4_Exercises.pdf) -->

<!-- * [Exercises of Chapter 4 with Solutions](Exercises/Ch4_Exercises_with_Solutions.pdf) -->








<!-- ```{r, fig.align="center"} -->
<!-- par(mfrow=c(1,3)) -->
<!-- plot(x = n_seq, y = Bias_n_seq, type = "b", ylim = c(-0.2, 0.2),  -->
<!--      main="Bias", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- plot(x = n_seq, y = Var_n_seq, type = "b", ylim = c(0, 1.5), -->
<!--      main="Variance", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- plot(x = n_seq, y = MSE_n_seq, type = "b", ylim = c(0, 1.5), -->
<!--      main="MSE", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- ``` -->




<!-- like, for instance, the arithmetic mean   -->
<!-- $$ -->
<!-- \bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i -->
<!-- $$ -->
<!-- as an estimator of the population mean value $\mu$.  -->

