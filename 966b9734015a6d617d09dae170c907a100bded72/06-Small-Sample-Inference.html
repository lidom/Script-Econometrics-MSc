<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8" />
<meta name="generator" content="quarto-1.5.57" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />


<title>6  Small Sample Inference – Basis Module Econometrics (M.Sc.)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<!-- htmldependencies:E3FAD763 -->
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn"
      data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" 
      aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation"
      onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <h1 class="quarto-secondary-nav-title no-breadcrumbs"></h1>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" role="link"
        aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation"
        onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="/index.html" class="sidebar-logo-link">
      <img src="/images/Uni_Bonn_Logo.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none"/>
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="/">
      Basis Module Econometrics (M.Sc.)
      </a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Organization of the Course</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/01-Introduction-to-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/02-Probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/03-Matrix-Algebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>3</span>  <span class='chapter-title'>Matrix Algebra</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/04-Monte-Carlo-Simulations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>4</span>  <span class='chapter-title'>Estimation Theory and Monte Carlo Simulations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/05-Multiple-Linear-Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple Linear Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/06-Small-Sample-Inference.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class='chapter-number'>6</span>  <span class='chapter-title'>Small Sample Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/07-Asymptotics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>7</span>  <span class='chapter-title'>Large Sample Inference</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" ></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <div id="quarto-toc-target"></div>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-ssinf" class="quarto-section-identifier"><span class="chapter-number">6</span>  <span class="chapter-title">Small Sample Inference</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>

<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#normality-of-the-ols-estimator" id="toc-normality-of-the-ols-estimator"><span class="header-section-number">6.1</span> Normality of the OLS-Estimator</a></li>
  <li><a href="#sec-testmultp" id="toc-sec-testmultp"><span class="header-section-number">6.2</span> <span class="math inline">\(F\)</span>-Tests: Hypothesis Tests about Multiple Parameters</a>
  <ul>
  <li><a href="#the-test-statistic-and-its-null-distribution" id="toc-the-test-statistic-and-its-null-distribution"><span class="header-section-number">6.2.1</span> The Test Statistic and its Null Distribution</a></li>
  <li><a href="#test-decision-using-the-rejection-region" id="toc-test-decision-using-the-rejection-region"><span class="header-section-number">6.2.2</span> Test Decision using the Rejection Region</a></li>
  <li><a href="#test-decision-using-the-p-value" id="toc-test-decision-using-the-p-value"><span class="header-section-number">6.2.3</span> Test Decision using the <span class="math inline">\(p\)</span>-Value</a></li>
  </ul></li>
  <li><a href="#sec-testingsinglep" id="toc-sec-testingsinglep"><span class="header-section-number">6.3</span> <span class="math inline">\(t\)</span>-Tests: Hypothesis Tests about One Parameter</a>
  <ul>
  <li><a href="#sec-tTestTestStat" id="toc-sec-tTestTestStat"><span class="header-section-number">6.3.1</span> The Test Statistic and its Null Distribution</a></li>
  <li><a href="#test-decision-using-the-rejection-region-one-sided-12" id="toc-test-decision-using-the-rejection-region-one-sided-12"><span class="header-section-number">6.3.2</span> Test Decision using the Rejection Region (One-Sided 1/2)</a></li>
  <li><a href="#test-decision-using-the-rejection-region-one-sided-22" id="toc-test-decision-using-the-rejection-region-one-sided-22"><span class="header-section-number">6.3.3</span> Test Decision using the Rejection Region (One-Sided 2/2)</a></li>
  <li><a href="#test-decision-using-the-rejection-region-two-sided" id="toc-test-decision-using-the-rejection-region-two-sided"><span class="header-section-number">6.3.4</span> Test Decision using the Rejection Region (Two-Sided)</a></li>
  <li><a href="#sec-TDecRS" id="toc-sec-TDecRS"><span class="header-section-number">6.3.5</span> Test Decision using the <span class="math inline">\(p\)</span>-Value (One-Sided 1/2)</a></li>
  <li><a href="#test-decision-using-the-p-value-one-sided-22" id="toc-test-decision-using-the-p-value-one-sided-22"><span class="header-section-number">6.3.6</span> Test Decision using the <span class="math inline">\(p\)</span>-Value (One-Sided 2/2)</a></li>
  <li><a href="#test-decision-using-the-p-value-two-sided" id="toc-test-decision-using-the-p-value-two-sided"><span class="header-section-number">6.3.7</span> Test Decision using the <span class="math inline">\(p\)</span>-Value (Two-Sided)</a></li>
  </ul></li>
  <li><a href="#sec-CIsmallsample" id="toc-sec-CIsmallsample"><span class="header-section-number">6.4</span> Confidence Intervals</a>
  <ul>
  <li><a href="#confidence-intervals-for-statistical-hypothesis-testing" id="toc-confidence-intervals-for-statistical-hypothesis-testing"><span class="header-section-number">6.4.1</span> Confidence Intervals for Statistical Hypothesis Testing</a></li>
  </ul></li>
  <li><a href="#testtheory" id="toc-testtheory"><span class="header-section-number">6.5</span> Testtheory</a>
  <ul>
  <li><a href="#simple-versus-composite-hypotheses" id="toc-simple-versus-composite-hypotheses"><span class="header-section-number">6.5.1</span> Simple versus Composite Hypotheses</a></li>
  <li><a href="#decisions-errors" id="toc-decisions-errors"><span class="header-section-number">6.5.2</span> Decisions Errors</a></li>
  <li><a href="#size" id="toc-size"><span class="header-section-number">6.5.3</span> Size</a></li>
  <li><a href="#power" id="toc-power"><span class="header-section-number">6.5.4</span> Power</a></li>
  <li><a href="#sec-pValue" id="toc-sec-pValue"><span class="header-section-number">6.5.5</span> <span class="math inline">\(p\)</span>-Value</a></li>
  </ul></li>
  <li><a href="#sec-PSSI" id="toc-sec-PSSI"><span class="header-section-number">6.6</span> Monte Carlo Simulations</a>
  <ul>
  <li><a href="#check-testing-multiple-parameters" id="toc-check-testing-multiple-parameters"><span class="header-section-number">6.6.1</span> Check: Testing Multiple Parameters</a></li>
  <li><a href="#check-dualty-of-confidence-intervals-and-hypothesis-tests" id="toc-check-dualty-of-confidence-intervals-and-hypothesis-tests"><span class="header-section-number">6.6.2</span> Check: Dualty of Confidence Intervals and Hypothesis Tests</a></li>
  </ul></li>
  <li><a href="#sec-RDSSInf" id="toc-sec-RDSSInf"><span class="header-section-number">6.7</span> Real Data Example</a></li>
  <li><a href="#exercises" id="toc-exercises"><span class="header-section-number">6.8</span> Exercises</a></li>
  <li><a href="#references" id="toc-references">References</a></li>
  </ul>
</nav>
<div class="hidden">
<p><span class="math display">\[
\require{color}
%% Colorbox within equation-environments:
\newcommand{\highlight}[2][yellow]{\mathchoice%
  {\colorbox{#1}{$\displaystyle#2$}}%
  {\colorbox{#1}{$\displaystyle#2$}}%
  {\colorbox{#1}{$\displaystyle#2$}}%
  }%
\]</span></p>
</div>
<blockquote>
<p>The original version of this chapter was inspired by Chapter 1 of <span class="citation" data-cites="Hayashi2000">Hayashi (<a href="#ref-Hayashi2000" role="doc-biblioref">2000</a>)</span>. The current version, however, deviates in many aspects from <span class="citation" data-cites="Hayashi2000">Hayashi (<a href="#ref-Hayashi2000" role="doc-biblioref">2000</a>)</span>.</p>
</blockquote>
<p>In this chapter, we focus on inference with small sample sizes. It’s is very hard to say when a sample size <span class="math inline">\(n\)</span> is small. A very rough rule of thumb could be, for instance, the following one:</p>
<ul>
<li><span class="math inline">\(n/K&lt;20\)</span> means small samples and <span class="math inline">\(n/K\geq 20\)</span> large samples</li>
</ul>
<p>The core issue with small sample sizes is that we cannot do inference using the law of large numbers and the central limit theorem—both requiring <span class="math inline">\(n\to\infty.\)</span> Thus we need rather strict assumptions on the distribution of the error term, in order to do inference in finite samples. If these assumption are fulfilled, however, then we do <strong>exact inference</strong>.</p>
<p><strong>Exact inference:</strong> By <em>exact inference</em> we mean correct inference for each sample size <span class="math inline">\(n\)</span>. That is, no approximate results based on asymptotic <span class="math inline">\((n\to\infty)\)</span> arguments will be used.</p>
<section id="normality-of-the-ols-estimator" class="level2" data-number="6.1">
<h2 data-number="6.1"><span class="header-section-number">6.1</span> Normality of the OLS-Estimator</h2>
<p><strong>Assumptions:</strong> In <a href="#sec-MLR" class="quarto-xref"><span class="quarto-unresolved-ref">sec-MLR</span></a>, we did not impose a complete distributional assumption on <span class="math inline">\(\varepsilon\)</span> (see Assumption 4). For instance, the i.i.d. normal case in Assumption 4 was only one possible <em>option</em>. However, to do inference in small samples, the normality Assumption on the error terms is not a mere option, but a <em>necessity</em>.</p>
<p>Therefore, in this chapter we assume that Assumptions 1-3 from <a href="#sec-MLR" class="quarto-xref"><span class="quarto-unresolved-ref">sec-MLR</span></a> hold and that additionally the following assumption holds:</p>
<p><strong>Assumption 4<span class="math inline">\(^\boldsymbol{\ast}\)</span>: Conditional Gaussian error distribution:</strong> The error terms are Gaussian and homoskedastik, i.e., <span class="math display">\[
\varepsilon_i|X_i\sim\mathcal{N}(0,\sigma^2)
\]</span> for all <span class="math inline">\(i=1,\dots,n.\)</span></p>
<p>Assumption 4<span class="math inline">\(^\boldsymbol{\ast}\)</span> together with the random sample assumption of Assumption 1, part (b), leads to Gaussian spherical errors, <span class="math display">\[
\varepsilon|X\sim\mathcal{N}_n\left(0,\sigma^2I_n\right),
\]</span> where <span class="math inline">\(\varepsilon=(\varepsilon_1,\dots,\varepsilon_n)&#39;,\)</span> and where <span class="math inline">\(\mathcal{N}_n\left(0,\sigma^2I_n\right)\)</span> denotes the <span class="math inline">\(n\)</span>-dimensional normal distribution with <span class="math inline">\((n\times 1)\)</span>-dimensional mean zero vector <span class="math inline">\(0\)</span> and <span class="math inline">\((n\times n)\)</span>-dimensional covariance matrix <span class="math inline">\(\sigma^2I_n.\)</span></p>
<!-- I.e. the distribution of $\varepsilon$ is here independent of $X.$ -->
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class='callout-icon no-icon'></i>
</div>
<div class="callout-body-container">
<div id="thm-normalbeta" class="theorem">
<p><span class="theorem-title"><strong>Theorem 6.1 (Normality of <span class="math inline">\(\hat\beta\)</span>)</strong></span> Under Assumptions 1-4<span class="math inline">\(^\ast\)</span> we have that <span id="eq-ssnorm"><span class="math display">\[
\hat\beta_n|X \sim \mathcal{N}_K\left(\beta,Var(\hat\beta_n|X)\right),
\qquad(6.1)\]</span></span> where <span class="math display">\[
Var(\hat\beta_n|X)=\underset{(K\times K)}{\sigma^2(X&#39;X)^{-1}}.
\]</span></p>
</div>
</div>
</div>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>This result follows from noting that <span class="math display">\[
\begin{align*}
\hat\beta_n
&amp;=(X&#39;X)^{-1}X&#39;Y\\[2ex]
&amp;=\beta+(X&#39;X)^{-1}X&#39;\varepsilon
\end{align*}
\]</span> and because <span class="math inline">\((X&#39;X)^{-1}X&#39;\varepsilon\)</span> is just a linear combination of the normally distributed error terms <span class="math inline">\(\varepsilon\)</span> which, therefore, is again normally distributed, conditionally on <span class="math inline">\(X\)</span>. Note that the specific normal distribution depends on the observed realization of <span class="math inline">\(X\)</span>.</p>
</div>
<p><strong>Remark:</strong> The subscript <span class="math inline">\(n\)</span> in <span class="math inline">\(\hat\beta_n\)</span> is here only to emphasize that the distribution of <span class="math inline">\(\hat\beta_n\)</span> depends on <span class="math inline">\(n\)</span>; we will, however, often simply write <span class="math inline">\(\hat\beta\)</span>.</p>
</section>
<section id="sec-testmultp" class="level2" data-number="6.2">
<h2 data-number="6.2"><span class="header-section-number">6.2</span> <span class="math inline">\(F\)</span>-Tests: Hypothesis Tests about Multiple Parameters</h2>
<p>Let us consider the following system of <span class="math inline">\(q\)</span>-many null hypotheses: <span class="math display">\[
\begin{align*}
H_0: \underset{(q\times K)}{R}\underset{(K\times 1)}{\beta}  = \underset{(q\times 1)}{r^{(0)}},
\end{align*}
\]</span> where</p>
<ul>
<li>the <span class="math inline">\((q \times K)\)</span> matrix <span class="math inline">\(R,\)</span> which describes the considered linear combinations of the unknown <span class="math inline">\(\beta=(\beta_1,\dots,\beta_K)&#39;\)</span> values, and</li>
<li>the <span class="math inline">\((q\times 1)\)</span> vector <span class="math inline">\(r^{(0)}=(r^{(0)}_{1},\dots,r^{(0)}_{q})&#39;\)</span> of null hypothetical values</li>
</ul>
<p><strong>are chosen by the statistician</strong> to specify the null hypothesis about the unknown true parameter vector <span class="math inline">\(\beta\)</span>.</p>
<p>To make sure that there are no redundant equations, it is required that <span class="math inline">\(\operatorname{rank}(R)=q\)</span>.</p>
<p>We must also specify the alternative against which we are testing the null hypothesis, for instance <span class="math display">\[
\begin{equation*}
H_1: R\beta  \neq r^{(0)}
\end{equation*}
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The above multiple parameter hypotheses cover also the special case of single parameter hypothesis; for instance, by setting</p>
<ul>
<li><span class="math inline">\(R=(0,1,0\dots,0)\)</span> and</li>
<li><span class="math inline">\(r^{(0)}=0\)</span></li>
</ul>
<p>we get the classic single parameter <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span> that allows us to test the hypothesis that “<span class="math inline">\(X_{i2}\)</span> has no effect”<br />
<span class="math display">\[
\begin{equation*}
\begin{array}{ll}
&amp;H_0:  \beta_{2}=0 \\
\text{versus}\quad &amp;H_1:  \beta_{2} \ne 0 \\
\end{array}
\end{equation*}
\]</span> We come back to this in <a href="#sec-testingsinglep" class="quarto-xref"><span class="quarto-unresolved-ref">sec-testingsinglep</span></a>.</p>
</div>
</div>
<p>Under our assumptions (Assumptions 1 to 4<span class="math inline">\(^\ast\)</span>), we have that <span class="math display">\[
\begin{align*}
(R\hat\beta_n-r^{(0)})|X&amp;\sim\mathcal{N}_q\left(R\beta -r^{(0)}, RVar(\hat\beta_n|X)R&#39;\right)%\\[2ex]
%\Leftrightarrow\quad \left(RVar(\hat\beta_n|X)R&#39;\right)^{-1/2}(R\hat\beta_n-r^{(0)})|X&amp;\sim\\[2ex]
%\hspace{2cm}\sim\mathcal{N}_q\left(\left(RVar(\hat\beta_n|X)R&#39;\right)^{-1/2}(R\beta -r^{(0)}),I_q\right)
\end{align*}
\]</span></p>
<p>Thus, under the scenario that the null-hypothesis is true, we have that <span class="math display">\[
\begin{align*}
(R\hat\beta_n-r^{(0)})|X&amp;\overset{{\color{red}{H_0}}}{\sim}\mathcal{N}_q\left(\,{\color{red}0}\,,RVar(\hat\beta_n|X)R&#39;\right)\\[2ex]
\Leftrightarrow\quad \left(RVar(\hat\beta_n|X)R&#39;\right)^{-1/2}(R\hat\beta_n-r^{(0)})\highlight{|X}&amp;\overset{{\color{red}{H_0}}}{\sim}\underbrace{\mathcal{N}_q\left(\,{\color{red}0}\,,I_q\right)}_{\highlight{\text{doesn&#39;t depend on $X$}}}\\[2ex]
\highlight{\Rightarrow}\quad \left(RVar(\hat\beta_n|X)R&#39;\right)^{-1/2}(R\hat\beta_n-r^{(0)})&amp;\overset{{\color{red}{H_0}}}{\sim}\mathcal{N}_q\left(\,{\color{red}0}\,,I_q\right),
\end{align*}
\]</span> where the last implication follows, since the standardized normal distribution does not depend on <span class="math inline">\(X.\)</span></p>
<p>That is, if <span class="math inline">\(H_0\)</span> is correct (i.e., if <span class="math inline">\(R\beta-r^{(0)}=0\)</span>), the realizations of <span class="math display">\[
\left(RVar(\hat\beta_n|X)R&#39;\right)^{-1/2}(R\hat\beta_n-r^{(0)})
\]</span> will scatter around the <span class="math inline">\((q\times 1)\)</span> vector <span class="math inline">\(0\)</span> in a Gaussian fashion.</p>
<p>We use a test statistic to detect a systematic location shift away from the <span class="math inline">\((q\times 1)\)</span> vector <span class="math inline">\(0.\)</span></p>
<!-- * if the alternative hypothesis is correct (i.e., $(R\beta-r)=a\neq 0$), there will be a systematic location-shift in $(R\hat\beta_n-r)|X$ which we try to detect using statistical hypothesis testing.  -->
<!-- the realizations of $R\hat\beta_n-r|X$ scatter around the $q$-vector $a\neq 0$.  So, under the alternative hypothesis,  -->
<section id="the-test-statistic-and-its-null-distribution" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1"><span class="header-section-number">6.2.1</span> The Test Statistic and its Null Distribution</h3>
<p>The fact that <span class="math display">\[
(R\hat\beta_n-r^{(0)})\in\mathbb{R}^q
\]</span> is a <span class="math inline">\(q\)</span>-dimensional random variable makes it a little bothersome to use as a test-statistic. Fortunately, we can turn <span class="math inline">\((R\hat\beta_n-r^{(0)})\)</span> into a scalar-valued test statistic using the following quadratic form: <span id="eq-TestStatW"><span class="math display">\[
\begin{align*}
W
&amp; = \overbrace{\left(\left(RVar(\hat\beta_n|X)R&#39;\right)^{-1/2}(R\hat\beta_n-r^{(0)})\right)&#39;\;\;}^{(1\times q)}\\
&amp;\;\;\;\;\;\;\underbrace{\left(\left(RVar(\hat\beta_n|X)R&#39;\right)^{-1/2}(R\hat\beta_n-r^{(0)})\right)}_{(q \times 1)}\\[2ex]
&amp; =\underbrace{(R\hat\beta_n -r^{(0)})&#39;}_{(1\times q)}\underbrace{[RVar(\hat\beta_n|X)R&#39;]^{-1}}_{(q\times q)}\underbrace{(R\hat\beta_n -r^{(0)})}_{(q\times 1)}
\end{align*}
\qquad(6.2)\]</span></span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that the test statistic <span class="math inline">\(W\)</span> is simply measuring the distance (it’s a weighted, squared Euclidean distance) between the <span class="math inline">\((q\times 1)\)</span> vectors <span class="math inline">\(R\hat\beta_n\)</span> and <span class="math inline">\(r^{(0)}.\)</span></p>
</div>
</div>
<p>Under the null hypothesis (i.e., if <span class="math inline">\(H_0\)</span> is true), <span class="math inline">\(W\)</span> is a sum of <span class="math inline">\(q\)</span>-many independent, squared standard normal <span class="math inline">\(\mathcal{N}(0,1)\)</span> random variables. Therefore, under the null hypothesis, <span class="math inline">\(W\)</span> is chi-square distributed with <span class="math inline">\(q\)</span> degrees of freedom (see definition of the chi-square distribution in <a href="#sec-chisqdist" class="quarto-xref"><span class="quarto-unresolved-ref">sec-chisqdist</span></a>), <span class="math display">\[
\begin{align*}
W&amp;\overset{H_0}{\sim} \chi^2_{(q)}
\end{align*}
\]</span> Note that the distribution of <span class="math inline">\(W\)</span> does not depend on <span class="math inline">\(X.\)</span> I.e. <span class="math inline">\(W\)</span> follows a <span class="math inline">\(\chi^2_{(q)}\)</span>-distribution no matter the realization of <span class="math inline">\(X.\)</span></p>
<p>Usually, however, we do not know <span class="math inline">\(Var(\hat\beta_n|X)=\sigma^2 (X&#39;X)^{-1},\)</span> since we usually do not know the value of <span class="math inline">\(\sigma^2.\)</span> Thus, we need to substitute <span class="math inline">\(\sigma^2\)</span> by an estimator.</p>
<p>For exact finite sample inference, we need a variance estimator of <span class="math inline">\(\sigma^2\)</span> for which we can derive its exact small sample distribution. Therefore, we require Assumption 4<span class="math inline">\(^*\)</span> of spherical errors, i.e. <span class="math inline">\(Var(\varepsilon|X)=\sigma^2I_n,\)</span> which implies that <span class="math inline">\(Var(\hat\beta_n|X)=\sigma^2(X&#39;X)^{-1}\)</span>, and where <span class="math inline">\(\sigma^2\)</span> can be estimated by the unbiased (<span class="math inline">\(UB\)</span>) variance estimator<br />
<span class="math display">\[
s_{UB}^2=(n-K)^{-1}\sum_{i=1}^n\hat\varepsilon_i^2.
\]</span><br />
From the normality assumption in Assumption 4<span class="math inline">\(^*\)</span>, it follows then that <span id="eq-distsquared"><span class="math display">\[
\frac{(n-K)}{\sigma^{2}}s_{UB}^2\sim\chi^2_{(n-K)}.
\qquad(6.3)\]</span></span></p>
<p>Substituting the unknown <span class="math display">\[
Var(\hat\beta_n|X)=\sigma^2 (X&#39;X)^{-1}
\]</span> in <a href="#eq-TestStatW" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-TestStatW</span></a> by its estimator <span class="math display">\[
\widehat{Var}(\hat\beta_n|X)=s_{UB}^2 (X&#39;X)^{-1}
\]</span> leads to the <span class="math inline">\(F\)</span>-test statistic <span class="math display">\[
F=(R\hat\beta_n -r^{(0)})&#39;[R(s_{UB}^2(X&#39;X)^{-1})R&#39;]^{-1}(R\hat\beta_n -r^{(0)})/q
\]</span> and takes into account the additional randomness (estimation errors) due to estimating <span class="math inline">\(\sigma^2\)</span> by <span class="math inline">\(s_{UB}^2.\)</span></p>
<p>Under the null-hypothesis, one can show that <span id="eq-Ftest"><span class="math display">\[
F\overset{H_0}{\sim} F_{(q,n-K)},
\qquad(6.4)\]</span></span> where <span class="math inline">\(F_{(q,n-K)}\)</span> denotes the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(q\)</span> numerator and <span class="math inline">\(n-K\)</span> denominator degrees of freedom.</p>
<p>As in the case of <span class="math inline">\(W\)</span>, the distribution of <span class="math inline">\(F\)</span> does not depend on <span class="math inline">\(X.\)</span></p>
<blockquote>
<p>Note: The distributional statements in <a href="#eq-distsquared" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-distsquared</span></a> and <a href="#eq-Ftest" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-Ftest</span></a> are a little cumbersome to derive and we do not go into details here, but in case you’re interested you can find some more details, for instance, in Chapter 1 of <span class="citation" data-cites="Hayashi2000">Hayashi (<a href="#ref-Hayashi2000" role="doc-biblioref">2000</a>)</span>.</p>
</blockquote>
<p>By contrast to <span class="math inline">\(W,\)</span> <span class="math inline">\(F\)</span> is now a practically useful test statistic, and we can use the observed value <span class="math inline">\(F_{\text{obs}}\)</span> to measure the distance of our observed estimate <span class="math inline">\(R\hat\beta_n\)</span> from its null-hypothetical value <span class="math inline">\(r^{(0)}.\)</span></p>
<p>Observed values, <span class="math inline">\(F_{\text{obs}}\)</span>, that are “unusually large” under the null hypothesis, lead to a rejection of the null hypothesis. The null distribution <span class="math inline">\(F_{(q,n-K)}\)</span> of <span class="math inline">\(F\)</span> is used to judge what’s “unusually large” under the null hypothesis.</p>
<p><strong>The F distribution.</strong> The F distribution is a ratio of two <span class="math inline">\(\chi^2\)</span> distributions. It has two parameters: the numerator degrees of freedom, and the denominator degrees of freedom. Each combination of the parameters yields a different F distribution (<a href="#fig-FDistribution" class="quarto-xref">Figure <span class="quarto-unresolved-ref">fig-FDistribution</span></a>). See <a href="#sec-Fdist" class="quarto-xref"><span class="quarto-unresolved-ref">sec-Fdist</span></a> for more information on the <span class="math inline">\(F\)</span> distribution.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-FDistribution" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-FDistribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06-Small-Sample-Inference_files/figure-html/fig-FDistribution-1.png" class="img-fluid quarto-figure quarto-figure-center" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-FDistribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 6.1: Graphs of the density function of the <span class="math inline">\(F\)</span>-distribution for different numerator degrees of freedom and different denominator degrees of freedom.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="test-decision-using-the-rejection-region" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2"><span class="header-section-number">6.2.2</span> Test Decision using the Rejection Region</h3>
<p>Let <span class="math inline">\(0&lt;\alpha&lt;1\)</span> denote the significance level and let <span class="math inline">\(c_{1-\alpha}\)</span> denote the <span class="math inline">\((1-\alpha)\)</span> quantile of the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\((q,n-K)\)</span> degrees of freedom.</p>
<p>This quantile <span class="math inline">\(c_{1-\alpha}\)</span> is the <strong>critical value</strong> that defines the <strong>rejection region</strong>: <span class="math display">\[
\mathcal{R}=\; ]c_{1-\alpha},\infty[
\]</span> <!-- , and 
- non-rejection region, $]0,c_{1-\alpha}]$  --></p>
<ul>
<li>We can rejection <span class="math inline">\(H_0\)</span> if <span class="math display">\[
F_{obs}\in \mathcal{R}=\; ]c_{1-\alpha},\infty[
\]</span></li>
<li>We cannot rejection <span class="math inline">\(H_0\)</span> if <span class="math display">\[
F_{obs}\not \in \mathcal{R}=\; ]c_{1-\alpha},\infty[
\]</span></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-FDistributionRejection" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-FDistributionRejection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06-Small-Sample-Inference_files/figure-html/fig-FDistributionRejection-1.png" class="img-fluid quarto-figure quarto-figure-center" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-FDistributionRejection-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 6.2: Graph of the density function of the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(9\)</span> numerator degrees of freedom and <span class="math inline">\(120\)</span> denominator degrees of freedom. The rejection region <span class="math inline">\(\mathcal{R}\)</span> is shown in red.
</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>The rejection region:</strong> The rejection region describes a range of values of the test statistic <span class="math inline">\(F\)</span> which we rarely see if the null hypothesis is true (only in at most <span class="math inline">\(\alpha \cdot 100\%\)</span> cases). If the observed value of the test statistic, <span class="math inline">\(F_{\text{obs}}\)</span>, falls in this region, we will reject the null hypothesis and acknowledge a type-I-error rate of at most <span class="math inline">\(\alpha\)</span>.</p>
<p><strong>The non-rejection region:</strong> The non-rejection region describes a range of values of the test statistic <span class="math inline">\(F\)</span> which we expect to see (in <span class="math inline">\((1-\alpha) \cdot 100\%\)</span> cases) if the null hypothesis is true. If the observed value of the test statistic, <span class="math inline">\(F_{\text{obs}}\)</span> falls in this region, we cannot reject the null hypothesis.</p>
<p>To find the critical value <span class="math inline">\(c_{1-\alpha}\)</span> we can use <code>R</code> as following:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb1"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># chosen significance level</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>df1   <span class="ot">&lt;-</span> <span class="dv">9</span>    <span class="co"># numerator df</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>df2   <span class="ot">&lt;-</span> <span class="dv">120</span>  <span class="co"># denominator df</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Critical value:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>crit_value <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df1 =</span> df1, <span class="at">df2 =</span> df2)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>crit_value</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.958763</code></pre>
</div>
</div>
<p>Changing the significance level from <span class="math inline">\(\alpha=0.05\)</span> to <span class="math inline">\(\alpha=0.01\)</span> makes the critical value <span class="math inline">\(c_{1-\alpha}\)</span> larger and, therefore, the rejection region smaller (smaller probability of type-I-errors).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.01</span> <span class="co"># chosen significance level</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Critical value:</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>crit_value <span class="ot">&lt;-</span> <span class="fu">qf</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df1 =</span> df1, <span class="at">df2 =</span> df2)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>crit_value</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.558574</code></pre>
</div>
</div>
</section>
<section id="test-decision-using-the-p-value" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3"><span class="header-section-number">6.2.3</span> Test Decision using the <span class="math inline">\(p\)</span>-Value</h3>
<p>Remember that (under Assumption 4<span class="math inline">\(^\boldsymbol{\ast}\)</span>) <span class="math display">\[
F\overset{H_0}{\sim}F_{q,n-K}.
\]</span></p>
<p>The <span class="math inline">\(p\)</span>-value of the <span class="math inline">\(F\)</span>-test is the probability of seeing realizations of <span class="math inline">\(F\)</span> that are equal to or larger than the observed value <span class="math inline">\(F_{\text{obs}}\)</span> given that the null hypothesis is true <span class="math display">\[
p_{\text{obs}}=P(F\geq F_{\text{obs}}\;|\;H_0 \text{ is true})
\]</span></p>
<ul>
<li><p>We reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} &lt; \alpha
\]</span></p></li>
<li><p>We cannot reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} \geq \alpha,
\]</span> where <span class="math inline">\(0&lt;\alpha&lt;1\)</span> denotes the chosen significance level. Typical choices are</p>
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(\alpha = 0.01\)</span></li>
</ul></li>
</ul>
</section>
</section>
<section id="sec-testingsinglep" class="level2" data-number="6.3">
<h2 data-number="6.3"><span class="header-section-number">6.3</span> <span class="math inline">\(t\)</span>-Tests: Hypothesis Tests about One Parameter</h2>
<p>A hypothesis about only <strong>one parameter</strong> <span class="math display">\[
\begin{equation*}
\begin{array}{ll}
&amp; H_0: \beta_k=\beta_k^{(0)}\\
\text{versus}\quad &amp; H_1: \beta_k\ne \beta_k^{(0)}\\
\end{array}
\end{equation*}
\]</span> is simply a special case of the general null hypothesis <span class="math inline">\(H_0:R\beta =r^{(0)},\)</span> where</p>
<ul>
<li><span class="math inline">\(R\)</span> is a <span class="math inline">\((1\times K)\)</span> row-vector of zeros, but with a one as the <span class="math inline">\(k\)</span>th element, and where</li>
<li>we write <span class="math inline">\(r^{(0)}=\beta_k^{(0)}\)</span> since we make a hypothesis only about <span class="math inline">\(\beta_k.\)</span></li>
</ul>
<p>Thus the <span class="math inline">\(F\)</span>-test statistic simplifies to <span class="math display">\[
F=\frac{\left(\hat{\beta}_k-\beta_k^{(0)}\right)^2}{\widehat{Var}(\hat{\beta}_k|X)}\overset{H_0}{\sim}F_{(1,n-K)},
\]</span> where <span class="math display">\[
\widehat{Var}(\hat{\beta}_k|X)=s^2_{UB}[(X&#39;X)^{-1}]_{(k,k)},
\]</span> and where <span class="math inline">\([(X&#39;X)^{-1}]_{(k,k)}\)</span> denotes the element in the <span class="math inline">\(k\)</span>th row and <span class="math inline">\(k\)</span>th column of the <span class="math inline">\((K\times K)\)</span> matrix <span class="math inline">\((X&#39;X)^{-1}.\)</span></p>
<section id="sec-tTestTestStat" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1"><span class="header-section-number">6.3.1</span> The Test Statistic and its Null Distribution</h3>
<p>Taking square roots yields the <span class="math inline">\(t\)</span> test statistic <span class="math display">\[
T=\frac{\hat{\beta}_k-\beta_k^{(0)}}{\widehat{\operatorname{SE}}(\hat{\beta}_k|X)}\overset{H_0}{\sim}t_{(n-K)},
\]</span> where <span class="math display">\[
\begin{align*}
\widehat{\operatorname{SE}}(\hat{\beta}_k|X)
&amp;=\sqrt{\widehat{Var}(\hat{\beta}_k|X)}\\[2ex]
&amp;=s_{UB}[(X&#39;X)^{-1/2}]_{(k,k)},
\end{align*}
\]</span> and where <span class="math inline">\(t_{(n-K)}\)</span> denotes the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K\)</span> degrees of freedom.</p>
<p>Thus the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K\)</span> degrees of freedom is the appropriate distribution to judge whether an observed value <span class="math inline">\(T_{\text{obs}}\)</span> of the test statistic is “unusually large” under the null hypothesis.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>All commonly used statistical software packages report in their regression output tables <span class="math inline">\(t\)</span>-tests testing the “no (linear) effect” null hypothesis <span class="math display">\[
H_0:\beta_k=0
\]</span> for each <span class="math inline">\(k=1,\dots,K.\)</span></p>
<p>This means to test the null hypothesis that <span class="math inline">\(X_k\)</span> has on average no (linear) effect on the outcome variable <span class="math inline">\(Y.\)</span></p>
</div>
</div>
<p><strong>The <span class="math inline">\(t\)</span> distribution.</strong> <a href="#fig-tDistribution" class="quarto-xref">Figure <span class="quarto-unresolved-ref">fig-tDistribution</span></a> illustrates that as the degrees of freedom increase, the shape of the <span class="math inline">\(t\)</span> distribution comes closer to that of a standard normal bell curve. Already for <span class="math inline">\(25\)</span> degrees of freedom we find little difference to the standard normal density. In case of small degrees of freedom values, we find the distribution to have heavier tails than a standard normal. See <a href="#sec-tdist" class="quarto-xref"><span class="quarto-unresolved-ref">sec-tdist</span></a> for more information about the <span class="math inline">\(t\)</span>-distribution.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-tDistribution" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-tDistribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06-Small-Sample-Inference_files/figure-html/fig-tDistribution-1.png" class="img-fluid quarto-figure quarto-figure-center" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tDistribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 6.3: Graphs of the density function of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(2,\,4,\)</span> and <span class="math inline">\(25\)</span> degrees of freedom and of the density of the standard normal distribution.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="test-decision-using-the-rejection-region-one-sided-12" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2"><span class="header-section-number">6.3.2</span> Test Decision using the Rejection Region (One-Sided 1/2)</h3>
<p>The right-sided version of the one-sided hypothesis is given by <span class="math display">\[
\begin{align*}
&amp;H_0: \beta_k \leq \beta_k^{(0)}\\
\text{versus}\quad
&amp; H_1: \beta_k &gt; \beta_k^{(0)},
\end{align*}
\]</span> where <span class="math inline">\(\beta_k\)</span> denotes the true (unknown) parameter value and <span class="math inline">\(\beta_k^{(0)}\)</span> the null hypothetical value specified by the statistician (e.g. <span class="math inline">\(\beta_k^{(0)}=0\)</span>).</p>
<p>The rejection region is <span class="math display">\[
\mathcal{R}=\;]c_{1-\alpha}, \infty[,
\]</span> where <span class="math inline">\(0&lt;\alpha&lt;1\)</span> denotes the significance level and <span class="math inline">\(c_{1-\alpha}\)</span> denotes the <span class="math inline">\((1-\alpha)\)</span> quantile of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom.</p>
<ul>
<li>We can reject <span class="math inline">\(H_0\)</span> if <span class="math display">\[
\begin{align*}
T_{obs}
&amp; \in \mathcal{R} = \;]c_{1-\alpha}, \infty[
\end{align*}
\]</span></li>
<li>We cannot reject <span class="math inline">\(H_0\)</span> if <span class="math display">\[
\begin{align*}
T_{obs}
&amp;\not \in \mathcal{R} = \;]c_{1-\alpha}, \infty[
\end{align*}
\]</span></li>
</ul>
<p><a href="#fig-oneSidedRight" class="quarto-xref">Figure <span class="quarto-unresolved-ref">fig-oneSidedRight</span></a> shows an example of the rejection region for the case of a significance level <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(n-K=12\)</span> degrees of freedom.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-oneSidedRight" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-oneSidedRight-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06-Small-Sample-Inference_files/figure-html/fig-oneSidedRight-1.png" class="img-fluid quarto-figure quarto-figure-center" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-oneSidedRight-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 6.4: <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K=12\)</span> degrees of freedom and critical value <span class="math inline">\(c_{1-\alpha}=1.78\)</span> for the significance level <span class="math inline">\(\alpha=0.05\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>To find the <span class="math inline">\(c_{1-\alpha}\)</span> critical value we can use <code>R</code> as following:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># chosen significance level </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df    <span class="ot">&lt;-</span> <span class="dv">12</span>   <span class="co"># degrees of freedom </span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="do">## One-sided critical value (1-alpha) quantile:</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>c_oneSided <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha, <span class="at">df =</span> df)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>c_oneSided</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.782288</code></pre>
</div>
</div>
</section>
<section id="test-decision-using-the-rejection-region-one-sided-22" class="level3" data-number="6.3.3">
<h3 data-number="6.3.3"><span class="header-section-number">6.3.3</span> Test Decision using the Rejection Region (One-Sided 2/2)</h3>
<p>The left-sided version of the one-sided hypothesis is given by <span class="math display">\[
\begin{align*}
&amp;H_0:  \beta_k \geq \beta_k^{(0)}\\
\text{versus}\quad
&amp;H_1:  \beta_k &lt;  \beta_k^{(0)},
\end{align*}
\]</span> where <span class="math inline">\(\beta_k\)</span> denotes the true (unknown) parameter value and <span class="math inline">\(\beta_k^{(0)}\)</span> the null hypothetical value specified by the statistician (e.g. <span class="math inline">\(\beta_k^{(0)}=0\)</span>).</p>
<p>The rejection region is <span class="math display">\[
\mathcal{R}=\;]-\infty,c_{\alpha}[,
\]</span> where <span class="math inline">\(0&lt;\alpha&lt;1\)</span> denotes the significance level and <span class="math inline">\(c_{1-\alpha}\)</span> denotes the <span class="math inline">\((1-\alpha)\)</span> quantile of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom.</p>
<ul>
<li>We can reject <span class="math inline">\(H_0\)</span> if <span class="math display">\[
\begin{align*}
T_{obs}
&amp; \in \mathcal{R} = \;]-\infty,c_{\alpha}[
\end{align*}
\]</span></li>
<li>We cannot reject <span class="math inline">\(H_0\)</span> if <span class="math display">\[
\begin{align*}
T_{obs}
&amp;\not \in \mathcal{R} = \;]-\infty,c_{\alpha}[
\end{align*}
\]</span></li>
</ul>
<p><a href="#fig-oneSidedLeft" class="quarto-xref">Figure <span class="quarto-unresolved-ref">fig-oneSidedLeft</span></a> shows an example of the rejection region for the case of a significance level <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(n-K=12\)</span> degrees of freedom.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-oneSidedLeft" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-oneSidedLeft-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06-Small-Sample-Inference_files/figure-html/fig-oneSidedLeft-1.png" class="img-fluid quarto-figure quarto-figure-center" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-oneSidedLeft-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 6.5: <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K=12\)</span> degrees of freedom and critical value <span class="math inline">\(c_{\alpha}=-1.78\)</span> for the significance level <span class="math inline">\(\alpha=0.05\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>To find the <span class="math inline">\(c_{\alpha}\)</span> critical value we can use <code>R</code> as following:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># chosen significance level </span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>df    <span class="ot">&lt;-</span> <span class="dv">12</span>   <span class="co"># degrees of freedom </span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="do">## One-sided critical value (alpha) quantile:</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>c_oneSided <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> alpha, <span class="at">df =</span> df)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>c_oneSided</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -1.782288</code></pre>
</div>
</div>
</section>
<section id="test-decision-using-the-rejection-region-two-sided" class="level3" data-number="6.3.4">
<h3 data-number="6.3.4"><span class="header-section-number">6.3.4</span> Test Decision using the Rejection Region (Two-Sided)</h3>
<p>The two-sided <span class="math inline">\(t\)</span>-test allows us to test <span class="math display">\[
\begin{align*}
&amp; H_0: \beta_k=\beta_k^{(0)}\\
\text{versus}\quad
&amp; H_1: \beta_k\ne \beta_k^{(0)},
\end{align*}
\]</span> where <span class="math inline">\(\beta_k\)</span> denotes the true (unknown) parameter value and <span class="math inline">\(\beta_k^{(0)}\)</span> the null hypothetical value specified by the statistician (e.g. <span class="math inline">\(\beta_k^{(0)}=0\)</span>).</p>
<p>The rejection region is <span class="math display">\[
\mathcal{R}=\;]-\infty,c_{\alpha/2}[\;\;\cup\;\;]c_{1-\alpha/2}, \infty[,
\]</span> where <span class="math inline">\(0&lt;\alpha&lt;1\)</span> denotes the significance level and <span class="math inline">\(c_{\alpha/2}\)</span> and <span class="math inline">\(c_{1-\alpha/2}\)</span> denote the <span class="math inline">\(\alpha/2\)</span> and the <span class="math inline">\((1-\alpha/2)\)</span> quantiles of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom.</p>
<ul>
<li>We can reject <span class="math inline">\(H_0\)</span> if <span class="math display">\[
\begin{align*}
T_{obs}
&amp; \in \mathcal{R}%\\[2ex]
%&amp; \in \;]-\infty,c_{\alpha/2}[\;\;\cup\;\;]c_{1-\alpha/2}, \infty[
\end{align*}
\]</span></li>
<li>We cannot reject <span class="math inline">\(H_0\)</span> if <span class="math display">\[
\begin{align*}
T_{obs}
&amp;\not \in \mathcal{R}%\\[2ex]
%&amp;\not \in \;]-\infty,c_{\alpha/2}[\;\;\cup\;\;]c_{1-\alpha/2}, \infty[
\end{align*}
\]</span></li>
</ul>
<p><a href="#fig-twoSided" class="quarto-xref">Figure <span class="quarto-unresolved-ref">fig-twoSided</span></a> shows an example of the rejection region for the case of a significance level <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(n-K=12\)</span> degrees of freedom.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-twoSided" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-twoSided-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06-Small-Sample-Inference_files/figure-html/fig-twoSided-1.png" class="img-fluid quarto-figure quarto-figure-center" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-twoSided-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 6.6: <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K=12\)</span> degrees of freedom and critical values <span class="math inline">\(c_{\alpha/2}=-2.18\)</span> and <span class="math inline">\(c_{1-\alpha/2}=2.18\)</span> for the significance level <span class="math inline">\(\alpha=0.05\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>To find the <span class="math inline">\(c_{\alpha/2}\)</span> and <span class="math inline">\(c_{1-\alpha/2}\)</span> critical values we can use <code>R</code> as following:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span> <span class="co"># chosen signficance level </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>df    <span class="ot">&lt;-</span> <span class="dv">12</span>   <span class="co"># degrees of freedom </span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Two-sided critical value (= (1-alpha/2) quantile):</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>c_twoSided <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> <span class="dv">1</span><span class="sc">-</span>alpha<span class="sc">/</span><span class="dv">2</span>, <span class="at">df =</span> df)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="do">## lower critical value</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span>c_twoSided</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -2.178813</code></pre>
</div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="do">## upper critical value</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>c_twoSided</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.178813</code></pre>
</div>
</div>
</section>
<section id="sec-TDecRS" class="level3" data-number="6.3.5">
<h3 data-number="6.3.5"><span class="header-section-number">6.3.5</span> Test Decision using the <span class="math inline">\(p\)</span>-Value (One-Sided 1/2)</h3>
<p>Right-sided version of the one-sided hypothesis: <span class="math display">\[
\begin{align*}
&amp;H_0: \beta_k \leq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1:\beta_k &gt;    \beta_k^{(0)}\\
\end{align*}
\]</span></p>
<!-- In case of a one-sided $t$-test, we will reject the null if $T_{\text{obs}}$ is sufficiently "far away" from zero in the relevant direction of $H_1$.  -->
<p>We know that <span class="math display">\[
T\overset{H_0}{\sim}t_{n-K}.
\]</span></p>
<p>The <span class="math inline">\(p\)</span>-value is the probability of seeing realizations of <span class="math inline">\(T\)</span> that are equal to or larger than the observed value <span class="math inline">\(T_{\text{obs}}\)</span> given that the null hypothesis is true <span class="math display">\[
p_{\text{obs}}=P(T\geq T_{\text{obs}}\;|\;H_0 \text{ is true}).
\]</span> * We reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} &lt; \alpha
\]</span></p>
<ul>
<li>We cannot reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} \geq \alpha,
\]</span> where <span class="math inline">\(0&lt;\alpha&lt;1\)</span> denotes the chosen significance level. Typical choices are
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(\alpha = 0.01\)</span></li>
</ul></li>
</ul>
</section>
<section id="test-decision-using-the-p-value-one-sided-22" class="level3" data-number="6.3.6">
<h3 data-number="6.3.6"><span class="header-section-number">6.3.6</span> Test Decision using the <span class="math inline">\(p\)</span>-Value (One-Sided 2/2)</h3>
<p>Left-sided version of the one-sided hypothesis: <span class="math display">\[
\begin{align*}
&amp;H_0: \beta_k \geq \beta_k^{(0)}\\
\text{versus}\quad &amp; H_1: \beta_k &lt;  \beta_k^{(0)}\\
\end{align*}
\]</span></p>
<p>The <span class="math inline">\(p\)</span>-value is the probability of seeing realizations of <span class="math inline">\(T\)</span> that are equal to or smaller than the observed value <span class="math inline">\(T_{\text{obs}}\)</span> given that the null hypothesis is true <span class="math display">\[
p_{\text{obs}}=P(T\leq T_{\text{obs}}\;|\;H_0 \text{ is true}).
\]</span></p>
<ul>
<li><p>We reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} &lt; \alpha
\]</span></p></li>
<li><p>We cannot reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} \geq \alpha,
\]</span> where <span class="math inline">\(0&lt;\alpha&lt;1\)</span> denotes the chosen significance level. Typical choices are</p>
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(\alpha = 0.01\)</span></li>
</ul></li>
</ul>
</section>
<section id="test-decision-using-the-p-value-two-sided" class="level3" data-number="6.3.7">
<h3 data-number="6.3.7"><span class="header-section-number">6.3.7</span> Test Decision using the <span class="math inline">\(p\)</span>-Value (Two-Sided)</h3>
<p>The two-sided <span class="math inline">\(t\)</span>-test allows us to test <span class="math display">\[
\begin{align*}
&amp; H_0: \beta_k=\beta_k^{(0)}\\
\text{versus}\quad
&amp; H_1: \beta_k\ne \beta_k^{(0)}
\end{align*}
\]</span> where <span class="math inline">\(\beta_k\)</span> denotes the true (unknown) parameter value and <span class="math inline">\(\beta_k^{(0)}\)</span> the null hypothetical value specified by the statisticaian (e.g. <span class="math inline">\(\beta_k^{(0)}=0\)</span>).</p>
<p>We know that <span class="math display">\[
T\overset{H_0}{\sim}t_{n-K}.
\]</span></p>
<p>The <span class="math inline">\(p\)</span>-value of the two-sided <span class="math inline">\(t\)</span>-test is the probability of seeing realizations of <span class="math inline">\(T\)</span> that are equal to or more extreme than the observed value <span class="math inline">\(T_{\text{obs}}\)</span> given that the null hypothesis is true <span class="math display">\[
\begin{align*}
p_{\text{obs}}
&amp;=P(|T|\geq |T_{\text{obs}}|\;|\;H_0 \text{ is true})\\[2ex]
&amp;=2\cdot\min\{P(T\leq T_{\text{obs}}\;|\;H_0 \text{ is true}),
            P(T\geq T_{\text{obs}}\;|\;H_0 \text{ is true})\}
\end{align*}
\]</span></p>
<ul>
<li><p>We reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} &lt; \alpha
\]</span></p></li>
<li><p>We cannot reject the null hypothesis <span class="math inline">\(H_0\)</span> if <span class="math display">\[
p_{\text{obs}} \geq \alpha,
\]</span> where <span class="math inline">\(0&lt;\alpha&lt;1\)</span> denotes the chosen significance level. Typical choices are</p>
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(\alpha = 0.01\)</span></li>
</ul></li>
</ul>
</section>
</section>
<section id="sec-CIsmallsample" class="level2" data-number="6.4">
<h2 data-number="6.4"><span class="header-section-number">6.4</span> Confidence Intervals</h2>
<p>We define a two-sided <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> percent confidence interval for the <em>deterministic</em> (unknown) true <span class="math inline">\(\beta_k\)</span> as the <strong>random interval</strong> <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha}\)</span> for which <span class="math display">\[
P\Big(\beta_k\in\operatorname{CI}_{k,n,1-\alpha}\Big)\geq 1-\alpha.
\]</span></p>
<section id="derivation-of-the-random-interval-operatornameci_kn1-alpha" class="level4 unnumbered">
<h4 class="unnumbered"><strong>Derivation of the random interval <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha}\)</span></strong></h4>
<p>Observe that (under Ass 1-4<span class="math inline">\(^\ast\)</span>) <span id="eq-CIDistr"><span class="math display">\[
\frac{\hat\beta_{n,k}-\beta_k}{\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)}\sim t_{(n-K)}
\qquad(6.5)\]</span></span> Therefore, <span class="math display">\[
\begin{align*}
P\left(-c_{n,1-\alpha/2}\leq\frac{\hat\beta_{n,k}-\beta_k}{\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)}\leq c_{n,1-\alpha/2}\right)=1-\alpha,
\end{align*}
\]</span> where <span class="math inline">\(c_{n,1-\alpha/2}\)</span> denotes the <span class="math inline">\((1-\alpha/2)\)</span> quantile of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom.</p>
<p>Next, we can do the following equivalent transformations <span class="math display">\[
\begin{align*}
P\left(-c_{n,1-\alpha/2}\leq\frac{\hat\beta_{n,k}-\beta_k}{\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)}\leq c_{n,1-\alpha/2}\right)&amp;=1-\alpha\\[2ex]
\Leftrightarrow P\left(\hat\beta_{n,k}-c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)\leq \beta_k\leq\hat\beta_{n,k} +c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)\right)&amp;=1-\alpha\\[2ex]
\Leftrightarrow P\left(\beta_k\in\underbrace{\left[\hat\beta_{n,k}-c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X),\;\hat\beta_{n,k} +c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)\right]}_{=:\operatorname{CI}_{k,n,1-\alpha}}\right)&amp;=1-\alpha
\end{align*}
\]</span> That is, the random interval <span class="math display">\[
\begin{align*}
\operatorname{CI}_{k,n,1-\alpha}
&amp;=\left[\hat\beta_{n,k}-c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X),\;\hat\beta_{n,k} + c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)\right]\\[2ex]
&amp;=\left[\hat\beta_{n,k}\pm c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)\right]
\end{align*}
\]</span> is our <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> confidence interval for <span class="math inline">\(\beta_k\)</span>.</p>
<p>Since the confidence interval is based on the exact distribution (under Assumptions 1-4<span class="math inline">\(^\ast\)</span>) in <a href="#eq-CIDistr" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-CIDistr</span></a>, the confidence interval has an <strong>exact</strong> coverage probability <span class="math display">\[
\begin{align*}
P\left(\beta_k\in\operatorname{CI}_{k,n,1-\alpha}\right)&amp;=1-\alpha
\end{align*}
\]</span> provided the Assumptions 1-4<span class="math inline">\(^\ast\)</span> are true.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Interpretation of Confidence Intervals
</div>
</div>
<div class="callout-body-container callout-body">
<p>The random interval <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha}\)</span> for <span class="math inline">\(\beta_k\)</span> contains the true parameter value <span class="math inline">\(\beta_k\)</span> with probability <span class="math inline">\(1-\alpha;\)</span> i.e. we expect that <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha}\)</span> covers <span class="math inline">\(\beta_k\)</span> in <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> of resamplings from the random sample.</p>
<p>It’s best to take a look at dynamic visualizations like this one:</p>
<center>
<a href="https://rpsychologist.com/d3/ci/">https://rpsychologist.com/d3/ci/</a>
</center>
<p>Unfortunately, this “frequentist” interpretation is not a statement about a single given <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha,\text{obs}}\)</span> realization computed for an observed realization of the random sample. A given, realized <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha,\text{obs}}\)</span> will either contain the true parameter <span class="math inline">\(\beta_k\)</span> or not, and usually we do not know the answer. So, confidence intervals are quite hard to interpret. However, they are very well suited as a tool to visualize estimation uncertainties in <span class="math inline">\(\hat\beta_{n,k}\)</span>, <span class="math inline">\(k=1,\dots,K\)</span>.</p>
<center>
<img src="images/Meme_CI_2.jpg" class="img-fluid" />
</center>
</div>
</div>
</section>
<section id="point-estimator-versus-interval-estimator" class="level4 unnumbered">
<h4 class="unnumbered"><strong>Point Estimator versus Interval Estimator</strong></h4>
<p>Often, <span class="math inline">\(\hat\beta_{n,k}\)</span> is called a <strong>point estimator</strong> of <span class="math inline">\(\beta_k\)</span> and the confidence interval <span class="math display">\[
\begin{align*}
\operatorname{CI}_{k,n,1-\alpha}
&amp;=\left[\hat\beta_{n,k}\pm c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)\right]
\end{align*}
\]</span> is called an <strong>interval estimator</strong> of <span class="math inline">\(\beta_k,\)</span> where the width of <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha}\)</span> quantifies the estimation uncertainties.</p>
</section>
<section id="confidence-intervals-for-statistical-hypothesis-testing" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1"><span class="header-section-number">6.4.1</span> Confidence Intervals for Statistical Hypothesis Testing</h3>
<p>We can use the <span class="math inline">\((1-\alpha)\cdot 100\%\)</span> confidence interval <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha}\)</span> to do statistical hypothesis testing at the significance level <span class="math inline">\(0&lt;\alpha&lt;1.\)</span> Typical significance levels:</p>
<p>Let us consider the following two-sided statistical hypotheses <span class="math display">\[
\begin{align*}
H_0:&amp;\;\beta_k=\beta^{(0)}_{k}\\
H_1:&amp;\;\beta_k\neq \beta^{(0)}_{k}
\end{align*}
\]</span></p>
<p><strong>Testing-Procedure:</strong></p>
<ul>
<li><p>If the observed (obs) realization of the confidence interval, <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha,\text{obs}},\)</span> <strong>contains</strong> the null-hypothetical value <span class="math inline">\(\beta^{(0)}_{k},\)</span> i.e. <span class="math display">\[
\begin{align*}
\beta^{(0)}_{k}&amp;\in\operatorname{CI}_{k,n,1-\alpha,\text{obs}}\\[2ex]
\Leftrightarrow\beta^{(0)}_{k}&amp;\in
\left[\hat\beta_{n,k,\text{obs}}\pm c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)_{\text{obs}}\right],
\end{align*}
\]</span> then we <strong>cannot reject the null hypothesis.</strong></p></li>
<li><p>If, however, the observed (obs) realization of the confidence interval, <span class="math inline">\(\operatorname{CI}_{k,n,1-\alpha,\text{obs}},\)</span> <strong>does <em>not</em> contain</strong> the null-hypothetical value <span class="math inline">\(\beta^{(0)}_{k},\)</span> i.e. <span class="math display">\[
\begin{align*}
\beta^{(0)}_{k}&amp;\not\in\operatorname{CI}_{k,n,1-\alpha,\text{obs}}\\[2ex]
\Leftrightarrow\beta^{(0)}_{k}&amp;\not\in
\left[\hat\beta_{n,k,\text{obs}}\pm c_{n,1-\alpha/2}\widehat{\operatorname{SE}}(\hat\beta_{n,k}|X)_{\text{obs}}\right],
\end{align*}
\]</span> then we <strong>reject the null hypothesis.</strong></p></li>
</ul>
<p>The test decisions are then perfectly equivalent to those based on the two-sided <span class="math inline">\(t\)</span>-test.</p>
</section>
</section>
<section id="testtheory" class="level2" data-number="6.5">
<h2 data-number="6.5"><span class="header-section-number">6.5</span> Testtheory</h2>
<p>Every statistical test statistic is a function of the random sample, i.e. <span class="math display">\[
T_n\equiv T((X_1,Y_1),\dots,(X_n,Y_n))
\]</span> and is thus a random variable.</p>
<p><strong>Caution:</strong> In this section, <span class="math inline">\(T_n\)</span> denotes <em>any</em> test statistic. Specific examples for <span class="math inline">\(T_n\)</span> are, for instance,</p>
<ul>
<li>the <span class="math inline">\(F\)</span>-test statistic (<a href="#sec-testmultp" class="quarto-xref"><span class="quarto-unresolved-ref">sec-testmultp</span></a>) and</li>
<li>the <span class="math inline">\(t\)</span>-test statistic (<a href="#sec-testingsinglep" class="quarto-xref"><span class="quarto-unresolved-ref">sec-testingsinglep</span></a>).</li>
</ul>
<p>Generally, we can only derive the distribution of <span class="math inline">\(T_n\)</span> under <span class="math inline">\(H_0;\)</span> i.e. under the scenario that <span class="math inline">\(H_0\)</span> is true, <span class="math display">\[
\begin{equation*}
\begin{array}{ll}
T_n &amp; \overset{{H_0}}\sim f_{T_n}\quad ✅
\end{array}
\end{equation*}
\]</span> For instance, in case of the <span class="math inline">\(F\)</span>-test, <span class="math inline">\(f_{T_n}\)</span> denotes the <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(q\)</span> and <span class="math inline">\(n-K\)</span> degrees of freedom and in case of the <span class="math inline">\(t\)</span>-test, <span class="math inline">\(f_{T_n}\)</span> denotes the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K\)</span> degrees of freedom.</p>
<p>However, the distribution of <span class="math inline">\(T_n\)</span> under <span class="math inline">\(H_1\)</span> is generally unknown. <span class="math display">\[
\begin{equation*}
\begin{array}{ll}
T_n &amp; \overset{{H_1}}\sim ❌
\end{array}
\end{equation*}
\]</span></p>
<!-- * in @sec-testmultp we discussed that $F\overset{H_0}{\sim} F_{(q,n-K)}.$

* in @sec-testingsinglep we discussed (for simple null hypothesis) that $T\overset{H_0}{\sim} t_{(n-K)}$ -->
<section id="simple-versus-composite-hypotheses" class="level3" data-number="6.5.1">
<h3 data-number="6.5.1"><span class="header-section-number">6.5.1</span> Simple versus Composite Hypotheses</h3>
<p>We use the observed realization <span class="math display">\[
T_{n,\text{obs}}\equiv T((X_{1,\text{obs}},Y_{1,\text{obs}}),\dots,(X_{n,\text{obs}},Y_{n,\text{obs}}))
\]</span> of the random test statistic <span class="math inline">\(T_n\)</span> to decide:</p>
<ul>
<li>whether we cannot reject a null hypothesis <span class="math inline">\(H_0\)</span> about some parameter <span class="math inline">\(\theta\)</span> <span class="math display">\[
H_0: \theta\in\Theta_0,
\]</span></li>
<li>or wether we can reject <span class="math inline">\(H_0\)</span> in favor of the alternative hypothesis <span class="math inline">\(H_1\)</span> <span class="math display">\[
H_1: \theta\in\Theta_1.
\]</span> The test decision is made using the <strong>rejection region</strong>, the <strong><span class="math inline">\(p\)</span>-value</strong>, or a confidence interval.</li>
</ul>
<p>Notation:</p>
<ul>
<li><span class="math inline">\(\Theta_0\)</span> denotes the set of parameter values <span class="math inline">\(\theta\)</span> under <span class="math inline">\(H_0\)</span>.</li>
<li><span class="math inline">\(\Theta_1\)</span> denotes the set of parameter values <span class="math inline">\(\theta\)</span> under <span class="math inline">\(H_1\)</span>.</li>
</ul>
<p>It is required that <span class="math display">\[
\Theta_0 \cap \Theta_1 = \emptyset.
\]</span></p>
<ul>
<li>If <span class="math inline">\(\Theta_j,\)</span> <span class="math inline">\(j=1,2,\)</span> contains only <strong>one value</strong> <span class="math display">\[
\Theta_j=\theta^{(j)},
\]</span> it is called a <strong>simple hypothesis</strong>.</li>
<li>If <span class="math inline">\(\Theta_j,\)</span> <span class="math inline">\(j=1,2,\)</span> contains <strong>multiple values</strong>, it is called a <strong>composite hypothesis</strong>.</li>
</ul>
<p>The idea of a <strong>composite null hypothesis</strong> <span class="math display">\[
H_0:\theta\in\Theta_0
\]</span> is to collect all hypotheses which we do not care to detect by the statistical test. This way, the set of alternative hypotheses <span class="math inline">\(H_1:\theta\in\Theta_1\)</span> becomes smaller which leads to more powerful tests.</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon no-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Example: Two-Sided Test with <span class="math inline">\(\theta\in\mathbb{R}\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{equation*}
\begin{array}{ll}
&amp; H_0: \theta = \theta^{(0)}\\
\text{versus}\quad
&amp; H_1: \theta\neq \theta^{(0)}\\
\end{array}
\end{equation*}
\]</span></p>
<p>Here we have a <strong>simple</strong> null hypothesis <span class="math display">\[
\Theta_0=\theta^{(0)}
\]</span> and a <strong>composite</strong> alternative hypothesis <span class="math display">\[
\Theta_1=\mathbb{R}\setminus\theta^{(0)}.
\]</span></p>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon no-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Example: One-Sided Test with <span class="math inline">\(\theta\in\mathbb{R}\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{equation*}
\begin{array}{ll}
&amp; H_0: \theta \geq  \theta^{(0)}\\
\text{versus}\quad
&amp; H_1: \theta  &lt; \theta^{(0)}\\
\end{array}
\end{equation*}
\]</span></p>
<p>Here we have a <strong>composite</strong> null hypothesis <span class="math display">\[
\Theta_0=\;[\theta^{(0)},\infty[
\]</span> and a <strong>composite</strong> alternative hypothesis <span class="math display">\[
\Theta_1=\;]-\infty,\theta^{(0)}[.
\]</span></p>
<p>(Likewise for the other direction of the one-sided test.)</p>
</div>
</div>
</section>
<section id="decisions-errors" class="level3" data-number="6.5.2">
<h3 data-number="6.5.2"><span class="header-section-number">6.5.2</span> Decisions Errors</h3>
<p>Hypothesis testing is like a legal trial. We assume someone is innocent unless the evidence strongly suggests that he is guilty. Similarly, we retain <span class="math inline">\(H_0\)</span> unless there is strong evidence to reject <span class="math inline">\(H_0.\)</span></p>
<p>We differentiate two decision errors events:</p>
<ul>
<li><strong>type-I-error (or false positive):</strong></br> Rejecting <span class="math inline">\(H_0\)</span> even though <span class="math inline">\(H_0\)</span> is true.</li>
<li><strong>type-II-error:</strong></br> Not rejecting <span class="math inline">\(H_0\)</span> even though <span class="math inline">\(H_1\)</span> is true.</li>
</ul>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Not being able to reject <span class="math inline">\(H_0,\)</span> does not mean a validation/confirmation of <span class="math inline">\(H_0,\)</span> but only reflects that we do not have sufficient evidence against a possibly false <span class="math inline">\(H_0.\)</span></p>
<p>Indeed, a given violation of <span class="math inline">\(H_0\)</span> may only be too small to stand out from the estimation errors; i.e. we may do a type-II-error. Problem is, we generally cannot control the probability of type-II-errors since we do not know the distribution of the test statistic under <span class="math inline">\(H_1.\)</span> We can only control the probability of type-I-errors since we know the distribution of the test statistic under <span class="math inline">\(H_0.\)</span></p>
<p>Therefore, if you are not able to reject <span class="math inline">\(H_0,\)</span> <strong>never ever</strong> state something like: “I conclude <span class="math inline">\(H_0\)</span> is true.”</p>
<div class="callout callout-style-default callout-tip no-icon callout-titled" title="">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon no-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
For the special case of a “no-effect” null hypothesis <span class="math display">\[
H_0:\beta_k=0,
\]</span> there’s a famous sentence which goes back to <span class="citation" data-cites="Altman_Bland_1995">Altman and Bland (<a href="#ref-Altman_Bland_1995" role="doc-biblioref">1995</a>)</span> :</br>
<center>
“Absence of evidence is not evidence of absence.”
</center>
</div>
</div>
</div>
</div>
</section>
<section id="size" class="level3" data-number="6.5.3">
<h3 data-number="6.5.3"><span class="header-section-number">6.5.3</span> Size</h3>
<p>The probability of a type-I-error event is called <strong>size</strong> of <span class="math inline">\(T_n.\)</span></p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class='callout-icon no-icon'></i>
</div>
<div class="callout-body-container">
<div id="def-size" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.1 (Size)</strong></span> The size of a test statistic <span class="math inline">\(T_n\)</span> is the largest probability of rejecting <span class="math inline">\(H_0\)</span> over all possible null-hypothetical parameter values <span class="math inline">\(\theta\in\Theta_0\)</span> <span class="math display">\[
\begin{align*}
\text{Size}_{n,\alpha}
=&amp; \sup_{\theta\in\Theta_0} P(T_n \in \mathcal{R}_{n,\alpha} | \theta\in \Theta_0 ).
\end{align*}
\]</span></p>
</div>
</div>
</div>
</div>
<p>A statistical hypothesis test procedure is called <strong>valid test</strong> if its size can be bounded from above by the chosen <strong>significance level (nominal size)</strong> <span class="math inline">\(\alpha\)</span>, i.e. if<br />
<span class="math display">\[
\begin{align*}
\text{Size}_{n,\alpha}\; \leq\; \alpha = \text{Nominal Size}
\end{align*}
\]</span></p>
<p>Since we want to keep the probability of falsely rejecting <span class="math inline">\(H_0\)</span> small, we choose small singificance levels such as</p>
<ul>
<li><span class="math inline">\(\alpha=0.05\)</span>,</li>
<li><span class="math inline">\(\alpha=0.01\)</span>, or</li>
<li><span class="math inline">\(\alpha=0.001.\)</span></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Exact vs conservative vs invalid
</div>
</div>
<div class="callout-body-container callout-body">
<p>A test statistic <span class="math inline">\(T_n\)</span> is called</p>
<ul>
<li><strong>exact</strong> if <span class="math display">\[
\text{Size}_{n,\alpha}=\sup_{\theta\in\Theta_0} P(T_n \in \mathcal{R}_{n,\alpha}| \theta\in \Theta_0 ) =\alpha,
\]</span></li>
<li><strong>conservative</strong> if <span class="math display">\[
\text{Size}_{n,\alpha}= \sup_{\theta\in\Theta_0} P(T_n \in \mathcal{R}_{n,\alpha}| \theta\in \Theta_0 ) &lt;\alpha,
\]</span></li>
<li><strong>invalid</strong> if <span class="math display">\[
\text{Size}_{n,\alpha}=\sup_{\theta\in\Theta_0} P(T_n \in \mathcal{R}_{n,\alpha}| \theta\in \Theta_0 ) &gt; \alpha.
\]</span></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Under Assumptions 1-4<span class="math inline">\(^\ast,\)</span> the <span class="math inline">\(F\)</span>-test and the <span class="math inline">\(t\)</span>-test are <strong>exact</strong> test statistics.</p>
</div>
</div>
<section id="showing-exactness-of-the-f-test" class="level4 unnumbered">
<h4 class="unnumbered"><strong>Showing Exactness of the <span class="math inline">\(F\)</span>-Test</strong></h4>
<p><span class="math display">\[
\begin{equation*}
\begin{array}{lll}
&amp; H_0: R\beta = r^{(0)}   &amp; (\text{simple hypothesis})\\
\text{versus}\quad
&amp; H_1: R\beta \neq r^{(0)}&amp; (\text{composite hypothesis})\\
\end{array}
\end{equation*}
\]</span></p>
<p>Under Assumptions 1-4<span class="math inline">\(^\ast\)</span> (see <a href="#sec-testmultp" class="quarto-xref"><span class="quarto-unresolved-ref">sec-testmultp</span></a>), we have that <span id="eq-FNullDistr"><span class="math display">\[
F_n\overset{H_0}{\sim}F_{q,n-K}.
\qquad(6.6)\]</span></span></p>
<p><a href="#eq-FNullDistr" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-FNullDistr</span></a> allows us to show that the <span class="math inline">\(F_n\)</span>-test is an exact test. Since the null hypothesis is a <strong>simple</strong> hypothesis we do not need to consider the supremum <span class="math inline">\((\sup_{\theta\in\Theta_0}),\)</span> but simply have <span class="math display">\[
\begin{align*}
\text{Size}_{n,\alpha}
= &amp; P(F_n \in \mathcal{R}_{n,\alpha} \;|\; R\beta = r^{(0)}).
\end{align*}
\]</span> Thus, <span class="math display">\[
\begin{align*}
\text{Size}_{n,\alpha}
= &amp; P(F_n \in \mathcal{R}_{n,\alpha} \;|\; R\beta = r^{(0)})\\[2ex]
= &amp; P\Big(F_n &gt; c_{n,1-\alpha}\;|\;R\beta = r^{(0)}\Big)\\[2ex]
= &amp; 1 - P\Big(F \leq c_{n,1-\alpha}\;|\;R\beta = r^{(0)}\Big)=\alpha,
\end{align*}
\]</span> for all sample sizes <span class="math inline">\(n&gt;K.\)</span></p>
</section>
<section id="showing-exactness-of-the-two-sided-t-test" class="level4 unnumbered">
<h4 class="unnumbered"><strong>Showing Exactness of the Two-Sided <span class="math inline">\(t\)</span>-Test:</strong></h4>
<p><span class="math display">\[
\begin{equation*}
\begin{array}{lll}
&amp; H_0: \beta_k =  \beta_k^{(0)}   &amp; (\text{simple hypothesis})\\
\text{versus}\quad
&amp; H_1: \beta_k \neq \beta_k^{(0)}&amp; (\text{composite hypothesis})\\
\end{array}
\end{equation*}
\]</span></p>
<p>Under Assumptions 1-4<span class="math inline">\(^\ast\)</span> (see <a href="#sec-testingsinglep" class="quarto-xref"><span class="quarto-unresolved-ref">sec-testingsinglep</span></a>), we have that <span id="eq-T2SNullDistr"><span class="math display">\[
T_n\overset{H_0}{\sim}t_{n-K}.
\qquad(6.7)\]</span></span></p>
<p><a href="#eq-T2SNullDistr" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-T2SNullDistr</span></a> allows us to show that the <span class="math inline">\(t\)</span>-test is an exact test. Since the null hypothesis is a <strong>simple</strong> hypothesis we do not need to consider the supremum <span class="math inline">\((\sup_{\theta\in\Theta_0}),\)</span> but simply have <span class="math display">\[
\begin{align*}
\text{Size}_{n,\alpha}
=&amp;P(T_n \in \mathcal{R}_{n,\alpha} \;|\; \beta_k = \beta_k^{(0)}).
\end{align*}
\]</span> Thus, <span class="math display">\[
\begin{align*}
\text{Size}_{n,\alpha}
=&amp;P(T_n \in \mathcal{R}_{n,\alpha} \;|\; \beta_k = \beta_k^{(0)})\\[2ex]
=&amp;P\Big(T_n &lt; c_{n,\alpha/2}\quad\text{or}\quad T_n&gt;c_{n,1-\alpha/2} \;\Big|\; \beta_k = \beta_k^{(0)}\Big)\\[2ex]
=&amp;P\Big(T_n &lt; c_{n,\alpha/2} \;\Big|\; \beta_k = \beta_k^{(0)}\Big) +
  P\Big(T_n &gt; c_{n,1-\alpha/2} \;\Big|\; \beta_k = \beta_k^{(0)}\Big)\\[2ex]
&amp;=\frac{\alpha}{2}+\frac{\alpha}{2}=\alpha.
\end{align*}
\]</span> for all sample sizes <span class="math inline">\(n&gt;K.\)</span></p>
</section>
<section id="showing-exactness-of-the-one-sided-t-test" class="level4 unnumbered">
<h4 class="unnumbered"><strong>Showing Exactness of the One-Sided <span class="math inline">\(t\)</span>-Test:</strong></h4>
<p>Consider, without loss of generality, the following right-side version of the one-sided hypothesis:</p>
<p><span class="math display">\[
\begin{equation*}
\begin{array}{lll}
&amp; H_0: \beta_k \leq \beta_k^{(0)}  &amp; (\text{composite hypothesis})\\
\text{versus}\quad
&amp; H_1: \beta_k &gt; \beta_k^{(0)}     &amp; (\text{composite hypothesis})\\
\end{array}
\end{equation*}
\]</span></p>
<blockquote>
<p>Considering the right-side version is without loss of generality, since effectively the same arguments apply to the case of the left-side version.</p>
</blockquote>
<p>The case of a one-sided hypothesis is slightly more involved since the null hypothesis is a <strong>composite hypothesis</strong>; here: <span class="math display">\[
H_0: \beta_k \in \;\big]-\infty,\beta_k^{(0)}\big].
\]</span></p>
<p>To conduct the <span class="math inline">\(t\)</span>-test we need to take <strong>one</strong> null hypothetical value <span class="math display">\[
\tilde\beta_k^{(0)}\in ]-\infty,\beta_k^{(0)}]
\]</span> which then leads to a <span class="math inline">\(\tilde\beta_k^{(0)}\)</span> specific <span class="math inline">\(t\)</span>-test <span class="math display">\[
\begin{align*}
T_n(\tilde\beta_k^{(0)}) :=
\frac{\hat\beta_{n,k} - \tilde\beta_k^{(0)}}{\widehat{SE}(\hat\beta_{n,k}|X)}
\end{align*}
\]</span></p>
<p>Under Assumptions 1-4<span class="math inline">\(^\ast,\)</span> we have that <span id="eq-NullDistrOneSided"><span class="math display">\[
\begin{align*}
T_n(\tilde\beta_{n,k}^{(0)})
&amp;=
\frac{\hat\beta_{n,k} \overbrace{- \beta_k + \beta_k}^{=0} - \tilde\beta_k^{(0)}}{\widehat{SE}(\hat\beta_{n,k}|X)}\\[2ex]
&amp;=
\underbrace{\frac{\hat\beta_{n,k} - \beta_k}{\widehat{SE}(\hat\beta_{n,k}|X)}}_{\sim t_{(n-K)}} +
\underbrace{\frac{\beta_k - \tilde\beta_k^{(0)}}{\widehat{SE}(\hat\beta_{n,k}|X)}}_{❓},
\end{align*}
\qquad(6.8)\]</span></span> where under <span class="math inline">\(H_0:\beta_k \in ]-\infty,\beta_k^{(0)}].\)</span></p>
<p>The second term in <a href="#eq-NullDistrOneSided" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-NullDistrOneSided</span></a> is challenging, since generally, we do not know its value and thus also not its sign.</p>
<p><strong>Solution:</strong></p>
<p>The solution of this problem is to set (as done in <a href="#sec-tTestTestStat" class="quarto-xref"><span class="quarto-unresolved-ref">sec-tTestTestStat</span></a>) <span class="math display">\[
\tilde\beta_k^{(0)} = \beta_k^{(0)}
\]</span> and to use the <span class="math inline">\(t\)</span>-test statistic <span class="math display">\[
T_n(\beta_k^{(0)})\equiv T_n
=\frac{\hat\beta_{n,k} - \beta_k^{(0)}}{\widehat{SE}(\hat\beta_{n,k}|X)}.
\]</span> Under <span class="math inline">\(H_0,\)</span><br />
<span class="math display">\[
\beta_k \leq \beta_k^{(0)} \Leftrightarrow \beta_k - \beta_k^{(0)}\highlight{\leq 0},
\]</span> which implies that <span id="eq-NullDistrOneSidedIneq"><span class="math display">\[
\begin{align*}
T_n
&amp;=
\frac{\hat\beta_{n,k} - \beta_k^{(0)}}{\widehat{SE}(\hat\beta_{n,k}|X)}\\[2ex]
&amp;=
\underbrace{\frac{\hat\beta_{n,k} - \beta_k}{\widehat{SE}(\hat\beta_{n,k}|X)}}_{\sim t_{(n-K)}} +
\underbrace{\frac{\beta_k - \beta_k^{(0)}}{\widehat{SE}(\hat\beta_{n,k}|X)}}_{\highlight{\leq 0}}\\[2ex]
&amp;\highlight{\leq}
\frac{\hat\beta_{n,k} - \beta_k}{\widehat{SE}(\hat\beta_{n,k}|X)} \overset{H_0}{\sim} t_{(n-K)},
\end{align*}
\qquad(6.9)\]</span></span> where the inequality holds with probability one (i.e. for any possible realization).</p>
<p>The inequality in <a href="#eq-NullDistrOneSidedIneq" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-NullDistrOneSidedIneq</span></a> implies that <span class="math display">\[
\begin{align*}
P(T_n\in\mathcal{R}_{n,\alpha}|\beta_k \leq \beta_k^{(0)}) \highlight{\leq}  P(T_n\in\mathcal{R}_{n,\alpha} \;|\;\beta_k = \beta_k^{(0)}) &amp; = \alpha\\[2ex]
\Leftrightarrow\quad  
\text{Size}_{n,\alpha} = \sup_{\beta_k \in ]-\infty,\beta_k^{(0)}]} P(T_n\in\mathcal{R}_{n,\alpha}\;|\;\beta_k \in ]-\infty,\beta_k^{(0)}]) &amp; = \alpha,
\end{align*}
\]</span> for all sample sizes <span class="math inline">\(n&gt;K,\)</span> where <span class="math display">\[
\mathcal{R}_{n,\alpha} = ]c_{n,1-\alpha},\infty[,
\]</span> with <span class="math inline">\(c_{n,1-\alpha}\)</span> denoting the <span class="math inline">\((1-\alpha)\)</span>-quantile of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\((n-K)\)</span> degrees of freedom.</p>
<!-- 
::: {.callout-tip icon="false"}
#
Let $F_{T(\beta_k^{(0)})}$ and $F_{t_{(n-K)}}$ denote cumulative distribution functions of $T(\beta_k^{(0)})$ and of the $t$-distribution with $(n-K)$ degrees of freedom. 

The inequality in @eq-NullDistrOneSidedIneq implies that:

1. If $\beta_k = \beta_k^{(0)},$ the distribution of $T(\beta_k^{(0)})$ equals the $t$-distribution with $(n-K)$ degrees of freedom, i.e.
$$
\begin{align*}
T(\beta_k^{(0)}) &\sim t_{(n-K)}\\[2ex] 
\Leftrightarrow \; F_{T(\beta_k^{(0)})} (x) &= F_{t_{(n-K)}}(x) \quad\text{for all}\quad x\in\mathbb{R} 
\end{align*}
$$
2. If $\beta_k < \beta_k^{(0)},$ the distribution of $T(\beta_k^{(0)})$ is **strictly dominated** by the $t$-distribution with $(n-K)$ degrees of freedom, i.e.
$$
F_{T(\beta_k^{(0)})} (x) > F_{t_{(n-K)}}(x) \quad\text{for all}\quad x\in\mathbb{R}. 
$$
::: -->
<!-- ::: {.callout-tip icon="false"}
#
The inequality in @eq-NullDistrOneSidedIneq implies that
$$
P(T(\beta_k^{(0)}) \in\mathcal{R}) = \alpha
\quad\text{if}\quad
\beta_k = \beta_k^{(0)}
$$
and that 
$$
P(T(\beta_k^{(0)}) \in\mathcal{R}) < \alpha
\quad\text{if}\quad
\beta_k < \beta_k^{(0)}.
$$
::: 
-->
<!-- 
### Rejection Regions of the $F$- and $t$-Test

To decide whether we can reject $H_0$, we need to compare the observed value $T_{\text{obs}}$ with the distribution of $T$ under $H_0.$ This can be done using 

* **rejection regions/critical values,** 
* **$p$-values** (@sec-pValue) or  
* **confidence intervals** (@sec-CIsmallsample)

All of these options lead to equivalent test decisions. 

The **rejection region** for a statistical test statistic $T$ is defined using **critical values** which are certain quantiles of the distribution of $T$ under $H_0.$  

#### Rejection Regions of the $F$-Test 

The $F$-test allows us to test
$$
\begin{align*}
&H_0: R\beta = r^{(0)}\\[2ex]
\text{versus}\quad 
&H_1: R\beta\neq r^{(0)},
\end{align*}
$$
where $\beta$ denotes the true (unknown) parameter vector and $r^{(0)}$ the null-hypothetical value specified by the statistician (often, e.g. $r^{(0)}$).  
-->
<!-- 
Let $0<\alpha<1$ denote the significance level and let $c_{1-\alpha}$ denote the $(1-\alpha)$ quantile of the $F$-distribution with $(q,n-K)$ degrees of freedom. 

This quantile $c_{1-\alpha}$ is the **critical value** that defines the **rejection region**: 
$$
\mathcal{R}=\; ]c_{1-\alpha},\infty[
$$
<!-- , and 
- non-rejection region, $]0,c_{1-\alpha}]$  
-->
<!-- * We can rejection $H_0$ if
$$
F_{obs}\in \mathcal{R}=\; ]c_{1-\alpha},\infty[
$$
* We cannot rejection $H_0$ if
$$
F_{obs}\not \in \mathcal{R}=\; ]c_{1-\alpha},\infty[
$$ -->
<!-- To handle this issue, it is useful to state the **composite null hypothesis** as a family of *infinitely many* specific null hypotheses:
\begin{align*}
&H_0: \beta_k =\tilde\beta_k^{(0)}\quad\text{with}\quad \tilde\beta_k^{(0)}\in ]-\infty,\beta_k^{(0)}]\\
\text{versus}\quad 
& H_1: \beta_k > \beta_k^{(0)}
\end{align*} -->
<!-- 
Thus, for testing 
$$
\begin{align*}
&H_0: \beta_k \leq \beta_k^{(0)}\\
\text{versus}\quad 
& H_1: \beta_k >    \beta_k^{(0)}\\
\end{align*}
$$ -->
</section>
</section>
<section id="power" class="level3" data-number="6.5.4">
<h3 data-number="6.5.4"><span class="header-section-number">6.5.4</span> Power</h3>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class='callout-icon no-icon'></i>
</div>
<div class="callout-body-container">
<div id="def-power" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.2 (Power)</strong></span> The power of a test statistic <span class="math inline">\(T_n\)</span> is the probability of correctly rejecting <span class="math inline">\(H_0\)</span> for a given <span class="math inline">\(\theta\in \Theta_1\)</span> <span class="math display">\[
\begin{align*}
\text{Power}_{n,\theta,\alpha}
&amp; = P(T_n \in \mathcal{R}_{n,\alpha} | \theta\in \Theta_1)\\[2ex]
&amp; = 1-P(\text{type-II-error}| \theta\in \Theta_1)
\end{align*}
\]</span></p>
</div>
</div>
</div>
</div>
<p>Since we want to detect a given violations of <span class="math inline">\(H_0,\)</span> we want test statistics with a large power.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Power is a function of <span class="math inline">\(\alpha,\)</span> <span class="math inline">\(\theta,\)</span> and <span class="math inline">\(n\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Large violations of <span class="math inline">\(H_0\)</span>: <span class="math display">\[
\begin{align*}
&amp;\text{Power}_{n,\theta,\alpha}
\to 1 \quad \text{as}\quad |\theta - \theta^{(0)}|\to\infty,
\end{align*}
\]</span> while keeping <span class="math inline">\(0&lt;\alpha&lt;1\)</span> and <span class="math inline">\(n\)</span> fix.</p></li>
<li><p>Large sample sizes <span class="math inline">\(n\)</span>: <span class="math display">\[
\begin{align*}
&amp;\text{Power}_{n,\theta,\alpha}
\to 1 \quad \text{as}\quad n\to\infty,
\end{align*}
\]</span> while keeping <span class="math inline">\(0&lt;\alpha&lt;1\)</span> and <span class="math inline">\(|\theta - \theta^{(0)}|&gt;0\)</span> fix.</p></li>
<li><p>Small significance levels <span class="math inline">\(\alpha\)</span>: <span class="math display">\[
\begin{align*}
&amp;\text{Power}_{n,\theta,\alpha}
\to 0 \quad \text{as}\quad \alpha\to 0,
\end{align*}
\]</span> while keeping <span class="math inline">\(n\)</span> and <span class="math inline">\(|\theta - \theta^{(0)}|&gt;0\)</span> fix.</p></li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class='callout-icon no-icon'></i>
</div>
<div class="callout-body-container">
<div id="def-power" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6.3 (Consistency of a Statistical Test)</strong></span> A statistical test is called <strong>consistent</strong> if its power increases as the sample size gets large <span class="math display">\[
\begin{align*}
&amp;\text{Power}_{n,\theta,\alpha}
\to 1 \quad \text{as}\quad n\to\infty\\[2ex]
\end{align*}
\]</span> for any fixed <span class="math inline">\(0&lt;\alpha&lt;1\)</span> and any fixed <span class="math inline">\(|\theta - \theta^{(0)}|&gt;0.\)</span></p>
</div>
</div>
</div>
</div>
<p><strong>Caution:</strong> Consistency of a statistical test is an important proporty, however, this property implies that even small, practically irrelevant violations of <span class="math inline">\(H_0\)</span> will be detected if the sample size is sufficiently large.</p>
<section id="power-of-the-one-sided-t-test" class="level4 unnumbered">
<h4 class="unnumbered"><strong>Power of the One-Sided <span class="math inline">\(t\)</span>-Test</strong></h4>
<!-- A type-II-error is the mistake of not rejecting the null hypothesis when in fact it should have been rejected. The probability of making a type-II-error equals one minus the probability of correctly rejecting the null hypothesis ("Power").  -->
<!-- For instance, in the case of using the $t$-test to test the null hypothesis $H_0: \beta_k=0$ versus the one-sided alternative hypothesis $H_1:\beta_k>0$) we have that 
\begin{align*}
P(\text{type-II-error})
&=P_{H_1}\Big(t\;\in\;\overbrace{]-\infty,c_{1-\alpha}]}^{\text{non-rejection region}}\Big)\\
&=1-\underbrace{P_{H_1}\Big(t\;\in\;\overbrace{]c_{1-\alpha},\infty[}^{\text{rejection region}}\Big)}_{\text{"Power"}},
\end{align*}
where $P_{H_1}$ means that we compute the probability under the assumption that $H_1$ is true.  -->
<!-- 
::: {.callout-note}
There is a trade off between the probability of making a type-I-error and the probability of making a type-II-error: a lower significance level $\alpha$ decreases $P(\text{type-I-error})$, but necessarily increases $P(\text{type-II-error})$ and vice versa.  
Ideally, we would have some sense of the costs of making each of these errors, and would choose our significance level to minimize these total costs. However, the costs are often difficult to know.  
:::  
-->
<p>Unfortunately, computing the power of a statistical test is usually impossible, since this requires knowing the distribution of the test statistic under the alternative hypothesis <span class="math inline">\(H_1.\)</span> The distribution of a test statistic under <span class="math inline">\(H_1\)</span> can only be derived under quite restrictive setups.</p>
<p>In the following, we consider such a restrictive setup for the <span class="math inline">\(t\)</span>-test statistic:</p>
<ul>
<li><p>Let’s consider the right-sided version of the one-sided hypothesis <span class="math display">\[
\begin{align*}
&amp;H_0: \beta_k\leq \beta_{k}^{(0)}\\
&amp;H_1: \beta_k &gt; \beta_{k}^{(0)}
\end{align*}
\]</span></p></li>
<li><p>Let <span class="math inline">\(X\)</span> be deterministic.</p></li>
<li><p>Let the true standard error of <span class="math inline">\(\hat\beta_{n,k}\)</span> be<br />
<span class="math display">\[
\operatorname{SE}(\hat\beta_{n,k}|X)=\frac{1}{\sqrt{n}}4.5.
\]</span></p></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Standard error of <span class="math inline">\(\hat\beta_{nk}\)</span> is proportional to <span class="math inline">\(1/\sqrt{n}\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Of course, usually we do not know the standard error of the estimator, but have to estimate it. However, it is true that the standard error of the OLS estimator <span class="math inline">\(\hat{\beta}_{n,k}\)</span> is <strong>proportional to</strong> <span class="math inline">\(\boldsymbol{1/\sqrt{n}},\)</span> <span class="math display">\[
\operatorname{SE}(\hat\beta_{n,k}|X) = C \cdot \frac{1}{\sqrt{n}},
\]</span> where <span class="math inline">\(C&gt;0\)</span> denotes a constant that does not depend on <span class="math inline">\(n.\)</span></p>
</div>
</div>
<p>Under this simplified setup and under Assumptions 1-4<span class="math inline">\(^\ast,\)</span> the <span class="math inline">\(t\)</span>-test statistic is <strong>normally distributed</strong>.</p>
<p>If <span class="math inline">\(H_0\)</span> is true with <span class="math inline">\(\beta_k=\beta_k^{(0)},\)</span> then <span class="math display">\[
\begin{align*}
T_n
&amp;=\frac{\hat\beta_{n,k}-\beta_k^{(0)}}{\frac{1}{\sqrt{n}}4.5}\\[2ex]
&amp;\overset{H_0}{=}\frac{\sqrt{n}(\hat\beta_{n,k}-\beta_k)}{4.5} \overset{H_0}{\sim} \mathcal{N}(0,1).
\end{align*}
\]</span></p>
<!-- 
> **Note:** It suffices to look at this specific null hypothesis $\beta_k=\beta_k^{(0)},$ since the distribution of $T$ is dominated by $\mathcal{N}(0,1)$ for all other null hypotheses $\beta_k<\beta_k^{(0)};$ see our discussions around @eq-NullDistrOneSidedIneq. 
-->
<p>If <span class="math inline">\(H_1: \beta_k-\beta_k^{(0)}&gt;0\)</span> is true, then <span class="math display">\[
\begin{align*}
T_n&amp;=\frac{\hat\beta_{n,k}-\beta_k^{(0)}}{\frac{1}{\sqrt{n}}4.5}
=\frac{\hat\beta_{n,k}\overbrace{-\beta_k+\beta_k}^{=0}-\beta_k^{(0)}}{\frac{1}{\sqrt{n}}4.5}\\[2ex]
&amp;=\underbrace{\frac{\sqrt{n}(\hat\beta_{n,k}-\beta_k)}{4.5}}_{\sim \mathcal{N}(0,1)}+\underbrace{\frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}}_{=\text{ mean shift }&gt;0}\\[2ex]
&amp;\overset{H_1}{\sim} \mathcal{N}\Bigg(\;\underbrace{\frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}}_{=\text{ mean shift }&gt;0}\;,\;1\Bigg)
\end{align*}
\]</span></p>
<p>Thus <span class="math display">\[
\begin{align*}
\text{Power}_{n,\theta,\alpha}
&amp; = P\Big(\;\underbrace{T_n &gt; z_{1-\alpha}}_{T_n\in\mathcal{R}_{n,\alpha}}\;|\; \underbrace{\beta_k &gt; \beta_k^{(0)}}_{H_1\text{ is true}}\;\Big),
\end{align*}
\]</span> where <span class="math inline">\(z_{1-\alpha}\)</span> denotes the <span class="math inline">\((1-\alpha)\)</span> quantile of the standard normal distribution <span class="math inline">\(\mathcal{N}(0,1),\)</span> and where <span class="math display">\[
T_n\sim \mathcal{N}\left(\frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5},1\right).
\]</span></p>
<p>This allows us to compute the power as following: <span class="math display">\[
\begin{align*}
&amp; \text{Power}_{n,\theta,\alpha}=\\[2ex]  
&amp; = P(T_n &gt; z_{1-\alpha}\;|\; \beta_k &gt; \beta_k^{(0)}),
\\[2ex]
&amp; = P\Bigg(\;\overbrace{T_n - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}}^{=Z\sim\mathcal{N}(0,1)} &gt; z_{1-\alpha} - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}\;\Bigg|\;\beta_k &gt; \beta_k^{(0)}\Bigg)\\[2ex]
&amp; = P\left(Z &gt; z_{1-\alpha} - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}\Bigg|\;\beta_k &gt; \beta_k^{(0)}\right)\\[2ex]
&amp;=1-P\left(Z \leq z_{1-\alpha} - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}\Bigg|\;\beta_k &gt; \beta_k^{(0)}\right)\\[2ex]
&amp;=1-\Phi\left(z_{1-\alpha} - \frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}\right)\quad\text{with}\quad \beta_k &gt; \beta_k^{(0)},
\end{align*}
\]</span> where <span class="math inline">\(\Phi\)</span> denotes the cumulative distribution function of the standard normal distribution <span class="math inline">\(\mathcal{N}(0,1).\)</span></p>
<p><a href="#fig-Power" class="quarto-xref">Figure <span class="quarto-unresolved-ref">fig-Power</span></a> illustrates the probability of a type-II-error and the power for the case where</p>
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(n=9\)</span></li>
<li><span class="math inline">\(\beta_k - \beta_k^{(0)}=3\)</span></li>
</ul>
<p>such that <span class="math display">\[
\begin{align*}
\text{Power}
&amp;=1-\Phi\Bigg(z_{1-\alpha} - \overbrace{\frac{\sqrt{n}(\beta_k-\beta_k^{(0)})}{4.5}}^{=\frac{3\cdot 3}{4.5} = 2}\Bigg)\\[2ex]
&amp;=1-\Phi\left(1.64  - 2 \right)\\[2ex]
&amp;=1-0.359=0.641
\end{align*}
\]</span> That is, we expect to detect the violation of the null hypothesis <span class="math inline">\((\beta_k - \beta_k^{(0)}=3)\)</span> in <span class="math inline">\(64\%\)</span> of resamplings from the random sample (data generating process).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-Power" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-Power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06-Small-Sample-Inference_files/figure-html/fig-Power-1.png" class="img-fluid quarto-figure quarto-figure-center" />
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-Power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 6.7: Probability of a type-II-error and the power for a one-sided <span class="math inline">\(t\)</span>-test at significance level <span class="math inline">\(\alpha = 0.05,\)</span> sample size <span class="math inline">\(n=9,\)</span> and violation of the null hypothesis <span class="math inline">\(\beta_k - \beta_k^{(0)}=3.\)</span>
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-pValue" class="level3" data-number="6.5.5">
<h3 data-number="6.5.5"><span class="header-section-number">6.5.5</span> <span class="math inline">\(p\)</span>-Value</h3>
<p>The <span class="math inline">\(p\)</span>-value of a test-statistic <span class="math inline">\(T_n\)</span> is defined as the probability of observing realizations of <span class="math inline">\(T_n\)</span> that are equal to or more extreme (in direction of the alternative) than the observed value <span class="math inline">\(T_{n,\text{obs}}\)</span> <strong>given that the null hypothesis is true.</strong></p>
<p><span class="math inline">\(p\)</span>-value for a left-sided version of a one-sided hypothesis test: <span class="math display">\[
p_{\text{left},\,\text{obs}} = P(T_n\leq T_{n,\text{obs}}\;|\;H_0 \text{ is true})
\]</span></p>
<p><span class="math inline">\(p\)</span>-value for a right-sided version of a one-sided hypothesis test: <span class="math display">\[
p_{\text{right},\,\text{obs}} = P(T_n\geq T_{n,\text{obs}}\;|\;H_0 \text{ is true})
\]</span></p>
<p><span class="math inline">\(p\)</span>-value for a two-sided hypothesis test: <span class="math display">\[
\begin{align*}
p_{\text{obs}}
&amp;=P(|T_n|\geq |T_{n,\text{obs}}|\;|\;H_0 \text{ is true})\\[2ex]
&amp;=2\cdot\min\{p_{\text{left},\,\text{obs}},
              p_{\text{right},\,\text{obs}}\}
\end{align*}
\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Marginal Significance Value
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <span class="math inline">\(p\)</span>-value equals the significance level <span class="math inline">\(\alpha\)</span> for which we just fail to reject the null. Therefore, the <span class="math inline">\(p\)</span>-value is sometimes also called “marginal significance value”.</p>
</div>
</div>
<p>Since the <span class="math inline">\(p\)</span>-value is defined under the hypothetical <strong>scenario that the null-hypothesis is true</strong>, …</p>
<center>
❗… the <span class="math inline">\(p\)</span>-value <strong>cannot</strong> be the probability that the null-hypothesis is true. (A common misinterpretation of the <span class="math inline">\(p\)</span>-value.)❗
</center>
<p></br></p>
<p><img src="images/terminator.jpeg" class="img-fluid" /></p>
<section id="the-p-value-is-a-random-variable" class="level4 unnumbered">
<h4 class="unnumbered"><strong>The <span class="math inline">\(p\)</span>-value is a Random Variable</strong></h4>
<p>Let’s consider, without loss of generality, the <span class="math inline">\(p\)</span>-value for a left-sided version of a one-sided hypothesis test: <span class="math display">\[
\begin{align*}
p_{\text{left},\,\text{obs}}
&amp;= P(T_n\leq T_{n,\text{obs}}\;|\;H_0 \text{ is true})\\
&amp;= F_{T_n}(T_{n,\text{obs}}),
\end{align*}
\]</span> where <span class="math inline">\(F_{T_n}\)</span> denotes the cumulative distribution function (see <a href="#sec-Defcdf" class="quarto-xref"><span class="quarto-unresolved-ref">sec-Defcdf</span></a>) of <span class="math inline">\(T_n.\)</span></p>
<blockquote>
<p><strong>In the case of the <span class="math inline">\(t\)</span>-test:</strong> Under <span class="math inline">\(H_0,\)</span> <span class="math inline">\(F_{T_n}\)</span> denotes the distribution function of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K\)</span> degrees of freedom.</p>
</blockquote>
<p>The <span class="math inline">\(p\)</span>-value is a random variable, since it depends on the data; i.e., for a given realization of the random sample, we observe the corresponding realization <span class="math inline">\(p_{\text{left},\,\text{obs}}.\)</span></p>
<p>Under <span class="math inline">\(H_0,\)</span> the <span class="math inline">\(p\)</span>-value is a <strong>uniformly distributed random variable</strong> <span class="math display">\[
p_{\text{left}} = F_{T_n}(T_{n}) \overset{H_0}{\sim}\mathcal{U}[0,1].
\]</span></p>
<p><strong>Proof:</strong></p>
<p>Observe that <span class="math inline">\(p_{\text{left}}\)</span> is defined as a transformed random variable; namely by transforming the random variable <span class="math inline">\(T_n\)</span> using the cumulative distribution function <span class="math inline">\(F_{T_n},\)</span> where, under <span class="math inline">\(H_0,\)</span> <span class="math display">\[
T_{n}\overset{H_0}{\sim}F_{T_n}.
\]</span></p>
<p>Let <span class="math inline">\(F_{p_{\text{left}}}\)</span> denote the cumulative distribution function of <span class="math inline">\(p_{\text{left}}\)</span>.</p>
<p>If the claim is correct, then the random variable <span class="math inline">\(p_{\text{left}}\)</span> has, under <span class="math inline">\(H_0,\)</span> the cumulative distribution function of <span class="math inline">\(\mathcal{U}[0,1];\)</span> i.e. <span class="math display">\[
F_{p_{\text{left}}}(x) = x\quad\text{for}\quad x\in[0,1].
\]</span></p>
<p>This is indeed true since, under <span class="math inline">\(H_0\)</span>: <span class="math display">\[
\begin{align*}
F_{p_{\text{left}}}(x)
&amp;= P(p_{\text{left}} &lt; x) \\[2ex]
&amp;= P(F_{T_n}(T_n) &lt; x) \\[2ex]
&amp;= P(T_n &lt; F_{T_n}^{-1}(x)) \\[2ex]
&amp;= F_{T_n}(F_{T_n}^{-1}(x)) \\[2ex]
&amp;= x
\end{align*}
\]</span></p>
</section>
</section>
</section>
<section id="sec-PSSI" class="level2" data-number="6.6">
<h2 data-number="6.6"><span class="header-section-number">6.6</span> Monte Carlo Simulations</h2>
<p>Let’s check the above exact inference results using Monte Carlo simulations. The check, of course, applies only to the considered special case and generally does not generalize to other data generating processes.</p>
<p>First, we program a function <code>myDataGenerator()</code> which allows us to generate data from the following model, i.e., from the following fully specified data generating process: <span class="math display">\[
\begin{align*}
Y_i &amp;=\beta_1+\beta_2X_{i2}+\beta_3X_{i3}+\varepsilon_i,\qquad i=1,\dots,n\\
\beta &amp;=(\beta_1,\beta_2,\beta_3)&#39;=(2,3,4)&#39;\\
X_{i2}&amp;\sim U[2,10]\\
X_{i3}&amp;\sim U[12,22]\\
\varepsilon_i|X&amp;\sim\mathcal{N}(0,3^2),
\end{align*}
\]</span> where <span class="math inline">\((Y_i,X_i)\)</span> is i.i.d. across <span class="math inline">\(i=1,\dots,n\)</span>.</p>
<p>Let us consider a small sample size of <span class="math inline">\(n=7\)</span>.</p>
<p>The below function <code>myDataGenerator()</code> allows to sample new realizations of the random sample <span class="math display">\[
((X_1,Y_1),\dots,(X_n,Y_n))
\]</span> You can provide your own values for the sample size <span class="math inline">\(n\)</span> and for the parameter vector <span class="math inline">\(\beta=(\beta_1,\beta_2,\beta_3)&#39;\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Function to generate artificial data</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="do">## If the user provides &#39;X_cond&#39; data, </span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="do">## the sampling of new Y variables is </span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="do">## conditionally on the given X_cond variables.</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="do">## If X_cond = NULL, sampling is done unconditionally. </span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>myDataGenerator <span class="ot">&lt;-</span> <span class="cf">function</span>(n, beta){</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="do">## sampling predictors X:</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>X   <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, n), </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>            <span class="fu">runif</span>(n, <span class="dv">2</span>, <span class="dv">10</span>), </span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>            <span class="fu">runif</span>(n,<span class="dv">12</span>, <span class="dv">22</span>))</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="do">## sampling error terms: </span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>eps  <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="dv">3</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="do">## generate realizations of Y:</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>Y    <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta <span class="sc">+</span> eps</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="do">## safe X and Y as a data frame:</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="st">&quot;Y&quot;</span>   <span class="ot">=</span> Y, </span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&quot;X_1&quot;</span> <span class="ot">=</span> X[,<span class="dv">1</span>], </span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&quot;X_2&quot;</span> <span class="ot">=</span> X[,<span class="dv">2</span>], </span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&quot;X_3&quot;</span> <span class="ot">=</span> X[,<span class="dv">3</span>])</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="do">## return the data frame</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(data)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="do">## Small sample size</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>n             <span class="ot">&lt;-</span> <span class="dv">7</span>        </span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="do">## Define the true beta vector</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>beta_true     <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate Y and X data </span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>test_data     <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta=</span>beta_true)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="do">## Look at the first six lines of the data frame</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">head</span>(test_data,     <span class="dv">3</span>), <span class="dv">2</span>) </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      Y X_1  X_2   X_3
1 97.53   1 4.23 20.50
2 75.37   1 8.06 12.35
3 70.92   1 4.70 14.95</code></pre>
</div>
</div>
<section id="check-testing-multiple-parameters" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1"><span class="header-section-number">6.6.1</span> Check: Testing Multiple Parameters</h3>
<p>In the following, we do inference about multiple parameters. We test <span class="math display">\[\begin{align*}
H_0:\;&amp;\beta_2=3\quad\text{and}\quad\beta_3=4\\
\text{versus}\quad H_1:\;&amp;\beta_2\neq 3\quad\text{and/or}\quad\beta_3\neq 4.
\end{align*}\]</span> Or equivalently <span class="math display">\[\begin{align*}
H_0:\;&amp;R\beta  = r^{(0)} \\
H_1:\;&amp;R\beta  \neq r^{(0)},
\end{align*}\]</span> where <span class="math display">\[
R=\left(
\begin{matrix}
0&amp;1&amp;0\\
0&amp;0&amp;1\\
\end{matrix}\right)\quad\text{ and }\quad
r^{(0)}=\left(\begin{matrix}3\\4\\\end{matrix}\right).
\]</span> The following <code>R</code> code can be used to test this hypothesis:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Library containing the function &#39;linearHyothesis()&#39; </span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="do">## for testing multiple parameters </span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressMessages</span>(<span class="fu">library</span>(<span class="st">&quot;car&quot;</span>)) </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="do">## See ?linearHypothesis</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Generate one Monte Carlo sample (under H0)</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>data   <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimate the linear regression model parameters</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>lm_obj <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> data)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Option 1:</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>test_result <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">linearHypothesis</span>(</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">model =</span> lm_obj, </span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">hypothesis.matrix =</span> <span class="fu">c</span>(<span class="st">&quot;X_2=3&quot;</span>, <span class="st">&quot;X_3=4&quot;</span>))   </span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>test_result        </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear hypothesis test

Hypothesis:
X_2 = 3
X_3 = 4

Model 1: restricted model
Model 2: Y ~ X_2 + X_3

  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1      6 46.527                           
2      4 32.573  2    13.954 0.8568 0.4901</code></pre>
</div>
</div>
The <span class="math inline">\(p\)</span>-value
<center>
<span class="math inline">\(p_{\text{obs}}=\)</span> 0.4901 <span class="math inline">\(\;&gt;\alpha=0.05\)</span>
</center>
<p>is larger than the chosen significance level <span class="math inline">\(\alpha=0.05.\)</span> Thus we <strong>cannot reject</strong> the null hypothesis <span class="math display">\[
H_0:\;\beta_2=3\quad\text{and}\quad \beta_3=4.
\]</span></p>
<p>The following codes gives an alternative, equivalent way to compute the test result:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb17"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Option 2:</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>),</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>           <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(<span class="at">model =</span> lm_obj, </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">hypothesis.matrix =</span> R, </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">rhs =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">4</span>))</span></code></pre></div>
</div>
<p>We simulated data under <span class="math inline">\(H_0\)</span> and thus it is not surprising that we cannot reject <span class="math inline">\(H_0.\)</span></p>
<p>However, in repeated samples we should nevertheless observe <span class="math inline">\(\alpha\cdot 100\%\)</span> type I errors (false rejections of <span class="math inline">\(H_0\)</span>) under <span class="math inline">\(H_0.\)</span> Let’s check the type-I-error rate using the following Monte Carlo simulation:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb18"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Let&#39;s generate 5000 F-test decisions and check </span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="do">## whether the empirical rate of type I errors is </span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="do">## close to the theoretical significance level. </span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>B               <span class="ot">&lt;-</span> <span class="dv">5000</span> <span class="co"># MC replications</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>F_test_pvalues  <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="at">times=</span>B)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  <span class="do">## generate new data (under H0)</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  MC_data <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="do">## estimate </span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  lm_obj  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> MC_data)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute test and p-value</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>  p       <span class="ot">&lt;-</span> <span class="fu">linearHypothesis</span>(lm_obj, <span class="fu">c</span>(<span class="st">&quot;X_2=3&quot;</span>, <span class="st">&quot;X_3=4&quot;</span>))<span class="sc">$</span><span class="st">`</span><span class="at">Pr(&gt;F)</span><span class="st">`</span>[<span class="dv">2</span>]</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>  <span class="do">## save the p-value</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>  F_test_pvalues[r] <span class="ot">&lt;-</span> p</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<p>Using the collection of <span class="math inline">\(p\)</span>-value realizations (under <span class="math inline">\(H_0\)</span>) we can check whether the size equals the nominal size (significance level) <span class="math inline">\(\alpha.\)</span></p>
<p>For <span class="math inline">\(\alpha = 0.05:\)</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb19"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>alpha        <span class="ot">&lt;-</span>  <span class="fl">0.05</span>          <span class="co"># signif level</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>rejections   <span class="ot">&lt;-</span> F_test_pvalues[F_test_pvalues <span class="sc">&lt;</span> alpha]</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">length</span>(rejections)<span class="sc">/</span>B, <span class="dv">4</span>) <span class="co"># actual type-I-error rate </span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0524</code></pre>
</div>
</div>
<p>For <span class="math inline">\(\alpha = 0.01:\)</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb21"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>alpha        <span class="ot">&lt;-</span>  <span class="fl">0.01</span>  <span class="co"># signif level</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>rejections   <span class="ot">&lt;-</span> F_test_pvalues[F_test_pvalues <span class="sc">&lt;</span> alpha]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">length</span>(rejections)<span class="sc">/</span>B, <span class="dv">4</span>) <span class="co"># actual type-I-error rate </span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0092</code></pre>
</div>
</div>
<p>Observations:</p>
<ol type="1">
<li>We correctly control for the type-I-error rate since the empirical type-I-error rate is not larger than the chosen significance level <span class="math inline">\(\alpha.\)</span></li>
<li>The <span class="math inline">\(F\)</span> test is not conservative since the empirical type-I-error rates essentially matches the chosen significance levels <span class="math inline">\(\alpha.\)</span> </br> In fact, if we would increase the number of Monte Carlo repetitions, the empirical type-I-error rate would converge to the nominal type-I-error rate <span class="math inline">\(\alpha\)</span> due to the law of large numbers.</li>
<li>Last but not least: All this works <strong>unconditionally</strong> on <span class="math inline">\(X\)</span> since the distribution of the <span class="math inline">\(F\)</span> statistic (<a href="#eq-Ftest" class="quarto-xref">Equation <span class="quarto-unresolved-ref">eq-Ftest</span></a>) does not depend on <span class="math inline">\(X\)</span>.</li>
</ol>
<p>Next, we check how well the <span class="math inline">\(F\)</span> test detects certain <strong>violations of the null hypothesis</strong>. We do this by using the same data generating process, but by testing the following <span style="color:#FF0000">incorrect</span> null hypothesis: <span class="math display">\[\begin{align*}
H_0:\;&amp;{\color{red}\beta_2=4}\quad\text{and}\quad\beta_3=4\\
H_1:\;&amp;\beta_2\neq 4\quad\text{and/or}\quad\beta_3\neq 4
\end{align*}\]</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb23"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>B               <span class="ot">&lt;-</span> <span class="dv">5000</span> <span class="co"># MC replications</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>F_test_pvalues  <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="at">times=</span>B)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="do">## generate new data </span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>  MC_data <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n    =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="do">## estimate </span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  lm_obj  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> MC_data)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute test and p-value (for a false H0)</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  p       <span class="ot">&lt;-</span> <span class="fu">linearHypothesis</span>(lm_obj, <span class="fu">c</span>(<span class="st">&quot;X_2=4&quot;</span>, <span class="st">&quot;X_3=4&quot;</span>))<span class="sc">$</span><span class="st">`</span><span class="at">Pr(&gt;F)</span><span class="st">`</span>[<span class="dv">2</span>]</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="do">## save the p-value</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>  F_test_pvalues[r] <span class="ot">&lt;-</span> p</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Checking the power of the F test </span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>alpha       <span class="ot">&lt;-</span>  <span class="fl">0.05</span>  <span class="co"># signif_level</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>rejections  <span class="ot">&lt;-</span> F_test_pvalues[F_test_pvalues <span class="sc">&lt;</span> alpha]</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(rejections)<span class="sc">/</span>B  <span class="co"># power </span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.204</code></pre>
</div>
</div>
<p>We can now correctly reject the false null hypothesis in approximately 20.4 % of all Monte Carlo replications.</p>
<p><strong>Caution:</strong> This means that we are not able to detect the violation of the null hypothesis in 79.6 % of cases. Therefore, we can never use an insignificant test result (<span class="math inline">\(p\)</span>-value <span class="math inline">\(\geq\alpha\)</span>) as a confirmation of the null hypothesis. Obviously, there are type-II-error events (not rejecting a false <span class="math inline">\(H_0\)</span>), but since we typically do not know the distribution of the test statistic under the alternative hypothesis, we cannot control the type-II-error rate. We can only control the type-I-error rate by using a small significance level <span class="math inline">\(\alpha\)</span>.</p>
<p>Moreover, note that the <span class="math inline">\(F\)</span> test is not informative about which part of the null hypothesis (<span class="math inline">\(\beta_2=4\)</span> and/or <span class="math inline">\(\beta_3=4\)</span>) is violated. We only get the information that at least one of the multiple parameter hypotheses is violated. Test statistics with this property are called <strong>omnibus tests</strong>.</p>
</section>
<section id="check-dualty-of-confidence-intervals-and-hypothesis-tests" class="level3" data-number="6.6.2">
<h3 data-number="6.6.2"><span class="header-section-number">6.6.2</span> Check: Dualty of Confidence Intervals and Hypothesis Tests</h3>
<p>Confidence intervals can be computed using <code>R</code> as following:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb25"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Significance level</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>alpha        <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Confidence level</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>conf_level   <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> alpha</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 95% CI for beta_2</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(lm_obj, <span class="at">parm =</span> <span class="st">&quot;X_2&quot;</span>, <span class="at">level =</span> conf_level)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       2.5 %  97.5 %
X_2 2.984806 4.18956</code></pre>
</div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 95% CI for beta_3 </span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(lm_obj, <span class="at">parm =</span> <span class="st">&quot;X_3&quot;</span>, <span class="at">level =</span> conf_level)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       2.5 %   97.5 %
X_3 3.877389 4.489954</code></pre>
</div>
</div>
<p>We can use these two-sided confidence intervals to conduct hypotheses tests. This property of confidence intervals is called the <strong>duality of confidence intervals and hypothesis tests</strong>.</p>
<p>For instance, when testing the null hypothesis <span class="math display">\[\begin{align*}
H_0:&amp;\;\beta_2=3\\
\text{versus}\quad H_1: &amp;\;\beta_2\neq 3
\end{align*}\]</span> we can either use a <span class="math inline">\(t\)</span>-test or equivalently check whether the confidence interval <span class="math inline">\(\operatorname{CI}_{2,1-\alpha}\)</span> for <span class="math inline">\(\beta_2\)</span> contains the hypothetical value <span class="math inline">\(4\)</span> or not.</p>
<ul>
<li>In case of <span class="math inline">\(3    \in\operatorname{CI}_{2,1-\alpha}\)</span>, we cannot reject the null hypothesis <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_2=3.\)</span></li>
<li>In case of <span class="math inline">\(3\not\in\operatorname{CI}_{2,1-\alpha}\)</span>, we can reject the null hypothesis <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_2=3.\)</span></li>
</ul>
<p>If the Assumptions 1-4<span class="math inline">\(^\ast\)</span> hold true, then <span class="math inline">\(\operatorname{CI}_{2,1-\alpha}\)</span> is an exact confidence interval. That is, under the null hypothesis, it falsely rejects the null hypothesis in only <span class="math inline">\(\alpha\cdot 100\%\)</span> of resamplings. Let’s check this in the following Monte Carlo simulation:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb29"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Significance level</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>alpha        <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="do">## beta_2 safed separately</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>beta_true_2  <span class="ot">&lt;-</span> beta_true[<span class="dv">2</span>]</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Container to save all CI realizations</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>confint_m  <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow=</span><span class="dv">2</span>, <span class="at">ncol=</span>B)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="do">##</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  <span class="do">## generate new data </span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>  MC_data <span class="ot">&lt;-</span> <span class="fu">myDataGenerator</span>(<span class="at">n =</span> n, <span class="at">beta =</span> beta_true)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>  <span class="do">## estimate</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>  lm_obj  <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X_2 <span class="sc">+</span> X_3, <span class="at">data =</span> MC_data)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>  <span class="do">## compute confidence interval </span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>  CI <span class="ot">&lt;-</span> <span class="fu">confint</span>(lm_obj, <span class="at">parm=</span><span class="st">&quot;X_2&quot;</span>, <span class="at">level =</span> <span class="dv">1</span> <span class="sc">-</span> alpha)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>  <span class="do">## save confidence interval</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>  confint_m[,r] <span class="ot">&lt;-</span> CI</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="do">## check whether true parameter is inside the CI</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>inside_CI  <span class="ot">&lt;-</span> confint_m[<span class="dv">1</span>,] <span class="sc">&lt;=</span> beta_true_2 <span class="sc">&amp;</span> </span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>                beta_true_2 <span class="sc">&lt;=</span> confint_m[<span class="dv">2</span>,]</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="do">## CI-lower, CI-upper, beta_true_2 inside?</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">cbind</span>(<span class="fu">t</span>(confint_m), inside_CI))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                       inside_CI
[1,] 2.507509 4.505450         1
[2,] 1.479413 4.468068         1
[3,] 2.540762 5.533256         1
[4,] 1.129250 6.473386         1
[5,] 1.167703 4.362476         1
[6,] 1.430087 4.107289         1</code></pre>
</div>
</div>
<p>The following code computes the relative frequency of confidence intervals <strong>not containing</strong> the true parameter value <span class="math inline">\((\beta_2=3)\)</span>:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb31"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">length</span>(inside_CI[inside_CI <span class="sc">==</span> <span class="cn">FALSE</span>])<span class="sc">/</span>B, <span class="dv">4</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0442</code></pre>
</div>
</div>
<p>That’s good! The relative frequency is basically equal to the chosen <span class="math inline">\(\alpha=0.05\)</span> value.</p>
<p>Next, we visualize a subsample of <code>100</code> confidence intervals from the total sample of <code>5000</code> generated confidence interval realizations:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb33"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>nCIs <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span><span class="dv">0</span>,<span class="at">type=</span><span class="st">&quot;n&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,nCIs), <span class="at">ylim=</span><span class="fu">range</span>(confint_m[,<span class="dv">1</span><span class="sc">:</span>nCIs]),</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Resamplings&quot;</span>, <span class="at">main=</span><span class="st">&quot;Confidence Intervals&quot;</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nCIs){</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(inside_CI[r]<span class="sc">==</span><span class="cn">TRUE</span>){</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">lines</span>(<span class="at">x=</span><span class="fu">c</span>(r,r), <span class="at">y=</span><span class="fu">c</span>(confint_m[<span class="dv">1</span>,r], confint_m[<span class="dv">2</span>,r]), <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="fu">gray</span>(.<span class="dv">5</span>,.<span class="dv">5</span>))</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  }<span class="cf">else</span>{</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">lines</span>(<span class="at">x=</span><span class="fu">c</span>(r,r), <span class="at">y=</span><span class="fu">c</span>(confint_m[<span class="dv">1</span>,r], confint_m[<span class="dv">2</span>,r]), <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;darkred&quot;</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">4</span>, <span class="at">at=</span>beta_true_2, <span class="at">labels =</span> <span class="fu">expression</span>(beta[<span class="dv">2</span>]))</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span>beta_true_2)</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="06-Small-Sample-Inference_files/figure-html/unnamed-chunk-23-1.png" class="img-fluid quarto-figure quarto-figure-center" /></p>
</figure>
</div>
</div>
</div>
<p>As expected, only about <span class="math inline">\(\alpha\cdot 100\%=5\%\)</span> of all confidence intervals do not contain the true parameter value <span class="math inline">\(\beta_2=3\)</span>, but about <span class="math inline">\((1-\alpha)\cdot 100\%=95\%\)</span> of all confidence intervals contain the true parameter value <span class="math inline">\(\beta_2=3\)</span>.</p>
</section>
</section>
<section id="sec-RDSSInf" class="level2" data-number="6.7">
<h2 data-number="6.7"><span class="header-section-number">6.7</span> Real Data Example</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb34"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="do">## The AER package contains a lot of datasets </span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(AER))</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Attach the DoctorVisits data to make it usable</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;DoctorVisits&quot;</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>lm_obj <span class="ot">&lt;-</span> <span class="fu">lm</span>(visits <span class="sc">~</span> gender <span class="sc">+</span> age <span class="sc">+</span> income, <span class="at">data =</span> DoctorVisits)</span></code></pre></div>
</div>
<p>The above <code>R</code> codes estimate the following regression model <span class="math display">\[
Y_i = \beta_1 + \beta_{gender} X_{gender,i}
              + \beta_{age} X_{age,i}
              + \beta_{income} X_{income,i} + \varepsilon_i,
\]</span> where <span class="math inline">\(i=1,\dots,n\)</span> and</p>
<ul>
<li><span class="math inline">\(X_{gender,i}=1\)</span> if the <span class="math inline">\(i\)</span>th subject is a woman and <span class="math inline">\(X_{gender,i}=0\)</span> if the <span class="math inline">\(i\)</span>th subject is a man</li>
<li><span class="math inline">\(X_{age,i}\)</span> is the age of subject <span class="math inline">\(i\)</span> measured in years divided by <span class="math inline">\(100\)</span></li>
<li><span class="math inline">\(X_{income,i}\)</span> is the annual income of subject <span class="math inline">\(i\)</span> in tens of thousands of dollars</li>
</ul>
<p>The following <code>R</code> codes produces the classic regression output table (simular tables are produced by all statistical/econometric software packages):</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb35"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>lm_obj_summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(lm_obj)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>lm_obj_summary</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = visits ~ gender + age + income, data = DoctorVisits)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.5009 -0.3435 -0.2306 -0.1682  8.6174 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   0.15371    0.03607   4.262 2.07e-05 ***
genderfemale  0.06245    0.02345   2.662  0.00778 ** 
age           0.40235    0.05713   7.043 2.13e-12 ***
income       -0.08231    0.03167  -2.599  0.00938 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.7908 on 5186 degrees of freedom
Multiple R-squared:  0.01885,   Adjusted R-squared:  0.01829 
F-statistic: 33.22 on 3 and 5186 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The above regression output table contains the following information:</p>
<ul>
<li><p><strong>Estimate:</strong> The column “Estimate” containes the estimates <span class="math display">\[
\hat\beta_{j},\quad j\in\{1,gender, age, income\}
\]</span> You can extract them using <code>coef(lm_obj)</code>.</p></li>
<li><p><strong>Std. Error:</strong> The column “Std. Error” containes the estimates <span class="math display">\[
\widehat{\operatorname{SE}}(\hat\beta_{j}|X),\quad j\in\{1,gender, age, income\}
\]</span></p>
<ul>
<li>You can extract the total <span class="math inline">\((K\times K)=(4\times 4)\)</span> variance-covariance matrix estimate <span class="math inline">\(\widehat{Var}(\hat\beta|X)\)</span> using <code>vcov(lm_obj)</code>.</li>
<li>The diagonal <code>diag(vcov(lm_obj))</code> contains the variance estimates <span class="math inline">\(\widehat{Var}(\hat\beta_j|X)\)</span>, <span class="math inline">\(j\in\{1,gender, age, income\}\)</span>.</li>
<li>The square root of the diagonal <code>sqrt(diag(vcov(lm_obj)))</code> allows you to compute the estimated standard errors shown in the regression table.</li>
</ul></li>
<li><p><strong>t value:</strong> The column “t value” contains the observed <span class="math inline">\(t\)</span> test statistics <span class="math display">\[
T_{obs,j}=\frac{\hat\beta_{j}-0}{\widehat{\operatorname{SE}}(\hat\beta_{j}|X)},\quad j\in\{1,gender, age, income\}
\]</span> You can extract the values using <code>lm_obj_summary$coefficients[,3]</code>.</p></li>
<li><p><strong>Pr(&gt;|t|):</strong> The column “Pr(&gt;|t|)” contains the <span class="math inline">\(p\)</span> values <span class="math display">\[
P_{H_0}(|t|&gt;t_{obs,j}),\quad j\in\{1,gender, age, income\}
\]</span> You can extract the values using <code>lm_obj_summary$coefficients[,4]</code>.</p></li>
<li><p><strong>Residual standard error</strong> <span class="math inline">\(\sqrt{\frac{1}{n-K}\sum_{i=1}^n\hat\varepsilon^2_i}=\)</span> <code>sqrt(sum(resid(lm_obj)^2)/(n-4))</code> <span class="math inline">\(=\)</span> 0.7908</p></li>
<li><p><strong>Multiple R-squared:</strong> <span class="math inline">\(R^2=\)</span> <code>lm_obj_summary$r.squared</code> <span class="math inline">\(=\)</span> 0.01885</p></li>
<li><p><strong>Adjusted R-squared:</strong> <span class="math inline">\(\bar{R}^2=\)</span> <code>lm_obj_summary$adj.r.squared</code> <span class="math inline">\(=\)</span> 0.01829</p></li>
<li><p><strong>F-statistic:</strong> This is a standard <span class="math inline">\(F\)</span> test that tests the null hypothesis that all parameters except the intercept are zero; i.e.<br> <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_{gender}=\beta_{age}=\beta_{income}=0\)</span><br> versus<br> <span class="math inline">\(H_1\)</span>: At least one parameter is not zero. <code>R</code>’s <code>summary()</code> functions reports an observed <span class="math inline">\(F\)</span> statistic value of <span class="math inline">\(33.22\)</span> which needs to be evaluated for an <span class="math inline">\(F\)</span> distribution with <span class="math inline">\(3\)</span> and <span class="math inline">\(5186\)</span> degrees of freedom leading to a <span class="math inline">\(p\)</span>-value <span class="math inline">\(p&lt; 0.00001.\)</span> <br><br> You can replicate this <span class="math inline">\(F\)</span>-test result using the following <code>R</code> code:</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb37"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">model =</span> lm_obj, </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">hypothesis.matrix =</span> <span class="fu">c</span>(<span class="st">&quot;genderfemale=0&quot;</span>, <span class="st">&quot;age=0&quot;</span>, <span class="st">&quot;income=0&quot;</span>))  </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Linear hypothesis test

Hypothesis:
genderfemale = 0
age = 0
income = 0

Model 1: restricted model
Model 2: visits ~ gender + age + income

  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
1   5189 3305.5                                  
2   5186 3243.2  3     62.32 33.218 &lt; 2.2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
</div>
<!-- #### Interpretation of $\hat\beta_{gender}$ {-} -->
<!-- Since $X_{gender,i}$ is a dummy variable,  -->
<section id="r-package-stargazer" class="level4 unnumbered">
<h4 class="unnumbered"><code>R</code> Package Stargazer</h4>
<p>Beautiful and “publication ready” regression outputs can be produced using the <code>R</code> package <code>stargazer</code> and its function <code>stargazer()</code>:</p>
<center>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb39"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Hint: use type = &quot;latex&quot; </span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="do">## to produce a latex table</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fu">stargazer</span>(lm_obj, <span class="at">type=</span><span class="st">&quot;html&quot;</span>)</span></code></pre></div>
<table style="text-align:center">
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
visits
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
genderfemale
</td>
<td>
0.062<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.023)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
age
</td>
<td>
0.402<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.057)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
income
</td>
<td>
-0.082<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.032)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
0.154<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.036)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
5,190
</td>
</tr>
<tr>
<td style="text-align:left">
R<sup>2</sup>
</td>
<td>
0.019
</td>
</tr>
<tr>
<td style="text-align:left">
Adjusted R<sup>2</sup>
</td>
<td>
0.018
</td>
</tr>
<tr>
<td style="text-align:left">
Residual Std. Error
</td>
<td>
0.791 (df = 5186)
</td>
</tr>
<tr>
<td style="text-align:left">
F Statistic
</td>
<td>
33.218<sup>***</sup> (df = 3; 5186)
</td>
</tr>
<tr>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
<em>Note:</em>
</td>
<td style="text-align:right">
<sup><em></sup>p&lt;0.1; <sup><strong></sup>p&lt;0.05; <sup></strong></em></sup>p&lt;0.01
</td>
</tr>
</table>
</div>
</center>
</section>
<section id="critical-discussion-of-the-regression-above-results" class="level4 unnumbered">
<h4 class="unnumbered">Critical Discussion of the Regression above Results</h4>
<p>The above real data analysis does <strong>not</strong> fit into the small sample inference framework we introduced in this chapter.</p>
<ol type="1">
<li>The dependent variable <span class="math inline">\(Y_i\)</span> <code>visits</code> is a <em>categorial</em> variable taking finitely many discrete values, indeed
<center>
<code>unique(DoctorVisits$visits)</code> = 1, 2, 3, 4, 8, 5, 7, 6, 9, 0.
</center>
Consequently, the error term <span class="math inline">\(\varepsilon_i\)</span> <strong>cannot be normal distributed</strong>.</li>
<li>The diagnostic plot (“Residuals versus Fitted”) indicates a possible issue <strong>violation of the homoskedasticity assumption</strong>. In case of homokedastic variances, the data points <span class="math inline">\((\hat\varepsilon_i,\hat{Y}_i)\)</span>, <span class="math inline">\(i=1,\dots,n\)</span> should roughly show a homogenous scattering across the fitted values <span class="math inline">\(\hat{Y}_i=X\hat\beta\)</span>. This seems not to be the case here.</li>
</ol>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb40"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Diagonstic Plot </span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Residuals versus fitted values</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_obj, <span class="at">which =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="06-Small-Sample-Inference_files/figure-html/unnamed-chunk-29-1.png" class="img-fluid quarto-figure quarto-figure-center" width="672" /></p>
</figure>
</div>
</div>
</div>
<p>Lukily, the data set <code>DoctorVisits</code> actually has a <strong>large sample size</strong> of <span class="math inline">\(n=\)</span> 5190 and thus there is a way out of this problem: The large sample inference framework introduced in the next chapter.</p>
</section>
</section>
<section id="exercises" class="level2" data-number="6.8">
<h2 data-number="6.8"><span class="header-section-number">6.8</span> Exercises</h2>
<ul>
<li><p><a href="https://www.dropbox.com/scl/fi/zga37r4btryd61uc1rb0b/Ch6_Exercises1.pdf?rlkey=ine2f41nivqteps58sj7ju6nj&amp;dl=0">Exercises for Chapter 6</a></p></li>
<li><p><a href="https://www.dropbox.com/scl/fi/o1k0b69ll10vyc8qbw850/Ch6_Exercises_with_Solutions1.pdf?rlkey=oue9pbl5jatyc9c9d1rmffni2&amp;dl=0">Exercises of Chapter 6 with Solutions</a></p></li>
</ul>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="quarto-navigation-envelope" class="hidden">
<p><span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar-title">Basis Module Econometrics (M.Sc.)</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-navbar-title">Basis Module Econometrics (M.Sc.)</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-next"><span class="chapter-number">7</span>  <span class="chapter-title">Large Sample Inference</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-prev"><span class="chapter-number">5</span>  <span class="chapter-title">Multiple Linear Regression</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/index.htmlOrganization-of-the-Course">Organization of the Course</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/01-Introduction-to-R.html&lt;span-class=&#39;chapter-number&#39;&gt;1&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Introduction-to-R&lt;/span&gt;"><span class="chapter-number">1</span>  <span class="chapter-title">Introduction to R</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/02-Probability.html&lt;span-class=&#39;chapter-number&#39;&gt;2&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Probability&lt;/span&gt;"><span class="chapter-number">2</span>  <span class="chapter-title">Probability</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/03-Matrix-Algebra.html&lt;span-class=&#39;chapter-number&#39;&gt;3&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Matrix-Algebra&lt;/span&gt;"><span class="chapter-number">3</span>  <span class="chapter-title">Matrix Algebra</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/04-Monte-Carlo-Simulations.html&lt;span-class=&#39;chapter-number&#39;&gt;4&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Estimation-Theory-and-Monte-Carlo-Simulations&lt;/span&gt;"><span class="chapter-number">4</span>  <span class="chapter-title">Estimation Theory and Monte Carlo Simulations</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/05-Multiple-Linear-Regression.html&lt;span-class=&#39;chapter-number&#39;&gt;5&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Multiple-Linear-Regression&lt;/span&gt;"><span class="chapter-number">5</span>  <span class="chapter-title">Multiple Linear Regression</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/06-Small-Sample-Inference.html&lt;span-class=&#39;chapter-number&#39;&gt;6&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Small-Sample-Inference&lt;/span&gt;"><span class="chapter-number">6</span>  <span class="chapter-title">Small Sample Inference</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-int-sidebar:/07-Asymptotics.html&lt;span-class=&#39;chapter-number&#39;&gt;7&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Large-Sample-Inference&lt;/span&gt;"><span class="chapter-number">7</span>  <span class="chapter-title">Large Sample Inference</span></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-breadcrumbs-&lt;span-class=&#39;chapter-number&#39;&gt;6&lt;/span&gt;--&lt;span-class=&#39;chapter-title&#39;&gt;Small-Sample-Inference&lt;/span&gt;"><span class="chapter-number">6</span>  <span class="chapter-title">Small Sample Inference</span></span></p>
</div>
<div id="quarto-meta-markdown" class="hidden">
<p><span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-metatitle"><span id="sec-ssinf" class="quarto-section-identifier"><span class="chapter-number">6</span>  <span class="chapter-title">Small Sample Inference</span></span> – Basis Module Econometrics (M.Sc.)</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-twittercardtitle"><span id="sec-ssinf" class="quarto-section-identifier"><span class="chapter-number">6</span>  <span class="chapter-title">Small Sample Inference</span></span> – Basis Module Econometrics (M.Sc.)</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-ogcardtitle"><span id="sec-ssinf" class="quarto-section-identifier"><span class="chapter-number">6</span>  <span class="chapter-title">Small Sample Inference</span></span> – Basis Module Econometrics (M.Sc.)</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-metasitename">Basis Module Econometrics (M.Sc.)</span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-twittercarddesc"></span> <span class="hidden quarto-markdown-envelope-contents" data-render-id="quarto-ogcardddesc"></span></p>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Altman_Bland_1995" class="csl-entry" role="listitem">
Altman, Douglas G, and J Martin Bland. 1995. <span>“Statistics Notes: Absence of Evidence Is Not Evidence of Absence.”</span> <em>British Medical Journal</em> 311 (7003): 485.
</div>
<div id="ref-Hayashi2000" class="csl-entry" role="listitem">
Hayashi, Fumio. 2000. <em>Econometrics</em>. Princeton University Press.
</div>
</div>
</section>

</main> <!-- /main -->
<script id = "quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a  href="/05-Multiple-Linear-Regression.html" class="pagination-link" aria-label="Multiple Linear Regression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class='chapter-number'>5</span>  <span class='chapter-title'>Multiple Linear Regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a  href="/07-Asymptotics.html" class="pagination-link" aria-label="Large Sample Inference">
        <span class="nav-page-text"><span class='chapter-number'>7</span>  <span class='chapter-title'>Large Sample Inference</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->

</body>

</html>
