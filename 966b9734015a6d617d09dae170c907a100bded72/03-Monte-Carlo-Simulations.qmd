# Estimation Theory and Monte Carlo Simulations


Learning outcomes of this chapter: 

* You know the basic concepts of estimation theory and you can apply them to specific estimators.
   * Estimate vs estimator
   * Estimator's distribution, bias, variance, and standard error 
* You know how to use a Monte Carlo simulation to check the accuracy (bias, variance, and standard error) of a given (simple) estimator 


## Estimator vs. Estimate 

Let's assume that we have an iid random sample $\{X_1,\dots,X_n\}$ with 
$$
X_i\overset{iid}{\sim} F_X
$$ 
for all $i=1,\dots,n$, and let $\theta\in\mathbb{R}$ denote some parameter (e.g. the mean or the variance) of the distribution $F_X$. 

An **estimator** $\hat\theta_n$ of $\theta$ is a function of the random sample $X_1,\dots,X_n$,
$$
\hat\theta_n:=\hat\theta(X_1,\dots,X_n).
$$

Since $\hat\theta_n$ is a function of the random variables $X_1,\dots,X_n$, the estimator $\hat\theta_n$ is itself a **random variable**. 

The observed data $X_{1,obs},\dots,X_{n,obs}$ is assumed to be a certain realization of the random sample $X_1,\dots,X_n$. The corresponding **realization** of the estimator is called an **estimate** of $\theta$
$$
\hat\theta_{n,obs}=\hat\theta(X_{1,obs},\dots,X_{n,obs}).
$$

**Examples:**

* The sample mean as an estimator of the population mean $E(X_i) =\theta$:
$$
\hat\theta_n=\bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i
$$ 

* The sample variance as an estimator of the population variance $Var(X_i) =\theta$:
$$
\hat\theta_n=s_{UB}^2=\frac{1}{n-1}\sum_{i=1}^n\left(X_i - \bar{X}_n\right)^2
$$ 


::: {.callout-note}
Often we do not use a distinguishing notation, but denote both the estimator and its realization as $\hat\theta_{n}$. This ambiguity is often convenient since both points of views can make sense in a given context. 
:::


## Deriving the Distribution of Estimators

Usually, we do not know the distribution $F_X$ of the random sample $X_1,\dots,X_n$ and thus we neither know the value of $\theta$ nor the distribution of the estimator 
$$
\hat\theta_n=\hat\theta(X_1,\dots,X_n).
$$ 
This is the fundamental statistical problem that we need to overcome in statistical inference (estimating $\theta$, hypothesis testing about $\theta$, etc.).  


There are (roughly) three different possibilities to derive/approximate the distribution of an estimator $\hat\theta_n:$  

* **Option 1: Mathematical derivation using a *complete* distributional assumption on $F_X$.** Assuming a certain distribution $F_X$ for the random sample $X_1,\dots,X_n$ may allow us to derive mathematically the *exact* distribution of $\hat\theta_n$ for given sample sizes $n.$<br>
‚û°Ô∏è We consider this option in @sec-ssinf.
  * Pro: If the distributional assumption is correct, one has *exact* inference for each sample size $n$. 
  * Con: This option can fail miserably if the distributional assumption on $F_X$ is wrong. 
  * Con: This option is often only possible for rather simple distributions $F_X$ like the normal distribution. 



* **Option 2: Mathematical derivation using only an *incomplete* distributional assumption on $F_X$ and asymptotic statistics.** Large sample $(n\to\infty)$ approximations (i.e. laws of large numbers and central limit theorems) often allows us to derive the *approximate* distribution of $\hat\theta_n$ for large sample sizes $n.$<br>
‚û°Ô∏è We consider this option in @sec-lsinf. 
  * Pro: Only a few qualitative distributional assumptions are needed. (Typically: A random sample with finite variances.)  
  * Con: The derived asymptotic ($n\to\infty$) distribution is only exact for the practically impossible case where $n=\infty$ and thus can fail to approximate the exact distribution of $\hat\theta_n$ for given (finite) sample sizes $n$; particularly if $n$ is small. 


* **Option 3: Monte Carlo (MC) Simulations using a *complete* distributional assumption on $F_X$.** Assuming a certain distribution $F_X$ for the random sample $X_1,\dots,X_n$ we can approximate (with arbitrary precision) the *exact* distribution of $\hat\theta_n$ for given sample sizes $n;$ see the Algorithm "MC-Simulation". <br> 
‚û°Ô∏è We use this option to check the behavior of estimators under different scenarios for $F_X$ and $n$ throughout the rest of this script.<br>
  * Pro: Works for a basically every distribution $F_X$ and sample size $n.$  
  * Con: This option can fail miserably if the distributional assumption on $F_X$ is wrong.

**Algorithm "MC-Simulation":**<br>
**1. Step: Generate realizations of $\hat{\theta}_n$.** Use a (pseudo-)random number generator to draw a large number of $B$ (e.g. $B=10,000$) many realizations of the random sample $\{X_1,\dots,X_n\}$ for a given distribution $F_X$ and a given sample size $n:$ 
\begin{align*}
&(X_{1,1,obs},\dots,X_{n,1,obs})\\
&(X_{1,2,obs},\dots,X_{n,2,obs})\\
& \hspace{2cm}\vdots \\
&(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}
Compute for each realization of the random sample a realization of $\hat{\theta}_n:$ 
\begin{align*}
\hat\theta_{n,1,obs} &= \hat\theta(X_{1,1,obs},\dots,X_{n,1,obs})\\
\hat\theta_{n,2,obs} &= \hat\theta(X_{1,2,obs},\dots,X_{n,2,obs})\\
&\vdots\\
\hat\theta_{n,B,obs} &= \hat\theta(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*} 
**2. Step: Approximate the distribution of $\hat{\theta}_n$ (or a features of it).**
Use the realizations $\hat\theta_{n,1,obs},\dots,\hat\theta_{n,B,obs}$ to approximate the exact distribution of $\hat\theta_n$ for a given $F_X$ and a give sample size $n.$<br>




::: {.callout-note}
Step 2 of the above algorithm works, since the empirical distribution function 
$$
\hat{F}_{\hat{\theta}_n,B}(x)=\frac{1}{B}\sum_{j=1}^BI_{(\hat\theta_{n,j} \leq x)}
$$
approximates the true (unknown) distribution function of $\hat{\theta}_n$
$$
F_{\hat{\theta}_n}(x)=P(\hat\theta_{n} \leq x)
$$
arbitrarily well as $B\to\infty.$ 

This hold true, since by the famous [Glivenko‚ÄìCantelli theorem](https://en.wikipedia.org/wiki/Glivenko%E2%80%93Cantelli_theorem)  
$$
\sup_x\left| \hat{F}_{\hat{\theta}_n,B}(x) - F_{\hat{\theta}_n}(x)\right|\to 0\quad\text{as}\quad B\to\infty.
$$
almost surely as $B\to\infty.$


Instead of approximating the whole distribution of $\hat{\theta}_n,$ we may only be interested in approximating specific features of the this distribution, such as: 

* the bias of $\hat{\theta}_n$
* the variance of $\hat{\theta}_n$
* the standard error of $\hat{\theta}_n$
* the mean squared error of $\hat{\theta}_n$
* etc.

**Note:** These features are simple functionals of $\hat{F}_{\hat{\theta}_n,B},$ and thus can also be approximated arbitrarily well as $B\to\infty.$
:::


### Example: Sample Mean $\bar{X}_n$ {#sec-ExampleSampleMean}

Let $\{X_1,\dots,X_n\}$ be an iid random sample  with 
$$
X_i\overset{iid}{\sim} F_X,
$$ 
where 

* $F_X$ is a normal distribution $\mathcal{N}(\mu, \sigma^2)$ with 
  * mean $(\theta=)\mu=10$ and 
  * variance $\sigma^2=5$. 

To estimate the (usually unknown) mean value $\mu=10,$ we use the sample mean estimator
$$
\bar{X}_n =  \frac{1}{n}\sum_{i=1}^n X_i
$$


We consider two sample sizes $n=5$ and $n=50.$

::: {.callout-note}

## Mathematical Derivation using the Distributional Assumptions

Here we have specified the distribution $F_X$ completely by setting $F_X=\mathcal{N}(\mu=10,\sigma^2=5).$ This is such a simple case, that we can actually use mathematical derivations to derive the distribution of $\bar{X}_n.$ (Often, this is not possible.)

Observe that since $X_i\overset{\text{iid}}{\sim}\mathcal{N}(\mu,\sigma^2),$ 
$$
\sum_{i=1}^nX_i\sim\mathcal{N}(n \mu, n \sigma^2).
$$
Multiplying by $\frac{1}{n}$ yields
\begin{align*}
\frac{1}{n}\sum_{i=1}^nX_i = \bar{X}_n 
&\sim\mathcal{N}\left(\frac{1}{n}n \mu, \frac{1}{n^2}n \sigma^2\right)\\[2ex]
\bar{X}_n &\sim\mathcal{N}\left( \mu, \frac{1}{n} \sigma^2\right).
\end{align*}

**Summing up:** If $X_i\overset{iid}{\sim}\mathcal{N}(\mu,\sigma^2),$ 
then the exact (exact for each $n$) distribution of $\bar{X}_n$ is given by 
$$
\bar{X}_n\sim\mathcal{N}\left( \mu, \frac{1}{n} \sigma^2\right).
$$

* For $\mu=10,$ $\sigma=5,$ $n=5$:
$$
\bar{X}_n\sim\mathcal{N}\left(10, 1\right).
$$
* For $\mu=10,$ $\sigma=5,$ $n=50$:
$$
\bar{X}_n\sim\mathcal{N}\left(10, 0.1\right).
$$

‚ö†Ô∏è Unfortunately, such a mathematical derivation works only for very simple estimators and only for simple (and completely specified) distributions $F_X.$

ü§ì But for this special case, we can now check, whether a Monte Carlo simulation is able to approximate the distribution of $\bar{X}_n\sim\mathcal{N}\left( \mu, \frac{1}{n} \sigma^2\right).$
:::



Next, we use a Monte Carlo simulation to approximate the distribution of the estimator 
$$
\bar{X}_n =  \frac{1}{n}\sum_{i=1}^n X_i.
$$


The following `R` code generates $B=10,000$ many realizations of the random sample $X_i\overset{iid}{\sim}\mathcal{N}(\mu,\sigma^2)$ with $\mu=10$ and $\sigma^2=5.$

\begin{align*}
&(X_{1,1,obs},\dots,X_{n,1,obs})\\
&(X_{1,2,obs},\dots,X_{n,2,obs})\\
& \hspace{2cm}\vdots \\
&(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}
leading to $B$ many realizations of the estimator $\bar{X}_n$ 
\begin{align*}
\bar{X}_{n,1,obs} &= \hat\theta(X_{1,1,obs},\dots,X_{n,1,obs})\\
\bar{X}_{n,2,obs} &= \hat\theta(X_{1,2,obs},\dots,X_{n,2,obs})\\
&\vdots\\
\bar{X}_{n,B,obs} &= \hat\theta(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*} 
These realizations are then used to approximate the true distribution of $\bar{X}_n.$

```{r}
## True parameter value 
mu            <- 10
## Number of Monte Carlo repetitions:
B             <- 10000
## Sequence of different sample sizes:
n_seq         <- c(5, 50)


## #############################################
## 1st Coding-Possibility: Using a for() loop ##
## #############################################

## Set seed for the random number generator to get reproducible results
set.seed(3)

# Container for the generated estimates:
estimates_mat <- matrix(NA, nrow = B, ncol = length(n_seq))

for(j in 1:length(n_seq)){
  ## select the sample size
  n <- n_seq[j]
  for(b in 1:B){
    ## generate realization of the random sample 
    X_sample <- rnorm(n = n, mean = mu, sd = sqrt(5))
    ## compute the sample mean and safe it
    estimates_mat[b,j] <- mean(X_sample)
  }
}

## ############################################
## 2nd Coding-Possibility: Using replicate() ##
## ############################################

## Set seed for the random number generator to get reproducible results
set.seed(3)

## Function that generates estimator realizations 
my_estimates_generator <- function(n){
  X_sample <- rnorm(n = n, mean = mu, sd = sqrt(5))
  ## compute the sample mean realization
  return(mean(X_sample))
}

estimates_mat <- cbind(
  replicate(B, my_estimates_generator(n = n_seq[1])),
  replicate(B, my_estimates_generator(n = n_seq[2]))
)
```

Based on the $B=10,000$ realizations of the estimator $\bar{X}_n$, we can compute the empirical density functions $\hat{F}_{X_n,B}$ (see @fig-ecdf) and histograms (see @fig-histdensplots) to get an idea about the true distribution of $\bar{X}_n.$ 

In this simple case, we also know the theoretical distribution function $F_{X_n}$ and density function which allows us to check the simulation results (see @fig-ecdf and @fig-histdensplots). 
```{r, fig.align="center", fig.cap=""}
#| label: fig-ecdf
#| fig-cap: "Empirical distribution functions $\\hat{F}_{X_{n},B}$ computed from the $(B=10000)$ simulated realizations $\\bar{X}_{n,1,obs},\\dots,\\bar{X}_{n,B,obs}$ and the theoretical distribution functions for $n=5,50.$ The empirical and the theoretical distribution functions match perfectly." 
library(scales)
par(mfrow=c(1,2))
plot(ecdf(estimates_mat[,1]), main="n=5", ylab="", xlab="", col = "black", xlim = range(estimates_mat[,1]), ylim=c(0,1.25))
mtext(expression(mu==10), side = 1, at = 10, line = 2.5)
curve(pnorm(x, mean=10, sd=sqrt(5/5)), add=TRUE, col="red", lty = 3, lwd=4)
legend("topleft", legend = c("Empir. Distr.-Function", "True Distr.-Function"), col = c("black", "red"), lty = c(1, 3), lwd = c(1.3, 2), bty = "n")
##      
plot(ecdf(estimates_mat[,2]), main="n=50", ylab="", xlab="", col = "black", xlim = range(estimates_mat[,1]), ylim=c(0,1.25))
mtext(expression(mu==10), side = 1, at = 10, line = 2.5)
curve(pnorm(x, mean=10, sd=sqrt(5/50)), add=TRUE, col="red", lty = 3, lwd=4)
legend("topleft", legend = c("Empir. Distr.-Function", "True Distr.-Function"), col = c("black", "red"), lty = c(1, 3), lwd = c(1.3, 2), bty = "n")
```


```{r, fig.align="center", fig.cap=""}
#| label: fig-histdensplots
#| fig-cap: "Histrograms of $(B=10000)$ simulated realizations $\\bar{X}_{n,1,obs},\\dots,\\bar{X}_{n,B,obs}$ and true density functions for $n=5,50.$ The empirical (simulation based) histrograms and the theoretical density functions match perfectly." 
library(scales)
par(mfrow=c(1,2))
hist(estimates_mat[,1], main="n=5", xlab="",  xlim = range(estimates_mat[,1]), prob = TRUE, ylim = c(0, 1.5))
mtext(expression(mu==10), side = 1, at = 10, line = 2.5)
curve(dnorm(x, mean=10, sd=sqrt(5/5)), add=TRUE, lty = 3, lwd=4, col="red")
legend("topleft", legend = c("Histogram","True Density"), 
      col = c("black", "red"), lty = c(1,3), lwd = c(1.3, 4), bty = "n")
##
hist(estimates_mat[,2], main="n=50", xlab="",  xlim = range(estimates_mat[,1]), prob = TRUE, ylim = c(0, 1.5))
mtext(expression(mu==10), side = 1, at = 10, line = 2.5)
curve(dnorm(x, mean=10, sd=sqrt(5/50)), add=TRUE, lty = 3, lwd=4, col="red")
legend("topleft", legend = c("Histogram","True Density"), 
      col = c("black", "red"), lty = c(1,3), lwd = c(1.3, 4), bty = "n")

```

Observations in @fig-ecdf and @fig-histdensplots: The empirical distribution functions and the histograms based on the simulated realizations 
$$
\bar{X}_{n,1,obs},\dots,\bar{X}_{n,B,obs}
$$ 
mach their theoretical counterparts almost perfectly since we chose a sufficient large number of $B=10000$ simulations. 

::: {.callout-tip}

## Take away message

We can use Monte Carlo simulations to approximate the *exact* distribution of an estimator $\hat{\theta}_n$ for given distributions $F_X$ of the underlying random sample. These approximations become arbitrarily precise as $B\to\infty$. 
:::

<!-- * At least on average, the estimates $\bar{X}_n$ are close to the target parameter $\mu=10$ for each sample size $n\in\{5,15,50\}$. This feature of the estimator's distribution is summarized by the **bias** (see next section) of an estimator.

* As the sample size increases, the distributions of the estimators $\bar{X}_n$ concentrate around the target parameter $\mu=10$. This feature of the estimator's distribution is summarized by the **mean squared error** (see next section) of an estimator.

Thus here the quality of the estimator $\bar{X}_n$ gets better as $n$ gets large. To describe the quality of estimators more compactly, statisticians/econometricians use specific metrics like bias, variance and the mean squared error of the distribution of a estimator $\hat\theta$. -->

## Assessing the Quality of Estimators 

<!-- But how good is a given estimator $\hat\theta_n$ for a given sample size?  -->

Any reasonable estimator $\hat\theta_n$ should be able to approximate the (usually unknown) parameter value $\theta$,
$$
\left(\text{random quantity}\right)\quad\hat\theta_n\approx\theta\quad\left(\text{deterministic parameter}\right),
$$
and the approximation should get better as the sample size increases, i.e. as $n\to\infty$. 


The simulation results shown in @fig-ecdf and @fig-histdensplots show this desired behavior for the case of $\hat{\theta}_n=\bar{X}_n.$ 

To check (via MC-Simulations) the quality of an estimator, one can look at the total distribution or density function of $\hat{\theta}_n$; as done in @fig-ecdf and @fig-histdensplots. However, it is often more convenient to consider only the most relevant features of the distribution of an estimator. 


Statisticians/econometricians use different metrics to assess the quality of an estimator $\hat\theta_n$. The most prominent metrics are:

* bias of an estimator $\hat{\theta}_n$
* variance and standard error of an estimator $\hat{\theta}_n$
* mean squared error (mse) of an estimator $\hat{\theta}_n$


::: {.callout-note icon=false}
##
::: {#def-bias}
## Bias of $\theta$

The **bias** of an estimator $\hat\theta_n$ is defined as

$$
\operatorname{Bias}\left(\hat\theta_n\right) = E\left(\hat\theta_n\right) - \theta.
$$
:::
:::

If an estimator $\hat\theta_n$ has no bias 
$$
\operatorname{Bias}\left(\hat\theta_n\right)=0
$$ 
for all $\theta$ and all sample sizes $n,$ we call it an **unbiased estimator**. 

Many modern estimators are *not* unbiased. However, every estimator should be at least **asymptotically unbiased**, i.e.
$$
\lim_{n\to\infty}\operatorname{Bias}\left(\hat\theta_n\right)=0
$$ 
for all $\theta.$


We would like to have estimators with a small (or zero) bias. 

If the bias of an estimator is small (or zero), we know that the distribution of the estimator is roughly (or exactly) centered around the true (usually unknown) parameter $\theta.$ 


However, also unbiased estimators $\hat{\theta}_n$ may still vary a lot around the parameter $\theta$ to be estimated. Therefore, is is also important to assess the variance of the estimator. 


::: {.callout-note icon=false}
##
::: {#def-var}

## Variance and Standard Error of $\theta$

The **variance** of an estimator $\hat\theta_n$ is defined equivalently to the variance of any other random variable

$$
Var\left(\hat\theta_n\right) = E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right].
$$
The square root of the variance of an estimator is called **standard error** (not standard deviation) of $\hat\theta_n$, 
$$
\operatorname{SE}\left(\hat\theta_n\right) = \sqrt{Var\left(\hat\theta_n\right)}.
$$
:::
:::

We would like to have estimators with a small as possible variance, and the variance should decline as the sample size increases, such that $\lim_{n\to\infty}Var\left(\hat\theta_n\right)=0$.


::: {.callout-note icon=false}
##
::: {#def-mse}

## Mean Squared Error of $\theta$

The **mean squared error** of an estimator $\hat\theta_n$ is defined as

$$
\operatorname{MSE}\left(\hat\theta_n\right) =  E\left[\left(\hat\theta_n - \theta\right)^2\right].
$$
:::
:::

We would like to have estimators with a small as possible mean squared error, and the mean squared error should decline as the sample size increases, such that $\lim_{n\to\infty}\operatorname{MSE}\left(\hat\theta_n\right)=0$.

The following holds true:

* The mean squared error equals the sum of the squared bias and the variance: 

$$
\operatorname{MSE}\left(\hat\theta_n\right) = \left(\operatorname{Bias}\left(\hat\theta_n\right)\right)^2 +  Var\left(\hat\theta_n\right) 
$$

* For unbiased estimators (i.e. $E(\hat\theta_n)=\theta$) the mean squared error equals the variance, i.e.

$$
\underbrace{E\left[\left(\hat\theta_n - \theta\right)^2\right]}_{\operatorname{MSE}\left(\hat\theta_n\right)} = \underbrace{E\left[\left(\hat\theta_n - E\left(\hat\theta_n\right)\right)^2\right]}_{ Var\left(\hat\theta_n\right)} 
$$


Unfortunately, it is often difficult to derive the above assessment metrics for given sample sizes $n$ and given data distributions $F_X$. Monte Carlo simulations allow us to solve this issue.

### Approximating Bias, Variance, and MSE using MC Simulations 

We can use Monte Carlo simulations to approximate the assessment metrics $\operatorname{Bias}\left(\hat\theta_n\right),$ $Var\left(\hat\theta_n\right),$ and  $\operatorname{MSE}\left(\hat\theta_n\right)$ for given sample sizes $n$ and given data distributions $F_X$ with arbitrary precision. 


Any of the the above assessment metrics require us to compute means of random variables: 

* For the $\operatorname{Bias}\left(\hat\theta_n\right)$ we need to compute $E\left(\hat\theta_n\right)-\theta$

* For the $Var\left(\hat\theta_n\right)$ we need to compute $E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right]$.

* For the $\operatorname{MSE}\left(\hat\theta_n\right)$ we need to compute $E\left[\left(\hat\theta_n - \theta\right)^2\right]$.


A Monte Carlo simulation can approximate these means by using the **law of large numbers** which states that a sample mean over iid random variables is able to approximate the population mean of these random variables as the number of random variables to average over get large.[^1]

[^1]: See @thm-SLLN1 in @sec-lsinf.


Thus, to compute a very precise approximation to $E\left(\hat\theta_n\right)-\theta$, we can use a computer to execute the following algorithm:

**Step 1.** Generate $B$ many (e.g. $B=10,000$) realizations of the iid random sample $(X_1,\dots,X_n)$
\begin{align*}
&(X_{1,1,obs},\dots,X_{n,1,obs})\\
&(X_{1,2,obs},\dots,X_{n,2,obs})\\
& \hspace{2cm}\vdots \\
&(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*}
leading to $B$ many realizations of the estimator $\hat{\theta}_n$ 
\begin{align*}
\hat{\theta}_{n,1,obs} &= \hat\theta(X_{1,1,obs},\dots,X_{n,1,obs})\\
\hat{\theta}_{n,2,obs} &= \hat\theta(X_{1,2,obs},\dots,X_{n,2,obs})\\
&\;\vdots\\
\hat{\theta}_{n,B,obs} &= \hat\theta(X_{1,B,obs},\dots,X_{n,B,obs})
\end{align*} 

**Step 2.** Use the simulated realizations $\hat{\theta}_{n,1,obs},\dots,\hat{\theta}_{n,B,obs}$ to approximate the bias, variance, and the mean squared error of the estimator $\hat{\theta}_n$:

* The bias of $\operatorname{Bias}\left(\hat\theta_n\right)=E\left(\hat\theta_n\right)-\theta$ can be approximated by 

$$
\widehat{\operatorname{Bias}}_{MC}\left(\hat\theta_n\right) = \left(\frac{1}{B}\sum_{b=1}^B \hat\theta_{n,b,obs}\right) - \theta 
$$

* The variance $Var\left(\hat\theta_n\right)=E\left[\left(\hat\theta_n - E(\hat\theta_n)\right)^2\right]$ can be approximated by
$$
\widehat{Var}_{MC}\left(\hat\theta_n\right) = \frac{1}{B}\sum_{b=1}^B \left(\hat\theta_{n,b,obs} - \left(\frac{1}{B}\sum_{b=1}^B \hat\theta_{n,b,obs}\right)\right)^2 
$$

* The mean squared error $\operatorname{MSE}\left(\hat\theta_n\right)=E\left[\left(\hat\theta_n - \theta\right)^2\right]$ can be approximated by 
$$
\widehat{\operatorname{MSE}}_{MC}\left(\hat\theta_n\right) = \frac{1}{B}\sum_{b=1}^B \left(\hat\theta_{n,b,obs} - \theta\right)^2 
$$

::: {.callout-note}

By the law of large numbers these approximations get arbitrarily precise as $B \to \infty,$ i.e.
\begin{align*}
\widehat{\operatorname{Bias}}_{MC}\left(\hat\theta_n\right)&\to
\operatorname{Bias}\left(\hat\theta_n\right)\quad\text{as}\quad B\to\infty\\[2ex]
\widehat{Var}_{MC}\left(\hat\theta_n\right)&\to
Var\left(\hat\theta_n\right)\quad\text{as}\quad B\to\infty\\[2ex]
\widehat{\operatorname{MSE}}_{MC}\left(\hat\theta_n\right)&\to
\operatorname{MSE}\left(\hat\theta_n\right)\quad\text{as}\quad B\to\infty
\end{align*} 

So for large $B$ (e.g. $B=10,000$) we can consider 
$$
\widehat{\operatorname{Bias}}_{MC}(\hat\theta_n), 
\widehat{Var}_{MC}(\hat\theta_n),\text{ and }\;\;  
\widehat{\operatorname{MSE}}_{MC}(\hat\theta_n)
$$ 
as roughly equal to 
$$
\operatorname{Bias}(\hat\theta_n), 
Var(\hat\theta_n),\text{ and } 
\operatorname{MSE}(\hat\theta_n).
$$
:::

### Example (revisited): Sample Mean {-}

The following `R` code contains a Monte Carlo simulation with $B = 10000$ replications to approximate the bias, the variance, and the mean squared error for the sample mean 
$$
(\hat\theta_n=)\bar{X}_n=\sum_{i=1}^nX_i
$$ 
Setup: 

* $X_i\overset{iid}{\sim}F_X$, $i=1,\dots,n$, with $F_X=\mathcal{N}(\mu,\sigma^2)$ 
* Mean $\mu=10$ and variance $\sigma^2=5$ 
* Sample sizes $n\in\{5,15,50\}$ 
<!-- The following `R` codes generated `B = 10000` realizations of the estimator $\bar{X}_n$ for each sample size $n\in\{5,15,50\}$ and stores all these realizations in a $10000\times 3$ matrix `estimates_mat`: -->
```{r}
## Set seed for the random number generator to get reproducible results
set.seed(3)
## True parameter value ('theta' here 'mu')
mu            <- 10
## Number of Monte Carlo repetitions:
B             <- 10000
## Sequence of different sample sizes:
n_seq         <- c(5, 15, 50)

## Function that generates estimator realizations 
my_estimates_generator <- function(n){
  X_sample <- rnorm(n = n, mean = mu, sd = sqrt(5))
  ## compute the sample mean realization
  return(mean(X_sample))
}

estimates_mat <- cbind(
  replicate(B, my_estimates_generator(n = n_seq[1])),
  replicate(B, my_estimates_generator(n = n_seq[2])),
  replicate(B, my_estimates_generator(n = n_seq[3]))
)

## Bias of the sample mean for different sample sizes n
MC_Bias_n_seq <- apply(estimates_mat, 2, mean) - mu

## Variance of the sample mean for different sample sizes n
MC_Var_n_seq  <- apply(estimates_mat, 2, var)

## Mean squared error of the sample mean for different sample sizes n
MC_MSE_n_seq  <- apply(estimates_mat, 2, function(x){mean((x - mu)^2)})
```



@tbl-mcbvmse shows the Monte Carlo approximations for the bias, the variance, and the mean squared error of $\bar{X}_n.$

```{r, echo=FALSE}
#| label: tbl-mcbvmse
#| tbl-cap: Monte Carlo approximations for the true bias, true variance, and true mean squared error of sample mean.
suppressPackageStartupMessages(library("kableExtra"))
suppressPackageStartupMessages(library("tidyverse"))

MCResults <- tibble(
  "n"                  = n_seq,
  "Bias (MC-Sim) "     = round(MC_Bias_n_seq, 3),
  "Variance (MC-Sim)"  = round(MC_Var_n_seq,  2),
  "MSE (MC-Sim) "      = round(MC_MSE_n_seq,  2))
           
MCResults %>% kbl() %>%  kable_styling()
```


These Monte Carlo approximations (@tbl-mcbvmse) indicate that:  

- The true bias $\operatorname{Bias}(\bar{X}_n)$ is very likely zero for all sample sizes $n\in\{5,15,50\}$

<!-- , and thus $Var(\bar{X}_n)\approx \operatorname{MSE}(\bar{X}_n)$ for all sample sizes $n\in\{5,15,50\}$. -->

- The true mean squared error $\operatorname{MSE}(\bar{X}_n)$ is very likely decreasing as the sample size $n$ get larger. 


<!-- The sample mean $\bar{X}_n$ is known to be a very good estimator of the population mean $\mu$ and the above simulation results conform this.  -->


### Comparing the MC-Results with the theoretical bias, variance, and mse of the sample mean {-}

Since this example is so simple, we actually know the true bias, the true variance, and the true mean squared error of $\bar{X}_n.$ In @sec-ExampleSampleMean, we have already derived the exact theoretical distribution of $\bar{X}_n$ under the assumed random sample with sampling distribution $F_X=\mathcal{N}(\mu,\sigma^2):$
$$
\bar{X}_n\sim\mathcal{N}\left(\mu,\frac{1}{n}\sigma^2\right).
$$ 

Using this, we can simply compute the *true* bias, variance and mean squared error of $\bar{X}_n$ for $n\in\{5,15,50\}$ and compare them with their Monte Carlo approximations: 

* True bias of $\bar{X}_n$:
\begin{align*}
\operatorname{Bias}\left(\bar{X}_n\right)
&=E\left(\bar{X}_n\right) - \mu \\[2ex]
&=E\left(\frac{1}{n}\sum_{i=1}^n X_i\right) - \mu \\[2ex]
&= \left(\frac{1}{n}\sum_{i=1}^nE(X_i)\right) -\mu\\[2ex] 
&= \frac{n}{n}\mu-\mu \\[2ex]
&=0,
\end{align*}
thus $\bar{X}_n$ is unbiased for all $\mu.$

* True variance of $\bar{X}_n$:
\begin{align*}
Var\left(\bar{X}_n\right)
&=Var\left(\frac{1}{n}\sum_{i=1}^n X_i\right)\\[2ex] 
&= \frac{1}{n^2} \sum_{i=1}^nVar\left(X_i\right)\\[2ex]
&= \frac{n}{n^2}\sigma^2 \\[2ex]
&= \frac{1}{n}\sigma^2 
\end{align*}

* True MSE of $\bar{X}_n$:
\begin{align*}
\operatorname{MSE}\left(\bar{X}_n\right)
&=\left(\operatorname{Bias}\left(\bar{X}_n\right)\right)^2 +
Var\left(\frac{1}{n}\sum_{i=1}^nX_i\right)\\[2ex]
&= 0+\frac{1}{n}\sigma^2 
\end{align*}

The following table shows the true bias, true variance and true mean squared error values for $\sigma^2=5$ and $n\in\{5,15,50\}$:

```{r, echo=FALSE}
#| label: tbl-truebvmse
#| tbl-cap: True bias, true variance, and true mean squared error of sample mean. (Only computable in simple special cases.)
suppressPackageStartupMessages(library("kableExtra"))
suppressPackageStartupMessages(library("tidyverse"))

MCResults <- tibble(
  "n"        = n_seq,
  "Bias (true) "     = rep(0, 3),
  "Variance (true)"  = round(5/n_seq, 2),
  "MSE (true) "      = round(5/n_seq, 2))
           
MCResults %>% kbl() %>%  kable_styling()
```

Obviously, the Monte Carlo approximations (@tbl-mcbvmse) for these true values (@tbl-truebvmse) are very good. 

If we would further increase the number of Monte Carlo repetitions $B,$ the Monte Carlo approximations in @tbl-mcbvmse would get even more precise since we can make them arbitrarily precise by letting $B\to\infty$ using the law of large numbers. 


::: {.callout-tip}

## Take away message (continued)

We can use Monte Carlo simulations to approximate the *exact* distribution and its features (e.g. bias, variance, mse) of an estimator $\hat{\theta}_n$ for given distributions $F_X$ of the underlying random sample. These approximations become arbitrarily precise as $B\to\infty$. 

Therefore, Monte Carlo simulations can be used to check the theoretical properties of estimation procedures under specific data generating processes and sample sizes. 

<!-- MC simulations are an important tool, since modern estimation procedures are usually only justified based on asymptotic statistics $(n\to\infty)$ and sometimes only under relative restrictive assumptions. 

In such cases, MC simulations can be used to investigate the behavior of the estimation procedure in practical, finite sample sizes $n$ and under different data generating processes. 

MC simulations can also help to get an idea about how restrictive theoretical assumptions are in practice and how sensitive the an estimation procedure is with respect to violations of the theoretical assumptions.   -->
:::


## Exercises

* [Exercises for Chapter 3](https://www.dropbox.com/scl/fi/xuqqzulvje2f07kq8da1f/Ch3_Exercises1.pdf?rlkey=i7b0c5x259eyd483na0esrtel&dl=0)

* [Exercises for Chapter 3 with Solutions](https://www.dropbox.com/scl/fi/lpek08w3v713b3fkfcqce/Ch3_Exercises_with_Solutions1.pdf?rlkey=covd2axn4sd56kassw6jhx6po&dl=0)






<!-- ```{r, fig.align="center"} -->
<!-- par(mfrow=c(1,3)) -->
<!-- plot(x = n_seq, y = Bias_n_seq, type = "b", ylim = c(-0.2, 0.2),  -->
<!--      main="Bias", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- plot(x = n_seq, y = Var_n_seq, type = "b", ylim = c(0, 1.5), -->
<!--      main="Variance", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- plot(x = n_seq, y = MSE_n_seq, type = "b", ylim = c(0, 1.5), -->
<!--      main="MSE", xlab = "n", ylab = "") -->
<!-- abline(h = 0) -->
<!-- ``` -->




<!-- like, for instance, the arithmetic mean   -->
<!-- $$ -->
<!-- \bar{X}_n=\frac{1}{n}\sum_{i=1}^nX_i -->
<!-- $$ -->
<!-- as an estimator of the population mean value $\mu$.  -->

